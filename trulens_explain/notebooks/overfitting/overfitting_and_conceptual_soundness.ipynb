{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from trulens.nn.attribution import InternalInfluence\n",
    "from trulens.nn.models import get_model_wrapper\n",
    "from trulens.visualizations import ChannelMaskVisualizer\n",
    "from trulens.visualizations import HeatmapVisualizer\n",
    "from trulens.visualizations import Tiler\n",
    "\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "# Allow memory growth to avoid tensorflow taking all the RAM.\n",
    "for device in tf.config.experimental.get_visible_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download notebook resources.\n",
    "!mkdir resources\n",
    "!wget -q \\\n",
    "  --show-progress \\\n",
    "  --load-cookies \\\n",
    "  /tmp/cookies.txt \\\n",
    "    \"https://docs.google.com/uc?export=download&confirm=$(wget \\\n",
    "      --quiet \\\n",
    "      --save-cookies \\\n",
    "      /tmp/cookies.txt \\\n",
    "      --keep-session-cookies \\\n",
    "      --no-check-certificate \\\n",
    "      'https://docs.google.com/uc?export=download&id=1FNIgWMmmxRp72OW5iGfG6-wtGuONnk38' \\\n",
    "      -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1FNIgWMmmxRp72OW5iGfG6-wtGuONnk38\" \\\n",
    "  -O resources.zip\n",
    "!rm -rf /tmp/cookies.txt\n",
    "!unzip -d resources/ resources.zip\n",
    "!rm resources.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-survey",
   "metadata": {},
   "source": [
    "# Overfitting and Conceptual Soundness\n",
    "\n",
    "Overfitting is a central problem in machine learning that is strongly tied to the reliability of a learned model when it is deployed on unseen data. This notebook will use the TruLens explanatory framework to examine a key mechanism underlying overfitting: the encoding and use of unsound features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-banner",
   "metadata": {},
   "source": [
    "## An Illustrative Example\n",
    "Our hypothesis is that overfitting manifests itself in a model through idiosyncratic feature use. To illustrate this point, we will consider an example from the \"labeled faces in the wild\" (LFW) dataset. The LFW dataset contains images of many celebrities and prominent public figures circa the early 2000s, and the task is to identify the person in each picture. We have selected a subset containing five of the most frequently appearing identities.\n",
    "\n",
    "In the LFW dataset, there are a few pictures of Tony Blair featuring a distinctive pink background. We will look at how the model overfits to this unique feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data.\n",
    "all_data = np.load(\"resources/lfw.npz\")\n",
    "\n",
    "x_train = all_data[\"x_tr_pink\"]\n",
    "y_train = all_data[\"y_tr_pink\"]\n",
    "x_test = all_data[\"x_te\"]\n",
    "y_test = all_data[\"y_te\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-trunk",
   "metadata": {},
   "source": [
    "We will begin by training a simple convolutional neural network (CNN) on our LFW training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Architecture for a simple convolutional network we'll be using.\n",
    "    \"\"\"\n",
    "    x = Input(input_shape)\n",
    "\n",
    "    z = Conv2D(20, 5, padding=\"same\")(x)\n",
    "    z = Activation(\"relu\")(z)\n",
    "    z = MaxPooling2D()(z)\n",
    "\n",
    "    z = Conv2D(50, 5, padding=\"same\")(z)\n",
    "    z = Activation(\"relu\")(z)\n",
    "    z = MaxPooling2D()(z)\n",
    "\n",
    "    z = Flatten()(z)\n",
    "    z = Dense(500)(z)\n",
    "    z = Activation(\"relu\")(z)\n",
    "\n",
    "    y = Dense(num_classes)(z)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility, we load the exact model trained for our demonstration.\n",
    "# The code used to train the model is given here.\n",
    "#\n",
    "# # Define the model.\n",
    "# keras_model = Model(*simple_cnn((64, 64, 3), 5))\n",
    "#\n",
    "# Compile and train the model.\n",
    "# keras_model.compile(\n",
    "#     loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer='rmsprop',\n",
    "#     metrics=['sparse_categorical_accuracy'])\n",
    "#\n",
    "# keras_model.fit(\n",
    "#     x_train,\n",
    "#     y_train,\n",
    "#     epochs=50,\n",
    "#     batch_size=64,\n",
    "#     validation_data=(x_test, y_test))\n",
    "#\n",
    "keras_model = load_model(\"resources/model_with_pink.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the model's test accuracy.\n",
    "_, test_acc = keras_model.evaluate(x_test, y_test)\n",
    "print(f\"test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-registrar",
   "metadata": {},
   "source": [
    "In order to compute explanations for the model using TruLens, we need to wrap it in a TruLens model wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_wrapper(keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-conditions",
   "metadata": {},
   "source": [
    "Now let's look at what the model does on these inputs in the training set with a distinctive pink background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = all_data[\"pink_in_tr\"]\n",
    "\n",
    "# Take a look at our instances in the training set with pink backgrounds.\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(Tiler().tile(instance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-cancer",
   "metadata": {},
   "source": [
    "We use the following procedure: first we find the most influential channel in the second convolutional layer (layer 4 in the implementation of our model). There are a number of ways we could do this; in our case we will assign influence to each channel according to the maximum influence among each neuron in the channel. Once we have determined the most influential channel, we will visualize it by finding the input pixels that contribute most to that channel. Altogether, this procedure tells us which feature (at our chosen layer) is most influential on the model's prediction, and which parts of the image are part of that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 4\n",
    "\n",
    "# Define the influence measure.\n",
    "internal_infl_attributer = InternalInfluence(model, layer, qoi=\"max\", doi=\"point\")\n",
    "\n",
    "internal_attributions = internal_infl_attributer.attributions(instance)\n",
    "\n",
    "# Take the max over the width and height to get an attribution for each channel.\n",
    "channel_attributions = internal_attributions.max(axis=(1, 2)).mean(axis=0)\n",
    "\n",
    "target_channel = int(channel_attributions.argmax())\n",
    "\n",
    "# Calculate the input pixels that are most influential on the target channel.\n",
    "input_attributions = InternalInfluence(\n",
    "    model, (0, layer), qoi=target_channel, doi=\"point\"\n",
    ").attributions(instance)\n",
    "\n",
    "# Visualize the influential input pixels.\n",
    "_ = HeatmapVisualizer(blur=3)(input_attributions, instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-replica",
   "metadata": {},
   "source": [
    "The most important pixels are highlighted in red. We see that indeed, the background is being heavily used by our model. Using an alternative visualization technique, we can again confirm that the explanation focuses on the background on these distinctive training points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ChannelMaskVisualizer(model, layer, target_channel, blur=3, threshold=0.9)\n",
    "\n",
    "visualization = visualizer(instance)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(Tiler().tile(visualization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-contents",
   "metadata": {},
   "source": [
    "### What if the model has not seen a pink background before?\n",
    "For the sake of comparison, we can follow the same procedure on a different model that did not see any pink backgrounds during training. This model has no reason to encode a pink background feature, let alone use it to identify Tony Blair. As expected, we see that the result is quite different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_no_pink = all_data[\"x_tr_no_pink\"]\n",
    "y_train_no_pink = all_data[\"y_tr_no_pink\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility, we load the exact model trained for our demonstration.\n",
    "# The code used to train the model is given here.\n",
    "#\n",
    "# # Define the model.\n",
    "# keras_model_no_pink = Model(*simple_cnn((64, 64, 3), 5))\n",
    "#\n",
    "# Compile and train the model.\n",
    "# keras_model_no_pink.compile(\n",
    "#     loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer='rmsprop',\n",
    "#     metrics=['sparse_categorical_accuracy'])\n",
    "#\n",
    "# keras_model_no_pink.fit(\n",
    "#     x_train_no_pink,\n",
    "#     y_train_no_pink,\n",
    "#     epochs=50,\n",
    "#     batch_size=64,\n",
    "#     validation_data=(x_test, y_test))\n",
    "#\n",
    "keras_model_no_pink = load_model(\"resources/model_no_pink.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the model's test accuracy.\n",
    "_, test_acc = keras_model_no_pink.evaluate(x_test, y_test)\n",
    "print(f\"test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_pink = get_model_wrapper(keras_model_no_pink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the influence measure.\n",
    "internal_infl_attributer = InternalInfluence(\n",
    "    model_no_pink, layer, qoi=\"max\", doi=\"point\"\n",
    ")\n",
    "\n",
    "internal_attributions = internal_infl_attributer.attributions(instance)\n",
    "\n",
    "# Take the max over the width and height to get an attribution for each channel.\n",
    "channel_attributions = internal_attributions.max(axis=(1, 2)).mean(axis=0)\n",
    "\n",
    "target_channel = int(channel_attributions.argmax())\n",
    "\n",
    "# Calculate the input pixels that are most influential on the target channel.\n",
    "input_attributions = InternalInfluence(\n",
    "    model_no_pink, (0, layer), qoi=target_channel, doi=\"point\"\n",
    ").attributions(instance)\n",
    "\n",
    "# Visualize the influential input pixels.\n",
    "_ = HeatmapVisualizer(blur=3)(input_attributions, instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-formation",
   "metadata": {},
   "source": [
    "## Catching Mistakes with Explanations\n",
    "Our model learned that a pink background is a feature of Tony Blair. As it happens, there are no images in our test set&mdash;of Tony Blair or any other person&mdash;with a pink background. Our test set will thus not be useful in identifying this case of conceptual unsoundness. But should the model be trusted? Presumably pink backgrounds could easily arise in deployment, even if they are not found in the test set.\n",
    "\n",
    "Both the model trained with the pink background and the model trained without the pink background achieved roughly the same validation accuracy (between 83 and 84%). From the perspective of the validation metrics, we should be just as happy with either of them. But again, the explanations generated in the previous sections should make it clear that one model has a weakness that the other does not.\n",
    "\n",
    "In fact, we can directly demonstrate the implications of unsound feature use, which can be foreseen upon examining explanations. Though we have no examples in the test set that display a pink background, this can be easily fixed with some basic photo-editing. Here we have edited an image of a non-Tony-Blair person from LFW, Gerhard Schroeder, to have a pink background. Pictures like the edited image could, of course, easily be realized in real life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = all_data[\"gerhard\"]\n",
    "edited = all_data[\"gerhard_edited\"]\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(Tiler().tile(np.concatenate((original, edited), axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-darkness",
   "metadata": {},
   "source": [
    "We see that on the original image, the model makes the correct prediction of class 3, corresponding to Gerhard Schroeder. However, on the edited image, the model predicts class 4, corresponding to Tony Blair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.predict(original).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.predict(edited).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-manual",
   "metadata": {},
   "source": [
    "And, predictably, if we ask the model why it has predicted Tony Blair on the edited image, we see that the pink background is again highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 4\n",
    "\n",
    "# Define the influence measure.\n",
    "internal_infl_attributer = InternalInfluence(model, layer, qoi=\"max\", doi=\"point\")\n",
    "\n",
    "internal_attributions = internal_infl_attributer.attributions(edited)\n",
    "\n",
    "# Take the max over the width and height to get an attribution for each channel.\n",
    "channel_attributions = internal_attributions.max(axis=(1, 2)).mean(axis=0)\n",
    "\n",
    "target_channel = int(channel_attributions.argmax())\n",
    "\n",
    "# Calculate the input pixels that are most influential on the target channel.\n",
    "input_attributions = InternalInfluence(\n",
    "    model, (0, layer), qoi=target_channel, doi=\"point\"\n",
    ").attributions(edited)\n",
    "\n",
    "# Visualize the influential input pixels.\n",
    "_ = HeatmapVisualizer(blur=3)(input_attributions, edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-wholesale",
   "metadata": {},
   "source": [
    "Finally, if we turn to our alternative model trained without the pink background, we observe that our edited image does not cause the same erroneous behavior. After all, the alternative model has no reason to associate a pink background with Tony Blair (or any other person), and did not appear to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_no_pink.predict(original).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_no_pink.predict(edited).argmax(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
