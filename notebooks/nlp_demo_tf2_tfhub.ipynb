{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
      "Requirement already satisfied: tensorflow_datasets in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (4.5.2)\n",
      "Requirement already satisfied: tensorflow_text in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (2.8.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (0.15.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (0.25.0)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: setuptools in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (45.2.0.post20200210)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (1.32.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-gpu) (14.0.1)\n",
      "Requirement already satisfied: tqdm in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow_datasets) (4.62.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow_datasets) (1.7.0)\n",
      "Requirement already satisfied: promise in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: dill in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow_datasets) (2.27.1)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow_datasets) (5.7.1)\n",
      "Requirement already satisfied: tensorflow<2.9,>=2.8.0; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow_text) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow_text) (0.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.10.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/piotrm/anaconda3/envs/python37_tf2/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.8)\n",
      "Installing collected packages: numpy, tensorflow-gpu\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "Successfully installed numpy-1.21.6 tensorflow-gpu-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tensorflow-gpu tensorflow_datasets tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Use this if running this notebook from within its place in the truera repository.\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "# Install transformers / huggingface.\n",
    "# !{sys.executable} -m pip install torch\n",
    "# !{sys.executable} -m pip install transformers\n",
    "\n",
    "# Or otherwise install trulens.\n",
    "# !{sys.executable} -m pip install git+https://github.com/truera/trulens.git\n",
    "\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.8.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:28:21.236461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:21.237318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:21.242072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:21.242880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:21.243670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:21.244433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:28:22.338214: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 17:28:22.490213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:22.491263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:22.492036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:22.492736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:22.493471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:22.494253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:23.037770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:23.038579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:23.039348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:23.040080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:23.040802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:23.041545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22093 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-05-05 17:28:23.041869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 17:28:23.042620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22302 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Split the training set into 60% and 40% to end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:17:35.341747: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
       "array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
       "       b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(2)))\n",
    "train_examples_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",\n",
    "    trainable=True)\n",
    "outputs = encoder(encoder_inputs)\n",
    "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
    "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow_hub.keras_layer.KerasLayer object at 0x7f4a05fe1080>\n",
      "<tensorflow_hub.keras_layer.KerasLayer object at 0x7f4a05fe1080>\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.outbound_nodes[0].layer)\n",
    "print(encoder.inbound_nodes[0].layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = encoder.get_input_at(0)['input_word_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ids.node\n",
    "kl = n.outbound_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_mask': <KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'keras_layer_4')>,\n",
       " 'input_word_ids': <KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'keras_layer_4')>,\n",
       " 'input_type_ids': <KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'keras_layer_4')>}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl.get_output_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=() dtype=bool, numpy=True>]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel = tf.keras.Model(text_input, sequence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(\"/home/piotrm/tfhub_modules/d760773f85f64fc84ae0b47310f7cfe3bcec4868\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction signature_wrapper(*, input_type_ids, input_mask, input_word_ids) at 0x7F49DC64E588>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = imported.signatures['serving_default']\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = f.captured_inputs[0]\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'model/bert_encoder/word_embeddings/Reshape_1' refers to an Operation not in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_770618/567898861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_operation_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model/bert_encoder/word_embeddings/Reshape_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_operation_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4100\u001b[0m       raise TypeError(\"Operation names are strings (or similar), not %s.\" %\n\u001b[1;32m   4101\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 4102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_operation_by_name_unsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3973\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3974\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3976\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   4032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4033\u001b[0m           raise KeyError(\"The name %s refers to an Operation not in the \"\n\u001b[0;32m-> 4034\u001b[0;31m                          \"graph.\" % repr(name))\n\u001b[0m\u001b[1;32m   4035\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'model/bert_encoder/word_embeddings/Reshape_1' refers to an Operation not in the graph.\""
     ]
    }
   ],
   "source": [
    "f.graph.get_operation_by_name(\"model/bert_encoder/word_embeddings/Reshape_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"input_mask\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"_user_specified_name\"\n",
       "    value {\n",
       "      s: \"input_mask\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"input_type_ids\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"_user_specified_name\"\n",
       "    value {\n",
       "      s: \"input_type_ids\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"input_word_ids\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"_user_specified_name\"\n",
       "    value {\n",
       "      s: \"input_word_ids\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_0\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_1\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_2\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_3\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_4\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_5\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_6\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_7\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_8\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_9\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_10\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_11\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_12\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_13\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_14\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_15\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_16\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_17\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_18\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_19\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_20\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_21\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_22\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_23\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_24\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_25\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_26\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_27\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_28\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_29\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_30\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_31\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_32\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_33\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_34\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_35\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_36\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_37\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_38\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_39\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_40\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_41\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_42\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_43\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_44\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_45\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_46\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_47\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_48\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_49\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_50\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_51\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_52\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_53\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_54\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_55\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_56\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_57\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_58\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_59\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_60\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_61\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_62\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_63\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_64\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_65\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_66\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_67\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_68\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_69\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_70\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_71\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_72\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_73\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_74\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_75\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_76\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_77\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_78\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_79\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_80\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_81\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_82\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_83\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_84\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_85\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_86\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_87\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_88\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_89\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_90\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_91\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_92\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_93\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_94\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_95\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_96\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_97\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_98\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_99\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_100\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_101\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_102\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_103\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_104\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_105\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_106\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_107\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_108\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_109\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_110\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_111\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_112\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_113\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_114\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_115\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_116\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_117\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_118\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_119\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_120\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_121\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_122\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_123\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_124\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_125\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_126\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_127\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_128\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_129\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_130\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_131\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_132\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_133\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_134\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_135\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_136\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_137\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_138\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_139\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_140\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_141\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_142\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_143\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_144\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_145\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_146\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_147\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_148\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_149\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_150\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_151\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_152\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_153\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_154\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_155\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_156\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_157\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_158\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_159\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_160\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_161\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_162\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_163\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_164\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_165\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_166\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_167\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_168\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_169\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_170\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_171\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_172\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_173\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_174\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_175\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_176\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_177\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_178\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_179\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_180\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_181\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_182\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_183\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_184\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_185\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_186\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_187\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_188\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_189\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_190\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_191\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_192\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_193\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_194\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_195\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_196\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"unknown_197\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_RESOURCE\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"StatefulPartitionedCall\"\n",
       "  op: \"StatefulPartitionedCall\"\n",
       "  input: \"input_mask\"\n",
       "  input: \"input_type_ids\"\n",
       "  input: \"input_word_ids\"\n",
       "  input: \"unknown\"\n",
       "  input: \"unknown_0\"\n",
       "  input: \"unknown_1\"\n",
       "  input: \"unknown_2\"\n",
       "  input: \"unknown_3\"\n",
       "  input: \"unknown_4\"\n",
       "  input: \"unknown_5\"\n",
       "  input: \"unknown_6\"\n",
       "  input: \"unknown_7\"\n",
       "  input: \"unknown_8\"\n",
       "  input: \"unknown_9\"\n",
       "  input: \"unknown_10\"\n",
       "  input: \"unknown_11\"\n",
       "  input: \"unknown_12\"\n",
       "  input: \"unknown_13\"\n",
       "  input: \"unknown_14\"\n",
       "  input: \"unknown_15\"\n",
       "  input: \"unknown_16\"\n",
       "  input: \"unknown_17\"\n",
       "  input: \"unknown_18\"\n",
       "  input: \"unknown_19\"\n",
       "  input: \"unknown_20\"\n",
       "  input: \"unknown_21\"\n",
       "  input: \"unknown_22\"\n",
       "  input: \"unknown_23\"\n",
       "  input: \"unknown_24\"\n",
       "  input: \"unknown_25\"\n",
       "  input: \"unknown_26\"\n",
       "  input: \"unknown_27\"\n",
       "  input: \"unknown_28\"\n",
       "  input: \"unknown_29\"\n",
       "  input: \"unknown_30\"\n",
       "  input: \"unknown_31\"\n",
       "  input: \"unknown_32\"\n",
       "  input: \"unknown_33\"\n",
       "  input: \"unknown_34\"\n",
       "  input: \"unknown_35\"\n",
       "  input: \"unknown_36\"\n",
       "  input: \"unknown_37\"\n",
       "  input: \"unknown_38\"\n",
       "  input: \"unknown_39\"\n",
       "  input: \"unknown_40\"\n",
       "  input: \"unknown_41\"\n",
       "  input: \"unknown_42\"\n",
       "  input: \"unknown_43\"\n",
       "  input: \"unknown_44\"\n",
       "  input: \"unknown_45\"\n",
       "  input: \"unknown_46\"\n",
       "  input: \"unknown_47\"\n",
       "  input: \"unknown_48\"\n",
       "  input: \"unknown_49\"\n",
       "  input: \"unknown_50\"\n",
       "  input: \"unknown_51\"\n",
       "  input: \"unknown_52\"\n",
       "  input: \"unknown_53\"\n",
       "  input: \"unknown_54\"\n",
       "  input: \"unknown_55\"\n",
       "  input: \"unknown_56\"\n",
       "  input: \"unknown_57\"\n",
       "  input: \"unknown_58\"\n",
       "  input: \"unknown_59\"\n",
       "  input: \"unknown_60\"\n",
       "  input: \"unknown_61\"\n",
       "  input: \"unknown_62\"\n",
       "  input: \"unknown_63\"\n",
       "  input: \"unknown_64\"\n",
       "  input: \"unknown_65\"\n",
       "  input: \"unknown_66\"\n",
       "  input: \"unknown_67\"\n",
       "  input: \"unknown_68\"\n",
       "  input: \"unknown_69\"\n",
       "  input: \"unknown_70\"\n",
       "  input: \"unknown_71\"\n",
       "  input: \"unknown_72\"\n",
       "  input: \"unknown_73\"\n",
       "  input: \"unknown_74\"\n",
       "  input: \"unknown_75\"\n",
       "  input: \"unknown_76\"\n",
       "  input: \"unknown_77\"\n",
       "  input: \"unknown_78\"\n",
       "  input: \"unknown_79\"\n",
       "  input: \"unknown_80\"\n",
       "  input: \"unknown_81\"\n",
       "  input: \"unknown_82\"\n",
       "  input: \"unknown_83\"\n",
       "  input: \"unknown_84\"\n",
       "  input: \"unknown_85\"\n",
       "  input: \"unknown_86\"\n",
       "  input: \"unknown_87\"\n",
       "  input: \"unknown_88\"\n",
       "  input: \"unknown_89\"\n",
       "  input: \"unknown_90\"\n",
       "  input: \"unknown_91\"\n",
       "  input: \"unknown_92\"\n",
       "  input: \"unknown_93\"\n",
       "  input: \"unknown_94\"\n",
       "  input: \"unknown_95\"\n",
       "  input: \"unknown_96\"\n",
       "  input: \"unknown_97\"\n",
       "  input: \"unknown_98\"\n",
       "  input: \"unknown_99\"\n",
       "  input: \"unknown_100\"\n",
       "  input: \"unknown_101\"\n",
       "  input: \"unknown_102\"\n",
       "  input: \"unknown_103\"\n",
       "  input: \"unknown_104\"\n",
       "  input: \"unknown_105\"\n",
       "  input: \"unknown_106\"\n",
       "  input: \"unknown_107\"\n",
       "  input: \"unknown_108\"\n",
       "  input: \"unknown_109\"\n",
       "  input: \"unknown_110\"\n",
       "  input: \"unknown_111\"\n",
       "  input: \"unknown_112\"\n",
       "  input: \"unknown_113\"\n",
       "  input: \"unknown_114\"\n",
       "  input: \"unknown_115\"\n",
       "  input: \"unknown_116\"\n",
       "  input: \"unknown_117\"\n",
       "  input: \"unknown_118\"\n",
       "  input: \"unknown_119\"\n",
       "  input: \"unknown_120\"\n",
       "  input: \"unknown_121\"\n",
       "  input: \"unknown_122\"\n",
       "  input: \"unknown_123\"\n",
       "  input: \"unknown_124\"\n",
       "  input: \"unknown_125\"\n",
       "  input: \"unknown_126\"\n",
       "  input: \"unknown_127\"\n",
       "  input: \"unknown_128\"\n",
       "  input: \"unknown_129\"\n",
       "  input: \"unknown_130\"\n",
       "  input: \"unknown_131\"\n",
       "  input: \"unknown_132\"\n",
       "  input: \"unknown_133\"\n",
       "  input: \"unknown_134\"\n",
       "  input: \"unknown_135\"\n",
       "  input: \"unknown_136\"\n",
       "  input: \"unknown_137\"\n",
       "  input: \"unknown_138\"\n",
       "  input: \"unknown_139\"\n",
       "  input: \"unknown_140\"\n",
       "  input: \"unknown_141\"\n",
       "  input: \"unknown_142\"\n",
       "  input: \"unknown_143\"\n",
       "  input: \"unknown_144\"\n",
       "  input: \"unknown_145\"\n",
       "  input: \"unknown_146\"\n",
       "  input: \"unknown_147\"\n",
       "  input: \"unknown_148\"\n",
       "  input: \"unknown_149\"\n",
       "  input: \"unknown_150\"\n",
       "  input: \"unknown_151\"\n",
       "  input: \"unknown_152\"\n",
       "  input: \"unknown_153\"\n",
       "  input: \"unknown_154\"\n",
       "  input: \"unknown_155\"\n",
       "  input: \"unknown_156\"\n",
       "  input: \"unknown_157\"\n",
       "  input: \"unknown_158\"\n",
       "  input: \"unknown_159\"\n",
       "  input: \"unknown_160\"\n",
       "  input: \"unknown_161\"\n",
       "  input: \"unknown_162\"\n",
       "  input: \"unknown_163\"\n",
       "  input: \"unknown_164\"\n",
       "  input: \"unknown_165\"\n",
       "  input: \"unknown_166\"\n",
       "  input: \"unknown_167\"\n",
       "  input: \"unknown_168\"\n",
       "  input: \"unknown_169\"\n",
       "  input: \"unknown_170\"\n",
       "  input: \"unknown_171\"\n",
       "  input: \"unknown_172\"\n",
       "  input: \"unknown_173\"\n",
       "  input: \"unknown_174\"\n",
       "  input: \"unknown_175\"\n",
       "  input: \"unknown_176\"\n",
       "  input: \"unknown_177\"\n",
       "  input: \"unknown_178\"\n",
       "  input: \"unknown_179\"\n",
       "  input: \"unknown_180\"\n",
       "  input: \"unknown_181\"\n",
       "  input: \"unknown_182\"\n",
       "  input: \"unknown_183\"\n",
       "  input: \"unknown_184\"\n",
       "  input: \"unknown_185\"\n",
       "  input: \"unknown_186\"\n",
       "  input: \"unknown_187\"\n",
       "  input: \"unknown_188\"\n",
       "  input: \"unknown_189\"\n",
       "  input: \"unknown_190\"\n",
       "  input: \"unknown_191\"\n",
       "  input: \"unknown_192\"\n",
       "  input: \"unknown_193\"\n",
       "  input: \"unknown_194\"\n",
       "  input: \"unknown_195\"\n",
       "  input: \"unknown_196\"\n",
       "  input: \"unknown_197\"\n",
       "  attr {\n",
       "    key: \"Tin\"\n",
       "    value {\n",
       "      list {\n",
       "        type: DT_INT32\n",
       "        type: DT_INT32\n",
       "        type: DT_INT32\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"Tout\"\n",
       "    value {\n",
       "      list {\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"_collective_manager_ids\"\n",
       "    value {\n",
       "      list {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"_read_only_resource_inputs\"\n",
       "    value {\n",
       "      list {\n",
       "        i: 3\n",
       "        i: 4\n",
       "        i: 5\n",
       "        i: 6\n",
       "        i: 7\n",
       "        i: 8\n",
       "        i: 9\n",
       "        i: 10\n",
       "        i: 11\n",
       "        i: 12\n",
       "        i: 13\n",
       "        i: 14\n",
       "        i: 15\n",
       "        i: 16\n",
       "        i: 17\n",
       "        i: 18\n",
       "        i: 19\n",
       "        i: 20\n",
       "        i: 21\n",
       "        i: 22\n",
       "        i: 23\n",
       "        i: 24\n",
       "        i: 25\n",
       "        i: 26\n",
       "        i: 27\n",
       "        i: 28\n",
       "        i: 29\n",
       "        i: 30\n",
       "        i: 31\n",
       "        i: 32\n",
       "        i: 33\n",
       "        i: 34\n",
       "        i: 35\n",
       "        i: 36\n",
       "        i: 37\n",
       "        i: 38\n",
       "        i: 39\n",
       "        i: 40\n",
       "        i: 41\n",
       "        i: 42\n",
       "        i: 43\n",
       "        i: 44\n",
       "        i: 45\n",
       "        i: 46\n",
       "        i: 47\n",
       "        i: 48\n",
       "        i: 49\n",
       "        i: 50\n",
       "        i: 51\n",
       "        i: 52\n",
       "        i: 53\n",
       "        i: 54\n",
       "        i: 55\n",
       "        i: 56\n",
       "        i: 57\n",
       "        i: 58\n",
       "        i: 59\n",
       "        i: 60\n",
       "        i: 61\n",
       "        i: 62\n",
       "        i: 63\n",
       "        i: 64\n",
       "        i: 65\n",
       "        i: 66\n",
       "        i: 67\n",
       "        i: 68\n",
       "        i: 69\n",
       "        i: 70\n",
       "        i: 71\n",
       "        i: 72\n",
       "        i: 73\n",
       "        i: 74\n",
       "        i: 75\n",
       "        i: 76\n",
       "        i: 77\n",
       "        i: 78\n",
       "        i: 79\n",
       "        i: 80\n",
       "        i: 81\n",
       "        i: 82\n",
       "        i: 83\n",
       "        i: 84\n",
       "        i: 85\n",
       "        i: 86\n",
       "        i: 87\n",
       "        i: 88\n",
       "        i: 89\n",
       "        i: 90\n",
       "        i: 91\n",
       "        i: 92\n",
       "        i: 93\n",
       "        i: 94\n",
       "        i: 95\n",
       "        i: 96\n",
       "        i: 97\n",
       "        i: 98\n",
       "        i: 99\n",
       "        i: 100\n",
       "        i: 101\n",
       "        i: 102\n",
       "        i: 103\n",
       "        i: 104\n",
       "        i: 105\n",
       "        i: 106\n",
       "        i: 107\n",
       "        i: 108\n",
       "        i: 109\n",
       "        i: 110\n",
       "        i: 111\n",
       "        i: 112\n",
       "        i: 113\n",
       "        i: 114\n",
       "        i: 115\n",
       "        i: 116\n",
       "        i: 117\n",
       "        i: 118\n",
       "        i: 119\n",
       "        i: 120\n",
       "        i: 121\n",
       "        i: 122\n",
       "        i: 123\n",
       "        i: 124\n",
       "        i: 125\n",
       "        i: 126\n",
       "        i: 127\n",
       "        i: 128\n",
       "        i: 129\n",
       "        i: 130\n",
       "        i: 131\n",
       "        i: 132\n",
       "        i: 133\n",
       "        i: 134\n",
       "        i: 135\n",
       "        i: 136\n",
       "        i: 137\n",
       "        i: 138\n",
       "        i: 139\n",
       "        i: 140\n",
       "        i: 141\n",
       "        i: 142\n",
       "        i: 143\n",
       "        i: 144\n",
       "        i: 145\n",
       "        i: 146\n",
       "        i: 147\n",
       "        i: 148\n",
       "        i: 149\n",
       "        i: 150\n",
       "        i: 151\n",
       "        i: 152\n",
       "        i: 153\n",
       "        i: 154\n",
       "        i: 155\n",
       "        i: 156\n",
       "        i: 157\n",
       "        i: 158\n",
       "        i: 159\n",
       "        i: 160\n",
       "        i: 161\n",
       "        i: 162\n",
       "        i: 163\n",
       "        i: 164\n",
       "        i: 165\n",
       "        i: 166\n",
       "        i: 167\n",
       "        i: 168\n",
       "        i: 169\n",
       "        i: 170\n",
       "        i: 171\n",
       "        i: 172\n",
       "        i: 173\n",
       "        i: 174\n",
       "        i: 175\n",
       "        i: 176\n",
       "        i: 177\n",
       "        i: 178\n",
       "        i: 179\n",
       "        i: 180\n",
       "        i: 181\n",
       "        i: 182\n",
       "        i: 183\n",
       "        i: 184\n",
       "        i: 185\n",
       "        i: 186\n",
       "        i: 187\n",
       "        i: 188\n",
       "        i: 189\n",
       "        i: 190\n",
       "        i: 191\n",
       "        i: 192\n",
       "        i: 193\n",
       "        i: 194\n",
       "        i: 195\n",
       "        i: 196\n",
       "        i: 197\n",
       "        i: 198\n",
       "        i: 199\n",
       "        i: 200\n",
       "        i: 201\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"config\"\n",
       "    value {\n",
       "      s: \"\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"config_proto\"\n",
       "    value {\n",
       "      s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\\202\\001\\000\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"executor_type\"\n",
       "    value {\n",
       "      s: \"\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"f\"\n",
       "    value {\n",
       "      func {\n",
       "        name: \"__inference__wrapped_model_201957\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"StatefulPartitionedCall\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"NoOp\"\n",
       "  op: \"NoOp\"\n",
       "  input: \"^StatefulPartitionedCall\"\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"NoOp\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_1\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:1\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_1\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_2\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:2\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_2\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_3\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:3\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_3\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_4\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:4\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_4\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_5\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:5\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_5\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_6\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:6\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_6\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_7\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:7\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_7\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_8\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:8\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_8\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_9\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:9\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_9\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_10\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:10\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_10\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_11\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:11\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_11\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_12\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:12\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_12\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_13\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:13\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_13\"\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity_14\"\n",
       "  op: \"Identity\"\n",
       "  input: \"StatefulPartitionedCall:14\"\n",
       "  input: \"^NoOp\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  experimental_debug_info {\n",
       "    original_node_names: \"Identity_14\"\n",
       "  }\n",
       "}\n",
       "library {\n",
       "  function {\n",
       "    signature {\n",
       "      name: \"__inference__wrapped_model_201957\"\n",
       "      input_arg {\n",
       "        name: \"input_mask\"\n",
       "        type: DT_INT32\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"input_type_ids\"\n",
       "        type: DT_INT32\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"input_word_ids\"\n",
       "        type: DT_INT32\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_word_embeddings_gather_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_position_embedding_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_type_embeddings_matmul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_embeddings_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_embeddings_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_0_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_1_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_2_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_3_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_4_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_5_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_6_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_7_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_8_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_9_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_10_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_query_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_key_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_value_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_attention_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_intermediate_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_output_einsum_einsum_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_output_add_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_transformer_layer_11_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_pooler_transform_matmul_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      input_arg {\n",
       "        name: \"model_bert_encoder_pooler_transform_biasadd_readvariableop_resource\"\n",
       "        type: DT_RESOURCE\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_1\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_2\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_3\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_4\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_5\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_6\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_7\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_8\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_9\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_10\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_11\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_12\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_13\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      output_arg {\n",
       "        name: \"identity_14\"\n",
       "        type: DT_FLOAT\n",
       "      }\n",
       "      is_stateful: true\n",
       "      control_output: \"model/bert_encoder/embeddings/layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/pooler_transform/BiasAdd/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/pooler_transform/MatMul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/position_embedding/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/intermediate/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention/key/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention/query/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention/value/add/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/type_embeddings/MatMul/ReadVariableOp\"\n",
       "      control_output: \"model/bert_encoder/word_embeddings/Gather\"\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/Reshape/shape\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/Reshape/shape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/Reshape\"\n",
       "      op: \"Reshape\"\n",
       "      input: \"input_word_ids\"\n",
       "      input: \"model/bert_encoder/word_embeddings/Reshape/shape:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tshape\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/Reshape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/Gather\"\n",
       "      op: \"ResourceGather\"\n",
       "      input: \"model_bert_encoder_word_embeddings_gather_resource\"\n",
       "      input: \"model/bert_encoder/word_embeddings/Reshape:output:0\"\n",
       "      attr {\n",
       "        key: \"Tindices\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"batch_dims\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"validate_indices\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/Gather\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/word_embeddings/Gather:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/Shape\"\n",
       "      op: \"Shape\"\n",
       "      input: \"input_word_ids\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"out_type\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/Shape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/concat/values_1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 768\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/concat/values_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/concat/axis\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "            }\n",
       "            int_val: 0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/concat/axis\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/concat\"\n",
       "      op: \"ConcatV2\"\n",
       "      input: \"model/bert_encoder/word_embeddings/Shape:output:0\"\n",
       "      input: \"model/bert_encoder/word_embeddings/concat/values_1:output:0\"\n",
       "      input: \"model/bert_encoder/word_embeddings/concat/axis:output:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/concat\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/word_embeddings/Reshape_1\"\n",
       "      op: \"Reshape\"\n",
       "      input: \"model/bert_encoder/word_embeddings/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/word_embeddings/concat:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tshape\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/word_embeddings/Reshape_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/Shape\"\n",
       "      op: \"Shape\"\n",
       "      input: \"model/bert_encoder/word_embeddings/Reshape_1:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"out_type\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/Shape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice/stack\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice/stack\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice/stack_1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice/stack_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice/stack_2\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice/stack_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice\"\n",
       "      op: \"StridedSlice\"\n",
       "      input: \"model/bert_encoder/position_embedding/Shape:output:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice/stack:output:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice/stack_1:output:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice/stack_2:output:0\"\n",
       "      attr {\n",
       "        key: \"Index\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"begin_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"ellipsis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"end_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"new_axis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"shrink_axis_mask\"\n",
       "        value {\n",
       "          i: 1\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_position_embedding_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice_1/stack\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 2\n",
       "              }\n",
       "            }\n",
       "            tensor_content: \"\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice_1/stack\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice_1/stack_1/1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "            }\n",
       "            int_val: 0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice_1/stack_1/1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice_1/stack_1\"\n",
       "      op: \"Pack\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice:output:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice_1/stack_1/1:output:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"axis\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice_1/stack_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice_1/stack_2\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 2\n",
       "              }\n",
       "            }\n",
       "            tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice_1/stack_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/strided_slice_1\"\n",
       "      op: \"StridedSlice\"\n",
       "      input: \"model/bert_encoder/position_embedding/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice_1/stack:output:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice_1/stack_1:output:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice_1/stack_2:output:0\"\n",
       "      attr {\n",
       "        key: \"Index\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"begin_mask\"\n",
       "        value {\n",
       "          i: 3\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"ellipsis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"end_mask\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"new_axis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"shrink_axis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/strided_slice_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/position_embedding/BroadcastTo\"\n",
       "      op: \"BroadcastTo\"\n",
       "      input: \"model/bert_encoder/position_embedding/strided_slice_1:output:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/Shape:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/position_embedding/BroadcastTo\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/Reshape/shape\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/Reshape/shape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/Reshape\"\n",
       "      op: \"Reshape\"\n",
       "      input: \"input_type_ids\"\n",
       "      input: \"model/bert_encoder/type_embeddings/Reshape/shape:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tshape\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/Reshape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/one_hot/on_value\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/one_hot/on_value\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/one_hot/off_value\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/one_hot/off_value\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/one_hot/depth\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/one_hot/depth\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/one_hot\"\n",
       "      op: \"OneHot\"\n",
       "      input: \"model/bert_encoder/type_embeddings/Reshape:output:0\"\n",
       "      input: \"model/bert_encoder/type_embeddings/one_hot/depth:output:0\"\n",
       "      input: \"model/bert_encoder/type_embeddings/one_hot/on_value:output:0\"\n",
       "      input: \"model/bert_encoder/type_embeddings/one_hot/off_value:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"TI\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"axis\"\n",
       "        value {\n",
       "          i: -1\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/one_hot\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/MatMul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_type_embeddings_matmul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/MatMul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/MatMul\"\n",
       "      op: \"MatMul\"\n",
       "      input: \"model/bert_encoder/type_embeddings/one_hot:output:0\"\n",
       "      input: \"model/bert_encoder/type_embeddings/MatMul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"transpose_a\"\n",
       "        value {\n",
       "          b: false\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"transpose_b\"\n",
       "        value {\n",
       "          b: false\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/MatMul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/Shape\"\n",
       "      op: \"Shape\"\n",
       "      input: \"input_type_ids\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"out_type\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/Shape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/concat/values_1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 768\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/concat/values_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/concat/axis\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "            }\n",
       "            int_val: 0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/concat/axis\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/concat\"\n",
       "      op: \"ConcatV2\"\n",
       "      input: \"model/bert_encoder/type_embeddings/Shape:output:0\"\n",
       "      input: \"model/bert_encoder/type_embeddings/concat/values_1:output:0\"\n",
       "      input: \"model/bert_encoder/type_embeddings/concat/axis:output:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/concat\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/type_embeddings/Reshape_1\"\n",
       "      op: \"Reshape\"\n",
       "      input: \"model/bert_encoder/type_embeddings/MatMul:product:0\"\n",
       "      input: \"model/bert_encoder/type_embeddings/concat:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tshape\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/type_embeddings/Reshape_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/add/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/word_embeddings/Reshape_1:output:0\"\n",
       "      input: \"model/bert_encoder/position_embedding/BroadcastTo:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/add/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/add/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/add/add:z:0\"\n",
       "      input: \"model/bert_encoder/type_embeddings/Reshape_1:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/add/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/add/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/add/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_embeddings_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/add/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_embeddings_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/embeddings/layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/Shape\"\n",
       "      op: \"Shape\"\n",
       "      input: \"model/bert_encoder/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"out_type\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/Shape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice/stack\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice/stack\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice/stack_1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice/stack_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice/stack_2\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice/stack_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice\"\n",
       "      op: \"StridedSlice\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/Shape:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice/stack:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice/stack_1:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice/stack_2:output:0\"\n",
       "      attr {\n",
       "        key: \"Index\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"begin_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"ellipsis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"end_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"new_axis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"shrink_axis_mask\"\n",
       "        value {\n",
       "          i: 1\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack_1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack_2\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice_1\"\n",
       "      op: \"StridedSlice\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/Shape:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack_1:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_1/stack_2:output:0\"\n",
       "      attr {\n",
       "        key: \"Index\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"begin_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"ellipsis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"end_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"new_axis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"shrink_axis_mask\"\n",
       "        value {\n",
       "          i: 1\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/Shape_1\"\n",
       "      op: \"Shape\"\n",
       "      input: \"input_mask\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"out_type\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/Shape_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack_1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack_2\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/strided_slice_2\"\n",
       "      op: \"StridedSlice\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/Shape_1:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack_1:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_2/stack_2:output:0\"\n",
       "      attr {\n",
       "        key: \"Index\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"begin_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"ellipsis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"end_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"new_axis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"shrink_axis_mask\"\n",
       "        value {\n",
       "          i: 1\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/strided_slice_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/Reshape/shape/1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/Reshape/shape/1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/Reshape/shape\"\n",
       "      op: \"Pack\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/Reshape/shape/1:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_2:output:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 3\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"axis\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/Reshape/shape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/Reshape\"\n",
       "      op: \"Reshape\"\n",
       "      input: \"input_mask\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/Reshape/shape:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tshape\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/Reshape\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/Cast\"\n",
       "      op: \"Cast\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/Reshape:output:0\"\n",
       "      attr {\n",
       "        key: \"DstT\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"SrcT\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Truncate\"\n",
       "        value {\n",
       "          b: false\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/Cast\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_1:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones/mul_1/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones/mul_1/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/ones/mul:z:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/ones/mul_1/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones/Less/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "            }\n",
       "            int_val: 1000\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones/Less/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones/Less\"\n",
       "      op: \"Less\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/ones/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/ones/Less/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones/Less\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones/packed/2\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "            }\n",
       "            int_val: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones/packed/2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones/packed\"\n",
       "      op: \"Pack\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/strided_slice_1:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/ones/packed/2:output:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 3\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"axis\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones/packed\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones/Const\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones/Const\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/ones\"\n",
       "      op: \"Fill\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/ones/packed:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/ones/Const:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"index_type\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/ones\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/self_attention_mask/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/ones:output:0\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/Cast:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/self_attention_mask/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/dropout/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/dropout/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/dropout/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/dropout/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_0_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_1_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_2_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_3_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_4_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_5_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_6_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_7_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_8_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_9_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_10_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_query_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/query/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_query_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/query/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/query/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/query/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/query/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_key_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/key/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_key_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/key/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/key/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/key/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/key/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_value_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cde->abde\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/value/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_value_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/value/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/value/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/value/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/value/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/Mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.125\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/Mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/Mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/query/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/Mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/Mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/key/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/Mul:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"aecd,abcd->acbe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/ExpandDims/dim\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: -3\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/ExpandDims/dim\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/ExpandDims\"\n",
       "      op: \"ExpandDims\"\n",
       "      input: \"model/bert_encoder/self_attention_mask/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/ExpandDims/dim:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tdim\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/ExpandDims\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/sub/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/sub/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/sub/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/ExpandDims:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/mul/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: -1000000000.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/mul/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/sub:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/mul/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/Softmax\"\n",
       "      op: \"Softmax\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/Softmax\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/dropout_3/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/softmax/Softmax:softmax:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/dropout_3/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/einsum_1/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/dropout_3/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/value/add:z:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"acbe,aecd->abcd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/einsum_1/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_attention_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/einsum_1/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abcd,cde->abe\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_attention_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/dropout/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/dropout/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/dropout/Identity:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_self_attention_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_intermediate_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/intermediate/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_intermediate_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/intermediate/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/intermediate/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/intermediate/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/intermediate/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Cast/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.044714998453855515\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Cast/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.5\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/intermediate/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Pow/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 3.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Pow/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Pow\"\n",
       "      op: \"Pow\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Pow/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Pow\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Cast/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Pow:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/intermediate/add:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_2/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 0.7978845834732056\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_2/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_2/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add_1/x\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 1.0\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add_1/x\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add_1/x:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/Tanh:y:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_3\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/dropout_1/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/activation/Gelu/mul_3:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/dropout_1/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_output_einsum_einsum_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum\"\n",
       "      op: \"Einsum\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/dropout_1/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"N\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"equation\"\n",
       "        value {\n",
       "          s: \"abc,cd->abd\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output/add/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_output_add_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output/add/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output/add/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/dropout_2/Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/dropout_2/Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/dropout_2/Identity:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/add_1:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/mean/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/mean\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/mean/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/mean\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/StopGradient\"\n",
       "      op: \"StopGradient\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/mean:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/StopGradient\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/SquaredDifference\"\n",
       "      op: \"SquaredDifference\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/StopGradient:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/SquaredDifference\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 1\n",
       "              }\n",
       "            }\n",
       "            int_val: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/variance/reduction_indices\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/variance\"\n",
       "      op: \"Mean\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/SquaredDifference:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/variance/reduction_indices:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"Tidx\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"keep_dims\"\n",
       "        value {\n",
       "          b: true\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/variance\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add/y\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_FLOAT\n",
       "            tensor_shape {\n",
       "            }\n",
       "            float_val: 9.999999960041972e-13\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add/y\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/variance:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add/y:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      op: \"Rsqrt\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/Rsqrt\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_output_layer_norm_batchnorm_mul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/Rsqrt:y:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul_1\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul_2\"\n",
       "      op: \"Mul\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/moments/mean:output:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_transformer_layer_11_output_layer_norm_batchnorm_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/sub\"\n",
       "      op: \"Sub\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/ReadVariableOp:value:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul_2:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/sub\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add_1\"\n",
       "      op: \"AddV2\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul_1:z:0\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/sub:z:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 3\n",
       "              }\n",
       "            }\n",
       "            tensor_content: \"\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack_1\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 3\n",
       "              }\n",
       "            }\n",
       "            tensor_content: \"\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack_2\"\n",
       "      op: \"Const\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"value\"\n",
       "        value {\n",
       "          tensor {\n",
       "            dtype: DT_INT32\n",
       "            tensor_shape {\n",
       "              dim {\n",
       "                size: 3\n",
       "              }\n",
       "            }\n",
       "            tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/tf.__operators__.getitem/strided_slice\"\n",
       "      op: \"StridedSlice\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack:output:0\"\n",
       "      input: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack_1:output:0\"\n",
       "      input: \"model/bert_encoder/tf.__operators__.getitem/strided_slice/stack_2:output:0\"\n",
       "      attr {\n",
       "        key: \"Index\"\n",
       "        value {\n",
       "          type: DT_INT32\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"begin_mask\"\n",
       "        value {\n",
       "          i: 5\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"ellipsis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"end_mask\"\n",
       "        value {\n",
       "          i: 5\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"new_axis_mask\"\n",
       "        value {\n",
       "          i: 0\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"shrink_axis_mask\"\n",
       "        value {\n",
       "          i: 2\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/tf.__operators__.getitem/strided_slice\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/pooler_transform/MatMul/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_pooler_transform_matmul_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/pooler_transform/MatMul/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/pooler_transform/MatMul\"\n",
       "      op: \"MatMul\"\n",
       "      input: \"model/bert_encoder/tf.__operators__.getitem/strided_slice:output:0\"\n",
       "      input: \"model/bert_encoder/pooler_transform/MatMul/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"transpose_a\"\n",
       "        value {\n",
       "          b: false\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"transpose_b\"\n",
       "        value {\n",
       "          b: false\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/pooler_transform/MatMul\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/pooler_transform/BiasAdd/ReadVariableOp\"\n",
       "      op: \"ReadVariableOp\"\n",
       "      input: \"model_bert_encoder_pooler_transform_biasadd_readvariableop_resource\"\n",
       "      attr {\n",
       "        key: \"dtype\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/pooler_transform/BiasAdd/ReadVariableOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/pooler_transform/BiasAdd\"\n",
       "      op: \"BiasAdd\"\n",
       "      input: \"model/bert_encoder/pooler_transform/MatMul:product:0\"\n",
       "      input: \"model/bert_encoder/pooler_transform/BiasAdd/ReadVariableOp:value:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      attr {\n",
       "        key: \"data_format\"\n",
       "        value {\n",
       "          s: \"NHWC\"\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/pooler_transform/BiasAdd\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"model/bert_encoder/pooler_transform/Tanh\"\n",
       "      op: \"Tanh\"\n",
       "      input: \"model/bert_encoder/pooler_transform/BiasAdd:output:0\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"model/bert_encoder/pooler_transform/Tanh\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"NoOp\"\n",
       "      op: \"NoOp\"\n",
       "      input: \"^model/bert_encoder/embeddings/layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/embeddings/layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/pooler_transform/BiasAdd/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/pooler_transform/MatMul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/position_embedding/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/intermediate/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention/key/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention/query/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention/value/add/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/type_embeddings/MatMul/ReadVariableOp\"\n",
       "      input: \"^model/bert_encoder/word_embeddings/Gather\"\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"NoOp\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/pooler_transform/Tanh:y:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_1\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_1\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_2\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_2\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_3\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_3\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_4\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_4\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_5\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/pooler_transform/Tanh:y:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_5\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_6\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_6\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_7\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_7\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_8\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_8\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_9\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_9\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_10\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_10\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_11\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_11\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_12\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_12\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_13\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_13\"\n",
       "      }\n",
       "    }\n",
       "    node_def {\n",
       "      name: \"Identity_14\"\n",
       "      op: \"Identity\"\n",
       "      input: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/add_1:z:0\"\n",
       "      input: \"^NoOp\"\n",
       "      attr {\n",
       "        key: \"T\"\n",
       "        value {\n",
       "          type: DT_FLOAT\n",
       "        }\n",
       "      }\n",
       "      experimental_debug_info {\n",
       "        original_node_names: \"Identity_14\"\n",
       "      }\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity\"\n",
       "      value: \"Identity:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_1\"\n",
       "      value: \"Identity_1:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_10\"\n",
       "      value: \"Identity_10:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_11\"\n",
       "      value: \"Identity_11:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_12\"\n",
       "      value: \"Identity_12:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_13\"\n",
       "      value: \"Identity_13:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_14\"\n",
       "      value: \"Identity_14:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_2\"\n",
       "      value: \"Identity_2:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_3\"\n",
       "      value: \"Identity_3:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_4\"\n",
       "      value: \"Identity_4:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_5\"\n",
       "      value: \"Identity_5:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_6\"\n",
       "      value: \"Identity_6:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_7\"\n",
       "      value: \"Identity_7:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_8\"\n",
       "      value: \"Identity_8:output:0\"\n",
       "    }\n",
       "    ret {\n",
       "      key: \"identity_9\"\n",
       "      value: \"Identity_9:output:0\"\n",
       "    }\n",
       "    attr {\n",
       "      key: \"_construction_context\"\n",
       "      value {\n",
       "        s: \"kEagerRuntime\"\n",
       "      }\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/embeddings/layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/embeddings/layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/embeddings/layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/pooler_transform/BiasAdd/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/pooler_transform/BiasAdd/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/pooler_transform/MatMul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/pooler_transform/MatMul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/position_embedding/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/position_embedding/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_10/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_11/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_2/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_3/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_4/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_5/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_6/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_7/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_8/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/intermediate/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/intermediate/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/intermediate/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/output_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention/attention_output/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention/key/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention/key/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention/key/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention/query/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention/query/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention/query/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention/value/add/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention/value/add/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention/value/einsum/Einsum/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/transformer/layer_9/self_attention_layer_norm/batchnorm/mul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/type_embeddings/MatMul/ReadVariableOp\"\n",
       "      value: \"model/bert_encoder/type_embeddings/MatMul/ReadVariableOp\"\n",
       "    }\n",
       "    control_ret {\n",
       "      key: \"model/bert_encoder/word_embeddings/Gather\"\n",
       "      value: \"model/bert_encoder/word_embeddings/Gather\"\n",
       "    }\n",
       "    arg_attr {\n",
       "      key: 0\n",
       "      value {\n",
       "        attr {\n",
       "          key: \"_output_shapes\"\n",
       "          value {\n",
       "            list {\n",
       "              shape {\n",
       "                dim {\n",
       "                  size: -1\n",
       "                }\n",
       "                dim {\n",
       "                  size: -1\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "        attr {\n",
       "          key: \"_user_specified_name\"\n",
       "          value {\n",
       "            s: \"input_mask\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    arg_attr {\n",
       "      key: 1\n",
       "      value {\n",
       "        attr {\n",
       "          key: \"_output_shapes\"\n",
       "          value {\n",
       "            list {\n",
       "              shape {\n",
       "                dim {\n",
       "                  size: -1\n",
       "                }\n",
       "                dim {\n",
       "                  size: -1\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "        attr {\n",
       "          key: \"_user_specified_name\"\n",
       "          value {\n",
       "            s: \"input_type_ids\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    arg_attr {\n",
       "      key: 2\n",
       "      value {\n",
       "        attr {\n",
       "          key: \"_output_shapes\"\n",
       "          value {\n",
       "            list {\n",
       "              shape {\n",
       "                dim {\n",
       "                  size: -1\n",
       "                }\n",
       "                dim {\n",
       "                  size: -1\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "        attr {\n",
       "          key: \"_user_specified_name\"\n",
       "          value {\n",
       "            s: \"input_word_ids\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 987\n",
       "  min_consumer: 12\n",
       "}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.graph.as_graph_def()#get_tensor_by_name(\"model/bert_encoder/word_embeddings/Reshape_1/output:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = preprocessor(tf.constant(['this is a sentence', 'and so is this']))\n",
    "out = f(**encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       "array([[[ 0.15590554, -0.01118364, -0.07785353, ...,  0.06163237,\n",
       "          0.03383987,  0.06297513],\n",
       "        [-0.47564048,  0.5763171 ,  0.13226584, ..., -0.05813633,\n",
       "          0.41404092,  0.04797438],\n",
       "        [-0.9628004 , -0.28790185, -0.43244758, ...,  0.12608324,\n",
       "          0.17628382,  0.36824045],\n",
       "        ...,\n",
       "        [ 0.0069404 , -0.13526879,  0.65538305, ...,  0.3379342 ,\n",
       "         -0.4274403 ,  0.04114941],\n",
       "        [-0.05847672, -0.13744244,  0.5261469 , ...,  0.34803838,\n",
       "         -0.33752677, -0.04055665],\n",
       "        [ 0.04865304, -0.05239412,  0.5647512 , ...,  0.66545975,\n",
       "         -0.6454591 , -0.13866827]],\n",
       "\n",
       "       [[ 0.0116337 ,  0.02451276, -0.10758655, ...,  0.15397519,\n",
       "         -0.08475358, -0.03019335],\n",
       "        [-0.06115007,  0.32749522, -0.3740465 , ...,  0.41276175,\n",
       "          0.9359753 ,  0.08835143],\n",
       "        [-0.33425915,  0.52792215,  0.42075735, ..., -0.45563135,\n",
       "          1.0646499 ,  1.0318441 ],\n",
       "        ...,\n",
       "        [-0.04013953, -0.18043831,  0.55556905, ...,  0.2940378 ,\n",
       "         -0.3908257 , -0.01595289],\n",
       "        [-0.13510552, -0.19147974,  0.44391418, ...,  0.30496097,\n",
       "         -0.28514376, -0.09482287],\n",
       "        [-0.02960647, -0.1303178 ,  0.4675176 , ...,  0.6234789 ,\n",
       "         -0.5757037 , -0.15533984]]], dtype=float32)>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as gt:\n",
    "    # l1 = out['bert_encoder_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables []\n",
      "local_variables []\n",
      "trainable_variables []\n",
      "('__variable_store',) []\n",
      "('__varscope',) [<tensorflow.python.ops.variable_scope._VariableScopeStore object at 0x7f49dd0a0468>]\n"
     ]
    }
   ],
   "source": [
    "for c in f.graph.collections:\n",
    "    print(c, f.graph.get_collection_ref(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watching word_embeddings/embeddings:0\n",
      "watching position_embedding/embeddings:0\n",
      "watching type_embeddings/embeddings:0\n",
      "watching embeddings/layer_norm/gamma:0\n",
      "watching embeddings/layer_norm/beta:0\n",
      "watching transformer/layer_0/self_attention/query/kernel:0\n",
      "watching transformer/layer_0/self_attention/query/bias:0\n",
      "watching transformer/layer_0/self_attention/key/kernel:0\n",
      "watching transformer/layer_0/self_attention/key/bias:0\n",
      "watching transformer/layer_0/self_attention/value/kernel:0\n",
      "watching transformer/layer_0/self_attention/value/bias:0\n",
      "watching transformer/layer_0/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_0/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_0/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_0/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_0/intermediate/kernel:0\n",
      "watching transformer/layer_0/intermediate/bias:0\n",
      "watching transformer/layer_0/output/kernel:0\n",
      "watching transformer/layer_0/output/bias:0\n",
      "watching transformer/layer_0/output_layer_norm/gamma:0\n",
      "watching transformer/layer_0/output_layer_norm/beta:0\n",
      "watching transformer/layer_1/self_attention/query/kernel:0\n",
      "watching transformer/layer_1/self_attention/query/bias:0\n",
      "watching transformer/layer_1/self_attention/key/kernel:0\n",
      "watching transformer/layer_1/self_attention/key/bias:0\n",
      "watching transformer/layer_1/self_attention/value/kernel:0\n",
      "watching transformer/layer_1/self_attention/value/bias:0\n",
      "watching transformer/layer_1/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_1/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_1/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_1/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_1/intermediate/kernel:0\n",
      "watching transformer/layer_1/intermediate/bias:0\n",
      "watching transformer/layer_1/output/kernel:0\n",
      "watching transformer/layer_1/output/bias:0\n",
      "watching transformer/layer_1/output_layer_norm/gamma:0\n",
      "watching transformer/layer_1/output_layer_norm/beta:0\n",
      "watching transformer/layer_2/self_attention/query/kernel:0\n",
      "watching transformer/layer_2/self_attention/query/bias:0\n",
      "watching transformer/layer_2/self_attention/key/kernel:0\n",
      "watching transformer/layer_2/self_attention/key/bias:0\n",
      "watching transformer/layer_2/self_attention/value/kernel:0\n",
      "watching transformer/layer_2/self_attention/value/bias:0\n",
      "watching transformer/layer_2/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_2/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_2/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_2/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_2/intermediate/kernel:0\n",
      "watching transformer/layer_2/intermediate/bias:0\n",
      "watching transformer/layer_2/output/kernel:0\n",
      "watching transformer/layer_2/output/bias:0\n",
      "watching transformer/layer_2/output_layer_norm/gamma:0\n",
      "watching transformer/layer_2/output_layer_norm/beta:0\n",
      "watching transformer/layer_3/self_attention/query/kernel:0\n",
      "watching transformer/layer_3/self_attention/query/bias:0\n",
      "watching transformer/layer_3/self_attention/key/kernel:0\n",
      "watching transformer/layer_3/self_attention/key/bias:0\n",
      "watching transformer/layer_3/self_attention/value/kernel:0\n",
      "watching transformer/layer_3/self_attention/value/bias:0\n",
      "watching transformer/layer_3/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_3/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_3/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_3/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_3/intermediate/kernel:0\n",
      "watching transformer/layer_3/intermediate/bias:0\n",
      "watching transformer/layer_3/output/kernel:0\n",
      "watching transformer/layer_3/output/bias:0\n",
      "watching transformer/layer_3/output_layer_norm/gamma:0\n",
      "watching transformer/layer_3/output_layer_norm/beta:0\n",
      "watching transformer/layer_4/self_attention/query/kernel:0\n",
      "watching transformer/layer_4/self_attention/query/bias:0\n",
      "watching transformer/layer_4/self_attention/key/kernel:0\n",
      "watching transformer/layer_4/self_attention/key/bias:0\n",
      "watching transformer/layer_4/self_attention/value/kernel:0\n",
      "watching transformer/layer_4/self_attention/value/bias:0\n",
      "watching transformer/layer_4/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_4/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_4/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_4/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_4/intermediate/kernel:0\n",
      "watching transformer/layer_4/intermediate/bias:0\n",
      "watching transformer/layer_4/output/kernel:0\n",
      "watching transformer/layer_4/output/bias:0\n",
      "watching transformer/layer_4/output_layer_norm/gamma:0\n",
      "watching transformer/layer_4/output_layer_norm/beta:0\n",
      "watching transformer/layer_5/self_attention/query/kernel:0\n",
      "watching transformer/layer_5/self_attention/query/bias:0\n",
      "watching transformer/layer_5/self_attention/key/kernel:0\n",
      "watching transformer/layer_5/self_attention/key/bias:0\n",
      "watching transformer/layer_5/self_attention/value/kernel:0\n",
      "watching transformer/layer_5/self_attention/value/bias:0\n",
      "watching transformer/layer_5/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_5/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_5/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_5/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_5/intermediate/kernel:0\n",
      "watching transformer/layer_5/intermediate/bias:0\n",
      "watching transformer/layer_5/output/kernel:0\n",
      "watching transformer/layer_5/output/bias:0\n",
      "watching transformer/layer_5/output_layer_norm/gamma:0\n",
      "watching transformer/layer_5/output_layer_norm/beta:0\n",
      "watching transformer/layer_6/self_attention/query/kernel:0\n",
      "watching transformer/layer_6/self_attention/query/bias:0\n",
      "watching transformer/layer_6/self_attention/key/kernel:0\n",
      "watching transformer/layer_6/self_attention/key/bias:0\n",
      "watching transformer/layer_6/self_attention/value/kernel:0\n",
      "watching transformer/layer_6/self_attention/value/bias:0\n",
      "watching transformer/layer_6/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_6/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_6/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_6/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_6/intermediate/kernel:0\n",
      "watching transformer/layer_6/intermediate/bias:0\n",
      "watching transformer/layer_6/output/kernel:0\n",
      "watching transformer/layer_6/output/bias:0\n",
      "watching transformer/layer_6/output_layer_norm/gamma:0\n",
      "watching transformer/layer_6/output_layer_norm/beta:0\n",
      "watching transformer/layer_7/self_attention/query/kernel:0\n",
      "watching transformer/layer_7/self_attention/query/bias:0\n",
      "watching transformer/layer_7/self_attention/key/kernel:0\n",
      "watching transformer/layer_7/self_attention/key/bias:0\n",
      "watching transformer/layer_7/self_attention/value/kernel:0\n",
      "watching transformer/layer_7/self_attention/value/bias:0\n",
      "watching transformer/layer_7/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_7/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_7/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_7/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_7/intermediate/kernel:0\n",
      "watching transformer/layer_7/intermediate/bias:0\n",
      "watching transformer/layer_7/output/kernel:0\n",
      "watching transformer/layer_7/output/bias:0\n",
      "watching transformer/layer_7/output_layer_norm/gamma:0\n",
      "watching transformer/layer_7/output_layer_norm/beta:0\n",
      "watching transformer/layer_8/self_attention/query/kernel:0\n",
      "watching transformer/layer_8/self_attention/query/bias:0\n",
      "watching transformer/layer_8/self_attention/key/kernel:0\n",
      "watching transformer/layer_8/self_attention/key/bias:0\n",
      "watching transformer/layer_8/self_attention/value/kernel:0\n",
      "watching transformer/layer_8/self_attention/value/bias:0\n",
      "watching transformer/layer_8/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_8/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_8/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_8/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_8/intermediate/kernel:0\n",
      "watching transformer/layer_8/intermediate/bias:0\n",
      "watching transformer/layer_8/output/kernel:0\n",
      "watching transformer/layer_8/output/bias:0\n",
      "watching transformer/layer_8/output_layer_norm/gamma:0\n",
      "watching transformer/layer_8/output_layer_norm/beta:0\n",
      "watching transformer/layer_9/self_attention/query/kernel:0\n",
      "watching transformer/layer_9/self_attention/query/bias:0\n",
      "watching transformer/layer_9/self_attention/key/kernel:0\n",
      "watching transformer/layer_9/self_attention/key/bias:0\n",
      "watching transformer/layer_9/self_attention/value/kernel:0\n",
      "watching transformer/layer_9/self_attention/value/bias:0\n",
      "watching transformer/layer_9/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_9/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_9/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_9/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_9/intermediate/kernel:0\n",
      "watching transformer/layer_9/intermediate/bias:0\n",
      "watching transformer/layer_9/output/kernel:0\n",
      "watching transformer/layer_9/output/bias:0\n",
      "watching transformer/layer_9/output_layer_norm/gamma:0\n",
      "watching transformer/layer_9/output_layer_norm/beta:0\n",
      "watching transformer/layer_10/self_attention/query/kernel:0\n",
      "watching transformer/layer_10/self_attention/query/bias:0\n",
      "watching transformer/layer_10/self_attention/key/kernel:0\n",
      "watching transformer/layer_10/self_attention/key/bias:0\n",
      "watching transformer/layer_10/self_attention/value/kernel:0\n",
      "watching transformer/layer_10/self_attention/value/bias:0\n",
      "watching transformer/layer_10/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_10/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_10/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_10/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_10/intermediate/kernel:0\n",
      "watching transformer/layer_10/intermediate/bias:0\n",
      "watching transformer/layer_10/output/kernel:0\n",
      "watching transformer/layer_10/output/bias:0\n",
      "watching transformer/layer_10/output_layer_norm/gamma:0\n",
      "watching transformer/layer_10/output_layer_norm/beta:0\n",
      "watching transformer/layer_11/self_attention/query/kernel:0\n",
      "watching transformer/layer_11/self_attention/query/bias:0\n",
      "watching transformer/layer_11/self_attention/key/kernel:0\n",
      "watching transformer/layer_11/self_attention/key/bias:0\n",
      "watching transformer/layer_11/self_attention/value/kernel:0\n",
      "watching transformer/layer_11/self_attention/value/bias:0\n",
      "watching transformer/layer_11/self_attention/attention_output/kernel:0\n",
      "watching transformer/layer_11/self_attention/attention_output/bias:0\n",
      "watching transformer/layer_11/self_attention_layer_norm/gamma:0\n",
      "watching transformer/layer_11/self_attention_layer_norm/beta:0\n",
      "watching transformer/layer_11/intermediate/kernel:0\n",
      "watching transformer/layer_11/intermediate/bias:0\n",
      "watching transformer/layer_11/output/kernel:0\n",
      "watching transformer/layer_11/output/bias:0\n",
      "watching transformer/layer_11/output_layer_norm/gamma:0\n",
      "watching transformer/layer_11/output_layer_norm/beta:0\n",
      "watching pooler_transform/kernel:0\n",
      "watching pooler_transform/bias:0\n",
      "watching Variable:0\n",
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "input = tf.constant([\"hello there\"])\n",
    "\n",
    "vs = []\n",
    "\n",
    "with tf.GradientTape() as gt:\n",
    "    encoded = preprocessor(input)\n",
    "\n",
    "    for v in encoder.variables:\n",
    "        print(\"watching\", v.name)\n",
    "        gt.watch(v)\n",
    "\n",
    "    output = encoder(encoded)\n",
    "\n",
    "d = gt.gradient(tf.math.reduce_sum(output['sequence_output']), vs)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_model(text):\n",
    "    encoder_inputs = preprocessor(text)\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    return outputs[\"pooled_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = run_model.get_concrete_function(input).graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'transformer/layer_0:0' refers to a Tensor which does not exist. The operation, 'transformer/layer_0', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_770618/835566895.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# g.get_tensor_by_name(\"word_embeddings/embeddings:0\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transformer/layer_0:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4148\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   4149\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 4150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3969\u001b[0m     \"\"\"\n\u001b[1;32m   3970\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3971\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3973\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   4014\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   4015\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4016\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   4017\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4018\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'transformer/layer_0:0' refers to a Tensor which does not exist. The operation, 'transformer/layer_0', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "# g.get_tensor_by_name(\"word_embeddings/embeddings:0\")\n",
    "g.get_tensor_by_name(\"transformer/layer_0:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_770618/3803451141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'g'"
     ]
    }
   ],
   "source": [
    "encoder_inputs['input_mask'].g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables []\n",
      "local_variables []\n",
      "trainable_variables []\n",
      "('__variable_store',) []\n",
      "('__varscope',) [<tensorflow.python.ops.variable_scope._VariableScopeStore object at 0x7f52331fdd68>]\n",
      "local_variablses []\n",
      "__varscope []\n"
     ]
    }
   ],
   "source": [
    "for c in g.collections:\n",
    "    print(c, g.get_collection_ref(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables []\n",
      "local_variables []\n",
      "trainable_variables []\n",
      "('__variable_store',) []\n",
      "('__varscope',) [<tensorflow.python.ops.variable_scope._VariableScopeStore object at 0x7f52331fdd68>]\n"
     ]
    }
   ],
   "source": [
    "for c in g.outer_graph.collections:\n",
    "    print(c, g.outer_graph.get_collection_ref(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "versions {\n",
       "  producer: 987\n",
       "}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.outer_graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'keras_layer_1/55213:0' shape=() dtype=resource>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operation_by_name(\"keras_layer_1/55213\").outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"text\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"_user_specified_name\"\n",
      "  value {\n",
      "    s: \"text\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_STRING\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer/55146\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer/55148\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_INT64\n",
      "      tensor_shape {\n",
      "      }\n",
      "      int64_val: -1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer/StatefulPartitionedCall\"\n",
      "op: \"StatefulPartitionedCall\"\n",
      "input: \"text\"\n",
      "input: \"keras_layer/55146\"\n",
      "input: \"keras_layer/55148\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_collective_manager_ids\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0022\\007*\\0030,1J\\0008\\001\\202\\001\\000\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_restored_function_body_7422\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55153\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55155\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55157\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55159\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55161\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55163\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55165\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55167\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55169\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55171\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55173\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55175\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55177\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55179\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55181\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55183\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55185\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55187\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55189\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55191\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55193\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55195\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55197\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55199\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55201\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55203\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55205\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55207\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55209\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55211\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55213\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55215\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55217\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55219\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55221\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55223\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55225\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55227\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55229\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55231\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55233\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55235\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55237\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55239\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55241\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55243\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55245\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55247\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55249\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55251\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55253\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55255\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55257\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55259\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55261\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55263\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55265\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55267\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55269\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55271\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55273\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55275\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55277\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55279\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55281\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55283\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55285\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55287\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55289\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55291\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55293\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55295\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55297\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55299\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55301\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55303\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55305\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55307\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55309\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55311\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55313\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55315\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55317\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55319\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55321\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55323\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55325\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55327\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55329\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55331\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55333\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55335\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55337\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55339\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55341\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55343\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55345\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55347\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55349\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55351\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55353\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55355\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55357\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55359\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55361\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55363\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55365\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55367\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55369\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55371\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55373\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55375\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55377\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55379\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55381\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55383\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55385\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55387\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55389\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55391\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55393\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55395\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55397\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55399\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55401\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55403\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55405\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55407\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55409\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55411\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55413\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55415\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55417\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55419\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55421\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55423\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55425\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55427\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55429\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55431\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55433\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55435\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55437\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55439\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55441\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55443\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55445\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55447\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55449\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55451\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55453\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55455\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55457\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55459\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55461\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55463\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55465\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55467\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55469\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55471\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55473\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55475\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55477\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55479\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55481\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55483\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55485\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55487\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55489\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55491\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55493\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55495\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55497\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55499\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55501\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55503\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55505\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55507\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55509\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55511\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55513\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55515\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55517\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55519\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55521\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55523\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55525\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55527\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55529\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55531\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55533\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55535\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55537\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55539\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55541\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55543\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55545\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55547\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/55549\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_RESOURCE\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"keras_layer_1/StatefulPartitionedCall\"\n",
      "op: \"StatefulPartitionedCall\"\n",
      "input: \"keras_layer/StatefulPartitionedCall\"\n",
      "input: \"keras_layer/StatefulPartitionedCall:1\"\n",
      "input: \"keras_layer/StatefulPartitionedCall:2\"\n",
      "input: \"keras_layer_1/55153\"\n",
      "input: \"keras_layer_1/55155\"\n",
      "input: \"keras_layer_1/55157\"\n",
      "input: \"keras_layer_1/55159\"\n",
      "input: \"keras_layer_1/55161\"\n",
      "input: \"keras_layer_1/55163\"\n",
      "input: \"keras_layer_1/55165\"\n",
      "input: \"keras_layer_1/55167\"\n",
      "input: \"keras_layer_1/55169\"\n",
      "input: \"keras_layer_1/55171\"\n",
      "input: \"keras_layer_1/55173\"\n",
      "input: \"keras_layer_1/55175\"\n",
      "input: \"keras_layer_1/55177\"\n",
      "input: \"keras_layer_1/55179\"\n",
      "input: \"keras_layer_1/55181\"\n",
      "input: \"keras_layer_1/55183\"\n",
      "input: \"keras_layer_1/55185\"\n",
      "input: \"keras_layer_1/55187\"\n",
      "input: \"keras_layer_1/55189\"\n",
      "input: \"keras_layer_1/55191\"\n",
      "input: \"keras_layer_1/55193\"\n",
      "input: \"keras_layer_1/55195\"\n",
      "input: \"keras_layer_1/55197\"\n",
      "input: \"keras_layer_1/55199\"\n",
      "input: \"keras_layer_1/55201\"\n",
      "input: \"keras_layer_1/55203\"\n",
      "input: \"keras_layer_1/55205\"\n",
      "input: \"keras_layer_1/55207\"\n",
      "input: \"keras_layer_1/55209\"\n",
      "input: \"keras_layer_1/55211\"\n",
      "input: \"keras_layer_1/55213\"\n",
      "input: \"keras_layer_1/55215\"\n",
      "input: \"keras_layer_1/55217\"\n",
      "input: \"keras_layer_1/55219\"\n",
      "input: \"keras_layer_1/55221\"\n",
      "input: \"keras_layer_1/55223\"\n",
      "input: \"keras_layer_1/55225\"\n",
      "input: \"keras_layer_1/55227\"\n",
      "input: \"keras_layer_1/55229\"\n",
      "input: \"keras_layer_1/55231\"\n",
      "input: \"keras_layer_1/55233\"\n",
      "input: \"keras_layer_1/55235\"\n",
      "input: \"keras_layer_1/55237\"\n",
      "input: \"keras_layer_1/55239\"\n",
      "input: \"keras_layer_1/55241\"\n",
      "input: \"keras_layer_1/55243\"\n",
      "input: \"keras_layer_1/55245\"\n",
      "input: \"keras_layer_1/55247\"\n",
      "input: \"keras_layer_1/55249\"\n",
      "input: \"keras_layer_1/55251\"\n",
      "input: \"keras_layer_1/55253\"\n",
      "input: \"keras_layer_1/55255\"\n",
      "input: \"keras_layer_1/55257\"\n",
      "input: \"keras_layer_1/55259\"\n",
      "input: \"keras_layer_1/55261\"\n",
      "input: \"keras_layer_1/55263\"\n",
      "input: \"keras_layer_1/55265\"\n",
      "input: \"keras_layer_1/55267\"\n",
      "input: \"keras_layer_1/55269\"\n",
      "input: \"keras_layer_1/55271\"\n",
      "input: \"keras_layer_1/55273\"\n",
      "input: \"keras_layer_1/55275\"\n",
      "input: \"keras_layer_1/55277\"\n",
      "input: \"keras_layer_1/55279\"\n",
      "input: \"keras_layer_1/55281\"\n",
      "input: \"keras_layer_1/55283\"\n",
      "input: \"keras_layer_1/55285\"\n",
      "input: \"keras_layer_1/55287\"\n",
      "input: \"keras_layer_1/55289\"\n",
      "input: \"keras_layer_1/55291\"\n",
      "input: \"keras_layer_1/55293\"\n",
      "input: \"keras_layer_1/55295\"\n",
      "input: \"keras_layer_1/55297\"\n",
      "input: \"keras_layer_1/55299\"\n",
      "input: \"keras_layer_1/55301\"\n",
      "input: \"keras_layer_1/55303\"\n",
      "input: \"keras_layer_1/55305\"\n",
      "input: \"keras_layer_1/55307\"\n",
      "input: \"keras_layer_1/55309\"\n",
      "input: \"keras_layer_1/55311\"\n",
      "input: \"keras_layer_1/55313\"\n",
      "input: \"keras_layer_1/55315\"\n",
      "input: \"keras_layer_1/55317\"\n",
      "input: \"keras_layer_1/55319\"\n",
      "input: \"keras_layer_1/55321\"\n",
      "input: \"keras_layer_1/55323\"\n",
      "input: \"keras_layer_1/55325\"\n",
      "input: \"keras_layer_1/55327\"\n",
      "input: \"keras_layer_1/55329\"\n",
      "input: \"keras_layer_1/55331\"\n",
      "input: \"keras_layer_1/55333\"\n",
      "input: \"keras_layer_1/55335\"\n",
      "input: \"keras_layer_1/55337\"\n",
      "input: \"keras_layer_1/55339\"\n",
      "input: \"keras_layer_1/55341\"\n",
      "input: \"keras_layer_1/55343\"\n",
      "input: \"keras_layer_1/55345\"\n",
      "input: \"keras_layer_1/55347\"\n",
      "input: \"keras_layer_1/55349\"\n",
      "input: \"keras_layer_1/55351\"\n",
      "input: \"keras_layer_1/55353\"\n",
      "input: \"keras_layer_1/55355\"\n",
      "input: \"keras_layer_1/55357\"\n",
      "input: \"keras_layer_1/55359\"\n",
      "input: \"keras_layer_1/55361\"\n",
      "input: \"keras_layer_1/55363\"\n",
      "input: \"keras_layer_1/55365\"\n",
      "input: \"keras_layer_1/55367\"\n",
      "input: \"keras_layer_1/55369\"\n",
      "input: \"keras_layer_1/55371\"\n",
      "input: \"keras_layer_1/55373\"\n",
      "input: \"keras_layer_1/55375\"\n",
      "input: \"keras_layer_1/55377\"\n",
      "input: \"keras_layer_1/55379\"\n",
      "input: \"keras_layer_1/55381\"\n",
      "input: \"keras_layer_1/55383\"\n",
      "input: \"keras_layer_1/55385\"\n",
      "input: \"keras_layer_1/55387\"\n",
      "input: \"keras_layer_1/55389\"\n",
      "input: \"keras_layer_1/55391\"\n",
      "input: \"keras_layer_1/55393\"\n",
      "input: \"keras_layer_1/55395\"\n",
      "input: \"keras_layer_1/55397\"\n",
      "input: \"keras_layer_1/55399\"\n",
      "input: \"keras_layer_1/55401\"\n",
      "input: \"keras_layer_1/55403\"\n",
      "input: \"keras_layer_1/55405\"\n",
      "input: \"keras_layer_1/55407\"\n",
      "input: \"keras_layer_1/55409\"\n",
      "input: \"keras_layer_1/55411\"\n",
      "input: \"keras_layer_1/55413\"\n",
      "input: \"keras_layer_1/55415\"\n",
      "input: \"keras_layer_1/55417\"\n",
      "input: \"keras_layer_1/55419\"\n",
      "input: \"keras_layer_1/55421\"\n",
      "input: \"keras_layer_1/55423\"\n",
      "input: \"keras_layer_1/55425\"\n",
      "input: \"keras_layer_1/55427\"\n",
      "input: \"keras_layer_1/55429\"\n",
      "input: \"keras_layer_1/55431\"\n",
      "input: \"keras_layer_1/55433\"\n",
      "input: \"keras_layer_1/55435\"\n",
      "input: \"keras_layer_1/55437\"\n",
      "input: \"keras_layer_1/55439\"\n",
      "input: \"keras_layer_1/55441\"\n",
      "input: \"keras_layer_1/55443\"\n",
      "input: \"keras_layer_1/55445\"\n",
      "input: \"keras_layer_1/55447\"\n",
      "input: \"keras_layer_1/55449\"\n",
      "input: \"keras_layer_1/55451\"\n",
      "input: \"keras_layer_1/55453\"\n",
      "input: \"keras_layer_1/55455\"\n",
      "input: \"keras_layer_1/55457\"\n",
      "input: \"keras_layer_1/55459\"\n",
      "input: \"keras_layer_1/55461\"\n",
      "input: \"keras_layer_1/55463\"\n",
      "input: \"keras_layer_1/55465\"\n",
      "input: \"keras_layer_1/55467\"\n",
      "input: \"keras_layer_1/55469\"\n",
      "input: \"keras_layer_1/55471\"\n",
      "input: \"keras_layer_1/55473\"\n",
      "input: \"keras_layer_1/55475\"\n",
      "input: \"keras_layer_1/55477\"\n",
      "input: \"keras_layer_1/55479\"\n",
      "input: \"keras_layer_1/55481\"\n",
      "input: \"keras_layer_1/55483\"\n",
      "input: \"keras_layer_1/55485\"\n",
      "input: \"keras_layer_1/55487\"\n",
      "input: \"keras_layer_1/55489\"\n",
      "input: \"keras_layer_1/55491\"\n",
      "input: \"keras_layer_1/55493\"\n",
      "input: \"keras_layer_1/55495\"\n",
      "input: \"keras_layer_1/55497\"\n",
      "input: \"keras_layer_1/55499\"\n",
      "input: \"keras_layer_1/55501\"\n",
      "input: \"keras_layer_1/55503\"\n",
      "input: \"keras_layer_1/55505\"\n",
      "input: \"keras_layer_1/55507\"\n",
      "input: \"keras_layer_1/55509\"\n",
      "input: \"keras_layer_1/55511\"\n",
      "input: \"keras_layer_1/55513\"\n",
      "input: \"keras_layer_1/55515\"\n",
      "input: \"keras_layer_1/55517\"\n",
      "input: \"keras_layer_1/55519\"\n",
      "input: \"keras_layer_1/55521\"\n",
      "input: \"keras_layer_1/55523\"\n",
      "input: \"keras_layer_1/55525\"\n",
      "input: \"keras_layer_1/55527\"\n",
      "input: \"keras_layer_1/55529\"\n",
      "input: \"keras_layer_1/55531\"\n",
      "input: \"keras_layer_1/55533\"\n",
      "input: \"keras_layer_1/55535\"\n",
      "input: \"keras_layer_1/55537\"\n",
      "input: \"keras_layer_1/55539\"\n",
      "input: \"keras_layer_1/55541\"\n",
      "input: \"keras_layer_1/55543\"\n",
      "input: \"keras_layer_1/55545\"\n",
      "input: \"keras_layer_1/55547\"\n",
      "input: \"keras_layer_1/55549\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "      type: DT_RESOURCE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_collective_manager_ids\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "      i: 3\n",
      "      i: 4\n",
      "      i: 5\n",
      "      i: 6\n",
      "      i: 7\n",
      "      i: 8\n",
      "      i: 9\n",
      "      i: 10\n",
      "      i: 11\n",
      "      i: 12\n",
      "      i: 13\n",
      "      i: 14\n",
      "      i: 15\n",
      "      i: 16\n",
      "      i: 17\n",
      "      i: 18\n",
      "      i: 19\n",
      "      i: 20\n",
      "      i: 21\n",
      "      i: 22\n",
      "      i: 23\n",
      "      i: 24\n",
      "      i: 25\n",
      "      i: 26\n",
      "      i: 27\n",
      "      i: 28\n",
      "      i: 29\n",
      "      i: 30\n",
      "      i: 31\n",
      "      i: 32\n",
      "      i: 33\n",
      "      i: 34\n",
      "      i: 35\n",
      "      i: 36\n",
      "      i: 37\n",
      "      i: 38\n",
      "      i: 39\n",
      "      i: 40\n",
      "      i: 41\n",
      "      i: 42\n",
      "      i: 43\n",
      "      i: 44\n",
      "      i: 45\n",
      "      i: 46\n",
      "      i: 47\n",
      "      i: 48\n",
      "      i: 49\n",
      "      i: 50\n",
      "      i: 51\n",
      "      i: 52\n",
      "      i: 53\n",
      "      i: 54\n",
      "      i: 55\n",
      "      i: 56\n",
      "      i: 57\n",
      "      i: 58\n",
      "      i: 59\n",
      "      i: 60\n",
      "      i: 61\n",
      "      i: 62\n",
      "      i: 63\n",
      "      i: 64\n",
      "      i: 65\n",
      "      i: 66\n",
      "      i: 67\n",
      "      i: 68\n",
      "      i: 69\n",
      "      i: 70\n",
      "      i: 71\n",
      "      i: 72\n",
      "      i: 73\n",
      "      i: 74\n",
      "      i: 75\n",
      "      i: 76\n",
      "      i: 77\n",
      "      i: 78\n",
      "      i: 79\n",
      "      i: 80\n",
      "      i: 81\n",
      "      i: 82\n",
      "      i: 83\n",
      "      i: 84\n",
      "      i: 85\n",
      "      i: 86\n",
      "      i: 87\n",
      "      i: 88\n",
      "      i: 89\n",
      "      i: 90\n",
      "      i: 91\n",
      "      i: 92\n",
      "      i: 93\n",
      "      i: 94\n",
      "      i: 95\n",
      "      i: 96\n",
      "      i: 97\n",
      "      i: 98\n",
      "      i: 99\n",
      "      i: 100\n",
      "      i: 101\n",
      "      i: 102\n",
      "      i: 103\n",
      "      i: 104\n",
      "      i: 105\n",
      "      i: 106\n",
      "      i: 107\n",
      "      i: 108\n",
      "      i: 109\n",
      "      i: 110\n",
      "      i: 111\n",
      "      i: 112\n",
      "      i: 113\n",
      "      i: 114\n",
      "      i: 115\n",
      "      i: 116\n",
      "      i: 117\n",
      "      i: 118\n",
      "      i: 119\n",
      "      i: 120\n",
      "      i: 121\n",
      "      i: 122\n",
      "      i: 123\n",
      "      i: 124\n",
      "      i: 125\n",
      "      i: 126\n",
      "      i: 127\n",
      "      i: 128\n",
      "      i: 129\n",
      "      i: 130\n",
      "      i: 131\n",
      "      i: 132\n",
      "      i: 133\n",
      "      i: 134\n",
      "      i: 135\n",
      "      i: 136\n",
      "      i: 137\n",
      "      i: 138\n",
      "      i: 139\n",
      "      i: 140\n",
      "      i: 141\n",
      "      i: 142\n",
      "      i: 143\n",
      "      i: 144\n",
      "      i: 145\n",
      "      i: 146\n",
      "      i: 147\n",
      "      i: 148\n",
      "      i: 149\n",
      "      i: 150\n",
      "      i: 151\n",
      "      i: 152\n",
      "      i: 153\n",
      "      i: 154\n",
      "      i: 155\n",
      "      i: 156\n",
      "      i: 157\n",
      "      i: 158\n",
      "      i: 159\n",
      "      i: 160\n",
      "      i: 161\n",
      "      i: 162\n",
      "      i: 163\n",
      "      i: 164\n",
      "      i: 165\n",
      "      i: 166\n",
      "      i: 167\n",
      "      i: 168\n",
      "      i: 169\n",
      "      i: 170\n",
      "      i: 171\n",
      "      i: 172\n",
      "      i: 173\n",
      "      i: 174\n",
      "      i: 175\n",
      "      i: 176\n",
      "      i: 177\n",
      "      i: 178\n",
      "      i: 179\n",
      "      i: 180\n",
      "      i: 181\n",
      "      i: 182\n",
      "      i: 183\n",
      "      i: 184\n",
      "      i: 185\n",
      "      i: 186\n",
      "      i: 187\n",
      "      i: 188\n",
      "      i: 189\n",
      "      i: 190\n",
      "      i: 191\n",
      "      i: 192\n",
      "      i: 193\n",
      "      i: 194\n",
      "      i: 195\n",
      "      i: 196\n",
      "      i: 197\n",
      "      i: 198\n",
      "      i: 199\n",
      "      i: 200\n",
      "      i: 201\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0022\\007*\\0030,1J\\0008\\001\\202\\001\\000\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_restored_function_body_53011\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"Identity\"\n",
      "op: \"Identity\"\n",
      "input: \"keras_layer_1/StatefulPartitionedCall:13\"\n",
      "input: \"^NoOp\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"NoOp\"\n",
      "op: \"NoOp\"\n",
      "input: \"^keras_layer_1/StatefulPartitionedCall\"\n",
      "input: \"^keras_layer/StatefulPartitionedCall\"\n",
      "attr {\n",
      "  key: \"_acd_function_control_output\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for op in g.get_operations():\n",
    "    print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = g.get_collection_ref(('__varscope',))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.current_scope.trainable_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(text_input, sequence_output)\n",
    "model_encoder = tf.keras.Model(text_input, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_mask': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       dtype=int32)>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       dtype=int32)>,\n",
       " 'input_word_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[ 101, 7592, 2045,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0]], dtype=int32)>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tf.constant([\"hello there\"])\n",
    "model_encoder(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = encoder.build(input_shape=input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer_1')>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_770618/733764327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[0;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    315\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    480\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    481\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "tf.gradients(tf.math.reduce_sum(pooled_output[:,0]), encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:22:02.740923: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"keras_layer_1\" (type KerasLayer).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * Tensor(\"inputs:0\", shape=(2,), dtype=string)\n    * False\n    * None\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids')}\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask')}\n    * True\n    * None\n  Keyword arguments: {}\n\nCall arguments received:\n   inputs=tf.Tensor(shape=(2,), dtype=string)\n   training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_747641/2364115312.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m hub_layer = hub.KerasLayer(embedding, input_shape=[], \n\u001b[1;32m      4\u001b[0m                            dtype=tf.string, trainable=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhub_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    237\u001b[0m       result = smart_cond.smart_cond(training,\n\u001b[1;32m    238\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                                      lambda: f(training=False))\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;31m# Unwrap dicts returned by signatures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37_tf2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m       result = smart_cond.smart_cond(training,\n\u001b[1;32m    238\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                                      lambda: f(training=False))\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;31m# Unwrap dicts returned by signatures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"keras_layer_1\" (type KerasLayer).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * Tensor(\"inputs:0\", shape=(2,), dtype=string)\n    * False\n    * None\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids')}\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask')}\n    * True\n    * None\n  Keyword arguments: {}\n\nCall arguments received:\n   inputs=tf.Tensor(shape=(2,), dtype=string)\n   training=None"
     ]
    }
   ],
   "source": [
    "# embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "embedding = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                816       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 48,191,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Model\n",
    "\n",
    "[Huggingface](https://huggingface.co/models) offers a variety of pre-trained NLP models to explore. We exemplify in this notebook a [transformer-based twitter sentiment classification model](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment). Before getting started, familiarize yourself with the general Truera API as demonstrated in the [intro notebook using pytorch](intro_demo_pytorch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Wrap all of the necessary components.\n",
    "class TwitterSentiment:\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "    device = 'cpu'\n",
    "    # Can also use cuda if available:\n",
    "    # device = 'cuda:0'\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "    NEGATIVE = labels.index('negative')\n",
    "    NEUTRAL = labels.index('neutral')\n",
    "    POSITIVE = labels.index('positive')\n",
    "\n",
    "task = TwitterSentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model quantifies tweets (or really any text you give it) according to its sentiment: positive, negative, or neutral. Lets try it out on some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   0,  100,  437,   98, 1372,  328,    2,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   0,  100,  437,   98, 5074,  328,    2,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   0,  100, 1395, 1137,  549,   38,  197,   28, 1372,   50, 5074,  328,\n",
      "            2],\n",
      "        [   0, 1794,  298,    2,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "['<s>', 'I', \"'m\", ' so', ' happy', '!', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<s>', 'I', \"'m\", ' so', ' sad', '!', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<s>', 'I', ' cannot', ' tell', ' whether', ' I', ' should', ' be', ' happy', ' or', ' sad', '!', '</s>', '<s>', 'me', 'h', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I'm so happy!\", \"I'm so sad!\", \"I cannot tell whether I should be happy or sad!\", \"meh\"]\n",
    "\n",
    "# Input sentences need to be tokenized first.\n",
    "\n",
    "inputs = task.tokenizer(sentences, padding=True, return_tensors=\"pt\").to(task.device) # pt refers to pytorch tensor\n",
    "\n",
    "# The tokenizer gives us vocabulary indexes for each input token (in this case,\n",
    "# words and some word parts like the \"'m\" part of \"I'm\" are tokens).\n",
    "\n",
    "print(inputs)\n",
    "\n",
    "# Decode helps inspecting the tokenization produced:\n",
    "\n",
    "print(task.tokenizer.batch_decode(torch.flatten(inputs['input_ids'])))\n",
    "# Normally decode would give us a single string for each sentence but we would\n",
    "# not be able to see some of the non-word tokens there. Flattening first gives\n",
    "# us a string for each input_id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating huggingface models is straight-forward if we use the structure produced by the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-2.3217, -0.8764,  4.0706],\n",
      "        [ 2.5737, -0.4016, -2.1465],\n",
      "        [ 0.5973,  0.3778, -0.7691],\n",
      "        [-0.2267,  0.6011, -0.2009]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "[-2.3217378 -0.8763628  4.0705967] positive I'm so happy!\n",
      "[ 2.5736785  -0.40158105 -2.1465425 ] negative I'm so sad!\n",
      "[ 0.59733623  0.37779403 -0.7691068 ] negative I cannot tell whether I should be happy or sad!\n",
      "[-0.22674142  0.601109   -0.20089385] neutral meh\n"
     ]
    }
   ],
   "source": [
    "outputs = task.model(**inputs)\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "# From logits we can extract the most likely class for each sentence and its readable label.\n",
    "\n",
    "predictions = [task.labels[i] for i in outputs.logits.argmax(axis=1)]\n",
    "\n",
    "for sentence, logits, prediction in zip(sentences, outputs.logits, predictions):\n",
    "    print(logits.to('cpu').detach().numpy(), prediction, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Wrapper\n",
    "\n",
    "As in the prior notebooks, we need to wrap the pytorch model with the appropriate Trulens functionality. Here we specify the maximum input size (in terms of tokens) each tweet may have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Detected pytorch backend for <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>.\n",
      "INFO: Using backend Backend.PYTORCH.\n",
      "INFO: If this seems incorrect, you can force the correct backend by passing the `backend` parameter directly into your get_model_wrapper call.\n",
      "DEBUG: Input dtype was not passed in. Defaulting to `torch.float32`.\n"
     ]
    }
   ],
   "source": [
    "from trulens.nn.models import get_model_wrapper\n",
    "from trulens.nn.quantities import ClassQoI\n",
    "from trulens.nn.attribution import IntegratedGradients\n",
    "from trulens.nn.attribution import Cut, OutputCut\n",
    "from trulens.utils.typing import ModelInputs\n",
    "\n",
    "task.wrapper = get_model_wrapper(task.model, input_shape=(None, task.tokenizer.model_max_length), device=task.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ed9c783-b745-4c6a-b674-d8b6935dd62d"
    }
   },
   "source": [
    "# Attributions\n",
    "\n",
    "Applying integrated gradents to the sentiment model is similar as in the prior notebooks except special considerations need to be made for the cuts used as the targets of the attribution (i.e. what do we want to assign importance to). As you may have noted above, the model takes as input integer indexes associated with tokens. As we cannot take gradient with respect to these, we use an alternative: the embedding representation of those same inputs. To instantiate trulens with this regard, we need to find inspect the layer names inside our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'roberta_embeddings_word_embeddings':\tEmbedding(50265, 768, padding_idx=1)\n",
      "'roberta_embeddings_position_embeddings':\tEmbedding(514, 768, padding_idx=1)\n",
      "'roberta_embeddings_token_type_embeddings':\tEmbedding(1, 768)\n",
      "'roberta_embeddings_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_embeddings_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_0_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_0_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_0_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_0_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_0_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_0_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_0_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_1_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_1_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_1_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_1_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_1_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_1_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_1_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_2_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_2_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_2_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_2_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_2_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_2_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_2_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_3_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_3_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_3_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_3_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_3_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_3_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_3_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_4_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_4_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_4_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_4_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_4_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_4_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_4_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_5_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_5_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_5_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_5_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_5_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_5_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_5_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_6_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_6_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_6_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_6_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_6_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_6_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_6_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_7_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_7_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_7_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_7_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_7_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_7_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_7_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_8_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_8_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_8_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_8_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_8_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_8_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_8_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_9_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_9_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_9_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_9_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_9_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_9_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_9_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_10_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_10_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_10_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_10_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_10_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_10_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_10_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_11_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_11_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_11_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_11_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_11_intermediate_intermediate_act_fn':\tGELUActivation()\n",
      "'roberta_encoder_layer_11_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_11_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'classifier_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'classifier_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'classifier_out_proj':\tLinear(in_features=768, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "task.wrapper.print_layer_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Above, `roberta_embeddings_word_embeddings` is the layer that produces a continuous representation of each input token so we will use that layer as the one defining the **distribution of interest**. While most neural NLP models contain a token embedding, the layer name will differ.\n",
    "\n",
    "The second thing to note is the form of model outputs. Specifically, outputs are structures which contain a 'logits' attribute that stores the model scores.\n",
    "\n",
    "Putting these things together, we instantiate `IntegratedGradients` to attribute each embedding dimension to the maximum class (i.e. the predicted class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "infl_max = IntegratedGradients(\n",
    "    model = task.wrapper,\n",
    "    doi_cut=Cut('roberta_embeddings_word_embeddings'),\n",
    "    qoi_cut=OutputCut(accessor=lambda o: o['logits'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively we can look at a particular class:\n",
    "\n",
    "infl_positive = IntegratedGradients(\n",
    "    model = task.wrapper,\n",
    "    doi_cut=Cut('roberta_embeddings_word_embeddings'),\n",
    "    qoi=ClassQoI(task.POSITIVE),\n",
    "    qoi_cut=OutputCut(accessor=lambda o: o['logits'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting attributions uses the same call as model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>(0.057) I(0.202) 'm(0.220)  so(0.279)  happy(0.506) !(0.106) </s>(-0.078) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) \n",
      "<s>(0.022) I(0.039) 'm(-0.143)  so(0.168)  sad(-0.019) !(-0.149) </s>(-0.044) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) \n",
      "<s>(-0.028) I(0.002)  cannot(-0.237)  tell(-0.018)  whether(0.125)  I(-0.065)  should(0.021)  be(-0.048)  happy(-0.133)  or(-0.156)  sad(-0.452) !(-0.161) </s>(0.001) \n",
      "<s>(0.041) me(-0.259) h(-0.384) </s>(-0.089) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) <pad>(0.000) \n"
     ]
    }
   ],
   "source": [
    "attrs = infl_max.attributions(**inputs)\n",
    "\n",
    "for token_ids, token_attr in zip(inputs['input_ids'], attrs):\n",
    "    for token_id, token_attr in zip(token_ids, token_attr):\n",
    "        # Not that each `word_attr` has a magnitude for each of the embedding\n",
    "        # dimensions, of which there are many. We aggregate them for easier\n",
    "        # interpretation and display.\n",
    "        attr = token_attr.sum()\n",
    "\n",
    "        word = task.tokenizer.decode(token_id)\n",
    "\n",
    "        print(f\"{word}({attr:0.3f})\", end=' ')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A listing as above is not very readable so Trulens comes with some utilities to present token influences a bit more concisely. First we need to set up a few parameters to make use of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QOI = MAX PREDICTION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>positive:&nbsp;<span title='0.057' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(247.68304707482457, 255.0, 247.68304707482457);'>&lt;s&gt;</span><span title='0.202' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(229.27583634853363, 255.0, 229.27583634853363);'>I</span><span title='0.220' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(226.89138069748878, 255.0, 226.89138069748878);'>&#x27;m</span>&nbsp;<span title='0.279' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(219.364106208086, 255.0, 219.364106208086);'>so</span>&nbsp;<span title='0.506' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(190.46714320778847, 255.0, 190.46714320778847);'>happy</span><span title='0.106' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(241.44961930811405, 255.0, 241.44961930811405);'>!</span><span title='-0.078' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 245.11291533708572, 245.11291533708572);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>negative:&nbsp;<span title='0.022' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(252.141924938187, 255.0, 252.141924938187);'>&lt;s&gt;</span><span title='0.039' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(249.98223150148988, 255.0, 249.98223150148988);'>I</span><span title='-0.143' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 236.80223688483238, 236.80223688483238);'>&#x27;m</span>&nbsp;<span title='0.168' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(233.54991160333157, 255.0, 233.54991160333157);'>so</span>&nbsp;<span title='-0.019' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 252.58222108706832, 252.58222108706832);'>sad</span><span title='-0.149' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 236.0615825280547, 236.0615825280547);'>!</span><span title='-0.044' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 249.4463519565761, 249.4463519565761);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>negative:&nbsp;<span title='-0.028' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 251.42857971601188, 251.42857971601188);'>&lt;s&gt;</span><span title='0.002' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(254.74594183266163, 255.0, 254.74594183266163);'>I</span>&nbsp;<span title='-0.237' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 224.8368138447404, 224.8368138447404);'>cannot</span>&nbsp;<span title='-0.018' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 252.68398105166852, 252.68398105166852);'>tell</span>&nbsp;<span title='0.125' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(239.07489873468876, 255.0, 239.07489873468876);'>whether</span>&nbsp;<span title='-0.065' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 246.72427777200937, 246.72427777200937);'>I</span>&nbsp;<span title='0.021' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(252.37579193897545, 255.0, 252.37579193897545);'>should</span>&nbsp;<span title='-0.048' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 248.90295783989131, 248.90295783989131);'>be</span>&nbsp;<span title='-0.133' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 238.0878921970725, 238.0878921970725);'>happy</span>&nbsp;<span title='-0.156' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 235.14230735599995, 235.14230735599995);'>or</span>&nbsp;<span title='-0.452' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 197.39933162927628, 197.39933162927628);'>sad</span><span title='-0.161' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 234.45207819342613, 234.45207819342613);'>!</span><span title='0.001' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(254.83282452682033, 255.0, 254.83282452682033);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>neutral:&nbsp;<span title='0.041' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(249.78517217561603, 255.0, 249.78517217561603);'>&lt;s&gt;</span><span title='-0.259' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 222.01264768838882, 222.01264768838882);'>me</span><span title='-0.384' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 206.05345465242863, 206.05345465242863);'>h</span><span title='-0.089' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 243.63598303869367, 243.63598303869367);'>&lt;/s&gt;</span></span><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QOI = POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>positive:&nbsp;<span title='-0.019' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 252.56002980284393, 252.56002980284393);'>&lt;s&gt;</span><span title='0.184' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(231.51043944060802, 255.0, 231.51043944060802);'>I</span><span title='0.505' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(190.57948037981987, 255.0, 190.57948037981987);'>&#x27;m</span>&nbsp;<span title='1.305' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(88.5709673166275, 255.0, 88.5709673166275);'>so</span>&nbsp;<span title='2.129' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(-16.483758687973022, 255.0, -16.483758687973022);'>happy</span><span title='0.715' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(163.87892872095108, 255.0, 163.87892872095108);'>!</span><span title='0.419' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(201.60088777542114, 255.0, 201.60088777542114);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>negative:&nbsp;<span title='-0.097' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 242.5963692739606, 242.5963692739606);'>&lt;s&gt;</span><span title='-0.001' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 254.88419432658702, 254.88419432658702);'>I</span><span title='0.179' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(232.19074543565512, 255.0, 232.19074543565512);'>&#x27;m</span>&nbsp;<span title='-0.264' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 221.29018485546112, 221.29018485546112);'>so</span>&nbsp;<span title='-0.763' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 157.69540652632713, 157.69540652632713);'>sad</span><span title='0.127' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(238.81316877901554, 255.0, 238.81316877901554);'>!</span><span title='0.285' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(218.69466572999954, 255.0, 218.69466572999954);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>negative:&nbsp;<span title='-0.031' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 251.08558542095125, 251.08558542095125);'>&lt;s&gt;</span><span title='-0.082' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 244.48287209495902, 244.48287209495902);'>I</span>&nbsp;<span title='-1.158' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 107.30368852615356, 107.30368852615356);'>cannot</span>&nbsp;<span title='-0.044' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 249.4150596857071, 249.4150596857071);'>tell</span>&nbsp;<span title='-0.706' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 164.9373771250248, 164.9373771250248);'>whether</span>&nbsp;<span title='0.095' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(242.93751496821642, 255.0, 242.93751496821642);'>I</span>&nbsp;<span title='0.279' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(219.40964676439762, 255.0, 219.40964676439762);'>should</span>&nbsp;<span title='0.391' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(205.1455883681774, 255.0, 205.1455883681774);'>be</span>&nbsp;<span title='1.559' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(56.23079627752304, 255.0, 56.23079627752304);'>happy</span>&nbsp;<span title='0.063' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(246.92863270640373, 255.0, 246.92863270640373);'>or</span>&nbsp;<span title='-0.514' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 189.4447396695614, 189.4447396695614);'>sad</span><span title='0.309' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(215.64184874296188, 255.0, 215.64184874296188);'>!</span><span title='-0.216' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 227.5144598633051, 227.5144598633051);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>neutral:&nbsp;<span title='-0.071' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 245.9774924442172, 245.9774924442172);'>&lt;s&gt;</span><span title='0.546' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(185.40966019034386, 255.0, 185.40966019034386);'>me</span><span title='0.202' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(229.2325433716178, 255.0, 229.2325433716178);'>h</span><span title='0.086' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(244.06341260299087, 255.0, 244.06341260299087);'>&lt;/s&gt;</span></span><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trulens.visualizations import NLP\n",
    "\n",
    "V = NLP(\n",
    "    wrapper=task.wrapper,\n",
    "    labels=task.labels,\n",
    "    decode=lambda x: task.tokenizer.decode(x),\n",
    "    tokenize=lambda sentences: ModelInputs(kwargs=task.tokenizer(sentences, padding=True, return_tensors='pt')).map(lambda t: t.to(task.device)),\n",
    "    # huggingface models can take as input the keyword args as per produced by their tokenizers.\n",
    "\n",
    "    input_accessor=lambda x: x.kwargs['input_ids'],\n",
    "    # for huggingface models, input/token ids are under input_ids key in the input dictionary\n",
    "\n",
    "    output_accessor=lambda x: x['logits'],\n",
    "    # and logits under 'logits' key in the output dictionary\n",
    "\n",
    "    hidden_tokens=set([task.tokenizer.pad_token_id])\n",
    "    # do not display these tokens\n",
    ")\n",
    "\n",
    "print(\"QOI = MAX PREDICTION\")\n",
    "display(V.token_attribution(sentences, infl_max))\n",
    "\n",
    "print(\"QOI = POSITIVE\")\n",
    "display(V.token_attribution(sentences, infl_positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "We see in the above results that special tokens such as the sentence end **&lt;/s&gt;** contributes are found to contribute a lot to the model outputs. While this may be useful in some contexts, we are more interested in the contributions of the actual words in these sentences. To focus on the words more, we need to adjust the **baseline** used in the integrated gradients computation. By default in the instantiation so far, the baseline for each token is a zero vector of the same shape as its embedding. By making the basaeline be identicaly to the explained instances on special tokens, we can rid their impact from our measurement. Trulens provides a utility for this purpose in terms of `token_baseline` which constructs for you the methods to compute the appropriate baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.utils.nlp import token_baseline\n",
    "\n",
    "inputs_baseline_ids, inputs_baseline_embeddings = token_baseline(\n",
    "    keep_tokens=set([task.tokenizer.cls_token_id, task.tokenizer.sep_token_id]),\n",
    "    # Which tokens to preserve.\n",
    "\n",
    "    replacement_token=task.tokenizer.pad_token_id,\n",
    "    # What to replace tokens with.\n",
    "\n",
    "    input_accessor=lambda x: x.kwargs['input_ids'],\n",
    "\n",
    "    ids_to_embeddings=task.model.get_input_embeddings()\n",
    "    # Callable to produce embeddings from token ids.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the baselines on some example sentences. The first method returned by `token_baseline` gives us token ids to inspect while the second gives us the embeddings of the baseline which we will pass to the attributions method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "originals= [\"<s>I'm so happy!</s><pad><pad><pad><pad><pad><pad>\", \"<s>I'm so sad!</s><pad><pad><pad><pad><pad><pad>\", '<s>I cannot tell whether I should be happy or sad!</s>', '<s>meh</s><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      "baselines= ['<s><pad><pad><pad><pad><pad></s><pad><pad><pad><pad><pad><pad>', '<s><pad><pad><pad><pad><pad></s><pad><pad><pad><pad><pad><pad>', '<s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>', '<s><pad><pad></s><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n"
     ]
    }
   ],
   "source": [
    "print(\"originals=\", task.tokenizer.batch_decode(inputs['input_ids']))\n",
    "\n",
    "baseline_word_ids = inputs_baseline_ids(model_inputs=ModelInputs(args=[], kwargs=inputs))\n",
    "print(\"baselines=\", task.tokenizer.batch_decode(baseline_word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QOI = POSITIVE WITH BASELINE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>positive:&nbsp;<span title='0.000' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 255.0, 255.0);'>&lt;s&gt;</span><span title='-0.297' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 217.12565392255783, 217.12565392255783);'>I</span><span title='0.708' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(164.76285248994827, 255.0, 164.76285248994827);'>&#x27;m</span>&nbsp;<span title='1.267' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(93.4041103720665, 255.0, 93.4041103720665);'>so</span>&nbsp;<span title='2.180' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(-22.937393188476562, 255.0, -22.937393188476562);'>happy</span><span title='0.422' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(201.15538828074932, 255.0, 201.15538828074932);'>!</span><span title='0.000' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 255.0, 255.0);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>negative:&nbsp;<span title='0.000' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 255.0, 255.0);'>&lt;s&gt;</span><span title='-0.033' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 250.80068288370967, 250.80068288370967);'>I</span><span title='-0.148' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 236.1368963867426, 236.1368963867426);'>&#x27;m</span>&nbsp;<span title='-0.616' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 176.46940112113953, 176.46940112113953);'>so</span>&nbsp;<span title='-0.755' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 158.7597218155861, 158.7597218155861);'>sad</span><span title='-0.418' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 201.6704848408699, 201.6704848408699);'>!</span><span title='0.000' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 255.0, 255.0);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>negative:&nbsp;<span title='0.000' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 255.0, 255.0);'>&lt;s&gt;</span><span title='-0.082' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 244.59380809217691, 244.59380809217691);'>I</span>&nbsp;<span title='-0.568' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 182.6339167356491, 182.6339167356491);'>cannot</span>&nbsp;<span title='-0.053' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 248.29621019773185, 248.29621019773185);'>tell</span>&nbsp;<span title='-0.543' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 185.82351118326187, 185.82351118326187);'>whether</span>&nbsp;<span title='0.318' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(214.4155177474022, 255.0, 214.4155177474022);'>I</span>&nbsp;<span title='0.100' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(242.24157756194472, 255.0, 242.24157756194472);'>should</span>&nbsp;<span title='0.359' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(209.26762238144875, 255.0, 209.26762238144875);'>be</span>&nbsp;<span title='0.842' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(147.66522154211998, 255.0, 147.66522154211998);'>happy</span>&nbsp;<span title='0.117' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(240.13791164383292, 255.0, 240.13791164383292);'>or</span>&nbsp;<span title='-0.523' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 188.3174465596676, 188.3174465596676);'>sad</span><span title='-0.188' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 231.07558697462082, 231.07558697462082);'>!</span><span title='0.000' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 255.0, 255.0);'>&lt;/s&gt;</span></span><br/><br/><span style='padding: 2px; margin: 2px; background: gray; border-radius: 4px;'>neutral:&nbsp;<span title='0.000' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 255.0, 255.0);'>&lt;s&gt;</span><span title='0.372' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(207.56098195910454, 255.0, 207.56098195910454);'>me</span><span title='-0.778' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 155.8505067229271, 155.8505067229271);'>h</span><span title='0.000' style='margin: 1px; padding: 1px; border-radius: 4px; background: black; color: rgb(255.0, 255.0, 255.0);'>&lt;/s&gt;</span></span><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infl_positive_baseline = IntegratedGradients(\n",
    "    model = task.wrapper,\n",
    "    resolution=50,\n",
    "    baseline = inputs_baseline_embeddings,\n",
    "    doi_cut=Cut('roberta_embeddings_word_embeddings'),\n",
    "    qoi=ClassQoI(task.POSITIVE),\n",
    "    qoi_cut=OutputCut(accessor=lambda o: o['logits'])\n",
    ")\n",
    "\n",
    "print(\"QOI = POSITIVE WITH BASELINE\")\n",
    "display(V.token_attribution(sentences, infl_positive_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the baseline eliminated the measurement of contribution of the special tokens."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "51eb71198507ab2c2a4108a27eda9d9658549732e67153fc0e371d8439827db7"
  },
  "kernelspec": {
   "display_name": "test-fresh-11-29",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
