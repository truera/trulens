{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "from typing import Set\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Model\n",
    "\n",
    "[Huggingface](https://huggingface.co/models) offers a variety of pre-trained NLP models to explore. We exemplify in this notebook a [transformer-based twitter sentiment classification model](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment). Before getting started, familiarize yourself with the general Truera API as demonstrated in the [intro notebook using pytorch](intro_demo_pytorch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Wrap all of the necessary components.\n",
    "class TwitterSentiment:\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "    NEGATIVE = labels.index('negative')\n",
    "    NEUTRAL = labels.index('neutral')\n",
    "    POSITIVE = labels.index('positive')\n",
    "\n",
    "task = TwitterSentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model quantifies tweets (or really any text you give it) according to its sentiment: positive, negative, or neutral. Lets try it out on some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   0,  100,  437,   98, 1372,  328,    2,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   0,  100,  437,   98, 5074,  328,    2,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   0,  100, 1395, 1137,  549,   38,  197,   28, 1372,   50, 5074,  328,\n",
      "            2],\n",
      "        [   0, 1794,  298,    2,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "['<s>', 'I', \"'m\", ' so', ' happy', '!', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<s>', 'I', \"'m\", ' so', ' sad', '!', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<s>', 'I', ' cannot', ' tell', ' whether', ' I', ' should', ' be', ' happy', ' or', ' sad', '!', '</s>', '<s>', 'me', 'h', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I'm so happy!\", \"I'm so sad!\", \"I cannot tell whether I should be happy or sad!\", \"meh\"]\n",
    "\n",
    "# Input sentences need to be tokenized first.\n",
    "\n",
    "inputs = task.tokenizer(sentences, padding=True, return_tensors=\"pt\") # pt refers to pytorch tensor\n",
    "\n",
    "# The tokenizer gives us vocabulary indexes for each input token (in this case,\n",
    "# words and some word parts like the \"'m\" part of \"I'm\" are tokens).\n",
    "\n",
    "print(inputs)\n",
    "\n",
    "# Decode helps inspecting the tokenization produced:\n",
    "\n",
    "print(task.tokenizer.batch_decode(torch.flatten(inputs['input_ids'])))\n",
    "# Normally decode would give us a single string for each sentence but we would\n",
    "# not be able to see some of the non-word tokens there. Flattening first gives\n",
    "# us a string for each input_id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating huggingface models is straight-forward if we use the structure produced by the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-2.3217, -0.8764,  4.0706],\n",
      "        [ 2.5737, -0.4016, -2.1465],\n",
      "        [ 0.5973,  0.3778, -0.7691],\n",
      "        [-0.2267,  0.6011, -0.2009]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "[-2.3217378 -0.8763628  4.0705967] positive I'm so happy!\n",
      "[ 2.5736785  -0.40158105 -2.1465425 ] negative I'm so sad!\n",
      "[ 0.59733623  0.37779403 -0.7691068 ] negative I cannot tell whether I should be happy or sad!\n",
      "[-0.22674142  0.601109   -0.20089385] neutral meh\n"
     ]
    }
   ],
   "source": [
    "outputs = task.model(**inputs)\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "# From logits we can extract the most likely class for each sentence and its readable label.\n",
    "\n",
    "predictions = [task.labels[i] for i in outputs.logits.argmax(axis=1)]\n",
    "\n",
    "for sentence, logits, prediction in zip(sentences, outputs.logits, predictions):\n",
    "    print(logits.detach().numpy(), prediction, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Wrapper\n",
    "\n",
    "As in the prior notebooks, we need to wrap the pytorch model with the appropriate Trulens functionality. Here we specify the maximum input size (in terms of tokens) each tweet may have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Detected pytorch backend for <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>.\n",
      "INFO: Using backend Backend.PYTORCH.\n",
      "INFO: If this seems incorrect, you can force the correct backend by passing the `backend` parameter directly into your get_model_wrapper call.\n",
      "DEBUG: Input dtype was not passed in. Defaulting to `torch.float32`.\n"
     ]
    }
   ],
   "source": [
    "from trulens.nn.models import get_model_wrapper\n",
    "from trulens.nn.quantities import LambdaQoI, ClassQoI\n",
    "from trulens.nn.attribution import InputAttribution, InternalInfluence\n",
    "from trulens.nn.attribution import IntegratedGradients\n",
    "from trulens.nn.attribution import Cut, InputCut, OutputCut\n",
    "from trulens.nn.distributions import LinearDoi, PointDoi\n",
    "from trulens.utils.typing import ModelInputs\n",
    "\n",
    "task.wrapper = get_model_wrapper(task.model, input_shape=(None, task.tokenizer.model_max_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ed9c783-b745-4c6a-b674-d8b6935dd62d"
    }
   },
   "source": [
    "# Attributions\n",
    "\n",
    "Applying integrated gradents to the sentiment model is similar as in the prior notebooks except special considerations need to be made for the cuts used as the targets of the attribution (i.e. what do we want to assign importance to). As you may have noted above, the model takes as input integer indexes associated with tokens. As we cannot take gradient with respect to these, we use an alternative: the embedding representation of those same inputs. To instantiate trulens with this regard, we need to find inspect the layer names inside our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'roberta_embeddings_word_embeddings':\tEmbedding(50265, 768, padding_idx=1)\n",
      "'roberta_embeddings_position_embeddings':\tEmbedding(514, 768, padding_idx=1)\n",
      "'roberta_embeddings_token_type_embeddings':\tEmbedding(1, 768)\n",
      "'roberta_embeddings_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_embeddings_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_0_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_0_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_0_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_0_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_0_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_0_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_0_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_1_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_1_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_1_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_1_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_1_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_1_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_1_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_2_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_2_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_2_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_2_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_2_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_2_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_2_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_3_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_3_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_3_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_3_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_3_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_3_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_3_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_4_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_4_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_4_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_4_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_4_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_4_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_4_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_5_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_5_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_5_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_5_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_5_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_5_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_5_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_6_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_6_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_6_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_6_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_6_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_6_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_6_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_7_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_7_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_7_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_7_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_7_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_7_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_7_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_8_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_8_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_8_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_8_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_8_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_8_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_8_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_9_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_9_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_9_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_9_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_9_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_9_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_9_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_10_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_10_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_10_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_10_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_10_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_10_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_10_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_11_attention_self_query':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_attention_self_key':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_attention_self_value':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_attention_self_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_11_attention_output_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_attention_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_11_attention_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'roberta_encoder_layer_11_intermediate_dense':\tLinear(in_features=768, out_features=3072, bias=True)\n",
      "'roberta_encoder_layer_11_output_dense':\tLinear(in_features=3072, out_features=768, bias=True)\n",
      "'roberta_encoder_layer_11_output_LayerNorm':\tLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "'roberta_encoder_layer_11_output_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'classifier_dense':\tLinear(in_features=768, out_features=768, bias=True)\n",
      "'classifier_dropout':\tDropout(p=0.1, inplace=False)\n",
      "'classifier_out_proj':\tLinear(in_features=768, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "task.wrapper.print_layer_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Above, `roberta_embeddings_word_embeddings` is the layer that produces a continuous representation of each input token so we will use that layer as the one defining the **distribution of interest**. While most neural NLP models contain a token embedding, the layer name will differ.\n",
    "\n",
    "The second thing to note is the form of model outputs. Specifically, outputs are structures which contain a 'logits' attribute that stores the model scores.\n",
    "\n",
    "Putting these things together, we instantiate `IntegratedGradients` to attribute each embedding dimension to the maximum class (i.e. the predicted class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "qoi_cut = OutputCut(accessor=lambda o: o['logits'])\n",
    "\n",
    "infl_max = IntegratedGradients(\n",
    "    model = task.wrapper,\n",
    "    doi_cut=Cut('roberta_embeddings_word_embeddings'),\n",
    "    qoi_cut=qoi_cut\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively we can look at a particular class:\n",
    "\n",
    "infl_positive = IntegratedGradients(\n",
    "    model = task.wrapper,\n",
    "    doi_cut=Cut('roberta_embeddings_word_embeddings'),\n",
    "    qoi=ClassQoI(task.POSITIVE),\n",
    "    qoi_cut=qoi_cut\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting attributions uses the same call as model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>(0.01430558506399393) I(0.1570846438407898) 'm(0.2109372615814209)  so(0.16590110957622528)  happy(0.3861175775527954) !(0.033557694405317307) </s>(0.08000269532203674) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) \n",
      "<s>(-0.023036574944853783) I(0.14019989967346191) 'm(0.06912591308355331)  so(0.32284340262413025)  sad(-0.09265868365764618) !(-0.1359325796365738) </s>(-0.6459164619445801) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) \n",
      "<s>(-0.033364128321409225) I(-0.028419066220521927)  cannot(-0.4824056029319763)  tell(-0.03216502070426941)  whether(0.11183696985244751)  I(-0.06631225347518921)  should(-0.02624373510479927)  be(-0.118565633893013)  happy(-0.13628575205802917)  or(-0.09041191637516022)  sad(-0.30004382133483887) !(-0.2053295373916626) </s>(-0.5073875188827515) \n",
      "<s>(-0.07814183086156845) me(-0.15589091181755066) h(-0.15215334296226501) </s>(0.05180875211954117) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) <pad>(0.0) \n"
     ]
    }
   ],
   "source": [
    "attrs = infl_max.attributions(**inputs)\n",
    "\n",
    "for token_ids, token_attr in zip(inputs['input_ids'], attrs):\n",
    "    for token_id, token_attr in zip(token_ids, token_attr):\n",
    "        # Not that each `word_attr` has a magnitude for each of the embedding\n",
    "        # dimensions, of which there are many. We aggregate them for easier\n",
    "        # interpretation and display.\n",
    "        attr = token_attr.sum()\n",
    "\n",
    "        word = task.tokenizer.decode(token_id)\n",
    "\n",
    "        print(f\"{word}({attr})\", end=' ')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A listing as above is not very readable so Trulens comes with some utilities to present token influences a bit more concisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAX'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "positive: <span style='color: rgb(254.23854745924473, 255.0, 254.23854745924473);'>&lt;s&gt;</span> <span style='color: rgb(246.14879770204425, 255.0, 246.14879770204425);'>I</span> <span style='color: rgb(245.70139260962605, 255.0, 245.70139260962605);'>&#x27;m</span> <span style='color: rgb(255.0, 240.2330670878291, 240.2330670878291);'> so</span> <span style='color: rgb(255.0, 247.13965105824172, 247.13965105824172);'> happy</span> <span style='color: rgb(251.98140872642398, 255.0, 251.98140872642398);'>!</span> <span style='color: rgb(251.8728877371177, 255.0, 251.8728877371177);'>&lt;/s&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "negative: <span style='color: rgb(244.9613538198173, 255.0, 244.9613538198173);'>&lt;s&gt;</span> <span style='color: rgb(239.7719257324934, 255.0, 239.7719257324934);'>I</span> <span style='color: rgb(235.61439022421837, 255.0, 235.61439022421837);'>&#x27;m</span> <span style='color: rgb(106.89470887184143, 255.0, 106.89470887184143);'> so</span> <span style='color: rgb(54.8655903339386, 255.0, 54.8655903339386);'> sad</span> <span style='color: rgb(255.0, 244.43799175322056, 244.43799175322056);'>!</span> <span style='color: rgb(255.0, 192.0517911761999, 192.0517911761999);'>&lt;/s&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "negative: <span style='color: rgb(255.0, 252.79329192359, 252.79329192359);'>&lt;s&gt;</span> <span style='color: rgb(255.0, 242.90205052122474, 242.90205052122474);'>I</span> <span style='color: rgb(255.0, 177.660211622715, 177.660211622715);'> cannot</span> <span style='color: rgb(254.33854004368186, 255.0, 254.33854004368186);'> tell</span> <span style='color: rgb(255.0, 252.11683535948396, 252.11683535948396);'> whether</span> <span style='color: rgb(255.0, 251.55480894260108, 251.55480894260108);'> I</span> <span style='color: rgb(255.0, 251.84701088815928, 251.84701088815928);'> should</span> <span style='color: rgb(255.0, 245.0815024226904, 245.0815024226904);'> be</span> <span style='color: rgb(255.0, 225.97885966300964, 225.97885966300964);'> happy</span> <span style='color: rgb(255.0, 240.6993410177529, 240.6993410177529);'> or</span> <span style='color: rgb(255.0, 225.85391096770763, 225.85391096770763);'> sad</span> <span style='color: rgb(255.0, 233.08869995176792, 233.08869995176792);'>!</span> <span style='color: rgb(255.0, 234.34045538306236, 234.34045538306236);'>&lt;/s&gt;</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "neutral: <span style='color: rgb(247.82107656821609, 255.0, 247.82107656821609);'>&lt;s&gt;</span> <span style='color: rgb(255.0, 254.54539809376, 254.54539809376);'>me</span> <span style='color: rgb(255.0, 215.76983347535133, 215.76983347535133);'>h</span> <span style='color: rgb(255.0, 225.45758083462715, 225.45758083462715);'>&lt;/s&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "positive: <span style='color: rgb(255.0, 252.49011117964983, 252.49011117964983);'>&lt;s&gt;</span> <span style='color: rgb(234.61392670869827, 255.0, 234.61392670869827);'>I</span> <span style='color: rgb(206.01555168628693, 255.0, 206.01555168628693);'>&#x27;m</span> <span style='color: rgb(154.247387945652, 255.0, 154.247387945652);'> so</span> <span style='color: rgb(85.5169951915741, 255.0, 85.5169951915741);'> happy</span> <span style='color: rgb(197.09770381450653, 255.0, 197.09770381450653);'>!</span> <span style='color: rgb(228.55966597795486, 255.0, 228.55966597795486);'>&lt;/s&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "negative: <span style='color: rgb(255.0, 253.65165588911623, 253.65165588911623);'>&lt;s&gt;</span> <span style='color: rgb(255.0, 248.27708154916763, 248.27708154916763);'>I</span> <span style='color: rgb(233.81768703460693, 255.0, 233.81768703460693);'>&#x27;m</span> <span style='color: rgb(255.0, 226.2422102317214, 226.2422102317214);'> so</span> <span style='color: rgb(255.0, 178.7289422750473, 178.7289422750473);'> sad</span> <span style='color: rgb(232.30608064681292, 255.0, 232.30608064681292);'>!</span> <span style='color: rgb(255.0, 216.5991845726967, 216.5991845726967);'>&lt;/s&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "negative: <span style='color: rgb(255.0, 249.3259729910642, 249.3259729910642);'>&lt;s&gt;</span> <span style='color: rgb(255.0, 246.21349018067122, 246.21349018067122);'>I</span> <span style='color: rgb(255.0, 158.23812380433083, 158.23812380433083);'> cannot</span> <span style='color: rgb(255.0, 244.11389954388142, 244.11389954388142);'> tell</span> <span style='color: rgb(255.0, 191.44965648651123, 191.44965648651123);'> whether</span> <span style='color: rgb(240.3447924926877, 255.0, 240.3447924926877);'> I</span> <span style='color: rgb(238.59019294381142, 255.0, 238.59019294381142);'> should</span> <span style='color: rgb(226.24484919011593, 255.0, 226.24484919011593);'> be</span> <span style='color: rgb(146.96965366601944, 255.0, 146.96965366601944);'> happy</span> <span style='color: rgb(249.55677593126893, 255.0, 249.55677593126893);'> or</span> <span style='color: rgb(255.0, 201.24161705374718, 201.24161705374718);'> sad</span> <span style='color: rgb(212.51351460814476, 255.0, 212.51351460814476);'>!</span> <span style='color: rgb(229.7504384815693, 255.0, 229.7504384815693);'>&lt;/s&gt;</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "neutral: <span style='color: rgb(255.0, 251.07493103016168, 251.07493103016168);'>&lt;s&gt;</span> <span style='color: rgb(206.22566521167755, 255.0, 206.22566521167755);'>me</span> <span style='color: rgb(228.40160965919495, 255.0, 228.40160965919495);'>h</span> <span style='color: rgb(239.732469599694, 255.0, 239.732469599694);'>&lt;/s&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> <span style='color: rgb(255.0, 255.0, 255.0);'>&lt;pad&gt;</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "def vis(labels, model, tokenizer, sentences, ig):\n",
    "\n",
    "    inputs = tokenizer(sentences, padding=True, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    attrs = ig.attributions(**inputs)\n",
    "\n",
    "    for i, (sentence_word_id, attr, logits) in enumerate(zip(inputs['input_ids'], attrs, outputs['logits'])):\n",
    "\n",
    "        logits = logits.detach().numpy()\n",
    "        pred = logits.argmax()\n",
    "        pred_name = labels[pred]\n",
    "\n",
    "        sent = f\"{pred_name}: \"\n",
    "\n",
    "        for word_id, attr in zip(sentence_word_id, attr):\n",
    "            word = tokenizer.decode(word_id)\n",
    "            mag = attr.sum()\n",
    "            red = 0.0\n",
    "            green = 0.0\n",
    "            if mag > 0:\n",
    "                green = 1.0 # 0.5 + mag * 0.5\n",
    "                red = 1.0 - mag * 0.5\n",
    "            else:\n",
    "                red = 1.0\n",
    "                green = 1.0 + mag * 0.5\n",
    "                #red = 0.5 - mag * 0.5\n",
    "\n",
    "            blue = min(red, green)\n",
    "            # blue = 1.0 - max(red, green)\n",
    "\n",
    "            sent += f\"<span style='color: rgb({red*255}, {green*255}, {blue*255});'>{html.escape(word)}</span> \"\n",
    "\n",
    "        display(HTML(sent))\n",
    "\n",
    "display(\"MAX\")\n",
    "vis(task.labels, task.model, task.tokenizer, sentences, infl_max)\n",
    "\n",
    "display(\"POSITIVE\")\n",
    "vis(task.labels, task.model, task.tokenizer, sentences, infl_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "We see in the above results that special tokens such as the sentence end **&lt;/s&gt;** contributes are found to contribute a lot to the model outputs. While this may be useful in some contexts, we are more interested in the contributions of the actual words in these sentences. To focus on the words more, we need to adjust the **baseline** used in the integrated gradients computation. By default in the instantiation so far, the baseline for each token is a zero vector of the same shape as its embedding. By making the basaeline be identicaly to the explained instances on special tokens, we can rid their impact from our measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "6a7dd470-8385-4028-8b44-3f1e427af157"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TRULENS_BACKEND']=\"pytorch\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from trulens.nn.models import get_model_wrapper\n",
    "\n",
    "from trulens.nn.quantities import LambdaQoI, ClassQoI\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "from typing import Set\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "from trulens.nn.attribution import InputAttribution, InternalInfluence\n",
    "from trulens.nn.attribution import IntegratedGradients\n",
    "from trulens.nn.attribution import Cut, InputCut, OutputCut\n",
    "from trulens.nn.distributions import LinearDoi, PointDoi\n",
    "from trulens.utils.typing import ModelInputs\n",
    "\n",
    "def as_tensor(thing):\n",
    "    if isinstance(thing, torch.Tensor):\n",
    "        return torch.clone(thing)\n",
    "    else:\n",
    "        return torch.Tensor(thing).type_as(thing.dtype).device(thing.device)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "bert = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
    "\n",
    "bt = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "sentences = [\"I'm so happy!\", \"I'm so sad!\"]\n",
    "inputs = bt(sentences, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "inputs['input_ids'] = inputs['input_ids'].to(device)\n",
    "inputs['attention_mask'] = inputs['attention_mask'].to(device)\n",
    "\n",
    "# outs = bert(**inputs)\n",
    "\n",
    "model = get_model_wrapper(bert, input_shape=(None, bt.model_max_length))\n",
    "model.print_layer_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_baseline(keep_tokens: Set[int], replacement_token: int, ids_to_embeddings):\n",
    "    \"\"\"\n",
    "    Replace all tokens except those in the keep_tokens set with the specified\n",
    "    replacement token. Returns a methods\n",
    "    \"\"\"\n",
    "\n",
    "    def base_ids(z=None, model_inputs=None):\n",
    "        input_ids = model_inputs.kwargs['input_ids']\n",
    "        ids = (1 - sum(input_ids == v for v in keep_tokens)).bool()\n",
    "\n",
    "        input_ids[ids] = replacement_token\n",
    "\n",
    "        return input_ids\n",
    "\n",
    "    def base_embeddings(z=None, model_inputs=None):\n",
    "        input_ids = base_ids(z, model_inputs)\n",
    "\n",
    "        return ids_to_embeddings(input_ids)\n",
    "\n",
    "    return base_ids, base_embeddings\n",
    "\n",
    "inputs_baseline_ids, inputs_baseline_embeddings = token_baseline(\n",
    "    keep_tokens=set([task.tokenizer.cls_token_id, task.tokenizer.sep_token_id]),\n",
    "    replacement_token=task.tokenizer.pad_token_id,\n",
    "    ids_to_embeddings=task.model.get_input_embeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"I'm so happy!\", \"I'm so sad!\", \"I cannot tell whether I should be happy or sad!\"]\n",
    "\n",
    "model_input_tensors = ModelInputs(args=[], kwargs=inputs).map(task.wrapper._to_tensor)\n",
    "\n",
    "inputs = task.tokenizer(sentences, padding=True, return_tensors=\"pt\")\n",
    "print(task.tokenizer.batch_decode(inputs['input_ids']))\n",
    "baseline_word_ids = inputs_baseline_ids(model_inputs=ModelInputs(args=[], kwargs=inputs).map(as_tensor))\n",
    "baseline_embeddings = inputs_baseline_embeddings(model_inputs=ModelInputs(args=[], kwargs=inputs).map(as_tensor))\n",
    "print(task.tokenizer.batch_decode(baseline_word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(inputs['input_ids'])\n",
    "\n",
    "task.wrapper = get_model_wrapper(task.model, input_shape=(None, task.tokenizer.model_max_length))\n",
    "task.wrapper.print_layer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infl = IntegratedGradients(\n",
    "    model = task.wrapper,\n",
    "    resolution=50,\n",
    "    baseline = inputs_baseline,\n",
    "    doi_cut=Cut('roberta_embeddings_word_embeddings'),\n",
    "    qoi=ClassQoI(task.POSITIVE),\n",
    "    qoi_cut=OutputCut(accessor=lambda o: o['logits'])\n",
    ")\n",
    "attrs_input = infl.attributions(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "class ToySentiment(nn.Module):\n",
    "    @staticmethod\n",
    "    def from_pretrained(model_code_path: Path) -> 'ToySentiment':\n",
    "        # Not strictly necessary to load or save given fixed parameters can be populated, but \n",
    "        # implementing this for better integration testing.\n",
    "        model = ToySentiment()\n",
    "        model.load_state_dict(torch.load(model_code_path))\n",
    "\n",
    "    def to_pretrained(self, model_code_path: Path) -> None:\n",
    "        torch.save(self.state_dict(), model_code_path)\n",
    "\n",
    "    def set_parameters(self) -> None:\n",
    "        \"\"\"Set model parameters as per fixed specification.\"\"\"\n",
    "\n",
    "        Wi = torch.zeros_like(self.lstm.weight_ih_l0) + 0.1\n",
    "        bi = torch.zeros_like(self.lstm.bias_ih_l0) + 0.1\n",
    "        Wh = torch.zeros_like(self.lstm.weight_hh_l0) + 0.1\n",
    "        bh = torch.zeros_like(self.lstm.bias_hh_l0) + 0.1\n",
    "\n",
    "        big = 20.0 # Multipliers to help dealing with LSTM sigmoids.\n",
    "        half = 8.0 # Intention here is that sigmoid((x*big) - half) is ~0 if x is ~0; and\n",
    "                    # ~1 when indicator is >~ 1.\n",
    "\n",
    "        hs = self.hidden_size\n",
    "\n",
    "        sneutral = 0\n",
    "        sgood = 1\n",
    "        sbad = 2\n",
    "        sconfused = 3\n",
    "\n",
    "        wneutral = self.vocab['neutral']\n",
    "        wgood = self.vocab['good']\n",
    "        wbad = self.vocab['bad']\n",
    "        \n",
    "        # make sure c gate is always big\n",
    "        bi[0:hs*3] = 100.0\n",
    "        bh[0:hs*3] = 100.0\n",
    "\n",
    "        # o gate weights:\n",
    "        Wi[3*hs,   wneutral] = big # read neutral word\n",
    "        Wi[3*hs+1, wgood] = big # read good word\n",
    "        Wi[3*hs+2, wbad] = big # read bad word\n",
    "        Wh[3*hs,   sneutral] = big # keep prior neutral, good, bad states\n",
    "        Wh[3*hs+1, sgood] = big # \n",
    "        Wh[3*hs+2, sbad] = big #\n",
    "        bi[3*hs:4*hs] = -half # sigmoid will be 0 unless one of the three words was read\n",
    "\n",
    "        # set \"good to bad\" confused if prior was good, and input was bad\n",
    "        Wh[3*hs+3, sgood] = big    # (prior state was good\n",
    "        Wi[3*hs+3, wbad] = big    #  and input was bad)\n",
    "        Wh[3*hs+3, sconfused] = 2*big  # or (was already in this confused state)\n",
    "        bh[3*hs+3] = -(half*2) # Want at least 2 of first two to fire, or just the last one to fire.\n",
    "\n",
    "        # set \"bad to good\" confused if prior was bad, and input was good\n",
    "        Wh[3*hs+4, sbad] = big     # (prior state was bad\n",
    "        Wi[3*hs+4, wgood] = big     #  and input was good)\n",
    "        Wh[3*hs+4, sconfused] = 2*big   # or (was already confused)\n",
    "        bh[3*hs+4] = -(half*2)  #\n",
    "\n",
    "        self.lstm.weight_hh_l0 = nn.Parameter(Wh)\n",
    "        self.lstm.bias_hh_l0 = nn.Parameter(bh)\n",
    "        self.lstm.weight_ih_l0 = nn.Parameter(Wi)\n",
    "        self.lstm.bias_ih_l0 = nn.Parameter(bi)\n",
    "\n",
    "        self.embedding.weight = nn.Parameter(torch.eye(self.emb_size))\n",
    "\n",
    "        self.lin.weight = nn.Parameter(torch.tensor(\n",
    "            [\n",
    "                [10.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 20.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 20.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 30.0, 30.0]\n",
    "            ]\n",
    "        ))\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "        self.vocab = {\"[UNKNOWN]\": 0, \"neutral\": 1, \"good\": 2, \"bad\": 3}\n",
    "\n",
    "        self.emb_size = len(self.vocab)\n",
    "\n",
    "        self.hidden_size = 5\n",
    "        # 5 states, one for neutral, one for positive, one for negative, and two for confused. Requiring two\n",
    "        # confused states for simplicity of the model; it is easier to encode semantics of confusion based on \n",
    "        # which initial positive/negative state was set first.\n",
    "\n",
    "        # Identity embedding, each vocab word has its own dimension where its presence is encoded.\n",
    "        self.embedding = nn.Embedding(\n",
    "            # padding_idx=0, \n",
    "            embedding_dim=self.emb_size, \n",
    "            num_embeddings=self.emb_size,\n",
    "            padding_idx=None,\n",
    "            max_norm=None,\n",
    "            norm_type=None\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.emb_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Linear layer to combine the two types of confused state and weight things so that\n",
    "        # confused outweighs positive and negative, while positive and negative outweigh neutral \n",
    "        # if more than one of these states is set.\n",
    "        self.lin = torch.nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=4,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        # self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        # Finally add a softmax for classification.\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        # self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.set_parameters()\n",
    "\n",
    "    def forward(self, word_ids: torch.Tensor, embeds=None) -> torch.Tensor:\n",
    "        if word_ids is not None:\n",
    "            batch_size = word_ids.shape[0]\n",
    "        else:\n",
    "            batch_size = embeds.shape[0]\n",
    "\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        h0[0, 0, 0] = 1.0 # initial state is neutral\n",
    "        c0 = torch.zeros(1, batch_size, self.hidden_size)\n",
    "\n",
    "        if embeds is None:\n",
    "            embeds = self.embedding(word_ids)\n",
    "            \n",
    "        embeds.retain_grad()\n",
    "\n",
    "        out, (hn, cn) = self.lstm(embeds, (h0, c0))\n",
    "        hn = hn[0,:,:]\n",
    "\n",
    "        lin_out = self.lin(hn)\n",
    "\n",
    "        probits = self.softmax(lin_out)\n",
    "        # preds = torch.argmax(probits, axis=1)\n",
    "        # pred_prob = torch.gather(probits, dim=1, index=preds[:,None])\n",
    "        # pred_prob.backward(torch.ones_like(pred_prob))\n",
    "        # attr = embeds.grad\n",
    "        # return preds, probits, attr\n",
    "\n",
    "        return probits\n",
    "\n",
    "\n",
    "    def input_of_text(self, texts: List[str]) -> torch.Tensor:\n",
    "        tokens = [self.tokenizer(text) for text in texts]\n",
    "\n",
    "        word_ids = [[(self.vocab[t] if t in self.vocab else 0) for t in token] for token in tokens]\n",
    "\n",
    "        return torch.Tensor(word_ids).int()\n",
    "\n",
    "\n",
    "def generate_dataset(n, l):\n",
    "    \"\"\"Generate random sentiment sentences and their labels.\"\"\"\n",
    "\n",
    "    ret = []\n",
    "    cls = []\n",
    "    for i in range(n):\n",
    "        sent = []\n",
    "        while len(sent) < l:\n",
    "            r = random.random()\n",
    "\n",
    "            word = \"neutral\"\n",
    "\n",
    "            if r > 0.9 and len(sent) > 0:\n",
    "                continue\n",
    "            elif r > 0.8:\n",
    "                word = \"good\"\n",
    "            elif r > 0.7:\n",
    "                word = \"bad\"\n",
    "\n",
    "            sent.append(word)\n",
    "\n",
    "        ret.append(\" \".join(sent))\n",
    "\n",
    "        gt = 0 # neutral\n",
    "        if \"good\" in sent and \"bad\" in sent:\n",
    "            gt = 3 # confused\n",
    "        elif \"good\" in sent:\n",
    "            gt = 1 # positive\n",
    "        elif \"bad\" in sent:\n",
    "            gt = 2 # negative\n",
    "\n",
    "        cls.append(gt)\n",
    "\n",
    "    return pd.DataFrame(dict(sentence=ret, sentiment=cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = ToySentiment()\n",
    "device = 'cpu'\n",
    "# Produce a wrapped model from the pytorch model.\n",
    "model = get_model_wrapper(pt, input_shape=(4), device=device, input_dtype=int, )\n",
    "\n",
    "# test_data = generate_dataset(5, 4)\n",
    "\n",
    "test_data = generate_dataset(16, 4)\n",
    "\n",
    "x_sentences = test_data['sentence']\n",
    "x_tokens = [pt.tokenizer(s) for s in x_sentences]\n",
    "x_ids = pt.input_of_text(x_sentences)\n",
    "labels = test_data['sentiment']\n",
    "\n",
    "# TODO: define \"EmbeddedInfluence\" for InputInfluence except with an initial embedding layer and initialize internal influence as below:\n",
    "\n",
    "\n",
    "cls_names = {0:\"neutral\", 1:\"positive\", 2:\"negative\", 3:\"confused\"}\n",
    "\n",
    "infl = {}\n",
    "attrs = {}\n",
    "for cls in [0,1,2,3]:\n",
    "    infl[cls] = InternalInfluence(\n",
    "        model,\n",
    "        cuts=(Cut(\"embedding\"), Cut(\"softmax\")),\n",
    "        #doi=PointDoi(cut=Cut(\"embedding\")),\n",
    "        doi=LinearDoi(cut=Cut(\"embedding\"), resolution=100),\n",
    "        qoi=ClassQoI(cls),\n",
    "        multiply_activation=False\n",
    "    )\n",
    "    attrs[cls] = infl[cls].attributions(x_ids)\n",
    "\n",
    "\n",
    "preds = pt(x_ids)\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, (words, label, pred) in enumerate(zip(x_tokens, labels, preds)):\n",
    "    data.append([f\"<b>GT={cls_names[label]} PRED={cls_names[pred.argmax().item()]}</b>\"] + [\" \".join(words)])\n",
    "\n",
    "    for cls in [0,1,2,3]:\n",
    "        # print(f\"{cls_names[cls]} | \", end='')\n",
    "\n",
    "        row = [cls_names[cls]]\n",
    "\n",
    "        sent = \"\"\n",
    "\n",
    "        for word, attr in zip(words, attrs[cls][i]):\n",
    "            # print(f\"{word}[{attr.sum()}] \", end=\"\")\n",
    "            mag = attr.sum()\n",
    "            red = 0.0\n",
    "            green = 0.0\n",
    "            if mag > 0:\n",
    "                green = 1.0 # 0.5 + mag * 0.5\n",
    "                red = 1.0 - mag * 0.5\n",
    "            else:\n",
    "                red = 1.0\n",
    "                green = 1.0 + mag * 0.5\n",
    "                #red = 0.5 - mag * 0.5\n",
    "\n",
    "            blue = min(red, green)\n",
    "            # blue = 1.0 - max(red, green)\n",
    "\n",
    "            sent += f\"<span style='color: rgb({red*255}, {green*255}, {blue*255});'>{word}</span> \"\n",
    "\n",
    "        row.append(sent)\n",
    "        data.append(row)\n",
    "\n",
    "        # print()\n",
    "\n",
    "tab = tabulate.tabulate(data, tablefmt='html')\n",
    "display(HTML(tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['sentence'][0] = \"neutral neutral neutral neutral\"\n",
    "test_data['sentence'][1] = \"good neutral neutral neutral\"\n",
    "test_data['sentence'][2] = \"neutral good neutral neutral\"\n",
    "test_data['sentence'][3] = \"neutral neutral good neutral\"\n",
    "test_data['sentence'][4] = \"neutral neutral neutral good\"\n",
    "test_data['sentiment'][0] = 0\n",
    "test_data['sentiment'][1:] = 1\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_dataset(4, 2)\n",
    "pm = ToySentiment()\n",
    "pm.requires_grad_(True)\n",
    "pm.train()\n",
    "\n",
    "word_ids = pm.input_of_text(test_data['sentence'])\n",
    "# embeds = pm.embedding(word_ids)\n",
    "# embeds.retain_grad()\n",
    "\n",
    "probits = pm(word_ids=word_ids)\n",
    "\n",
    "print(probits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I'm so sad!\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# text = \"Good night 😊\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in csvreader:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "51eb71198507ab2c2a4108a27eda9d9658549732e67153fc0e371d8439827db7"
  },
  "kernelspec": {
   "display_name": "test-fresh-11-29",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
