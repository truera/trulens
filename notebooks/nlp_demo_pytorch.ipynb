{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ed9c783-b745-4c6a-b674-d8b6935dd62d"
    }
   },
   "source": [
    "# Attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1cfd9f6d-1cb6-4fc1-a69b-0338d68ce62c"
    }
   },
   "source": [
    "## Model Wrappers\n",
    "\n",
    "In order to support a wide variety of backends with different interfaces for their respective models, TruLens uses its own `ModelWrapper` class which provides a general model interface to simplify the implementation of the API functions.\n",
    "To get the model wrapper, use the `get_model_wrapper` method in `trulens.nn.models`. A model wrapper class exists for each backend that converts a model in the respective backend's format to the general TruLens `ModelWrapper` interface. The wrappers are found in the `models` module, and any model defined using Keras, Pytorch, or Tensorflow should be wrapped before being used with the other API functions that require a model -- all other TruLens functionalities expect models to be an instance of `trulens.nn.models.ModelWrapper`.\n",
    "\n",
    "For more details on allowed parameters, see the [get_model_wrapper](https://truera.github.io/trulens/api/model_wrappers/) documentation.\n",
    "\n",
    "For this demo, we will be using a Pytorch model pre-trained on Imagenet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "6a7dd470-8385-4028-8b44-3f1e427af157"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from trulens.nn.models import get_model_wrapper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "class ToySentiment(nn.Module):\n",
    "    @staticmethod\n",
    "    def from_pretrained(model_code_path: Path) -> 'ToySentiment':\n",
    "        # Not strictly necessary to load or save given fixed parameters can be populated, but \n",
    "        # implementing this for better integration testing.\n",
    "        model = ToySentiment()\n",
    "        model.load_state_dict(torch.load(model_code_path))\n",
    "\n",
    "    def to_pretrained(self, model_code_path: Path) -> None:\n",
    "        torch.save(self.state_dict(), model_code_path)\n",
    "\n",
    "    def set_parameters(self) -> None:\n",
    "        \"\"\"Set model parameters as per fixed specification.\"\"\"\n",
    "\n",
    "        Wi = torch.zeros_like(self.lstm.weight_ih_l0) + 0.1\n",
    "        bi = torch.zeros_like(self.lstm.bias_ih_l0) + 0.1\n",
    "        Wh = torch.zeros_like(self.lstm.weight_hh_l0) + 0.1\n",
    "        bh = torch.zeros_like(self.lstm.bias_hh_l0) + 0.1\n",
    "\n",
    "        big = 20.0 # Multipliers to help dealing with LSTM sigmoids.\n",
    "        half = 8.0 # Intention here is that sigmoid((x*big) - half) is ~0 if x is ~0; and\n",
    "                    # ~1 when indicator is >~ 1.\n",
    "\n",
    "        hs = self.hidden_size\n",
    "\n",
    "        sneutral = 0\n",
    "        sgood = 1\n",
    "        sbad = 2\n",
    "        sconfused = 3\n",
    "\n",
    "        wneutral = self.vocab['neutral']\n",
    "        wgood = self.vocab['good']\n",
    "        wbad = self.vocab['bad']\n",
    "        \n",
    "        # make sure c gate is always big\n",
    "        bi[0:hs*3] = 100.0\n",
    "        bh[0:hs*3] = 100.0\n",
    "\n",
    "        # o gate weights:\n",
    "        Wi[3*hs,   wneutral] = big # read neutral word\n",
    "        Wi[3*hs+1, wgood] = big # read good word\n",
    "        Wi[3*hs+2, wbad] = big # read bad word\n",
    "        Wh[3*hs,   sneutral] = big # keep prior neutral, good, bad states\n",
    "        Wh[3*hs+1, sgood] = big # \n",
    "        Wh[3*hs+2, sbad] = big #\n",
    "        bi[3*hs:4*hs] = -half # sigmoid will be 0 unless one of the three words was read\n",
    "\n",
    "        # set \"good to bad\" confused if prior was good, and input was bad\n",
    "        Wh[3*hs+3, sgood] = big    # (prior state was good\n",
    "        Wi[3*hs+3, wbad] = big    #  and input was bad)\n",
    "        Wh[3*hs+3, sconfused] = 2*big  # or (was already in this confused state)\n",
    "        bh[3*hs+3] = -(half*2) # Want at least 2 of first two to fire, or just the last one to fire.\n",
    "\n",
    "        # set \"bad to good\" confused if prior was bad, and input was good\n",
    "        Wh[3*hs+4, sbad] = big     # (prior state was bad\n",
    "        Wi[3*hs+4, wgood] = big     #  and input was good)\n",
    "        Wh[3*hs+4, sconfused] = 2*big   # or (was already confused)\n",
    "        bh[3*hs+4] = -(half*2)  #\n",
    "\n",
    "        self.lstm.weight_hh_l0 = nn.Parameter(Wh)\n",
    "        self.lstm.bias_hh_l0 = nn.Parameter(bh)\n",
    "        self.lstm.weight_ih_l0 = nn.Parameter(Wi)\n",
    "        self.lstm.bias_ih_l0 = nn.Parameter(bi)\n",
    "\n",
    "        self.embedding.weight = nn.Parameter(torch.eye(self.emb_size))\n",
    "\n",
    "        self.lin.weight = nn.Parameter(torch.tensor(\n",
    "            [\n",
    "                [10.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 20.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 20.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 30.0, 30.0]\n",
    "            ]\n",
    "        ))\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "        self.vocab = {\"[UNKNOWN]\": 0, \"neutral\": 1, \"good\": 2, \"bad\": 3}\n",
    "\n",
    "        self.emb_size = len(self.vocab)\n",
    "\n",
    "        self.hidden_size = 5\n",
    "        # 5 states, one for neutral, one for positive, one for negative, and two for confused. Requiring two\n",
    "        # confused states for simplicity of the model; it is easier to encode semantics of confusion based on \n",
    "        # which initial positive/negative state was set first.\n",
    "\n",
    "        # Identity embedding, each vocab word has its own dimension where its presence is encoded.\n",
    "        self.embedding = nn.Embedding(\n",
    "            # padding_idx=0, \n",
    "            embedding_dim=self.emb_size, \n",
    "            num_embeddings=self.emb_size,\n",
    "            padding_idx=None,\n",
    "            max_norm=None,\n",
    "            norm_type=None\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.emb_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Linear layer to combine the two types of confused state and weight things so that\n",
    "        # confused outweighs positive and negative, while positive and negative outweigh neutral \n",
    "        # if more than one of these states is set.\n",
    "        self.lin = torch.nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=4,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        # self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        # Finally add a softmax for classification.\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        # self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.set_parameters()\n",
    "\n",
    "    def forward(self, word_ids: torch.Tensor, embeds=None) -> torch.Tensor:\n",
    "        if word_ids is not None:\n",
    "            batch_size = word_ids.shape[0]\n",
    "        else:\n",
    "            batch_size = embeds.shape[0]\n",
    "\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        h0[0, 0, 0] = 1.0 # initial state is neutral\n",
    "        c0 = torch.zeros(1, batch_size, self.hidden_size)\n",
    "\n",
    "        if embeds is None:\n",
    "            embeds = self.embedding(word_ids)\n",
    "            \n",
    "        embeds.retain_grad()\n",
    "\n",
    "        out, (hn, cn) = self.lstm(embeds, (h0, c0))\n",
    "        hn = hn[0,:,:]\n",
    "\n",
    "        lin_out = self.lin(hn)\n",
    "\n",
    "        probits = self.softmax(lin_out)\n",
    "        # preds = torch.argmax(probits, axis=1)\n",
    "        # pred_prob = torch.gather(probits, dim=1, index=preds[:,None])\n",
    "        # pred_prob.backward(torch.ones_like(pred_prob))\n",
    "        # attr = embeds.grad\n",
    "        # return preds, probits, attr\n",
    "\n",
    "        return probits\n",
    "\n",
    "\n",
    "    def input_of_text(self, texts: List[str]) -> torch.Tensor:\n",
    "        tokens = [self.tokenizer(text) for text in texts]\n",
    "\n",
    "        word_ids = [[(self.vocab[t] if t in self.vocab else 0) for t in token] for token in tokens]\n",
    "\n",
    "        return torch.Tensor(word_ids).int()\n",
    "\n",
    "\n",
    "def generate_dataset(n, l):\n",
    "    \"\"\"Generate random sentiment sentences and their labels.\"\"\"\n",
    "\n",
    "    ret = []\n",
    "    cls = []\n",
    "    for i in range(n):\n",
    "        sent = []\n",
    "        while len(sent) < l:\n",
    "            r = random.random()\n",
    "\n",
    "            word = \"neutral\"\n",
    "\n",
    "            if r > 0.9 and len(sent) > 0:\n",
    "                continue\n",
    "            elif r > 0.8:\n",
    "                word = \"good\"\n",
    "            elif r > 0.7:\n",
    "                word = \"bad\"\n",
    "\n",
    "            sent.append(word)\n",
    "\n",
    "        ret.append(\" \".join(sent))\n",
    "\n",
    "        gt = 0 # neutral\n",
    "        if \"good\" in sent and \"bad\" in sent:\n",
    "            gt = 3 # confused\n",
    "        elif \"good\" in sent:\n",
    "            gt = 1 # positive\n",
    "        elif \"bad\" in sent:\n",
    "            gt = 2 # negative\n",
    "\n",
    "        cls.append(gt)\n",
    "\n",
    "    return pd.DataFrame(dict(sentence=ret, sentiment=cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Detected pytorch backend for <class '__main__.ToySentiment'>.\n",
      "INFO: Using backend Backend.PYTORCH.\n",
      "INFO: If this seems incorrect, you can force the correct backend by passing the `backend` parameter directly into your get_model_wrapper call.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td><b>GT=neutral PRED=neutral</b>  </td><td>neutral neutral neutral neutral                                                                                                                                                                                                                                                                                                                              </td></tr>\n",
       "<tr><td>neutral                         </td><td><span style='color: rgb(240.96710124984384, 255.0, 240.96710124984384);'>neutral</span> <span style='color: rgb(226.5994043648243, 255.0, 226.5994043648243);'>neutral</span> <span style='color: rgb(224.79377925395966, 255.0, 224.79377925395966);'>neutral</span> <span style='color: rgb(229.8781705275178, 255.0, 229.8781705275178);'>neutral</span>  </td></tr>\n",
       "<tr><td>positive                        </td><td><span style='color: rgb(255.0, 250.3104417398572, 250.3104417398572);'>neutral</span> <span style='color: rgb(255.0, 245.50907922908664, 245.50907922908664);'>neutral</span> <span style='color: rgb(255.0, 244.90858795121312, 244.90858795121312);'>neutral</span> <span style='color: rgb(255.0, 246.96659931913018, 246.96659931913018);'>neutral</span></td></tr>\n",
       "<tr><td>negative                        </td><td><span style='color: rgb(255.0, 250.3104417398572, 250.3104417398572);'>neutral</span> <span style='color: rgb(255.0, 245.50907922908664, 245.50907922908664);'>neutral</span> <span style='color: rgb(255.0, 244.90858795121312, 244.90858795121312);'>neutral</span> <span style='color: rgb(255.0, 246.96659931913018, 246.96659931913018);'>neutral</span></td></tr>\n",
       "<tr><td>confused                        </td><td><span style='color: rgb(255.0, 250.34622489474714, 250.34622489474714);'>neutral</span> <span style='color: rgb(255.0, 245.58125540614128, 245.58125540614128);'>neutral</span> <span style='color: rgb(255.0, 244.97661570087075, 244.97661570087075);'>neutral</span> <span style='color: rgb(255.0, 245.9449709393084, 245.9449709393084);'>neutral</span></td></tr>\n",
       "<tr><td><b>GT=positive PRED=positive</b></td><td>good neutral neutral neutral                                                                                                                                                                                                                                                                                                                                 </td></tr>\n",
       "<tr><td>neutral                         </td><td><span style='color: rgb(254.86428225209238, 255.0, 254.86428225209238);'>good</span> <span style='color: rgb(228.44274625182152, 255.0, 228.44274625182152);'>neutral</span> <span style='color: rgb(217.85459160804749, 255.0, 217.85459160804749);'>neutral</span> <span style='color: rgb(223.31265293061733, 255.0, 223.31265293061733);'>neutral</span> </td></tr>\n",
       "<tr><td>positive                        </td><td><span style='color: rgb(254.97933680711867, 255.0, 254.97933680711867);'>good</span> <span style='color: rgb(255.0, 246.14250998944044, 246.14250998944044);'>neutral</span> <span style='color: rgb(255.0, 242.5934225320816, 242.5934225320816);'>neutral</span> <span style='color: rgb(255.0, 244.7858364880085, 244.7858364880085);'>neutral</span>     </td></tr>\n",
       "<tr><td>negative                        </td><td><span style='color: rgb(255.0, 254.92147869779728, 254.92147869779728);'>good</span> <span style='color: rgb(255.0, 246.11632369458675, 246.11632369458675);'>neutral</span> <span style='color: rgb(255.0, 242.58786723017693, 242.58786723017693);'>neutral</span> <span style='color: rgb(255.0, 244.78467850014567, 244.78467850014567);'>neutral</span> </td></tr>\n",
       "<tr><td>confused                        </td><td><span style='color: rgb(255.0, 254.922076438379, 254.922076438379);'>good</span> <span style='color: rgb(255.0, 246.18391731753945, 246.18391731753945);'>neutral</span> <span style='color: rgb(255.0, 242.6733217947185, 242.6733217947185);'>neutral</span> <span style='color: rgb(255.0, 243.74214554205537, 243.74214554205537);'>neutral</span>       </td></tr>\n",
       "<tr><td><b>GT=positive PRED=positive</b></td><td>neutral good neutral neutral                                                                                                                                                                                                                                                                                                                                 </td></tr>\n",
       "<tr><td>neutral                         </td><td><span style='color: rgb(254.1093410924077, 255.0, 254.1093410924077);'>neutral</span> <span style='color: rgb(254.86061904084636, 255.0, 254.86061904084636);'>good</span> <span style='color: rgb(208.67892757058144, 255.0, 208.67892757058144);'>neutral</span> <span style='color: rgb(207.41787023842335, 255.0, 207.41787023842335);'>neutral</span>   </td></tr>\n",
       "<tr><td>positive                        </td><td><span style='color: rgb(255.0, 254.7275479102973, 254.7275479102973);'>neutral</span> <span style='color: rgb(254.3359215685632, 255.0, 254.3359215685632);'>good</span> <span style='color: rgb(255.0, 239.67737540602684, 239.67737540602684);'>neutral</span> <span style='color: rgb(255.0, 239.53779559582472, 239.53779559582472);'>neutral</span>     </td></tr>\n",
       "<tr><td>negative                        </td><td><span style='color: rgb(255.0, 254.68970787827857, 254.68970787827857);'>neutral</span> <span style='color: rgb(255.0, 254.59678059909493, 254.59678059909493);'>good</span> <span style='color: rgb(255.0, 239.44636395201087, 239.44636395201087);'>neutral</span> <span style='color: rgb(255.0, 239.4884818419814, 239.4884818419814);'>neutral</span>   </td></tr>\n",
       "<tr><td>confused                        </td><td><span style='color: rgb(255.0, 254.6920833742479, 254.6920833742479);'>neutral</span> <span style='color: rgb(255.0, 254.59975779871456, 254.59975779871456);'>good</span> <span style='color: rgb(255.0, 239.5551796630025, 239.5551796630025);'>neutral</span> <span style='color: rgb(255.0, 238.39160799980164, 238.39160799980164);'>neutral</span>     </td></tr>\n",
       "<tr><td><b>GT=positive PRED=positive</b></td><td>neutral neutral good neutral                                                                                                                                                                                                                                                                                                                                 </td></tr>\n",
       "<tr><td>neutral                         </td><td><span style='color: rgb(232.80960492789745, 255.0, 232.80960492789745);'>neutral</span> <span style='color: rgb(235.75218982994556, 255.0, 235.75218982994556);'>neutral</span> <span style='color: rgb(255.0, 160.01365453004837, 160.01365453004837);'>good</span> <span style='color: rgb(248.3315644506365, 255.0, 248.3315644506365);'>neutral</span>   </td></tr>\n",
       "<tr><td>positive                        </td><td><span style='color: rgb(255.0, 247.61224309913814, 247.61224309913814);'>neutral</span> <span style='color: rgb(255.0, 249.00284830480814, 249.00284830480814);'>neutral</span> <span style='color: rgb(155.44148907065392, 255.0, 155.44148907065392);'>good</span> <span style='color: rgb(242.18510689213872, 255.0, 242.18510689213872);'>neutral</span> </td></tr>\n",
       "<tr><td>negative                        </td><td><span style='color: rgb(255.0, 247.57015988230705, 247.57015988230705);'>neutral</span> <span style='color: rgb(255.0, 248.3492225781083, 248.3492225781083);'>neutral</span> <span style='color: rgb(255.0, 252.71095556672662, 252.71095556672662);'>good</span> <span style='color: rgb(255.0, 245.870111156255, 245.870111156255);'>neutral</span>       </td></tr>\n",
       "<tr><td>confused                        </td><td><span style='color: rgb(255.0, 247.62720622122288, 247.62720622122288);'>neutral</span> <span style='color: rgb(255.0, 248.4001217968762, 248.4001217968762);'>neutral</span> <span style='color: rgb(255.0, 252.71688087377697, 252.71688087377697);'>good</span> <span style='color: rgb(255.0, 244.6465559117496, 244.6465559117496);'>neutral</span>     </td></tr>\n",
       "<tr><td><b>GT=positive PRED=positive</b></td><td>neutral neutral neutral good                                                                                                                                                                                                                                                                                                                                 </td></tr>\n",
       "<tr><td>neutral                         </td><td><span style='color: rgb(194.52302657067776, 255.0, 194.52302657067776);'>neutral</span> <span style='color: rgb(177.4167738854885, 255.0, 177.4167738854885);'>neutral</span> <span style='color: rgb(216.5016894042492, 255.0, 216.5016894042492);'>neutral</span> <span style='color: rgb(255.0, 123.88078540563583, 123.88078540563583);'>good</span>     </td></tr>\n",
       "<tr><td>positive                        </td><td><span style='color: rgb(255.0, 218.49150583148003, 218.49150583148003);'>neutral</span> <span style='color: rgb(255.0, 208.2658327370882, 208.2658327370882);'>neutral</span> <span style='color: rgb(255.0, 232.54973877221346, 232.54973877221346);'>neutral</span> <span style='color: rgb(101.44938826560974, 255.0, 101.44938826560974);'>good</span>   </td></tr>\n",
       "<tr><td>negative                        </td><td><span style='color: rgb(255.0, 242.96891078352928, 242.96891078352928);'>neutral</span> <span style='color: rgb(255.0, 239.5155050419271, 239.5155050419271);'>neutral</span> <span style='color: rgb(255.0, 246.9497348740697, 246.9497348740697);'>neutral</span> <span style='color: rgb(255.0, 244.32138646021485, 244.32138646021485);'>good</span>     </td></tr>\n",
       "<tr><td>confused                        </td><td><span style='color: rgb(255.0, 243.06261470541358, 243.06261470541358);'>neutral</span> <span style='color: rgb(255.0, 239.63543515652418, 239.63543515652418);'>neutral</span> <span style='color: rgb(255.0, 247.0022110082209, 247.0022110082209);'>neutral</span> <span style='color: rgb(255.0, 243.2472581975162, 243.2472581975162);'>good</span>     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pt = ToySentiment()\n",
    "device = 'cpu'\n",
    "# Produce a wrapped model from the pytorch model.\n",
    "model = get_model_wrapper(pt, input_shape=(4), device=device, input_dtype=int, )\n",
    "\n",
    "# test_data = generate_dataset(5, 4)\n",
    "\n",
    "x_sentences = test_data['sentence']\n",
    "x_tokens = [pt.tokenizer(s) for s in x_sentences]\n",
    "x_ids = pt.input_of_text(x_sentences)\n",
    "labels = test_data['sentiment']\n",
    "\n",
    "# TODO: define \"EmbeddedInfluence\" for InputInfluence except with an initial embedding layer and initialize internal influence as below:\n",
    "from trulens.nn.quantities import LambdaQoI, ClassQoI\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "cls_names = {0:\"neutral\", 1:\"positive\", 2:\"negative\", 3:\"confused\"}\n",
    "\n",
    "infl = {}\n",
    "attrs = {}\n",
    "for cls in [0,1,2,3]:\n",
    "    infl[cls] = InternalInfluence(\n",
    "        model,\n",
    "        cuts=(Cut(\"embedding\"), Cut(\"softmax\")),\n",
    "        #doi=PointDoi(cut=Cut(\"embedding\")),\n",
    "        doi=LinearDoi(cut=Cut(\"embedding\"), resolution=100),\n",
    "        qoi=ClassQoI(cls),\n",
    "        multiply_activation=False\n",
    "    )\n",
    "    attrs[cls] = infl[cls].attributions(x_ids)\n",
    "\n",
    "\n",
    "preds = pt(x_ids)\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, (words, label, pred) in enumerate(zip(x_tokens, labels, preds)):\n",
    "    data.append([f\"<b>GT={cls_names[label]} PRED={cls_names[pred.argmax().item()]}</b>\"] + [\" \".join(words)])\n",
    "\n",
    "    for cls in [0,1,2,3]:\n",
    "        # print(f\"{cls_names[cls]} | \", end='')\n",
    "\n",
    "        row = [cls_names[cls]]\n",
    "\n",
    "        sent = \"\"\n",
    "\n",
    "        for word, attr in zip(words, attrs[cls][i]):\n",
    "            # print(f\"{word}[{attr.sum()}] \", end=\"\")\n",
    "            mag = attr.sum()\n",
    "            red = 0.0\n",
    "            green = 0.0\n",
    "            if mag > 0:\n",
    "                green = 1.0 # 0.5 + mag * 0.5\n",
    "                red = 1.0 - mag * 0.5\n",
    "            else:\n",
    "                red = 1.0\n",
    "                green = 1.0 + mag * 0.5\n",
    "                #red = 0.5 - mag * 0.5\n",
    "\n",
    "            blue = min(red, green)\n",
    "            # blue = 1.0 - max(red, green)\n",
    "\n",
    "            sent += f\"<span style='color: rgb({red*255}, {green*255}, {blue*255});'>{word}</span> \"\n",
    "\n",
    "        row.append(sent)\n",
    "        data.append(row)\n",
    "\n",
    "        # print()\n",
    "\n",
    "tab = tabulate.tabulate(data, tablefmt='html')\n",
    "display(HTML(tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotrm/anaconda3/envs/demo3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/piotrm/anaconda3/envs/demo3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/piotrm/anaconda3/envs/demo3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/piotrm/anaconda3/envs/demo3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/piotrm/anaconda3/envs/demo3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/piotrm/anaconda3/envs/demo3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/piotrm/anaconda3/envs/demo3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/piotrm/anaconda3/envs/demo3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral neutral neutral neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good neutral neutral neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral good neutral neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral neutral good neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral neutral neutral good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence  sentiment\n",
       "0  neutral neutral neutral neutral          0\n",
       "1     good neutral neutral neutral          1\n",
       "2     neutral good neutral neutral          1\n",
       "3     neutral neutral good neutral          1\n",
       "4     neutral neutral neutral good          1"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['sentence'][0] = \"neutral neutral neutral neutral\"\n",
    "test_data['sentence'][1] = \"good neutral neutral neutral\"\n",
    "test_data['sentence'][2] = \"neutral good neutral neutral\"\n",
    "test_data['sentence'][3] = \"neutral neutral good neutral\"\n",
    "test_data['sentence'][4] = \"neutral neutral neutral good\"\n",
    "test_data['sentiment'][0] = 0\n",
    "test_data['sentiment'][1:] = 1\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9980e-01, 6.5042e-05, 6.5042e-05, 6.5042e-05],\n",
      "        [9.9980e-01, 6.5042e-05, 6.5042e-05, 6.5042e-05],\n",
      "        [4.2322e-09, 1.0000e+00, 4.2322e-09, 4.2322e-09],\n",
      "        [6.5051e-05, 4.2319e-09, 9.9993e-01, 4.2319e-09]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_data = generate_dataset(4, 2)\n",
    "pm = ToySentiment()\n",
    "pm.requires_grad_(True)\n",
    "pm.train()\n",
    "\n",
    "word_ids = pm.input_of_text(test_data['sentence'])\n",
    "# embeds = pm.embedding(word_ids)\n",
    "# embeds.retain_grad()\n",
    "\n",
    "probits = pm(word_ids=word_ids)\n",
    "\n",
    "print(probits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Initializing a DistilBERT configuration\n",
    "# configuration = DistilBertConfig()\n",
    "\n",
    "# Initializing a model from the configuration\n",
    "#bert = DistilBertModel(configuration)\n",
    "bert = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Accessing the model configuration\n",
    "# configuration = bert.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 6251,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [[\"this is a sentence\"], [\"and so is this\"]]\n",
    "#ins = [bt(s) for s in sentences]\n",
    "#input_ids = torch.Tensor([i['input_ids'] for i in ins]).long()\n",
    "#input_ids\n",
    "inputs = bt(\"this is a sentence\", return_tensors=\"pt\")\n",
    "# bt(sentences)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0166, -0.0666, -0.0163,  ..., -0.0200, -0.0514, -0.0264],\n",
       "        [-0.0132, -0.0673, -0.0161,  ..., -0.0227, -0.0554, -0.0260],\n",
       "        [-0.0176, -0.0709, -0.0144,  ..., -0.0246, -0.0596, -0.0232],\n",
       "        ...,\n",
       "        [-0.0231, -0.0588, -0.0105,  ..., -0.0195, -0.0262, -0.0212],\n",
       "        [-0.0490, -0.0561, -0.0047,  ..., -0.0107, -0.0180, -0.0219],\n",
       "        [-0.0065, -0.0915, -0.0025,  ..., -0.0151, -0.0504,  0.0460]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.distilbert.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "bert.eval()\n",
    "bert.requires_grad_(True)\n",
    "# bert.retain_grad()\n",
    "embeds = bert.distilbert.embeddings.word_embeddings(inputs['input_ids'])\n",
    "embeds.retain_grad()\n",
    "# embeds\n",
    "outs = bert(inputs_embeds=embeds)\n",
    "outs.logits.abs().sum().backward()\n",
    "attr = embeds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.7252e-05,  4.6484e-03, -3.0422e-02,  ...,  5.2301e-03,\n",
       "           3.6593e-02,  5.0404e-02],\n",
       "         [-6.2519e-03,  1.0962e-02, -4.2026e-03,  ...,  1.3291e-03,\n",
       "           1.5315e-02,  1.0347e-02],\n",
       "         [-2.8572e-03,  1.0138e-02, -3.9614e-03,  ...,  3.5016e-03,\n",
       "           1.5171e-02,  9.4054e-03],\n",
       "         [-5.5624e-03,  9.6869e-03, -3.6593e-03,  ...,  2.0852e-03,\n",
       "           1.4146e-02,  1.0402e-02],\n",
       "         [-7.1661e-03,  1.0525e-02, -1.9546e-03,  ...,  7.5274e-03,\n",
       "           2.0054e-02,  1.2984e-02],\n",
       "         [ 3.3965e-02,  1.6431e-02, -1.2048e-03,  ...,  5.7613e-02,\n",
       "           8.7031e-03,  9.5926e-03]]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "nbpresent": {
     "id": "ee31d8b0-864d-4c7e-b3d2-d937e1d287ba"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Detected pytorch backend for <class '__main__.ToySentiment'>.\n",
      "INFO: Using backend Backend.PYTORCH.\n",
      "INFO: If this seems incorrect, you can force the correct backend by passing the `backend` parameter directly into your get_model_wrapper call.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'embedding':\tEmbedding(4, 4, norm_type=None)\n",
      "'lstm':\tLSTM(4, 5, batch_first=True)\n",
      "'lin':\tLinear(in_features=5, out_features=4, bias=False)\n",
      "'softmax':\tSoftmax(dim=1)\n"
     ]
    }
   ],
   "source": [
    "model.print_layer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral good bad neutral \t tensor([[1, 2, 3, 1]], dtype=torch.int32) \t prediction= tensor([[1.9945e-22, 4.3440e-18, 4.3441e-18, 1.0000e+00]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 3\n",
      "neutral neutral neutral neutral \t tensor([[1, 1, 1, 1]], dtype=torch.int32) \t prediction= tensor([[9.9986e-01, 4.5707e-05, 4.5707e-05, 4.5699e-05]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 0\n",
      "neutral neutral neutral neutral \t tensor([[1, 1, 1, 1]], dtype=torch.int32) \t prediction= tensor([[9.9986e-01, 4.5707e-05, 4.5707e-05, 4.5699e-05]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 0\n",
      "neutral neutral neutral neutral \t tensor([[1, 1, 1, 1]], dtype=torch.int32) \t prediction= tensor([[9.9986e-01, 4.5707e-05, 4.5707e-05, 4.5699e-05]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 0\n",
      "neutral neutral good good \t tensor([[1, 1, 2, 2]], dtype=torch.int32) \t prediction= tensor([[4.5577e-05, 9.9995e-01, 2.0893e-09, 2.0889e-09]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 1\n",
      "neutral neutral neutral neutral \t tensor([[1, 1, 1, 1]], dtype=torch.int32) \t prediction= tensor([[9.9986e-01, 4.5707e-05, 4.5707e-05, 4.5699e-05]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 0\n",
      "neutral neutral neutral neutral \t tensor([[1, 1, 1, 1]], dtype=torch.int32) \t prediction= tensor([[9.9986e-01, 4.5707e-05, 4.5707e-05, 4.5699e-05]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 0\n",
      "neutral neutral good neutral \t tensor([[1, 1, 2, 1]], dtype=torch.int32) \t prediction= tensor([[4.5956e-05, 9.9995e-01, 2.1008e-09, 2.1005e-09]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 1\n",
      "good neutral neutral bad \t tensor([[2, 1, 1, 3]], dtype=torch.int32) \t prediction= tensor([[3.6047e-09, 7.8644e-05, 7.8692e-05, 9.9984e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 3\n",
      "neutral good bad neutral \t tensor([[1, 2, 3, 1]], dtype=torch.int32) \t prediction= tensor([[1.9945e-22, 4.3440e-18, 4.3441e-18, 1.0000e+00]],\n",
      "       grad_fn=<SoftmaxBackward0>) \t label= 3\n"
     ]
    }
   ],
   "source": [
    "m = ToySentiment()\n",
    "m.requires_grad_(True)\n",
    "\n",
    "test_data = generate_dataset(10, 4)\n",
    "\n",
    "for sentence, sentiment in zip(test_data['sentence'], test_data['sentiment']):\n",
    "    word_ids = m.input_of_text([sentence])\n",
    "    pred = m(word_ids)\n",
    "    print(sentence, \"\\t\", word_ids, \"\\t\", \"prediction=\", pred, \"\\t\", \"label=\", sentiment)\n",
    "    # print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.nn.attribution import InputAttribution, InternalInfluence\n",
    "from trulens.nn.attribution import IntegratedGradients\n",
    "from trulens.nn.attribution import Cut, InputCut, OutputCut\n",
    "from trulens.nn.distributions import LinearDoi, PointDoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saliency maps are implemented by the `InputAttribution` class. This takes several optional arguments, the meaning of which we will discuss later in this notebook. The provided defaults instantiate an `AttributionMethod` that is consistent with the method described in the reference above.\n",
    "\n",
    "The required argument to the constructor is a `ModelWrapper`. After constructing the attribution method, we call it on our data point, and receive an array containing the attributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0->0 neutral[-0.003716949839144945] neutral[-0.00554325757548213] neutral[-0.004302475601434708] neutral[-0.009433472529053688] \n",
      "0->0 neutral[-0.003716949839144945] neutral[-0.00554325757548213] neutral[-0.004302475601434708] neutral[-0.009433472529053688] \n",
      "2->2 neutral[-0.004279387649148703] neutral[-0.006282697431743145] neutral[-0.003931532613933086] bad[-0.16649414598941803] \n",
      "1->1 neutral[0.004782388918101788] neutral[0.007022105157375336] neutral[0.004406385123729706] good[0.8117256164550781] \n",
      "1->1 neutral[0.004782388918101788] neutral[0.007022105157375336] neutral[0.004406385123729706] good[0.8117256164550781] \n",
      "2->2 neutral[-6.288810254773125e-05] neutral[-9.242133819498122e-05] bad[-0.0003415872051846236] neutral[-0.07553716003894806] \n",
      "0->0 neutral[-0.003716949839144945] neutral[-0.00554325757548213] neutral[-0.004302475601434708] neutral[-0.009433472529053688] \n",
      "0->0 neutral[-0.003716949839144945] neutral[-0.00554325757548213] neutral[-0.004302475601434708] neutral[-0.009433472529053688] \n",
      "1->1 good[1.0006002187728882] neutral[-0.2607613205909729] neutral[-0.3057054877281189] neutral[-0.16655999422073364] \n",
      "3->2 good[8.360376523341984e-05] bad[-0.0006586036179214716] neutral[-0.14857947826385498] neutral[-0.17366889119148254] \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the attributions, we can use `MaskVisualizer` from the `visualizations` module. This class takes a `blur` and `threshold` argument, and allows us to overlay a partially-opaque mask over a given image that reveals the top-threshold percentage of pixels by attribution, after applying a Gaussian blur of the given radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.visualizations import MaskVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = MaskVisualizer(blur=5, threshold=0.95)(attrs_input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning to Integrated Gradients, the workflow for obtaining attributions is nearly identical. The only difference is that the `AttributionMethod` instance we construct is one of `IntegratedGradients` rather than `InputGradients`.\n",
    "\n",
    "The `resolution` argument, which is optional and defaults to 50, specifies the number of samples to take. Larger values approximate the true aggregate quantity more closely, and in practical terms, tend to be more stable.\n",
    "\n",
    "Another optional argument is the `baseline`, which specifies the linear subspace over which the quantity is aggregated. By default this is `None`, which is interpreted as an appropriately-sized zero tensor. In this case the linear subspace is the line between this zero tensor, and the point for which the attributions are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infl = IntegratedGradients(model, resolution=10)\n",
    "attrs_input = infl.attributions(x_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the results, it is apparent that Integrated Gradients in this case is better able to focus on the pixels corresponding to the beagle, which is consistent with the model's top predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = MaskVisualizer(blur=5, threshold=0.95)(attrs_input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "88aa57f0-b3be-47b7-a144-408300b135b7"
    }
   },
   "source": [
    "### Discovering Important Internal Neurons \n",
    "\n",
    "Now we'll examine is *Internal Influence* (Leino et al.), a powerful and general attribution method that can calculate attributions for internal neurons in a network as well as for the inputs to the network. Internal Influence is implemented by the `InternalInfluence` class in the `attribution` module.\n",
    "\n",
    "The `InternalInfluence` constructor takes a TruLens `ModelWrapper` and three special parameters: a *slice*, a *quantity of interest* (QoI), and a *distribution of interest* (DoI), which are instances of the `Slice` (in the `slices` module), `QoI` (in the `quantities` module), and `DoI` (in the `distributions` module) classes, respectively.\n",
    "\n",
    "The slice essentially defines a layer to use for internal attributions. A `Slice` object specifies two `Cut`s corresponding to two layers: (1) the layer of the variables that we are calculating attribution *for* (e.g., the input layer), and (2) the layer whose output defines our quantity of interest (e.g., the output layer; see below for more on quantities of interest).\n",
    "\n",
    "The shape of the attributions will always match the shape of the first cut. In the case of `InputAttribution`, it is the shape of the input. For neuron explanations, the attributions can take the shape of the output or input of a specific network layer. The default behavior is to create attributions for the output of a layer, but this can be specified via the `anchor` in the `Cut` class. See the [Slice](https://truera.github.io/trulens/api/slices/) documentation for more detail.\n",
    "\n",
    "The quantity of interest (QoI) essentially defines the model behavior we would like to explain using attributions. The QoI is a function of the model's output at some layer. For example, it may select the confidence score for a particular class. In its most general form, the QoI can be pecified by an implementation of the `QoI` class in the `quantities` module. Several common default implementations are provided in this module as well.\n",
    "\n",
    "The distribution of interest (DoI) essentially specifies points surrounding each record for which the calculated attribution should be faithful. The distribution can be specified via an implementation of the `DoI` class in the `distributions` module, which is a function taking an input record and producing a list of input points to aggregate attribution over. A few common default distributions implementing the `DoI` class can be found in the `distributions` module.\n",
    "\n",
    "---\n",
    "\n",
    "* Klas Leino, Shayak Sen, Anupam Datta, Matt Fredrikson, and Linyi Li. *Influence-Directed Explanations for Deep Convolutional Networks*. IEEE ITC 2018. [ArXiv](https://arxiv.org/pdf/1802.03788.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "96deed0e-c142-4477-b714-4162adead875"
    }
   },
   "outputs": [],
   "source": [
    "from trulens.nn.attribution import InternalInfluence\n",
    "from trulens.nn.distributions import PointDoi\n",
    "from trulens.nn.quantities import ClassQoI, InternalChannelQoI, MaxClassQoI\n",
    "from trulens.nn.slices import Cut, InputCut, OutputCut, Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "78dd231f-e9fc-45bb-b504-0fed08b15af1"
    }
   },
   "source": [
    "We will be calculating attributions for the feature maps in the layer labeled `'features_28'` (specified via the slice below). In our first example, we are interested in explaining the model's *predicted class* for our record. We specify this by using a `MaxClassQoI`, which sets the attributions to explain the model's output for its highest-confidence class. We will initially use the `PointDoI` which specifies that we are only concerned with the model's behavior on one particular point, i.e., we want a very *local* explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "115edae1-4b53-4201-8ceb-88bd50a88b49"
    }
   },
   "outputs": [],
   "source": [
    "# Define the influence measure.\n",
    "infl = InternalInfluence(\n",
    "    model, \n",
    "    Slice(Cut('features_28'), OutputCut()), \n",
    "    MaxClassQoI(),\n",
    "    PointDoi())\n",
    "\n",
    "# Get the attributions for the internal neurons at layer -10. Because layer -10\n",
    "# contains 2D feature maps, we take the sum over the width and height of the \n",
    "# feature maps to obtain a single attribution for each feature map.\n",
    "attrs_internal = infl.attributions(x_pp).sum(axis=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "911e85a8-3a49-4a65-a8e9-3e58a084943e"
    }
   },
   "source": [
    "Note that above we used the `Slice`, `MaxClassQoI`, and `PointDoI` classes to define the slice, QoI, and DoI. The TruLens API also offers several simple shorthands for defining these parameters more simply. For example, the above code could be more succinctly written as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f651628f-267a-4f03-9f71-8ad3ec4f9c5e"
    }
   },
   "outputs": [],
   "source": [
    "# Define the influence measure.\n",
    "infl = InternalInfluence(model, 'features_28', 'max', 'point')\n",
    "\n",
    "# Get the attributions for the internal neurons at layer 'features_28'. Because \n",
    "# layer 'features_28' contains 2D feature maps, we take the sum over the width \n",
    "# and height of the feature maps to obtain a single attribution for each feature \n",
    "# map.\n",
    "attrs_internal = infl.attributions(x_pp).sum(axis=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "667e717b-c8c2-422d-aec2-d4804da9eae2"
    }
   },
   "source": [
    "Now we can calculate the most important feature map towards the model's top prediction, by taking the argmax over the internal attributions for this record. The most important feature map represents some type of *learned feature* that was the *most important* in the network's decision to label this point as `'beagle'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "dbf80486-bb3e-4fce-929e-f41abbad0e3e"
    }
   },
   "outputs": [],
   "source": [
    "top_feature_map = int(attrs_internal[0].argmax())\n",
    "\n",
    "print('Top feature map:', top_feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d4e40366-566f-414d-8a82-71df260f874d"
    }
   },
   "source": [
    "### Visualizing Important Internal Neurons\n",
    "\n",
    "We would now like to visualize our identified feature map in a meaningful way. Since the feature map represents a learned feature, which is not readily interpretable, we will use a second set of attributions to identify the input features that are most important in defining this particular feature map. We will then use a *visualizer*, found in the `visualizations` module, to visualize these input features that relate to our identified important feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e63b4f03-3d87-4598-bd6c-fbc42bc64977"
    }
   },
   "outputs": [],
   "source": [
    "from trulens.visualizations import MaskVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "90fd4a5e-0541-484b-acf3-6b1dfc71bb4e"
    }
   },
   "source": [
    "First, we create another attributer, again using `InternalInfluence`. This time, we specify our slice to begin at the input of the model and end at layer `'features_28`, the layer of our identified feature map. We select our quantity of interest to be an `InternalChannelQoI` - this allows us to specify a particular channel that we want to calculate attributions towards (in our case we specify this channel to be our identified feature map). We will again use the `Point` DoI.\n",
    "\n",
    "Note that if we simply give the top feature map to `InternalInfluence`, it will automatically wrap it in an instance of `InternalChannelQoI` for us; additionally, the `Slice` object is inferred from the tuple of cuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "37276a51-494e-49b1-ba60-23a4959aca54"
    }
   },
   "outputs": [],
   "source": [
    "infl_input = InternalInfluence(\n",
    "    model, \n",
    "    Slice(InputCut(), Cut('features_28')),\n",
    "    InternalChannelQoI(top_feature_map), \n",
    "    PointDoi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the above code can be simplified to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a19c0cbb-2eb2-4a10-b2d1-95d612a0d909"
    }
   },
   "outputs": [],
   "source": [
    "infl_input = InternalInfluence(\n",
    "    model, \n",
    "    (InputCut(), Cut('features_28')), \n",
    "    top_feature_map, \n",
    "    'point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "789c1fc0-2a96-4aa3-9453-562fc2cc3deb"
    }
   },
   "source": [
    "Now we can calculate the input attributions and visualize the top feature map by using the input attributions as a mask over the original image, using the `MaskVisualizer` (found in the `visualizations` module).\n",
    "\n",
    "The `MaskVisualizer` takes two fine-tuning parameters, `blur` and `threshold`, that affect the quality of the visualization. The attributions are first blurred using a Gaussian blur with radius `blur`, and then only the pixels whose blurred attribution value are at or above the percentile given by `threshold` are highlighted. Depending on the particular record and application, different `blur` and `threshold` parameters may be appropriate.\n",
    "\n",
    "Increasing `blur` gives a more abstract, region-focused explanation, while a smaller blur gives a noisier, but more precise explanation.\n",
    "\n",
    "Increasing `threshold` selects a smaller portion of the image to highlight, showing only the most important regions, while a smaller threshold will highlight a larger portion of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8b22e40f-0535-4cd1-93dc-b3a3a6a3b3b6"
    }
   },
   "outputs": [],
   "source": [
    "attrs_input = infl_input.attributions(x_pp)\n",
    "\n",
    "masked_image = MaskVisualizer(blur=10, threshold=0.95)(attrs_input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "290b4e59-5107-4237-b665-b92f3ba7f3b2"
    }
   },
   "source": [
    "The above procedure &mdash; using a second set of attributions to identify the input features that are most important in defining a particular feature map, then using a visualizer on the resulting input attributions &mdash; is a common use case when dealing with internal attributions. This procedure can instead be done via a single step, using a `ChannelMaskVisualizer` also found in the `visualizations` module, demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ed603579-efc9-48e8-85a2-6f4a85653138"
    }
   },
   "outputs": [],
   "source": [
    "from trulens.visualizations import ChannelMaskVisualizer\n",
    "\n",
    "masked_image = ChannelMaskVisualizer(\n",
    "    model,\n",
    "    'features_28',\n",
    "    top_feature_map,\n",
    "    blur=10,\n",
    "    threshold=0.95)(x, x_pp)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(masked_image[0].transpose((1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3f7c812d-52a0-481b-acbf-5ff41f1e3041"
    }
   },
   "source": [
    "#### Other Quantities of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a08ca9a2-2d87-47b3-a409-52e7740b3d40"
    }
   },
   "source": [
    "We can also change the quantity that we want the attributions to explain. For example, our example image contains both a bike and a dog. Recall that while the top class predicted by our model was `'beagle'`, imagenet also contains bike-related classes, e.g., `'mountain bike, all-terrain bike, off-roader'`. We will use the `ClassQoI` to view the attributions towards the class `'mountain bike, all-terrain bike, off-roader'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e5fc2566-8e1c-4fc9-8c75-457320c11a42"
    }
   },
   "outputs": [],
   "source": [
    "# Define the influence measure.\n",
    "infl_bike = InternalInfluence(model, 'features_28', 671, 'point')\n",
    "\n",
    "# The above is shorthand for\n",
    "#\n",
    "# infl_bike = InternalInfluence(\n",
    "#     model, \n",
    "#     Slice(Cut('features_28', OutputCut()),\n",
    "#     ClassQoI(671), \n",
    "#     PointDoi())\n",
    "\n",
    "# Get the attributions for each feature map.\n",
    "attrs_bike_internal = infl_bike.attributions(x_pp).sum(axis=(2,3))\n",
    "\n",
    "# Find the index of the top feature map.\n",
    "top_feature_map_bike = int(attrs_bike_internal[0].argmax())\n",
    "\n",
    "print('Top feature map:', top_feature_map_bike)\n",
    "\n",
    "# Visualize the top feature map in the input space.\n",
    "masked_image = ChannelMaskVisualizer(\n",
    "    model,\n",
    "    'features_28',\n",
    "    top_feature_map_bike,\n",
    "    blur=10, \n",
    "    threshold=0.95)(x, x_pp)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(masked_image[0].transpose((1,2,0)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "51eb71198507ab2c2a4108a27eda9d9658549732e67153fc0e371d8439827db7"
  },
  "kernelspec": {
   "display_name": "test-fresh-11-29",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
