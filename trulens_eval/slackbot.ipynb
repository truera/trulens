{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slackbot-related work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.keys import *\n",
    "from trulens_eval.slackbot import get_or_make_chain, get_answer\n",
    "from trulens_eval.util import TP\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_feedback import Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tru().start_dashboard(_dev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = Tru().start_evaluator()\n",
    "# Tru().stop_evaluator()\n",
    "# Tru().reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = [0,1,3,4]\n",
    "messages = [\"Who is Shayak?\", \"Wer ist Shayak?\", \"Kim jest Shayak?\", \"¿Quién es Shayak?\", \"Was ist QII?\", \"Co jest QII?\"]\n",
    "\n",
    "# selectors = selectors[0:2]\n",
    "# messages = messages[0:2]\n",
    "\n",
    "def test_bot(selector, question):\n",
    "    print(selector, question)\n",
    "    chain = get_or_make_chain(cid=question + str(selector), selector=selector)\n",
    "    answer = get_answer(chain=chain, question=question)\n",
    "    return answer\n",
    "\n",
    "results = []\n",
    "\n",
    "for s in selectors:\n",
    "    for m in messages:\n",
    "        results.append(TP().promise(test_bot, selector=s, question=m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP().finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP().promises.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    print(res.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_db import Record, TruDB, LocalSQLite, Chain, Query\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.util import TP\n",
    "from trulens_eval import tru_feedback\n",
    "from IPython.display import JSON\n",
    "from ipywidgets import widgets\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = tru.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, c = db._connect()\n",
    "# c.execute(\"select * from records\")\n",
    "# rows = c.fetchall()\n",
    "c.execute(\"delete from records where chain_id='2/relevance_prompt'\")\n",
    "db._close(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, c = tru.db._connect()\n",
    "c.execute(\"select * from records\")\n",
    "rows = c.fetchall()\n",
    "tru.db._close(conn)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.provider_apis import Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms.base import BaseLLM\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "from trulens_eval import tru\n",
    "from trulens_eval import tru_chain\n",
    "from trulens_eval.keys import *\n",
    "from trulens_eval.keys import PINECONE_API_KEY\n",
    "from trulens_eval.keys import PINECONE_ENV\n",
    "\n",
    "# Set up GPT-3 model\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "chain_id = \"TruBot_relevance\"\n",
    "\n",
    "# Pinecone configuration.\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_ENV  # next to api key in console\n",
    ")\n",
    "\n",
    "identity = lambda h: h\n",
    "\n",
    "# Embedding needed for Pinecone vector db.\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-ada-002')  # 1536 dims\n",
    "docsearch = Pinecone.from_existing_index(\n",
    "    index_name=\"llmdemo\", embedding=embedding\n",
    ")\n",
    "retriever = docsearch.as_retriever()\n",
    "\n",
    "# LLM for completing prompts, and other tasks.\n",
    "llm = OpenAI(temperature=0, max_tokens=128)\n",
    "\n",
    "# Conversation memory.\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    max_token_limit=650,\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    output_key='answer'\n",
    ")\n",
    "\n",
    "# Conversational chain puts it all together.\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    get_chat_history=identity,\n",
    "    max_tokens_limit=4096\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "# Language mismatch fix:\n",
    "chain.combine_docs_chain.llm_chain.prompt.template = \\\n",
    "    \"Use the following pieces of context to answer the question at the end \" \\\n",
    "    \"in the same language as the question. If you don't know the answer, \" \\\n",
    "    \"just say that you don't know, don't try to make up an answer.\\n\\n\" \\\n",
    "    \"{context}\\n\\n\" \\\n",
    "    \"Question: {question}\\n\" \\\n",
    "    \"Helpful Answer: \"\n",
    "\"\"\"\n",
    "\n",
    "# Contexts fix\n",
    "chain.combine_docs_chain.llm_chain.prompt.template = \\\n",
    "    \"Use only the relevant contexts to answer the question at the end \" \\\n",
    "    \". Some pieces of context may not be relevant. If you don't know the answer, \" \\\n",
    "    \"just say that you don't know, don't try to make up an answer.\\n\\n\" \\\n",
    "    \"Contexts: \\n{context}\\n\\n\" \\\n",
    "    \"Question: {question}\\n\" \\\n",
    "    \"Helpful Answer: \"\n",
    "\n",
    "chain.combine_docs_chain.document_prompt.template=\"\\tContext: {page_content}\"\n",
    "\n",
    "# Trulens instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugs = tru_feedback.Huggingface()\n",
    "openai = tru_feedback.OpenAI()\n",
    "\n",
    "f_toxic = tru_feedback.Feedback(hugs.not_toxic).on_response()\n",
    "f_lang_match = tru_feedback.Feedback(hugs.language_match).on(text1=\"prompt\", text2=\"response\")\n",
    "f_relevance = tru_feedback.Feedback(openai.relevance).on(prompt=\"input\", response=\"output\")\n",
    "f_qs_relevance = tru_feedback.Feedback(openai.qs_relevance) \\\n",
    "    .on(question=\"input\", statement=Record.chain.combine_docs_chain._call.args.inputs.input_documents) \\\n",
    "    .on_multiple(multiarg=\"statement\", each_query=Query().page_content)\n",
    "\n",
    "# feedbacks = tru.run_feedback_functions(chain=tc, record=record, feedback_functions=[f_qs_relevance, f_toxic, f_lang_match, f_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_statements(question: str, statements: str, threshold: float = 0.5):\n",
    "    promises = []\n",
    "    for statement in statements:\n",
    "        promises.append((statement, TP().promise(openai.qs_relevance, question=question, statement=statement)))\n",
    "    \n",
    "    results = []\n",
    "    for statement, promise in promises:\n",
    "        results.append((statement, promise.get()))\n",
    "\n",
    "    results = map(lambda sr: sr[0], filter(lambda sr: sr[1] >= threshold, results))\n",
    "\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = filter_statements(question=\"Who is Shayak?\", statements=[\"Piotr is a person.\", \"Shayak is a person.\", \"Shammek is a person.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# help(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WithFilterDocuments.of_vectorstoreretriever(retriever=retriever, filter_func=ffunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.get_relevant_documents(\"Who is Shayak?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = tru_chain.TruChain(\n",
    "    chain,\n",
    "    chain_id=chain_id,\n",
    "    feedbacks=[f_toxic, f_lang_match, f_relevance, f_qs_relevance],\n",
    "    db=tru.lms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, record = tc.call_with_record(\"What is TruEra?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_feedback import Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = f_qs_relevance.json\n",
    "display(obj)\n",
    "#display(Feedback.of_json(obj).to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tinydb import Query\n",
    "from trulens_eval.tru_db import Query, Record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(Record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in TruDB.project(query=Record.chain.combine_docs_chain._call.args.inputs.input_documents, obj=record):\n",
    "    print(doc)\n",
    "    content = TruDB.project(query=Record.page_content, obj=doc)\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = Endpoint(name=\"openai\", rpm=120)\n",
    "# print(e.pace.qsize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.endpoint_openai.tqdm.display()\n",
    "i = 0\n",
    "while True:\n",
    "    # print(e.pace.qsize())\n",
    "    tru.endpoint_openai.pace_me()\n",
    "    # print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tru_feedback.huggingface_language_match(prompt=\"Hello there?\", response=\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = LocalTinyDB(\"slackbot.json\")\n",
    "#tru.init_db(\"slackbot.sql\")\n",
    "#db = LocalSQLite(\"slackbot.sql.db\")\n",
    "db = LocalSQLite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dff = db.get_records_and_feedback(chain_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter(compact=True)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    display(widgets.HTML(f\"<b>Question:</b> {row.input}\"))\n",
    "    \n",
    "    display(widgets.HTML(f\"<b>Answer:</b> {row.output}\"))\n",
    "    \n",
    "    details = json.loads(eval(row.details))\n",
    "\n",
    "    display(widgets.HTML(str(details['chain']['combine_docs_chain']['llm_chain']['prompt']['template'])))\n",
    "    \n",
    "    for doc in details['chain']['combine_docs_chain']['_call']['args']['inputs']['input_documents']:\n",
    "        display(widgets.HTML(f\"\"\"\n",
    "        <div style=\"border: 1px solid black; padding: 5px;\">\n",
    "        <b>Context chunk</b>: {doc['page_content']}\n",
    "        \"\"\"))\n",
    "\n",
    "        \"\"\"<br/>\n",
    "\n",
    "        <b>source</b>: {doc['metadata']['source']}\n",
    "        </div>\"\"\"\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db.select(\n",
    "    Record,\n",
    "    Record.record_id,\n",
    "    Record.chain_id,\n",
    "    Record.chain._call.args.inputs.question,\n",
    "    Record.chain._call.rets.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_id, row in df.iterrows():\n",
    "    record_id = row.record_id\n",
    "    chain_id = row.chain_id\n",
    "\n",
    "    main_question = row['Record.chain._call.args.inputs.question']\n",
    "    main_answer = row['Record.chain._call.rets.answer']\n",
    "\n",
    "    print(chain_id, record_id, main_question)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(question, answer)\n",
    "\n",
    "    # Run feedback function and get value\n",
    "\n",
    "    feedback = tru.run_feedback_function(\n",
    "        main_question, main_answer, [\n",
    "            tru_feedback.get_not_hate_function(\n",
    "                evaluation_choice='prompt',\n",
    "                provider='openai',\n",
    "                model_engine='moderation'\n",
    "            ),\n",
    "            tru_feedback.get_sentimentpositive_function(\n",
    "                evaluation_choice='response',\n",
    "                provider='openai',\n",
    "                model_engine='gpt-3.5-turbo'\n",
    "            ),\n",
    "            tru_feedback.get_relevance_function(\n",
    "                evaluation_choice='both',\n",
    "                provider='openai',\n",
    "                model_engine='gpt-3.5-turbo'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    print(f\"will insert overall feedback for chain {chain_id}, record {record_id}\")\n",
    "    db.insert_feedback(record_id=record_id, chain_id=chain_id, feedback=feedback)\n",
    "    \"\"\"\n",
    "    \n",
    "    # display(JSON(row.Record))\n",
    "    # print(row.Record['chain'])\n",
    "\n",
    "    model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "    \"\"\"\n",
    "    for page in TruDB.project(query=Record.chain.combine_docs_chain._call.args.inputs.input_documents, obj=row.Record):\n",
    "        answer = page['page_content']\n",
    "        feedback = tru.run_feedback_function(\n",
    "            main_question,\n",
    "            answer,\n",
    "\t        [\n",
    "            tru_feedback.get_qs_relevance_function(\n",
    "                evaluation_choice='prompt',\n",
    "                provider='openai',\n",
    "                model_engine=model_name\n",
    "            )]\n",
    "        )\n",
    "        db.insert_feedback(record_id=record_id, chain_id=chain_id, feedback=feedback)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    feedback = tru.run_feedback_function(\n",
    "        main_question, main_answer, [\n",
    "            tru_feedback.get_language_match_function(\n",
    "                provider='huggingface'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    print(f\"will insert language match feedback for chain {chain_id}, record {record_id}\")\n",
    "    db.insert_feedback(record_id=record_id, chain_id=chain_id, feedback=feedback)\n",
    "\n",
    "    # feedback = tru.run_feedback_function(\n",
    "\n",
    "    #for leaf in TruDB.leafs(row.Record):\n",
    "    #    print(leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row.record_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = {'openai_hate_function': 1.849137515819166e-05,\n",
    " 'openai_sentimentpositive_feedback_function': 1,\n",
    " 'openai_relevance_function': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert_feedback(2, feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.select(Record, table=db.feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "feedback = tru.run_feedback_function(\n",
    "    \"Who is Piotr?\",\n",
    "    \"Piotr Mardziel works on transparency and accountability in machine learning with applications to security, privacy, and fairness. He holds Bachelor’s and Master’s degrees from the Worcester Polytechnic Institute and a PhD in computer science from University of Maryland, College Park. He has conducted post-doctoral research at Carnegie Mellon University, as well as taught classes in trustworthy machine learning at Stanford University and machine learning privacy and security at Carnegie Mellon University.\",\n",
    "\t [\n",
    "        tru_feedback.get_qs_relevance_function(\n",
    "            evaluation_choice='prompt',\n",
    "            provider='openai',\n",
    "            model_engine=model_name\n",
    "        )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
