{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruLens for LLMs: Quickstart\n",
    "\n",
    "In this quickstart you will create a simple LLM Chain and learn how to log it and get feedback on an LLM response.\n",
    "\n",
    "Note: If you haven't already, make sure to set up your local .env file with your OpenAI and Huggingface Keys. Your .env file should be in the same directory that you run this notebook. If you need help, take a look at the [.env.example](https://github.com/truera/trulens_private/blob/e8b11c4689e644687d2eafe09d90d8d7774b581c/trulens_eval/trulens_eval/.env.example#L4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from LangChain and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY SET: OPENAI_API_KEY\n",
      "KEY SET: PINECONE_API_KEY\n",
      "KEY SET: PINECONE_ENV\n",
      "KEY SET: HUGGINGFACE_API_KEY\n",
      "KEY SET: SLACK_TOKEN\n",
      "KEY SET: SLACK_SIGNING_SECRET\n",
      "KEY SET: COHERE_API_KEY\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "# imports from trulens to log and get feedback on chain\n",
    "from trulens_eval.keys import *\n",
    "from trulens_eval import TruChain, Feedback, OpenAI, Huggingface, Tru\n",
    "\n",
    "# imports from langchain to build app\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Simple LLM Application\n",
    "\n",
    "This example uses a LangChain framework and OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\n",
    "        \"Provide a helpful response with relevant background information for the following: {prompt}\",\n",
    "        input_variables=[\"prompt\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.9)\n",
    "\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send your first request to your new app, asking how to adopt a dog in spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input = 'Como adopto un perro?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Provide a helpful response with relevant background information for the following: Como adopto un perro?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Como adopto un perro?',\n",
       " 'text': 'Adoptar un perro es una gran responsabilidad, pero también puede ser una experiencia muy gratificante. Primero, debes investigar y encontrar un refugio para animales cercano a ti. A menudo, estos refugios tienen perros que necesitan hogares amorosos. También puedes buscar en línea en sitios web como Adopt-a-Pet.com o Petfinder.com. \\n\\nCuando encuentres un perro que te guste, asegúrate de conocer su historial médico y comportamental. Pregunta sobre su peso, edad, si está vacunado, si tiene alguna enfermedad o necesidades especiales, y si ha tenido algún comportamiento agresivo. Los refugios generalmente hacen una evaluación de comportamiento, pero también es importante que puedas observar al perro con tus propios ojos.\\n\\nDespués de seleccionar a tu perro, deberás llenar una solicitud para la adopción y pagar una tarifa. Esta tarifa puede variar dependiendo de la organización, pero a menudo incluye el costo de la esterilización o castración del perro, las vacunas y los cuidados veterinarios iniciales.\\n\\nRecuerda que adoptar un perro es una decisión importante y deberás asegurarte de que estás dispuesto y en capacidad de cuidar al animal durante toda su vida. Esto incluirá proporcionarle comida, agua, ejercicio, entrenamiento y amor. ¡Buena suerte en tu búsqueda de un nuevo amigo peludo!'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt3_response = chain(prompt_input)\n",
    "\n",
    "display(gpt3_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:`feedback_mode` is withchainthread but `tru` was not specified. Reverting to None.\n"
     ]
    }
   ],
   "source": [
    "truchain: TruChain = TruChain(chain, chain_id='Chain1_ChatApplication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Provide a helpful response with relevant background information for the following: Como adopto un perro?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Como adopto un perro?',\n",
       " 'text': 'Adoptar un perro puede ser un proceso emocionante y satisfactorio, ya que estarás brindando un hogar amoroso a una mascota necesitada. Hay varias opciones para adoptar un perro, como ir a un refugio local de animales o trabajar con una organización de rescate de animales.\\n\\nAntes de adoptar un perro, es importante evaluar tu estilo de vida y tu capacidad para cuidar de una mascota. Las necesidades de los perros varían según la edad, la raza y la personalidad, y es importante encontrar un animal que se adapte bien a tu estilo de vida y pueda recibir la atención y el cuidado adecuados.\\n\\nUna vez que hayas encontrado un perro que te guste, es probable que debas completar una solicitud de adopción y someterte a una entrevista con un representante de la organización. También es posible que debas pagar una tarifa de adopción y proporcionar información sobre tus antecedentes y situación de vivienda.\\n\\nAdoptar un perro puede ser una experiencia increíblemente gratificante para ti y tu nueva mascota, y hay muchas organizaciones disponibles para ayudarte en el proceso. Si tienes interés en adoptar un perro, te recomendamos que te comuniques con tu refugio local de animales o una organización de rescate de animales para obtener más información.'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instrumented chain can operate like the original:\n",
    "\n",
    "gpt3_response = truchain(prompt_input)\n",
    "\n",
    "display(gpt3_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Provide a helpful response with relevant background information for the following: Como adopto un perro?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "_cost": {
        "total_cost": 0.00044400000000000006,
        "total_tokens": 222
       },
       "chain": {
        "_call": {
         "args": {
          "inputs": {
           "prompt": "Como adopto un perro?"
          }
         },
         "chain_stack": [
          [
           "chain"
          ]
         ],
         "end_time": "2023-05-22 19:08:44.103305",
         "pid": 806754,
         "rets": {
          "text": "¡Adoptar un perro es una de las decisiones más gratificantes que puede tomar! Primero, es importante determinar qué tipo de perro es adecuado para su estilo de vida y hogar. Luego, puede comenzar a buscar refugios locales o grupos de rescate de animales en su área que tengan perros disponibles para adoptar. Al adoptar un perro, estará salvando una vida y brindando un hogar amoroso a un animal necesitado. También puede considerar la adopción de un perro de raza mixta, ya que a menudo tienen menos problemas de salud que los perros de raza pura. Recuerde que la adopción de un perro es una responsabilidad importante y requiere tiempo, paciencia y dedicación, pero los beneficios de tener un perro como miembro de la familia son incomparables."
         },
         "start_time": "2023-05-22 19:08:28.180729",
         "tid": 806754
        }
       },
       "chain_id": "Chain1_ChatApplication"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But can also produce a log or \"record\" of the execution of the chain:\n",
    "\n",
    "gpt3_response, record = truchain.call_with_record(prompt_input)\n",
    "\n",
    "JSON(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating new Tru singleton instance for name = None ***\n"
     ]
    }
   ],
   "source": [
    "# We can log the records but first we need to log the chain itself:\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.add_chain(chain_json=truchain.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'record_hash_7c9388a886ec7489abd77ae3d12b5661'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the record:\n",
    "\n",
    "tru.add_record(\n",
    "    prompt=prompt_input, # prompt input\n",
    "    response=gpt3_response['text'], # LLM response\n",
    "    record_json=record # record is returned by the TruChain wrapper\n",
    ")\n",
    "\n",
    "# Note that the `add_record` call automatically sets the `record_id` field of the\n",
    "# `record_json` to the returned record id. Retrieving it from the output of `add_record` is not \n",
    "# necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating new Endpoint singleton instance for name = huggingface ***\n",
      "*** Creating huggingface endpoint ***\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbaa7ebba3040668621efb04a756813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "huggingface api: 0requests [00:00, ?requests/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating new TP singleton instance for name = None ***\n"
     ]
    }
   ],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on(\n",
    "    text1=\"prompt\", text2=\"response\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 20.0} (20.0) second(s).\n",
      "WARNING: Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 20.0} (20.0) second(s).\n"
     ]
    }
   ],
   "source": [
    "# This might take a moment if the public api needs to load the language model\n",
    "# used in the feedback function:\n",
    "feedback_result = f_lang_match.run_on_record(\n",
    "    chain_json=truchain.json, record_json=record\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "_success": true,
       "feedback_id": "feedback_hash_26c84c76d907d808c36028e024af63c0",
       "language_match": 0.005009680444345577,
       "record_id": "record_hash_7c9388a886ec7489abd77ae3d12b5661"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(feedback_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, run a collection of feedback functions:\n",
    "\n",
    "feedback_results = tru.run_feedback_functions(\n",
    "    record_json=record,\n",
    "    feedback_functions=[f_lang_match]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_success': True,\n",
       "  'feedback_id': 'feedback_hash_26c84c76d907d808c36028e024af63c0',\n",
       "  'record_id': 'record_hash_7c9388a886ec7489abd77ae3d12b5661',\n",
       "  'language_match': 0.005009680444345577}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(feedback_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tru.add_feedbacks() missing 1 required positional argument: 'db'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# These can be logged:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tru\u001b[39m.\u001b[39;49madd_feedbacks(feedback_results)\n",
      "\u001b[0;31mTypeError\u001b[0m: Tru.add_feedbacks() missing 1 required positional argument: 'db'"
     ]
    }
   ],
   "source": [
    "# These can be logged:\n",
    "\n",
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the TruLens dashboard to explore the quality of your LLM chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Logging\n",
    "\n",
    "The above logging and feedback function evaluation steps can be done by TruChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chain1_ChatApplication -> SQLite(default.sqlite)\n",
      "✅ feedback_hash_26c84c76d907d808c36028e024af63c0 -> SQLite(default.sqlite)\n"
     ]
    }
   ],
   "source": [
    "truchain: TruChain = TruChain(\n",
    "    chain,\n",
    "    chain_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_lang_match],\n",
    "    tru=tru\n",
    ")\n",
    "\n",
    "# Note: providing `db: TruDB` causes the above constructor to log the wrapped chain in the database specified.\n",
    "\n",
    "# Note: any `feedbacks` specified here will be evaluated and logged whenever the chain is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Provide a helpful response with relevant background information for the following: This will be automatically logged.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'This will be automatically logged.',\n",
       " 'text': 'Automatic logging is a feature used in many different types of technology, such as computer programs, web applications, and electronic devices. It involves capturing and recording specific information about user behavior, system events, and other important data. This information is stored in a log file, which can be used for troubleshooting, auditing, monitoring, or analysis purposes. By automatically logging certain activities, organizations can ensure compliance with regulations, maintain security and integrity of their systems, and make informed decisions based on data insights. So when you see the message \"This will be automatically logged\", it means that the system is capturing specific information required for tracking and analysis.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feedback functions now.\n"
     ]
    }
   ],
   "source": [
    "truchain(\"This will be automatically logged.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-band Feedback evaluation\n",
    "\n",
    "In the above example, the feedback function evaluation is done in the same process as the chain evaluation. The alternative approach is the use the provided persistent evaluator started via `tru.start_deferred_feedback_evaluator`. Then specify the `feedback_mode` for `TruChain` as `deferred` to let the evaluator handle the feedback functions.\n",
    "\n",
    "For demonstration purposes, we start the evaluator here but it can be started in another process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chain1_ChatApplication -> SQLite(default.sqlite)\n",
      "✅ feedback_hash_26c84c76d907d808c36028e024af63c0 -> SQLite(default.sqlite)\n"
     ]
    }
   ],
   "source": [
    "truchain: TruChain = TruChain(\n",
    "    chain,\n",
    "    chain_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_lang_match],\n",
    "    tru=tru,\n",
    "    feedback_mode=\"deferred\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.start_deferred_feedback_evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Provide a helpful response with relevant background information for the following: This will be logged by deferred evaluator.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'This will be logged by deferred evaluator.',\n",
       " 'text': 'Deferred evaluation is a programming technique where a value is not immediately computed when called, but is instead evaluated at a later time or only when needed. This approach can improve performance by only computing values when necessary, rather than wasting resources on values that may never be used. \\n\\nIn the context of logging, a deferred evaluator is a tool that allows for the delayed evaluation of log entries. This can be useful in situations where logging is performed continuously, but the actual processing and analysis of the logs happens on a separate schedule. By deferring the evaluation of log entries until they are needed, a deferred evaluator can help reduce the overhead associated with logging by only computing values when they are actually needed.\\n\\nOverall, the use of a deferred evaluator for logging provides a flexible and efficient way to manage logging data, allowing for delayed evaluation and processing of logs as needed.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truchain(\"This will be logged by deferred evaluator.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('trulens')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c633204c92f433e69d41413efde9db4a539ce972d10326abcceb024ad118839e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
