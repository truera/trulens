{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruLens for LLMs: Quickstart\n",
    "\n",
    "In this quickstart you will create a simple LLM Chain and learn how to log it and get feedback on an LLM response.\n",
    "\n",
    "Note: If you haven't already, make sure to set up your local .env file with your OpenAI and Huggingface Keys. Your .env file should be in the same directory that you run this notebook. If you need help, take a look at the [.env.example](https://github.com/truera/trulens_private/blob/e8b11c4689e644687d2eafe09d90d8d7774b581c/trulens_eval/trulens_eval/.env.example#L4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from LangChain and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "# imports from langchain to build app\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "\n",
    "# imports from trulens to log and get feedback on chain\n",
    "from trulens_eval import TruChain, Feedback, OpenAI, Huggingface, db, tru\n",
    "# from trulens_eval import tru_chain\n",
    "# from trulens_eval.tru_chain import TruChain\n",
    "# from trulens_eval.tru_feedback import Feedback, Huggingface, OpenAI\n",
    "from trulens_eval.keys import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Simple LLM Application\n",
    "\n",
    "This example uses a LangChain framework and OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\n",
    "        \"Provide a helpful response with relevant background information for the following: {prompt}\",\n",
    "        input_variables=[\"prompt\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.9)\n",
    "\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send your first request to your new app, asking how to adopt a dog in spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input = 'Como adopto un perro?'\n",
    "gpt3_response = chain(prompt_input)\n",
    "\n",
    "display(gpt3_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truchain: TruChain = TruChain(chain, chain_id='Chain1_ChatApplication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrumented chain can operate like the original:\n",
    "\n",
    "gpt3_response = truchain(prompt_input)\n",
    "\n",
    "display(gpt3_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But can also produce a log or \"record\" of the execution of the chain:\n",
    "\n",
    "gpt3_response, record = truchain.call_with_record(prompt_input)\n",
    "\n",
    "JSON(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can log the records but first we need to log the chain itself:\n",
    "\n",
    "tru.add_chain(chain_json=truchain.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the record:\n",
    "\n",
    "record_id = tru.add_record(\n",
    "    prompt=prompt_input, # prompt input\n",
    "    response=gpt3_response['text'], # LLM response\n",
    "    record_json=record # record is returned by the TruChain wrapper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on(text1=\"prompt\", text2=\"response\")\n",
    "\n",
    "# This might take a moment if the public api needs to load the language model used in the feedback function:\n",
    "feedback_result = f_lang_match.run_on_record(chain_json=truchain.json, record_json=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(feedback_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, run a collection of feedback functions:\n",
    "\n",
    "feedback_results = tru.run_feedback_functions(\n",
    "    record_json=record,\n",
    "    feedback_functions=[f_lang_match]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These can be logged:\n",
    "\n",
    "for result in feedback_results:\n",
    "    tru.add_feedback(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the TruLens dashboard to explore the quality of your LLM chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Logging\n",
    "\n",
    "The above logging and feedback function evaluation steps can be done by TruChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "truchain: TruChain = TruChain(\n",
    "    chain,\n",
    "    chain_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_lang_match],\n",
    "    db=db\n",
    ")\n",
    "\n",
    "# Note: providing `db: TruDB` causes the above constructor to log the wrapped chain in the database specified.\n",
    "\n",
    "# Note: any `feedbacks` specified here will be evaluated and logged whenever the chain is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Provide a helpful response with relevant background information for the following: How are you?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'How are you?',\n",
       " 'text': 'As an AI language model, I do not have the ability to feel emotions or physical sensations. However, I am always ready and available to assist you in any way I can. Is there anything specific you need help with today?'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truchain(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('trulens')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c633204c92f433e69d41413efde9db4a539ce972d10326abcceb024ad118839e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
