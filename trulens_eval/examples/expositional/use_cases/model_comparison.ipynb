{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "In this example you will learn how to compare different models with TruLens.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/model_comparison.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\"\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "# Imports main tools:\n",
    "from trulens_eval import Feedback, Tru, OpenAI\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple Text to Text Application\n",
    "\n",
    "This example uses a bare bones OpenAI LLM, and a non-LLM just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt35_turbo(prompt):\n",
    "    return openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a question and answer bot. Answer upbeat.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def gpt4(prompt):\n",
    "    return openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a question and answer bot. Answer upbeat.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def llama2(prompt):\n",
    "    return completion(\n",
    "        model = \"replicate/meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a question and answer bot. Answer upbeat.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )['choices'][0]['message']['content']\n",
    "\n",
    "def mistral7b(prompt):\n",
    "    return completion(\n",
    "        model = \"replicate/lucataco/mistral-7b-v0.1:992ccec19c0f8673d24cffbd27756f02010ab9cc453803b7b2da9e890dd87b41\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a question and answer bot. Answer upbeat.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )['choices'][0]['message']['content']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a sentiment feedback function using HuggingFace.\n",
    "f_sentiment = Feedback(hugs.positive_sentiment, feedback_mode = FeedbackMode.DEFERRED).on_output()\n",
    "\n",
    "# OpenAI based feedback function collection class\n",
    "openai_provider = OpenAI()\n",
    "\n",
    "# Relevance feedback function using openai\n",
    "f_relevance = Feedback(openai_provider.relevance, feedback_mode = FeedbackMode.DEFERRED).on_input_output()\n",
    "\n",
    "# Conciseness feedback function using openai\n",
    "f_conciseness = Feedback(openai_provider.conciseness, feedback_mode = FeedbackMode.DEFERRED).on_output()\n",
    "\n",
    "# Stereotypes feedback function using openai\n",
    "f_stereotypes = Feedback(openai_provider.stereotypes, feedback_mode = FeedbackMode.DEFERRED).on_input_output()\n",
    "\n",
    "feedbacks = [f_sentiment, f_relevance, f_conciseness, f_stereotypes]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument the callable for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruBasicApp\n",
    "gpt35_turbo_recorder = TruBasicApp(gpt35_turbo, app_id=\"gpt-3.5-turbo\", feedbacks=feedbacks)\n",
    "gpt4_recorder = TruBasicApp(gpt4, app_id=\"gpt-4-turbo\", feedbacks=feedbacks)\n",
    "llama2_recorder = TruBasicApp(llama2, app_id=\"llama2\", feedbacks=feedbacks, feedback_mode = FeedbackMode.DEFERRED)\n",
    "mistral7b_recorder = TruBasicApp(mistral7b, app_id=\"mistral7b\", feedbacks=feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Describe the implications of widespread adoption of autonomous vehicles on urban infrastructure.\",\n",
    "    \"Write a short story about a world where humans have developed telepathic communication.\",\n",
    "    \"Debate the ethical considerations of using CRISPR technology to genetically modify humans.\",\n",
    "    \"Compose a poem that captures the essence of a dystopian future ruled by artificial intelligence.\",\n",
    "    \"Explain the concept of the multiverse theory and its relevance to theoretical physics.\",\n",
    "    \"Provide a detailed plan for a sustainable colony on Mars, addressing food, energy, and habitat.\",\n",
    "    \"Discuss the potential benefits and drawbacks of a universal basic income policy.\",\n",
    "    \"Imagine a dialogue between two AI entities discussing the meaning of consciousness.\",\n",
    "    \"Elaborate on the impact of quantum computing on cryptography and data security.\",\n",
    "    \"Create a persuasive argument for or against the colonization of other planets as a solution to overpopulation on Earth.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gpt35_turbo_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        print(prompt)\n",
    "        gpt35_turbo_recorder.app(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gpt4_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        print(prompt)\n",
    "        gpt4_recorder.app(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llama2_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        print(prompt)\n",
    "        llama2_recorder.app(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mistral7b_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        mistral7b_recorder.app(prompt_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or view results directly in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_records_and_feedback(app_ids=[])[0] # pass an empty list of app_ids to get all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
