{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruLens-Canopy Quickstart\n",
    "\n",
    " Canopy is an open-source framework and context engine built on top of the Pinecone vector database so you can build and host your own production-ready chat assistant at any scale. By integrating TruLens into your Canopy assistant, you can quickly iterate on and gain confidence in the quality of your chat assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"d5589ecb-e0dd-4768-b92b-5d5aad35d304\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728aeea1-1dcf-5d0a-91f2-ecccd4dd4272</td>\n",
       "      <td># Scale indexes\\n\\n[Suggest Edits](/edit/scali...</td>\n",
       "      <td>https://docs.pinecone.io/docs/scaling-indexes</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'scaling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f19f269-171f-5556-93f3-a2d7eabbe50f</td>\n",
       "      <td># Understanding organizations\\n\\n[Suggest Edit...</td>\n",
       "      <td>https://docs.pinecone.io/docs/organizations</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'organiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2a71cb3-5148-5090-86d5-7f4156edd7cf</td>\n",
       "      <td># Manage datasets\\n\\n[Suggest Edits](/edit/dat...</td>\n",
       "      <td>https://docs.pinecone.io/docs/datasets</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'datasets'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1dafe68a-2e78-57f7-a97a-93e043462196</td>\n",
       "      <td># Architecture\\n\\n[Suggest Edits](/edit/archit...</td>\n",
       "      <td>https://docs.pinecone.io/docs/architecture</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b07b24d-4ec2-58a1-ac91-c8e6267b9ffd</td>\n",
       "      <td># Moving to production\\n\\n[Suggest Edits](/edi...</td>\n",
       "      <td>https://docs.pinecone.io/docs/moving-to-produc...</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'moving-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   \n",
       "0  728aeea1-1dcf-5d0a-91f2-ecccd4dd4272  \\\n",
       "1  2f19f269-171f-5556-93f3-a2d7eabbe50f   \n",
       "2  b2a71cb3-5148-5090-86d5-7f4156edd7cf   \n",
       "3  1dafe68a-2e78-57f7-a97a-93e043462196   \n",
       "4  8b07b24d-4ec2-58a1-ac91-c8e6267b9ffd   \n",
       "\n",
       "                                                text   \n",
       "0  # Scale indexes\\n\\n[Suggest Edits](/edit/scali...  \\\n",
       "1  # Understanding organizations\\n\\n[Suggest Edit...   \n",
       "2  # Manage datasets\\n\\n[Suggest Edits](/edit/dat...   \n",
       "3  # Architecture\\n\\n[Suggest Edits](/edit/archit...   \n",
       "4  # Moving to production\\n\\n[Suggest Edits](/edi...   \n",
       "\n",
       "                                              source   \n",
       "0      https://docs.pinecone.io/docs/scaling-indexes  \\\n",
       "1        https://docs.pinecone.io/docs/organizations   \n",
       "2             https://docs.pinecone.io/docs/datasets   \n",
       "3         https://docs.pinecone.io/docs/architecture   \n",
       "4  https://docs.pinecone.io/docs/moving-to-produc...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'created_at': '2023_10_25', 'title': 'scaling...  \n",
       "1  {'created_at': '2023_10_25', 'title': 'organiz...  \n",
       "2  {'created_at': '2023_10_25', 'title': 'datasets'}  \n",
       "3  {'created_at': '2023_10_25', 'title': 'archite...  \n",
       "4  {'created_at': '2023_10_25', 'title': 'moving-...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_parquet(\"https://storage.googleapis.com/pinecone-datasets-dev/pinecone_docs_ada-002/raw/file1.parquet\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ' world', '!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from canopy.tokenizer import Tokenizer\n",
    "Tokenizer.initialize()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.tokenize(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Load Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3d21a7f8fa4172b548303996364be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from canopy.knowledge_base import KnowledgeBase\n",
    "\n",
    "INDEX_NAME = \"my-index\"\n",
    "\n",
    "kb = KnowledgeBase(index_name=INDEX_NAME)\n",
    "\n",
    "from canopy.knowledge_base import list_canopy_indexes\n",
    "if not any(name.endswith(INDEX_NAME) for name in list_canopy_indexes()):\n",
    "    kb.create_canopy_index()\n",
    "\n",
    "kb = KnowledgeBase(index_name=INDEX_NAME)\n",
    "kb.connect()\n",
    "\n",
    "from canopy.models.data_models import Document\n",
    "\n",
    "documents = [Document(**row) for _, row in data.iterrows()]\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "for i in tqdm(range(0, len(documents), batch_size)):\n",
    "    kb.upsert(documents[i: i+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create context and chat engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from canopy.models.data_models import Query\n",
    "from canopy.context_engine import ContextEngine\n",
    "context_engine = ContextEngine(kb)\n",
    "\n",
    "from canopy.chat_engine import ChatEngine\n",
    "chat_engine = ChatEngine(context_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument static methods used by engine with TruLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "from canopy.context_engine import ContextEngine\n",
    "instrument.method(ContextEngine, \"query\")\n",
    "\n",
    "from canopy.chat_engine import ChatEngine\n",
    "instrument.method(ChatEngine, \"chat\")\n",
    "\n",
    "from canopy.chat_engine.query_generator.base import QueryGenerator\n",
    "instrument.method(QueryGenerator, \"generate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feedback functions using instrumented methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.context_engine.query.rets.content.root[:].snippets[:].text.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.app.chat.rets.choices[0].message.content .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.app.chat.args.messages[0].content .\n",
      "✅ In Answer Relevance, input response will be set to __record__.app.chat.rets.choices[0].message.content .\n",
      "✅ In Context Relevance, input question will be set to __record__.app.chat.args.messages[0].content .\n",
      "✅ In Context Relevance, input statement will be set to __record__.app.context_engine.query.rets.content.root[:].snippets[:].text .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from trulens_eval.feedback.provider.openai import OpenAI as fOpenAI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "fopenai = fOpenAI()\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=fopenai)\n",
    "\n",
    "intput = Select.RecordCalls.chat.args.messages[0].content\n",
    "context = Select.RecordCalls.context_engine.query.rets.content.root[:].snippets[:].text\n",
    "output = Select.RecordCalls.chat.rets.choices[0].message.content\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\", higher_is_better=True)\n",
    "    .on(context.collect())\n",
    "    .on(output)\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = (\n",
    "    Feedback(fopenai.relevance_with_cot_reasons, name = \"Answer Relevance\", higher_is_better=True)\n",
    "    .on(intput)\n",
    "    .on(output)\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(fopenai.qs_relevance_with_cot_reasons, name = \"Context Relevance\", higher_is_better=True)\n",
    "    .on(intput)\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "tru_recorder = TruCustomApp(chat_engine, feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsure what the main input string is for the call to chat with args [[UserMessage(role=<Role.USER: 'user'>, content='How can you get started with Pinecone and TruLens?')]].\n",
      "Unsure what the main output string is for the call to chat with return type <class 'canopy.models.api_models.ChatResponse'>.\n"
     ]
    }
   ],
   "source": [
    "from canopy.models.data_models import Messages, UserMessage\n",
    "\n",
    "query = [UserMessage(content=\"How can you get started with Pinecone and TruLens?\")]\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    chat_engine.chat(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c9f062df0c494cad68cbe8c4cde62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://172.20.10.2:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>app_hash_d31d0d4278e016266a7bab4f0b34e069</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.002671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_hash_727ea3fe2eefa2d7c8db72e2a75f0ca4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.003431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Context Relevance   \n",
       "app_id                                                         \n",
       "app_hash_d31d0d4278e016266a7bab4f0b34e069                0.7  \\\n",
       "app_hash_727ea3fe2eefa2d7c8db72e2a75f0ca4                NaN   \n",
       "\n",
       "                                           Answer Relevance  Groundedness   \n",
       "app_id                                                                      \n",
       "app_hash_d31d0d4278e016266a7bab4f0b34e069              0.83      0.394444  \\\n",
       "app_hash_727ea3fe2eefa2d7c8db72e2a75f0ca4               NaN           NaN   \n",
       "\n",
       "                                           latency  total_cost  \n",
       "app_id                                                          \n",
       "app_hash_d31d0d4278e016266a7bab4f0b34e069      5.7    0.002671  \n",
       "app_hash_727ea3fe2eefa2d7c8db72e2a75f0ca4      8.0    0.003431  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trucanopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
