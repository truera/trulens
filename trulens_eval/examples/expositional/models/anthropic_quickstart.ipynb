{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic\n",
    "\n",
    "Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems. Through our LiteLLM integration, you are able to easily run feedback functions with Anthropic's Claude and Claude Instant.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/models/anthropic_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install anthropic trulens_eval==0.20.3 langchain==0.0.347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "\n",
    "anthropic = Anthropic()\n",
    "\n",
    "def claude_2_app(prompt):\n",
    "    completion = anthropic.completions.create(\n",
    "        model=\"claude-2\",\n",
    "        max_tokens_to_sample=300,\n",
    "        prompt=f\"{HUMAN_PROMPT} {prompt} {AI_PROMPT}\",\n",
    "    ).completion\n",
    "    return completion\n",
    "\n",
    "claude_2_app(\"How does a case reach the supreme court?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.external import LiteLLM\n",
    "# Initialize Huggingface-based feedback function collection class:\n",
    "claude_2 = LiteLLM(model_engine=\"claude-2\")\n",
    "\n",
    "from trulens.core import Feedback\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_relevance = Feedback(claude_2.relevance).on_input_output()\n",
    "# By default this will check language match on the main app input and main app\n",
    "# output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruBasicApp\n",
    "\n",
    "tru_recorder = TruBasicApp(claude_2_app,\n",
    "app_id='Anthropic Claude 2',\n",
    "feedbacks=[f_relevance]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = tru_recorder.app(\"How does a case make it to the supreme court?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n\nrun_dashboard(tru) # open a local streamlit app to explore\n",
    "\n",
    "# stop_dashboard(tru) # stop if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or view results directly in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_records_and_feedback(app_ids=[])[0] # pass an empty list of app_ids to get all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('bedrock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbd8bda268d97161c416082acfe7f3544f1ce04ec31d1cf6cbb43b1d95b363a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
