{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "In this example you will learn how to evaluate various models for RAG with TruLens.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/huggingface_models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install install faiss-cpu unstructured==0.10.12 langchain git@trulens litellm openai trulens_eval flask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add API keys\n",
    "Enter your keys before running the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_KEY_HERE\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports main tools:\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval import OpenAI\n",
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Simple RAG Application\n",
    "\n",
    "This example uses a simple rag application, to demonstrate vectara hallucination for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by the great example from Joselin James here : https://github.com/truera/trulens/blob/29b7f3152d6058a8a7bbb680fe72368d3f020b53/trulens_eval/examples/expositional/vector-dbs/faiss/langchain_faiss_example.ipynb\n",
    "from typing import List\n",
    "from flask import Flask, request, jsonify\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "import numpy as np\n",
    "\n",
    "from trulens_eval import feedback\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval import Select\n",
    "from trulens_eval import Tru\n",
    "\n",
    "# Create a local FAISS Vector DB based on README.md .\n",
    "loader = UnstructuredMarkdownLoader(\"README.md\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Save it.\n",
    "db.save_local(\"faiss_index\")\n",
    "\n",
    "class VectorStoreRetrieverWithScore(VectorStoreRetriever):\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        if self.search_type == \"similarity\":\n",
    "            docs_and_scores = self.vectorstore.similarity_search_with_relevance_scores(\n",
    "                query, **self.search_kwargs\n",
    "            )\n",
    "\n",
    "            print(\"From relevant doc in vec store\")\n",
    "            docs = []\n",
    "            for doc, score in docs_and_scores:\n",
    "                if score > 0.6:\n",
    "                    doc.metadata[\"score\"] = score\n",
    "                    docs.append(doc)\n",
    "        elif self.search_type == \"mmr\":\n",
    "            docs = self.vectorstore.max_marginal_relevance_search(\n",
    "                query, **self.search_kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"search_type of {self.search_type} not allowed.\")\n",
    "        return docs\n",
    "\n",
    "# Create the example app.\n",
    "class FAISSWithScore(FAISS):\n",
    "\n",
    "    def as_retriever(self) -> VectorStoreRetrieverWithScore:\n",
    "        return VectorStoreRetrieverWithScore(\n",
    "            vectorstore=self,\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 4},\n",
    "        )\n",
    "\n",
    "class FAISSStore:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vector_store():\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        faiss_store = FAISSWithScore.load_local(\"faiss_index\", embeddings)\n",
    "        print(\"Faiss vector DB loaded\")\n",
    "        return faiss_store\n",
    "\n",
    "\n",
    "# Initialize the FAISS vector store\n",
    "faiss_store = FAISSStore.load_vector_store()\n",
    "\n",
    "def retrieve_documents(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents from the FAISS vector store based on the query.\n",
    "    \"\"\"\n",
    "    retriever = faiss_store.as_retriever()\n",
    "    documents = retriever._get_relevant_documents(query)\n",
    "    return documents\n",
    "\n",
    "def format_documents_for_mixtral(documents: List[Document], user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Format the retrieved documents and user query for Mixtral input.\n",
    "    \"\"\"\n",
    "    # Combine the text of each document, you might want to adjust the formatting\n",
    "    combined_docs = \" \".join([doc.text for doc in documents])\n",
    "    # Append the user query to the combined documents\n",
    "    mixtral_input = f\"\"\"Context : \n",
    "    {combined_docs} \n",
    "    Query :\n",
    "    {user_query}\"\"\"\n",
    "    return mixtral_input\n",
    "\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask():\n",
    "    \"\"\"\n",
    "    Endpoint to handle user queries, retrieve documents, and query Mixtral.\n",
    "    \"\"\"\n",
    "    data = request.json\n",
    "    user_query = data.get(\"query\")\n",
    "    if not user_query:\n",
    "        return jsonify({\"error\": \"No query provided\"}), 400\n",
    "    # Retrieve documents based on the user query\n",
    "    documents = retrieve_documents(user_query)\n",
    "    # Format the documents and user query for Mixtral\n",
    "    mixtral_input = format_documents_for_mixtral(documents, user_query)\n",
    "    # Query Mixtral API\n",
    "    mixtral_response = query({\"inputs\": mixtral_input})\n",
    "    # Return Mixtral's response\n",
    "    return jsonify(mixtral_response)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True, port=5000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a sentiment feedback function using HuggingFace.\n",
    "f_hallucination = Feedback(hugs.hallucination_evaluator, feedback_mode = FeedbackMode.DEFERRED).on_output()\n",
    "\n",
    "feedbacks = [f_hallucination]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument the callable for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the load_conversational_chain function\n",
    "def load_conversational_chain(vector_store):\n",
    "    llm = ask()\n",
    "    retriever = vector_store.as_retriever()\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm, retriever, return_source_documents=True\n",
    "    )\n",
    "\n",
    "    tru = Tru()\n",
    "\n",
    "    truchain = tru.Chain(chain,feedbacks=feedbacks,with_hugs=True)\n",
    "\n",
    "    return chain, truchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Describe the implications of widespread adoption of autonomous vehicles on urban infrastructure.\",\n",
    "    \"Write a short story about a world where humans have developed telepathic communication.\",\n",
    "    \"Debate the ethical considerations of using CRISPR technology to genetically modify humans.\",\n",
    "    \"Compose a poem that captures the essence of a dystopian future ruled by artificial intelligence.\",\n",
    "    \"Explain the concept of the multiverse theory and its relevance to theoretical physics.\",\n",
    "    \"Provide a detailed plan for a sustainable colony on Mars, addressing food, energy, and habitat.\",\n",
    "    \"Discuss the potential benefits and drawbacks of a universal basic income policy.\",\n",
    "    \"Imagine a dialogue between two AI entities discussing the meaning of consciousness.\",\n",
    "    \"Elaborate on the impact of quantum computing on cryptography and data security.\",\n",
    "    \"Create a persuasive argument for or against the colonization of other planets as a solution to overpopulation on Earth.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mistral7b_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        mistral7b_recorder.app(prompt_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or view results directly in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_records_and_feedback(app_ids=[])[0] # pass an empty list of app_ids to get all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
