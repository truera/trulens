{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158040279988997565257440694439896516614"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.getrandbits(16 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Span types.\n",
    "\n",
    "These are roughly equivalent to RecordAppCall but abstract away specific method\n",
    "information into type of call related to types of components.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import contextvars\n",
    "import datetime\n",
    "from enum import Enum\n",
    "import functools\n",
    "import random\n",
    "import time\n",
    "from typing import (ClassVar, Dict, Iterator, List, Mapping, Optional,\n",
    "                    Sequence, Tuple, Union)\n",
    "\n",
    "import opentelemetry\n",
    "from opentelemetry.trace import status as trace_status\n",
    "import opentelemetry.trace as ot_trace\n",
    "import opentelemetry.trace.span as ot_span\n",
    "from opentelemetry.util import types as ot_types\n",
    "from opentelemetry.util._decorator import _agnosticcontextmanager\n",
    "import pydantic\n",
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "# import trulens_eval\n",
    "\n",
    "TTimestamp = int # uint64, nonoseconds since epoch, as per OpenTelemetry\n",
    "TSpanID = int # as per OpenTelemetry\n",
    "TTraceID = int # as per OpenTelemetry\n",
    "\n",
    "# TODO: look into the open telemetry tracer/traceprovider api, ignoring for now.\n",
    "\n",
    "class OTSpan(pydantic.BaseModel, ot_span.Span):\n",
    "    \"\"\"Implementation of OpenTelemetry Span requirements.\n",
    "    \n",
    "    See also [OpenTelemetry Span](https://opentelemetry.io/docs/specs/otel/trace/api/#span).\n",
    "    \"\"\"\n",
    "\n",
    "    _vendor: ClassVar[str] = \"trulens_eval\"\n",
    "    @classmethod\n",
    "    def _attr(self, name):\n",
    "        return f\"{self._vendor}@{name}\"\n",
    "\n",
    "    model_config = {\n",
    "        'arbitrary_types_allowed': True,\n",
    "        'use_attribute_docstrings': True\n",
    "    }\n",
    "    \"\"\"Pydantic configuration.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    \"\"\"Name of span.\"\"\"\n",
    "\n",
    "    kind: ot_trace.SpanKind = ot_trace.SpanKind.INTERNAL\n",
    "    \"\"\"Kind of span.\"\"\"\n",
    "\n",
    "    status: trace_status.StatusCode = trace_status.StatusCode.UNSET\n",
    "    \"\"\"Status of the span as per OpenTelemetry Span requirements.\"\"\"\n",
    "\n",
    "    status_description: Optional[str] = None\n",
    "    \"\"\"Status description as per OpenTelemetry Span requirements.\"\"\"\n",
    "\n",
    "    start_timestamp: TTimestamp = pydantic.Field(default_factory=time.time_ns)\n",
    "    \"\"\"Timestamp when the span's activity started in nanoseconds since epoch.\"\"\"\n",
    "\n",
    "    end_timestamp: Optional[TTimestamp] = None\n",
    "    \"\"\"Timestamp when the span's activity ended in nanoseconds since epoch.\n",
    "\n",
    "    None if not yet ended.\n",
    "    \"\"\"\n",
    "\n",
    "    context: ot_span.SpanContext\n",
    "    \"\"\"Unique immutable identifier for the span.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def hash_context(context: ot_span.SpanContext) -> Tuple[int, int]:\n",
    "        return (context.trace_id, context.span_id)\n",
    "\n",
    "    def _context_hash(self) -> Tuple[int, int]:\n",
    "        return self.hash_context(self.context)\n",
    "\n",
    "    events: List[Tuple[str, ot_types.Attributes, TTimestamp]] = pydantic.Field(default_factory=list)\n",
    "    \"\"\"Events recorded in the span.\"\"\"\n",
    "\n",
    "    links: Dict[Tuple[int, int], Mapping[str, ot_types.AttributeValue]] = pydantic.Field(default_factory=dict)\n",
    "    \"\"\"Relationships to other spans with attributes on each link.\"\"\"\n",
    "\n",
    "    attributes: Dict[str, ot_types.AttributeValue] = pydantic.Field(default_factory=dict)\n",
    "    \"\"\"Attributes of span.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, context: ot_span.SpanContext, **kwargs):\n",
    "        kwargs['name'] = name\n",
    "        kwargs['context'] = context\n",
    "        kwargs['attributes'] = kwargs.get('attributes', {}) or {}\n",
    "        kwargs['links'] = kwargs.get('links', {}) or {}\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def end(self, end_time: Optional[TTimestamp] = None):\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.end]\"\"\"\n",
    "        if end_time:\n",
    "            self.end_timestamp = end_time\n",
    "        else:\n",
    "            self.end_timestamp = time.time_ns()\n",
    "\n",
    "        self.status = trace_status.StatusCode.OK\n",
    "\n",
    "    def get_span_context(self) -> ot_span.SpanContext:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.get_span_context]\"\"\"\n",
    "\n",
    "        return self.context\n",
    "\n",
    "    def set_attributes(self, attributes: Dict[str, ot_types.AttributeValue]) -> None:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.set_attributes]\"\"\"\n",
    "\n",
    "        self.attributes.update(attributes)\n",
    "\n",
    "    def set_attribute(self, key: str, value: ot_types.AttributeValue) -> None:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.set_attribute]\"\"\"\n",
    "\n",
    "        self.attributes[key] = value\n",
    "\n",
    "    def add_event(\n",
    "        self,\n",
    "        name: str,\n",
    "        attributes: ot_types.Attributes = None,\n",
    "        timestamp: Optional[int] = None\n",
    "    ) -> None:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.add_event]\"\"\"\n",
    "        self.events.append((name, attributes, timestamp or time.time_ns()))\n",
    "\n",
    "    def add_link(\n",
    "        self,\n",
    "        context: ot_span.SpanContext,\n",
    "        attributes: ot_types.Attributes = None\n",
    "    ) -> None:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.add_link]\"\"\"\n",
    "\n",
    "        if attributes is None:\n",
    "            attributes = {}\n",
    "\n",
    "        self.links[self.hash_context(context)] = attributes\n",
    "\n",
    "    def update_name(self, name: str) -> None:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.update_name].\"\"\"\n",
    "\n",
    "        self.name = name\n",
    "\n",
    "    def is_recording(self) -> bool:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.is_recording].\"\"\"\n",
    "\n",
    "        return self.status == trace_status.StatusCode.UNSET\n",
    "\n",
    "    def set_status(\n",
    "        self,\n",
    "        status: Union[ot_span.Status, ot_span.StatusCode],\n",
    "        description: Optional[str] = None\n",
    "    ) -> None:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.set_status]\"\"\"\n",
    "\n",
    "        if isinstance(status, ot_span.Status):\n",
    "            if description is not None:\n",
    "                raise ValueError(\"Ambiguous status description provided both in `status.description` and in `description`.\")\n",
    "            \n",
    "            self.status = status.status_code\n",
    "            self.status_description = status.description\n",
    "        else:\n",
    "            self.status = status\n",
    "            self.status_description = description\n",
    "\n",
    "    def record_exception(\n",
    "        self,\n",
    "        exception: Exception,\n",
    "        attributes: ot_types.Attributes = None,\n",
    "        timestamp: Optional[TTimestamp] = None,\n",
    "        escaped: bool = False\n",
    "    ) -> None:\n",
    "        \"\"\"See [end][opentelemetry.trace.span.Span.record_exception]\"\"\"\n",
    "\n",
    "        self.status = trace_status.StatusCode.ERROR\n",
    "\n",
    "        self.add_event(\n",
    "            self._attr(\"exception\"),\n",
    "            attributes,\n",
    "            timestamp\n",
    "        )\n",
    "\n",
    "class DictNamespace(Dict[str, ot_types.AttributeValue]):\n",
    "    \"\"\"View into a dict with keys prefixed by some `namespace` string.\n",
    "    \n",
    "    Replicates the values without the prefix in self.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, parent: Dict, namespace: str, **kwargs):\n",
    "        self.parent = parent\n",
    "        self.namespace = namespace\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return dict.__getitem__(self, key)\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        dict.__setitem__(self, key, value)\n",
    "        self.parent[f\"{self.namespace}.{key}\"] = value\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        dict.__delitem__(self, key)\n",
    "        del self.parent[f\"{self.namespace}.{key}\"]\n",
    "\n",
    "class SpanType(Enum):\n",
    "    \"\"\"Span types.\"\"\"\n",
    "\n",
    "    ROOT = \"root\"\n",
    "\n",
    "    RETRIEVER = \"retriever\"\n",
    "\n",
    "    RERANKER = \"reranker\"\n",
    "\n",
    "    LLM = \"llm\"\n",
    "\n",
    "    EMBEDDING = \"embedding\"\n",
    "\n",
    "    TOOL = \"tool\"\n",
    "\n",
    "    AGENT = \"agent\"\n",
    "\n",
    "    TASK = \"task\"\n",
    "\n",
    "    OTHER = \"other\"\n",
    "\n",
    "class Span(OTSpan):\n",
    "    \"\"\"Base Span type.\n",
    "    \n",
    "    Smallest unit of recorded activity.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def span_id(self) -> TSpanID:\n",
    "        \"\"\"Identifier for the span.\"\"\"\n",
    "\n",
    "        return self.context.span_id\n",
    "\n",
    "    @property\n",
    "    def trace_id(self) -> TTraceID:\n",
    "        \"\"\"Identifier for the trace this span belongs to.\"\"\"\n",
    "\n",
    "        return self.context.trace_id\n",
    "\n",
    "    @functools.cached_property\n",
    "    def parent_span_id(self) -> Optional[TSpanID]:\n",
    "        \"\"\"Id of parent span if any.\n",
    "\n",
    "        None if this is a root span.\n",
    "        \"\"\"\n",
    "\n",
    "        for link in self.links:\n",
    "            if link.trace_id == self.trace_id and link.attributes.get(self._attr(\"relationship\")) == \"parent\":\n",
    "                return link.span_id\n",
    "\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def tags(self) -> List[str]:\n",
    "        \"\"\"Tags associated with the span.\"\"\"\n",
    "\n",
    "        return self.attributes.get(self._attr(\"tags\"), [])\n",
    "    @tags.setter\n",
    "    def tags(self, value: List[str]):\n",
    "        self.attributes[self.attr(\"tags\")] = value\n",
    "\n",
    "    @property\n",
    "    def span_type(self) -> SpanType:\n",
    "        \"\"\"Type of span.\"\"\"\n",
    "\n",
    "        return self.attributes.get(self._attr(\"span_type\"), SpanType.OTHER)\n",
    "    @span_type.setter\n",
    "    def span_type(self, value: SpanType):\n",
    "        self.attributes[self._attr(\"span_type\")] = value\n",
    "\n",
    "    attributes_metadata: DictNamespace[str, ot_types.AttributeValue] \n",
    "    # will be set as a DictNamespace indexing elements in attributes\n",
    "    @property\n",
    "    def metadata(self) -> DictNamespace[str, ot_types.AttributeValue]:\n",
    "        return self.attributes_metadata\n",
    "\n",
    "    @metadata.setter\n",
    "    def metadata(self, value: Dict[str, str]):\n",
    "        for k, v in value.items():\n",
    "            self.attributes_metadata[k] = v\n",
    "\n",
    "    # input: Dict[str, str] = pydantic.Field(default_factory=dict)\n",
    "    # Make property\n",
    "\n",
    "    # output: Dict[str, str] = pydantic.Field(default_factory=dict)\n",
    "    # Make property\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs['attributes_metadata'] = DictNamespace(parent={}, namespace=\"temp\")\n",
    "        # Temporary fake for validation in super.__init__ below.\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Actual. This is needed as pydantic will copy attributes dict in init.\n",
    "        self.attributes_metadata = DictNamespace(\n",
    "            parent=self.attributes,\n",
    "            namespace=self._attr(\"metadata\")\n",
    "        )\n",
    "\n",
    "class SpanRoot(Span):\n",
    "    pass\n",
    "\n",
    "class SpanRetriever(Span):\n",
    "    pass\n",
    "\n",
    "class SpanReranker(Span):\n",
    "    pass\n",
    "\n",
    "class SpanLLM(Span):\n",
    "    pass\n",
    "\n",
    "class SpanEmbedding(Span):\n",
    "    pass\n",
    "\n",
    "class SpanTool(Span):\n",
    "    pass\n",
    "\n",
    "class SpanAgent(Span):\n",
    "    pass\n",
    "\n",
    "class SpanTask(Span):\n",
    "    pass\n",
    "\n",
    "class SpanOther(Span):\n",
    "    pass\n",
    "\n",
    "class Tracer(pydantic.BaseModel, ot_trace.Tracer):\n",
    "    context: Optional[ot_span.SpanContext] = None\n",
    "\n",
    "    instrumenting_module_name: str = \"trulens_eval\"\n",
    "    instrumenting_library_version: Optional[str] = None#trulens_eval.__version__\n",
    "\n",
    "    spans: Dict[Tuple[int, int], Span] = pydantic.Field(default_factory=dict)\n",
    "\n",
    "    trace_id: int\n",
    "    \"\"\"Unique identifier for the trace.\n",
    "    \n",
    "    16 bytes as per OpenTelemetry specification.\n",
    "    \"\"\"\n",
    "\n",
    "    model_config = {\n",
    "        'arbitrary_types_allowed': True,\n",
    "        'use_attribute_docstrings': True\n",
    "    }\n",
    "    \"\"\"Pydantic configuration.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        trace_id = random.getrandbits(16*8)\n",
    "\n",
    "        root_context = ot_span.SpanContext(\n",
    "            trace_id=trace_id,\n",
    "            span_id=random.getrandbits(8*8), # 8 bytes as per OpenTelemetry specification\n",
    "            is_remote=False\n",
    "        )\n",
    "\n",
    "        root_span = Span(\n",
    "            trace_id=trace_id,\n",
    "            span_id=root_context.span_id,\n",
    "            name=\"root\",\n",
    "            context=root_context,\n",
    "            kind=ot_trace.SpanKind.INTERNAL\n",
    "        )\n",
    "\n",
    "        kwargs['trace_id'] = trace_id\n",
    "        kwargs['context'] = root_context\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.spans[Span.hash_context(root_context)] = root_span\n",
    "\n",
    "    def start_span(\n",
    "        self,\n",
    "        name: str,\n",
    "        context: Optional[ot_trace.Context] = None,\n",
    "        kind: ot_trace.SpanKind = ot_trace.SpanKind.INTERNAL,\n",
    "        attributes: ot_trace.types.Attributes = None,\n",
    "        links: ot_trace._Links = None,\n",
    "        start_time: Optional[int] = None,\n",
    "        record_exception: bool = True,\n",
    "        set_status_on_exception: bool = True,\n",
    "\n",
    "    ) -> Span:\n",
    "        if context is None:\n",
    "            context = self.context\n",
    "        else:\n",
    "            self.context = context\n",
    "\n",
    "        if context.trace_id != self.trace_id:\n",
    "            logger.warning(\"Parent context is not being traced by this tracer.\")\n",
    "\n",
    "        span_context = ot_trace.SpanContext(\n",
    "            trace_id=self.trace_id,\n",
    "            span_id=random.getrandbits(8*8), # 8 bytes as per OpenTelemetry specification\n",
    "            is_remote=False\n",
    "        )\n",
    "\n",
    "        span = Span(\n",
    "            name=name,\n",
    "            context=span_context,\n",
    "            kind=kind,\n",
    "            attributes=attributes,\n",
    "            links=links,\n",
    "            start_time=start_time,\n",
    "            record_exception=record_exception,\n",
    "            set_status_on_exception=set_status_on_exception\n",
    "        )\n",
    "\n",
    "        self.spans[Span.hash_context(span_context)] = span\n",
    "\n",
    "        return span\n",
    "\n",
    "    @_agnosticcontextmanager\n",
    "    def start_as_current_span(\n",
    "        self,\n",
    "        name: str,\n",
    "        context: Optional[ot_trace.Context] = None,\n",
    "        kind: ot_trace.SpanKind = opentelemetry.trace.SpanKind.INTERNAL,\n",
    "        attributes: ot_types.Attributes = None,\n",
    "        links: ot_trace._Links = None,\n",
    "        start_time: Optional[int] = None,\n",
    "        record_exception: bool = True,\n",
    "        set_status_on_exception: bool = True,\n",
    "        end_on_exit: bool = True,\n",
    "    ) -> Iterator[OTSpan]:\n",
    "\n",
    "        span = self.start_span(\n",
    "            name,\n",
    "            context,\n",
    "            kind,\n",
    "            attributes,\n",
    "            links,\n",
    "            start_time,\n",
    "            record_exception,\n",
    "            set_status_on_exception\n",
    "        )\n",
    "\n",
    "        token = ot_trace.use_span(span, end_on_exit=end_on_exit).__enter__()\n",
    "        yield span\n",
    "\n",
    "        token.__exit__(None, None, None)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracer = Tracer()\n",
    "\n",
    "with tracer.start_as_current_span(\"test\") as s:\n",
    "    print(\"hello\")\n",
    "\n",
    "s.metadata.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': (62253270439664091948775267856289665795,\n",
       "  15593337627810139526,\n",
       "  False,\n",
       "  0,\n",
       "  [],\n",
       "  True),\n",
       " 'instrumenting_module_name': 'trulens_eval',\n",
       " 'instrumenting_library_version': None,\n",
       " 'spans': {(62253270439664091948775267856289665795,\n",
       "   15593337627810139526): {'name': 'root', 'kind': <SpanKind.INTERNAL: 0>, 'status': <StatusCode.UNSET: 0>, 'status_description': None, 'start_timestamp': 1713920705446151000, 'end_timestamp': None, 'context': (62253270439664091948775267856289665795,\n",
       "    15593337627810139526,\n",
       "    False,\n",
       "    0,\n",
       "    [],\n",
       "    True), 'events': [], 'links': {}, 'attributes': {}, 'attributes_metadata': {}},\n",
       "  (62253270439664091948775267856289665795,\n",
       "   12360611701822629681): {'name': 'test', 'kind': <SpanKind.INTERNAL: 0>, 'status': <StatusCode.OK: 1>, 'status_description': None, 'start_timestamp': 1713920705446222000, 'end_timestamp': 1713920705460184000, 'context': (62253270439664091948775267856289665795,\n",
       "    12360611701822629681,\n",
       "    False,\n",
       "    0,\n",
       "    [],\n",
       "    True), 'events': [], 'links': {}, 'attributes': {}, 'attributes_metadata': {}}},\n",
       " 'trace_id': 62253270439664091948775267856289665795}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracer.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62253270439664091948775267856289665795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.trace_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trulens_eval@metadata.b': 42}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.metadata['b'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Notebook\n",
    "\n",
    "This notebook loads the version of trulens_eval from the enclosing repo folder. You can use this to debug or devlop trulens_eval features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/dev_new/trulens/trulens_eval\n",
      "âœ… Key OPENAI_API_KEY set from environment (same value found in .env file at /Volumes/dev_new/.env).\n",
      "âœ… Key HUGGINGFACE_API_KEY set from environment (same value found in .env file at /Volumes/dev_new/.env).\n",
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n",
      "Database has been reconfigured. Please update it by running `tru.migrate_database(prior_prefix=\"\")` or reset it by running `tru.reset_database()`.\n"
     ]
    }
   ],
   "source": [
    "# pip uninstall -y trulens_eval\n",
    "# pip install git+https://github.com/truera/trulens@piotrm/azure_bugfixes#subdirectory=trulens_eval\n",
    "\n",
    "# trulens_eval notebook dev\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "base = Path().cwd()\n",
    "while not (base / \"trulens_eval\").exists():\n",
    "    base = base.parent\n",
    "\n",
    "\n",
    "import os\n",
    "if os.path.exists(\"default.sqlite\"):\n",
    "    os.unlink(\"default.sqlite\")\n",
    "\n",
    "print(base)\n",
    "\n",
    "import shutil\n",
    "shutil.copy(base / \"release_dbs\" / \"0.19.0\" / \"default.sqlite\", \"default.sqlite\")\n",
    "\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(base))\n",
    "\n",
    "# Uncomment for more debugging printouts.\n",
    "\"\"\"\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\"\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\",\n",
    "    \"HUGGINGFACE_API_KEY\"\n",
    ")\n",
    "\n",
    "from trulens_eval import Tru\n",
    "tru = Tru(database_prefix=\"dev\")\n",
    "#tru.reset_database()\n",
    "# tru.run_dashboard(_dev=base, force=True)\n",
    "# tru.db.migrate_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tru.db.migrate_database()\n",
    "tru.migrate_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tru.db.orm.registry.values():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.database.utils import copy_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_database(\"sqlite:///default.sqlite\", \"sqlite:///default2.sqlite\", src_prefix=\"dev\", tgt_prefix=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_llama import TruLlama\n",
    "\n",
    "check_keys(\"OPENAI_API_KEY\", \"HUGGINGFACE_API_KEY\")\n",
    "import os\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "if not os.path.exists(\"data/paul_graham_essay.txt\"):\n",
    "    os.system(\n",
    "        'wget https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt -P data/'\n",
    "    )\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# This test does not run correctly if async is used, i.e. not using\n",
    "# `sync` to convert to sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider.hugs import Dummy\n",
    "from trulens_eval import Select\n",
    "from trulens_eval.app import App\n",
    "from trulens_eval.feedback.feedback import Feedback\n",
    "\n",
    "f = Feedback(Dummy().language_match).on_input().on(\n",
    "    App.select_context(query_engine))\n",
    "\n",
    "tru_query_engine_recorder = TruLlama(query_engine, feedbacks=[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response, record = tru_query_engine_recorder.with_record(\n",
    "    query_engine.query, \"What did the author do growing up?\"\n",
    ")\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard(_dev=base, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = record_async.feedback_results[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "#with tru_query_engine_recorder as recording:\n",
    "llm_response_async, record = await tru_query_engine_recorder.awith_record(query_engine.aquery, \"What did the author do growing up?\")\n",
    "\n",
    "#record_async = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "with tru_query_engine_recorder as recording:\n",
    "    llm_response_async = query_engine.aquery(\"What did the author do growing up?\")\n",
    "\n",
    "#record_async = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.base_query_engine import BaseQueryEngine\n",
    "isinstance(query_engine, BaseQueryEngine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "with tru_query_engine_recorder as recording:\n",
    "    llm_response_sync = query_engine.query(\n",
    "        \"What did the author do growing up?\"\n",
    "    )\n",
    "record_sync = recording.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
