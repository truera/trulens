{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Notebook\n",
    "\n",
    "This notebook loads the version of trulens_eval from the enclosing repo folder. You can use this to debug or devlop trulens_eval features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall -y trulens_eval\n",
    "# pip install git+https://github.com/truera/trulens@piotrm/azure_bugfixes#subdirectory=trulens_eval\n",
    "\n",
    "# trulens_eval notebook dev\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "base = Path().cwd()\n",
    "while not (base / \"trulens_eval\").exists():\n",
    "    base = base.parent\n",
    "\n",
    "\n",
    "#import os\n",
    "#if os.path.exists(\"default.sqlite\"):\n",
    "#    os.unlink(\"default.sqlite\")\n",
    "\n",
    "print(base)\n",
    "\n",
    "# import shutil\n",
    "#shutil.copy(base / \"release_dbs\" / \"0.19.0\" / \"default.sqlite\", \"default.sqlite\")\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(base))\n",
    "\n",
    "# Uncomment for more debugging printouts.\n",
    "\"\"\"\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\"\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\",\n",
    "    \"HUGGINGFACE_API_KEY\"\n",
    ")\n",
    "\n",
    "# from trulens_eval import Tru\n",
    "# tru = Tru(database_prefix=\"dev\")\n",
    "#tru.reset_database()\n",
    "# tru.run_dashboard(_dev=base, force=True)\n",
    "# tru.db.migrate_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "model = ChatOpenAI()\n",
    "tools = []\n",
    "\n",
    "agent = create_structured_chat_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = agent_executor.invoke({\"input\": \"hi\"})\n",
    "\n",
    "# Using with chat history\n",
    "\n",
    "res2 = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"what's my name?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain\n",
    "recorder = TruChain(agent_executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with recorder as recs:\n",
    "\n",
    "    agent_executor.invoke({\"input\": \"hi\"})\n",
    "\n",
    "    # Using with chat history\n",
    "\n",
    "    \"\"\"\n",
    "    agent_executor.invoke(\n",
    "        {\n",
    "            \"input\": \"what's my name?\",\n",
    "            \"chat_history\": [\n",
    "                HumanMessage(content=\"hi! my name is bob\"),\n",
    "                AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = recs.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.main_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tru.db.orm.registry.values():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.database.utils import copy_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_database(\"sqlite:///default.sqlite\", \"sqlite:///default2.sqlite\", src_prefix=\"dev\", tgt_prefix=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_llama import TruLlama\n",
    "\n",
    "check_keys(\"OPENAI_API_KEY\", \"HUGGINGFACE_API_KEY\")\n",
    "import os\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "if not os.path.exists(\"data/paul_graham_essay.txt\"):\n",
    "    os.system(\n",
    "        'wget https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt -P data/'\n",
    "    )\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# This test does not run correctly if async is used, i.e. not using\n",
    "# `sync` to convert to sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider.hugs import Dummy\n",
    "from trulens_eval import Select\n",
    "from trulens_eval.app import App\n",
    "from trulens_eval.feedback.feedback import Feedback\n",
    "\n",
    "f = Feedback(Dummy().language_match).on_input().on(\n",
    "    App.select_context(query_engine))\n",
    "\n",
    "tru_query_engine_recorder = TruLlama(query_engine, feedbacks=[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response, record = tru_query_engine_recorder.with_record(\n",
    "    query_engine.query, \"What did the author do growing up?\"\n",
    ")\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard(_dev=base, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = record_async.feedback_results[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "#with tru_query_engine_recorder as recording:\n",
    "llm_response_async, record = await tru_query_engine_recorder.awith_record(query_engine.aquery, \"What did the author do growing up?\")\n",
    "\n",
    "#record_async = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "with tru_query_engine_recorder as recording:\n",
    "    llm_response_async = query_engine.aquery(\"What did the author do growing up?\")\n",
    "\n",
    "#record_async = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.base_query_engine import BaseQueryEngine\n",
    "isinstance(query_engine, BaseQueryEngine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "with tru_query_engine_recorder as recording:\n",
    "    llm_response_sync = query_engine.query(\n",
    "        \"What did the author do growing up?\"\n",
    "    )\n",
    "record_sync = recording.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
