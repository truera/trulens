{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit App UI Experimental\n",
    "\n",
    "**This notebook demonstrates experimental features. The more stable streamlit app ui is demonstrated in `quickstart/dashboard_appui.ipynb`.**\n",
    "\n",
    "This notebook demonstrates an app interface that runs alongside the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")\n",
    "\n",
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "tru.start_dashboard(\n",
    "    force = True,\n",
    "    _dev=Path().cwd().parent.parent.resolve()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_langchain_app():\n",
    "    # All relevant imports must be inside this function.\n",
    "\n",
    "    from langchain_community.llms import OpenAI\n",
    "    from langchain.chains import ConversationChain\n",
    "    from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "    llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "    # Conversation memory.\n",
    "    memory = ConversationSummaryBufferMemory(\n",
    "        max_token_limit=64,\n",
    "        llm=llm,\n",
    "    )\n",
    "\n",
    "    # Conversational app puts it all together.\n",
    "    app = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    return app \n",
    "\n",
    "app1 = load_langchain_app()\n",
    "\n",
    "tru_app1 = tru.Chain(\n",
    "    app1,\n",
    "    app_id='langchain_app',\n",
    "    initial_app_loader=load_langchain_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llama_index example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "# Be careful what you include as globals to be used by the loader function as it\n",
    "# will have to be serialized. We enforce a size limit which prohibits large\n",
    "# objects to be included in the loader's closure.\n",
    "\n",
    "# This object will be serialized alongside `load_llamaindex_app` below.\n",
    "documents = SimpleWebPageReader(\n",
    "    html_to_text=True\n",
    ").load_data([\"http://paulgraham.com/worked.html\"])\n",
    "\n",
    "def load_llamaindex_app():\n",
    "    from llama_index import VectorStoreIndex\n",
    "    index = VectorStoreIndex.from_documents(documents)    \n",
    "    query_engine = index.as_query_engine()\n",
    "\n",
    "    return query_engine\n",
    "\n",
    "app2 = load_llamaindex_app()\n",
    "tru_app2 = tru.Llama(\n",
    "    app2,\n",
    "    app_id=\"llamaindex_app\",\n",
    "    initial_app_loader=load_llamaindex_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic app example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_basic_app import TruWrapperApp\n",
    "\n",
    "def load_basic_app():\n",
    "    def custom_application(prompt: str) -> str:\n",
    "        return f\"a useful response to {prompt}\"\n",
    "    \n",
    "    return TruWrapperApp(custom_application)\n",
    "\n",
    "app3 = load_basic_app()\n",
    "\n",
    "tru_app3 = tru.Basic(\n",
    "    app3,\n",
    "    app_id=\"basic_app\",\n",
    "    initial_app_loader=load_basic_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom app example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.expositional.end2end_apps.custom_app.custom_app import CustomApp # our custom app\n",
    "\n",
    "# Create custom app:\n",
    "def load_custom_app():\n",
    "    app = CustomApp()\n",
    "    return app\n",
    "\n",
    "app4 = load_custom_app()\n",
    "\n",
    "# Create trulens wrapper:\n",
    "tru_app4 = tru.Custom(\n",
    "    app=app4,\n",
    "    app_id=\"custom_app\",\n",
    "    \n",
    "    # Make sure to specify using the bound method, bound to self=app.\n",
    "    main_method=app4.respond_to_query,\n",
    "\n",
    "    initial_app_loader = load_custom_app\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "You can get a list of apps that include the `initial_app_loader` with the following utility method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.schema import AppDefinition\n",
    "\n",
    "for app_json in AppDefinition.get_loadable_apps():\n",
    "    print(app_json['app_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
