{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook App UI Example\n",
    "\n",
    "This notebook demonstrates the in-notebook app interface letting you interact with a langchain app inside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")\n",
    "\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.appui import AppUI\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database() # if needed\n",
    "tru.start_dashboard(\n",
    "    force = True,\n",
    "    _dev=Path().cwd().parent.parent.resolve()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "# Conversation memory.\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    k=4,\n",
    "    max_token_limit=64,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Conversational app puts it all together.\n",
    "app = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from trulens_eval.instruments import instrument\n",
    "instrument.method(PromptTemplate, \"format\")\n",
    "\n",
    "truchain = tru.Chain(app, app_id=\"langchain_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting Select.App queries to look at:\n",
    "# - app.memory.chat_memory.messages[:].content\n",
    "# - app.memory.moving_summary_buffer\n",
    "# - app.prompt.template\n",
    "\n",
    "# Interesting Select.Record queries to look at:\n",
    "# - app.memory.save_context[0].args\n",
    "# - app.prompt.format.args.kwargs\n",
    "# - app.prompt.format.rets\n",
    "# The last two need to instrument PromptTemplate as above.\n",
    "\n",
    "aui = AppUI(\n",
    "    app=truchain,\n",
    "    \n",
    "    app_selectors=[\n",
    "        \"app.memory.chat_memory.messages[:].content\",\n",
    "        \"app.memory.moving_summary_buffer\",\n",
    "\n",
    "        \"app.prompt.template\"\n",
    "    ],\n",
    "    record_selectors=[\n",
    "        \"app.memory.save_context[0].args\",\n",
    "\n",
    "        \"app.prompt.format.args.kwargs\",\n",
    "        \"app.prompt.format.rets\"\n",
    "    ]\n",
    ")\n",
    "aui.widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llama_index example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "documents = SimpleWebPageReader(\n",
    "    html_to_text=True\n",
    ").load_data([\"http://paulgraham.com/worked.html\"])\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "trullama = tru.Llama(query_engine, app_id=\"llama_index_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aui = AppUI(\n",
    "    app=trullama,\n",
    "    \n",
    "    app_selectors=[\n",
    "    ],\n",
    "    record_selectors=[\n",
    "        \"app.retriever.retrieve[0].rets[:].score\",\n",
    "        \"app.retriever.retrieve[0].rets[:].node.text\",\n",
    "    ]\n",
    ")\n",
    "aui.widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic app example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_application(prompt: str) -> str:\n",
    "    return f\"a useful response to {prompt}\"\n",
    "\n",
    "trubasic = tru.Basic(custom_application, app_id=\"basic_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aui = AppUI(\n",
    "    app=trubasic,\n",
    "    \n",
    "    app_selectors=[ # nothing interesting to display here\n",
    "    ],\n",
    "    record_selectors=[\n",
    "        \"app._call[0].args.args[:]\",\n",
    "    ]\n",
    ")\n",
    "aui.widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom app example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.expositional.end2end_apps.custom_app.custom_app import CustomApp # our custom app\n",
    "\n",
    "# Create custom app:\n",
    "app = CustomApp()\n",
    "\n",
    "# Create trulens wrapper:\n",
    "trucustom = tru.Custom(\n",
    "    app=app,\n",
    "    app_id=\"custom_app\",\n",
    "    \n",
    "    # Make sure to specify using the bound method, bound to self=app.\n",
    "    main_method=app.respond_to_query\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aui = AppUI(\n",
    "    app=trucustom,\n",
    "    \n",
    "    app_selectors=[\n",
    "        \"app.memory.messages[:]\"\n",
    "    ],\n",
    "    record_selectors=[\n",
    "        \"app.retriever.retrieve_chunks[0].rets\",\n",
    "    ]\n",
    ")\n",
    "aui.widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
