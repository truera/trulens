{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Populate Notebook\n",
    "\n",
    "This notebook populates the database with a variety of apps, records, and\n",
    "feedback results. It is used primarily for database migration testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))\n",
    "\n",
    "# Enables: Debugging printouts.\n",
    "\"\"\"\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install llama_index==0.9.15.post2\n",
    "# ! pip install pydantic==2.5.2 pydantic_core==2.14.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test out DB migrations, copy one of the older db dumps to this folder first:\n",
    "\n",
    "! ls ../../release_dbs/\n",
    "! cp ../../release_dbs/0.3.0/default.sqlite default.sqlite\n",
    "# ! rm default.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.feedback.provider.hugs import Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tru and/or dashboard.\n",
    "\n",
    "tru = Tru(database_redact_keys=True)\n",
    "\n",
    "# tru.reset_database()\n",
    "\n",
    "tru.start_dashboard(force=True, _dev=Path().cwd().parent.parent.resolve())\n",
    "\n",
    "Tru().migrate_database()\n",
    "\n",
    "from trulens_eval.database.migrations.data import (\n",
    "    _sql_alchemy_serialization_asserts,\n",
    ")\n",
    "\n",
    "_sql_alchemy_serialization_asserts(tru.db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy endpoint\n",
    "\n",
    "dummy = Dummy(\n",
    "    loading_prob=0.1,\n",
    "    freeze_prob=0.0,  # we expect requests to have their own timeouts so freeze should never happen\n",
    "    error_prob=0.01,\n",
    "    overloaded_prob=0.1,\n",
    "    rpm=6000,\n",
    ")\n",
    "\n",
    "f_lang_match_dummy = Feedback(dummy.language_match).on_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface endpoint\n",
    "from trulens_eval import Huggingface\n",
    "\n",
    "hugs = Huggingface()\n",
    "\n",
    "f_lang_match_hugs = Feedback(hugs.language_match).on_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# inspect.signature(Huggingface).bind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openai endpoint\n",
    "from trulens_eval import OpenAI\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "f_relevance_openai = Feedback(openai.relevance).on_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock endpoint\n",
    "# Cohere as endpoint\n",
    "# LangChain as endpoint\n",
    "# Litellm as endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks = [f_lang_match_hugs, f_lang_match_dummy, f_relevance_openai]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _LangChain_ app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_community.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "# Conversation memory.\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    k=4,\n",
    "    max_token_limit=64,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Conversational app puts it all together.\n",
    "app_langchain = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from trulens_eval.instruments import instrument\n",
    "\n",
    "instrument.method(PromptTemplate, \"format\")\n",
    "\n",
    "truchain = tru.Chain(app_langchain, app_id=\"langchain_app\", feedbacks=feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with truchain as recs:\n",
    "    print(app_langchain(\"Hello?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama-index app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"http://paulgraham.com/worked.html\"]\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "trullama = tru.Llama(query_engine, app_id=\"llama_index_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with trullama as recs:\n",
    "    print(query_engine.query(\"Who is the author?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "\n",
    "def custom_application(prompt: str) -> str:\n",
    "    return f\"a useful response to {prompt}\"\n",
    "\n",
    "\n",
    "trubasic = tru.Basic(\n",
    "    custom_application, app_id=\"basic_app\", feedbacks=feedbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with trubasic as recs:\n",
    "    print(trubasic.app(\"hello?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.expositional.end2end_apps.custom_app.custom_app import CustomApp\n",
    "\n",
    "# Create custom app:\n",
    "app_custom = CustomApp()\n",
    "\n",
    "# Create trulens wrapper:\n",
    "trucustom = tru.Custom(\n",
    "    app=app_custom,\n",
    "    app_id=\"custom_app\",\n",
    "    # Make sure to specify using the bound method, bound to self=app.\n",
    "    main_method=app_custom.respond_to_query,\n",
    "    feedbacks=feedbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with trucustom as recs:\n",
    "    print(app_custom.respond_to_query(\"hello there\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
