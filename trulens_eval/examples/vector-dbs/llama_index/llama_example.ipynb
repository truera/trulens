{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.parent.parent.resolve()))\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "# Uncomment to get more debugging printouts:\n",
    "\"\"\"\n",
    "import logging\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-20 19:21:06,120 - numexpr.utils - INFO - Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-06-20 19:21:06,134 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n",
      "Using /Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/examples/.env\n",
      "KEY SET: OPENAI_API_KEY\n",
      "KEY SET: PINECONE_API_KEY\n",
      "KEY SET: PINECONE_ENV\n",
      "KEY SET: HUGGINGFACE_API_KEY\n",
      "KEY SET: SLACK_TOKEN\n",
      "KEY SET: SLACK_SIGNING_SECRET\n",
      "KEY SET: COHERE_API_KEY\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For aggregation,\n",
    "import numpy as np\n",
    "\n",
    "from trulens_eval import feedback, Feedback, Tru, TruLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-20 19:21:08,373 - trulens_eval.util - DEBUG - *** Creating new HuggingfaceEndpoint singleton instance for name = huggingface ***\n",
      "2023-06-20 19:21:08,374 - trulens_eval.provider_apis - DEBUG - *** Creating huggingface endpoint ***\n",
      "2023-06-20 19:21:08,375 - trulens_eval.provider_apis - DEBUG - Instrumenting requests.post for huggingface\n",
      "2023-06-20 19:21:08,375 - trulens_eval.provider_apis - DEBUG - Instrumenting post for huggingface .\n",
      "2023-06-20 19:21:08,375 - trulens_eval.util - DEBUG - *** Creating new OpenAIEndpoint singleton instance for name = openai ***\n",
      "2023-06-20 19:21:08,376 - trulens_eval.provider_apis - DEBUG - *** Creating openai endpoint ***\n",
      "2023-06-20 19:21:08,376 - trulens_eval.provider_apis - DEBUG - Instrumenting openai.*.create for openai\n",
      "2023-06-20 19:21:08,376 - trulens_eval.provider_apis - DEBUG - Instrumenting ChatCompletion.create for openai\n",
      "2023-06-20 19:21:08,376 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,377 - trulens_eval.provider_apis - DEBUG - Instrumenting Completion.create for openai\n",
      "2023-06-20 19:21:08,377 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,377 - trulens_eval.provider_apis - DEBUG - Instrumenting Customer.create for openai\n",
      "2023-06-20 19:21:08,378 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,378 - trulens_eval.provider_apis - DEBUG - Instrumenting Deployment.create for openai\n",
      "2023-06-20 19:21:08,378 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,379 - trulens_eval.provider_apis - DEBUG - Instrumenting Edit.create for openai\n",
      "2023-06-20 19:21:08,379 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,379 - trulens_eval.provider_apis - DEBUG - Instrumenting Embedding.create for openai\n",
      "2023-06-20 19:21:08,379 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,380 - trulens_eval.provider_apis - DEBUG - Instrumenting File.create for openai\n",
      "2023-06-20 19:21:08,380 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,380 - trulens_eval.provider_apis - DEBUG - Instrumenting FineTune.create for openai\n",
      "2023-06-20 19:21:08,381 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,381 - trulens_eval.provider_apis - DEBUG - Instrumenting Image.create for openai\n",
      "2023-06-20 19:21:08,381 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "2023-06-20 19:21:08,381 - trulens_eval.provider_apis - DEBUG - Instrumenting Moderation.create for openai\n",
      "2023-06-20 19:21:08,381 - trulens_eval.provider_apis - DEBUG - Instrumenting create for openai .\n",
      "✅ In language_match, input text1 will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In language_match, input text2 will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
      "✅ In relevance, input prompt will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In relevance, input response will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
      "✅ In qs_relevance, input question will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In qs_relevance, input statement will be set to *.__record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "# Construct feedback functions.\n",
    "\n",
    "hugs = feedback.Huggingface()\n",
    "openai = feedback.OpenAI()\n",
    "\n",
    "# Language match between question/answer.\n",
    "f_lang_match = Feedback(hugs.language_match).on_input_output()\n",
    "# By default this will evaluate feedback on main app input and main app output.\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# Same default inputs as the above.\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_qs_relevance = Feedback(openai.qs_relevance).on_input().on(\n",
    "    TruLlama.select_source_nodes().node.text\n",
    ").aggregate(np.min)\n",
    "# First feedback arg is the main app input while the second is the context\n",
    "# chunks retrieved from the main app output, output of `query`.\n",
    "\n",
    "feedbacks = [\n",
    "    f_lang_match, \n",
    "    f_qa_relevance, \n",
    "    f_qs_relevance\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-20 19:21:11,286 - trulens_eval.util - DEBUG - *** Creating new TP singleton instance for name = None ***\n",
      "2023-06-20 19:21:11,636 - trulens_eval.provider_apis - DEBUG - Calling wrapped post for huggingface.\n",
      "2023-06-20 19:21:11,643 - trulens_eval.provider_apis - DEBUG - Calling wrapped post for huggingface.\n",
      "2023-06-20 19:21:11,702 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443\n",
      "2023-06-20 19:21:11,702 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443\n",
      "2023-06-20 19:21:12,058 - urllib3.connectionpool - DEBUG - https://api-inference.huggingface.co:443 \"POST /models/papluca/xlm-roberta-base-language-detection HTTP/1.1\" 200 905\n",
      "2023-06-20 19:21:12,060 - trulens_eval.util - DEBUG - <code object wrapper at 0x160754920, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/provider_apis.py\", line 294>\n",
      "2023-06-20 19:21:12,060 - trulens_eval.util - DEBUG - <code object post at 0x1607542f0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/provider_apis.py\", line 173>\n",
      "2023-06-20 19:21:12,061 - trulens_eval.util - DEBUG - <code object get_scores at 0x143626df0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/feedback.py\", line 854>\n",
      "2023-06-20 19:21:12,061 - trulens_eval.util - DEBUG - <code object _thread_target_wrapper at 0x104c8b0e0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/util.py\", line 1053>\n",
      "2023-06-20 19:21:12,061 - trulens_eval.util - DEBUG - Found thread starter frame. Will walk over frames prior to thread start.\n",
      "2023-06-20 19:21:12,061 - trulens_eval.util - DEBUG - <code object worker at 0x104c9f0e0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/multiprocessing/pool.py\", line 97>\n",
      "2023-06-20 19:21:12,062 - trulens_eval.util - DEBUG - <code object run at 0x100b36a80, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/threading.py\", line 859>\n",
      "2023-06-20 19:21:12,062 - trulens_eval.util - DEBUG - <code object _bootstrap_inner at 0x100b36df0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/threading.py\", line 915>\n",
      "2023-06-20 19:21:12,062 - trulens_eval.util - DEBUG - <code object _bootstrap at 0x100b36b30, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/threading.py\", line 876>\n",
      "2023-06-20 19:21:12,063 - trulens_eval.util - DEBUG - <code object _thread_starter at 0x104c8b190, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/util.py\", line 1067>\n",
      "2023-06-20 19:21:12,063 - trulens_eval.util - DEBUG - <code object promise at 0x104c8b2f0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/util.py\", line 1081>\n",
      "2023-06-20 19:21:12,063 - trulens_eval.util - DEBUG - <code object language_match at 0x14362a030, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/feedback.py\", line 834>\n",
      "2023-06-20 19:21:12,063 - trulens_eval.util - DEBUG - <code object <cell line: 1> at 0x1623dbb30, file \"/var/folders/2j/xg0_cv993gl37s_8qs5qrdxm0000gn/T/ipykernel_5794/324110129.py\", line 1>\n",
      "2023-06-20 19:21:12,064 - trulens_eval.util - DEBUG - <code object run_code at 0x1022e97c0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3362>\n",
      "2023-06-20 19:21:12,064 - trulens_eval.util - DEBUG - <code object run_ast_nodes at 0x1022e9660, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3238>\n",
      "2023-06-20 19:21:12,064 - trulens_eval.util - DEBUG - <code object run_cell_async at 0x1022e92f0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2988>\n",
      "2023-06-20 19:21:12,065 - trulens_eval.util - DEBUG - <code object _pseudo_sync_runner at 0x1023d6df0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 120>\n",
      "2023-06-20 19:21:12,065 - trulens_eval.util - DEBUG - <code object _run_cell at 0x1022e90e0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2890>\n",
      "2023-06-20 19:21:12,065 - trulens_eval.util - DEBUG - <code object run_cell at 0x1022e9030, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2848>\n",
      "2023-06-20 19:21:12,066 - trulens_eval.util - DEBUG - <code object run_cell at 0x1038d5b30, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 537>\n",
      "2023-06-20 19:21:12,066 - trulens_eval.util - DEBUG - <code object do_execute at 0x10310d190, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 339>\n",
      "2023-06-20 19:21:12,066 - trulens_eval.util - DEBUG - <code object execute_request at 0x103127b30, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 684>\n",
      "2023-06-20 19:21:12,066 - trulens_eval.util - DEBUG - <code object dispatch_shell at 0x103120a80, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 360>\n",
      "2023-06-20 19:21:12,067 - urllib3.connectionpool - DEBUG - https://api-inference.huggingface.co:443 \"POST /models/papluca/xlm-roberta-base-language-detection HTTP/1.1\" 200 884\n",
      "2023-06-20 19:21:12,067 - trulens_eval.util - DEBUG - <code object process_one at 0x103127030, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 490>\n",
      "2023-06-20 19:21:12,068 - trulens_eval.util - DEBUG - <code object dispatch_queue at 0x1031270e0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 504>\n",
      "2023-06-20 19:21:12,068 - trulens_eval.util - DEBUG - <code object _run at 0x1012a33a0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/events.py\", line 79>\n",
      "2023-06-20 19:21:12,068 - trulens_eval.util - DEBUG - <code object _run_once at 0x1010badf0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/base_events.py\", line 1784>\n",
      "2023-06-20 19:21:12,069 - trulens_eval.util - DEBUG - <code object run_forever at 0x1010b0240, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/base_events.py\", line 557>\n",
      "2023-06-20 19:21:12,069 - trulens_eval.util - DEBUG - <code object start at 0x103a1f5b0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 194>\n",
      "2023-06-20 19:21:12,070 - trulens_eval.util - DEBUG - <code object start at 0x101f8b3a0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 706>\n",
      "2023-06-20 19:21:12,070 - trulens_eval.util - DEBUG - <code object launch_instance at 0x101695a80, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/traitlets/config/application.py\", line 1035>\n",
      "2023-06-20 19:21:12,070 - trulens_eval.util - DEBUG - <code object <module> at 0x1009912f0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel_launcher.py\", line 1>\n",
      "2023-06-20 19:21:12,071 - trulens_eval.util - DEBUG - <code object wrapper at 0x160754920, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/provider_apis.py\", line 294>\n",
      "2023-06-20 19:21:12,071 - trulens_eval.util - DEBUG - <code object _run_code at 0x1009be5b0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/runpy.py\", line 64>\n",
      "2023-06-20 19:21:12,071 - trulens_eval.util - DEBUG - <code object post at 0x1607542f0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/provider_apis.py\", line 173>\n",
      "2023-06-20 19:21:12,072 - trulens_eval.util - DEBUG - <code object _run_module_as_main at 0x1009bec90, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/runpy.py\", line 169>\n",
      "2023-06-20 19:21:12,072 - trulens_eval.util - DEBUG - <code object get_scores at 0x143626df0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/feedback.py\", line 854>\n",
      "2023-06-20 19:21:12,074 - trulens_eval.util - DEBUG - <code object _thread_target_wrapper at 0x104c8b0e0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/util.py\", line 1053>\n",
      "2023-06-20 19:21:12,074 - trulens_eval.util - DEBUG - Found thread starter frame. Will walk over frames prior to thread start.\n",
      "2023-06-20 19:21:12,075 - trulens_eval.util - DEBUG - <code object worker at 0x104c9f0e0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/multiprocessing/pool.py\", line 97>\n",
      "2023-06-20 19:21:12,075 - trulens_eval.util - DEBUG - <code object run at 0x100b36a80, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/threading.py\", line 859>\n",
      "2023-06-20 19:21:12,075 - trulens_eval.util - DEBUG - <code object _bootstrap_inner at 0x100b36df0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/threading.py\", line 915>\n",
      "2023-06-20 19:21:12,075 - trulens_eval.util - DEBUG - <code object _bootstrap at 0x100b36b30, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/threading.py\", line 876>\n",
      "2023-06-20 19:21:12,075 - trulens_eval.util - DEBUG - <code object _thread_starter at 0x104c8b190, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/util.py\", line 1067>\n",
      "2023-06-20 19:21:12,076 - trulens_eval.util - DEBUG - <code object promise at 0x104c8b2f0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/util.py\", line 1081>\n",
      "2023-06-20 19:21:12,076 - trulens_eval.util - DEBUG - <code object language_match at 0x14362a030, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/feedback.py\", line 834>\n",
      "2023-06-20 19:21:12,076 - trulens_eval.util - DEBUG - <code object <cell line: 1> at 0x1623dbb30, file \"/var/folders/2j/xg0_cv993gl37s_8qs5qrdxm0000gn/T/ipykernel_5794/324110129.py\", line 1>\n",
      "2023-06-20 19:21:12,076 - trulens_eval.util - DEBUG - <code object run_code at 0x1022e97c0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3362>\n",
      "2023-06-20 19:21:12,076 - trulens_eval.util - DEBUG - <code object run_ast_nodes at 0x1022e9660, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3238>\n",
      "2023-06-20 19:21:12,077 - trulens_eval.util - DEBUG - <code object run_cell_async at 0x1022e92f0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2988>\n",
      "2023-06-20 19:21:12,077 - trulens_eval.util - DEBUG - <code object _pseudo_sync_runner at 0x1023d6df0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 120>\n",
      "2023-06-20 19:21:12,077 - trulens_eval.util - DEBUG - <code object _run_cell at 0x1022e90e0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2890>\n",
      "2023-06-20 19:21:12,078 - trulens_eval.util - DEBUG - <code object run_cell at 0x1022e9030, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2848>\n",
      "2023-06-20 19:21:12,078 - trulens_eval.util - DEBUG - <code object run_cell at 0x1038d5b30, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 537>\n",
      "2023-06-20 19:21:12,078 - trulens_eval.util - DEBUG - <code object do_execute at 0x10310d190, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 339>\n",
      "2023-06-20 19:21:12,078 - trulens_eval.util - DEBUG - <code object execute_request at 0x103127b30, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 684>\n",
      "2023-06-20 19:21:12,079 - trulens_eval.util - DEBUG - <code object dispatch_shell at 0x103120a80, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 360>\n",
      "2023-06-20 19:21:12,079 - trulens_eval.util - DEBUG - <code object process_one at 0x103127030, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 490>\n",
      "2023-06-20 19:21:12,079 - trulens_eval.util - DEBUG - <code object dispatch_queue at 0x1031270e0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 504>\n",
      "2023-06-20 19:21:12,079 - trulens_eval.util - DEBUG - <code object _run at 0x1012a33a0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/events.py\", line 79>\n",
      "2023-06-20 19:21:12,079 - trulens_eval.util - DEBUG - <code object _run_once at 0x1010badf0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/base_events.py\", line 1784>\n",
      "2023-06-20 19:21:12,079 - trulens_eval.util - DEBUG - <code object run_forever at 0x1010b0240, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/base_events.py\", line 557>\n",
      "2023-06-20 19:21:12,080 - trulens_eval.util - DEBUG - <code object start at 0x103a1f5b0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 194>\n",
      "2023-06-20 19:21:12,080 - trulens_eval.util - DEBUG - <code object start at 0x101f8b3a0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 706>\n",
      "2023-06-20 19:21:12,080 - trulens_eval.util - DEBUG - <code object launch_instance at 0x101695a80, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/traitlets/config/application.py\", line 1035>\n",
      "2023-06-20 19:21:12,081 - trulens_eval.util - DEBUG - <code object <module> at 0x1009912f0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel_launcher.py\", line 1>\n",
      "2023-06-20 19:21:12,081 - trulens_eval.util - DEBUG - <code object _run_code at 0x1009be5b0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/runpy.py\", line 64>\n",
      "2023-06-20 19:21:12,081 - trulens_eval.util - DEBUG - <code object _run_module_as_main at 0x1009bec90, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/runpy.py\", line 169>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00838542406927445"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hugs.language_match(\"Wie gehts?\", \"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cost(n_requests=2, n_successful_requests=2, n_classes=40, n_tokens=0, n_prompt_tokens=0, n_completion_tokens=0, cost=0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hugs.endpoint.global_callback.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-20 19:21:30,702 - trulens_eval.provider_apis - DEBUG - Calling wrapped create for openai.\n",
      "2023-06-20 19:21:30,703 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "2023-06-20 19:21:30,703 - openai - DEBUG - api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"messages\": [{\"role\": \"system\", \"content\": \"You are a RELEVANCE classifier; providing the relevance of the given STATEMENT to the given QUESTION.\\\\nRespond only as a number from 1 to 10 where 1 is the least relevant and 10 is the most relevant.\\\\nNever elaborate.\\\\n\\\\nQUESTION: Who is Piotr?\\\\n\\\\nSTATEMENT: Piotr is a person.\\\\n\\\\nRELEVANCE: \"}]}' message='Post details'\n",
      "2023-06-20 19:21:30,704 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "2023-06-20 19:21:30,736 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443\n",
      "2023-06-20 19:21:31,275 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "2023-06-20 19:21:31,276 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=386 request_id=24aa96d35db6de346af5c163f76b9bae response_code=200\n",
      "2023-06-20 19:21:31,283 - trulens_eval.util - DEBUG - <code object wrapper at 0x160754920, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/provider_apis.py\", line 294>\n",
      "2023-06-20 19:21:31,284 - trulens_eval.util - DEBUG - <code object <lambda> at 0x143626500, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/feedback.py\", line 668>\n",
      "2023-06-20 19:21:31,284 - trulens_eval.util - DEBUG - <code object run_me at 0x1607543a0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/provider_apis.py\", line 195>\n",
      "2023-06-20 19:21:31,284 - trulens_eval.util - DEBUG - <code object qs_relevance at 0x1436265b0, file \"/Users/piotrm/Dropbox/repos/github/trulens/trulens_eval/trulens_eval/feedback.py\", line 653>\n",
      "2023-06-20 19:21:31,284 - trulens_eval.util - DEBUG - <code object <cell line: 1> at 0x16628e030, file \"/var/folders/2j/xg0_cv993gl37s_8qs5qrdxm0000gn/T/ipykernel_5794/2068826459.py\", line 1>\n",
      "2023-06-20 19:21:31,284 - trulens_eval.util - DEBUG - <code object run_code at 0x1022e97c0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3362>\n",
      "2023-06-20 19:21:31,285 - trulens_eval.util - DEBUG - <code object run_ast_nodes at 0x1022e9660, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3238>\n",
      "2023-06-20 19:21:31,285 - trulens_eval.util - DEBUG - <code object run_cell_async at 0x1022e92f0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2988>\n",
      "2023-06-20 19:21:31,285 - trulens_eval.util - DEBUG - <code object _pseudo_sync_runner at 0x1023d6df0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 120>\n",
      "2023-06-20 19:21:31,285 - trulens_eval.util - DEBUG - <code object _run_cell at 0x1022e90e0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2890>\n",
      "2023-06-20 19:21:31,286 - trulens_eval.util - DEBUG - <code object run_cell at 0x1022e9030, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2848>\n",
      "2023-06-20 19:21:31,286 - trulens_eval.util - DEBUG - <code object run_cell at 0x1038d5b30, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 537>\n",
      "2023-06-20 19:21:31,286 - trulens_eval.util - DEBUG - <code object do_execute at 0x10310d190, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 339>\n",
      "2023-06-20 19:21:31,286 - trulens_eval.util - DEBUG - <code object execute_request at 0x103127b30, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 684>\n",
      "2023-06-20 19:21:31,286 - trulens_eval.util - DEBUG - <code object dispatch_shell at 0x103120a80, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 360>\n",
      "2023-06-20 19:21:31,287 - trulens_eval.util - DEBUG - <code object process_one at 0x103127030, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 490>\n",
      "2023-06-20 19:21:31,287 - trulens_eval.util - DEBUG - <code object dispatch_queue at 0x1031270e0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 504>\n",
      "2023-06-20 19:21:31,287 - trulens_eval.util - DEBUG - <code object _run at 0x1012a33a0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/events.py\", line 79>\n",
      "2023-06-20 19:21:31,287 - trulens_eval.util - DEBUG - <code object _run_once at 0x1010badf0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/base_events.py\", line 1784>\n",
      "2023-06-20 19:21:31,287 - trulens_eval.util - DEBUG - <code object run_forever at 0x1010b0240, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/asyncio/base_events.py\", line 557>\n",
      "2023-06-20 19:21:31,288 - trulens_eval.util - DEBUG - <code object start at 0x103a1f5b0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 194>\n",
      "2023-06-20 19:21:31,288 - trulens_eval.util - DEBUG - <code object start at 0x101f8b3a0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 706>\n",
      "2023-06-20 19:21:31,288 - trulens_eval.util - DEBUG - <code object launch_instance at 0x101695a80, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/traitlets/config/application.py\", line 1035>\n",
      "2023-06-20 19:21:31,288 - trulens_eval.util - DEBUG - <code object <module> at 0x1009912f0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/ipykernel_launcher.py\", line 1>\n",
      "2023-06-20 19:21:31,289 - trulens_eval.util - DEBUG - <code object _run_code at 0x1009be5b0, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/runpy.py\", line 64>\n",
      "2023-06-20 19:21:31,289 - trulens_eval.util - DEBUG - <code object _run_module_as_main at 0x1009bec90, file \"/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/runpy.py\", line 169>\n",
      "handling openai\n",
      "generations=[[]] llm_output={'token_usage': <OpenAIObject at 0x16628b630> JSON: {\n",
      "  \"completion_tokens\": 1,\n",
      "  \"prompt_tokens\": 81,\n",
      "  \"total_tokens\": 82\n",
      "}, 'model_name': 'gpt-3.5-turbo'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.qs_relevance(\"Who is Piotr?\", \"Piotr is a person.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAICallback(cost=Cost(n_requests=1, n_successful_requests=1, n_classes=0, n_tokens=82, n_prompt_tokens=81, n_completion_tokens=1, cost=0.000164), langchain_handler=Tokens Used: 82\n",
       "\tPrompt Tokens: 81\n",
       "\tCompletion Tokens: 1\n",
       "Successful Requests: 1\n",
       "Total Cost (USD): $0.000164)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.endpoint.global_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "# response = query_engine.query(\"What did the author do growing up?\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lang_match.selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = TruLlama(app=query_engine, feedbacks=feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which components of the llama index app have been instrumented (will be\n",
    "# tracked as components in the dashboard).\n",
    "\n",
    "l.print_instrumented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, record = l.query_with_record(\"Who is Shayak?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the dashboard here:\n",
    "proc = Tru().start_dashboard(force=True, _dev=Path.cwd().parent.parent.parent)\n",
    "\n",
    "# If using deferred feedback evaluation, need to start this too:\n",
    "# thread = Tru().start_evaluator(restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f_qs_relevance.run(record=record, app=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
