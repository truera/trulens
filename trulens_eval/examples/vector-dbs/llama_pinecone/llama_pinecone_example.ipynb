{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex + Pinecone + TruLens\n",
    "\n",
    "In this quickstart you will create a simple Llama Index App with Pinecone to answer complex queries over multiple data sources.  You will also log it with TruLens and get feedback on an LLM response.\n",
    "\n",
    "* While Pinecone provides a powerful and efficient retrieval engine, it remains challenging to answer complex questions that require multi-step reasoning and synthesis over many data sources.\n",
    "\n",
    "* With LlamaIndex, we combine the power of vector similiarty search and multi-step reasoning to delivery higher quality and richer responses.\n",
    "\n",
    "* On top of it all, TruLens allows us to get feedback track and manage our experiments and get feedback on the quality of our app.\n",
    "\n",
    "Here, we show 2 specific use-cases:\n",
    "\n",
    "1. compare and contrast queries over Wikipedia articles about different cities.\n",
    "\n",
    "2. temporal queries that require reasoning over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install trulens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"\"\n",
    "\n",
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_ENV = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from Pinecone, LlamaIndex and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "pinecone.init(api_key = PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "\n",
    "# create index if it does not already exist\n",
    "# dimensions are for text-embedding-ada-002\n",
    "pinecone.create_index(\"quickstart-index\",\n",
    "    dimension=1536,\n",
    "    metric=\"euclidean\",\n",
    "    pod_type=\"starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index = pinecone.Index(\"quickstart-index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = [\"Toronto\", \"Seattle\", \"San Francisco\", \"Chicago\", \"Boston\", \"Washington, D.C.\", \"Cambridge, Massachusetts\", \"Houston\"]\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "data_path = Path('data_wiki')\n",
    "\n",
    "for title in wiki_titles:\n",
    "    response = requests.get(\n",
    "        'https://en.wikipedia.org/w/api.php',\n",
    "        params={\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'titles': title,\n",
    "            'prop': 'extracts',\n",
    "            'explaintext': True,\n",
    "        }\n",
    "    ).json()\n",
    "    page = next(iter(response['query']['pages'].values()))\n",
    "    wiki_text = page['extract']\n",
    "\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path / f\"{title}.txt\", 'w') as fp:\n",
    "        fp.write(wiki_text)\n",
    "        \n",
    " # Load all wiki documents\n",
    "city_docs = {}\n",
    "all_docs = []\n",
    "for wiki_title in wiki_titles:\n",
    "    city_docs[wiki_title] = SimpleDirectoryReader(input_files=[data_path / f\"{wiki_title}.txt\"]).load_data()\n",
    "    all_docs.extend(city_docs[wiki_title])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Toronto\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74108dcac092499a90dcbc27a3c1c8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Seattle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43214aa4946d45bebf3c42e9d7375508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for San Francisco\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00b215a0d8d4d34973070300e175224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Chicago\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d53c1bbd05046c5bd127ad6c88f4728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Boston\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09c23f800834a1ca52f441f2b10ce22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Washington, D.C.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b495d716cc45888626aefff16354b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Cambridge, Massachusetts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea7beadc5704bd0a8f027ae25f831a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Houston\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2ce720ee9f477c850faf47211406c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import StorageContext\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "\n",
    "# Build index for each city document\n",
    "city_indices = {}\n",
    "index_summaries = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    print(f\"Building index for {wiki_title}\")\n",
    "    # create storage context\n",
    "    vector_store = PineconeVectorStore(pinecone_index=pinecone_index, namespace=wiki_title)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "    # build index\n",
    "    city_indices[wiki_title] = VectorStoreIndex.from_documents(city_docs[wiki_title], storage_context=storage_context)\n",
    "\n",
    "    # set summary text for city\n",
    "    index_summaries[wiki_title] = f\"Wikipedia articles about {wiki_title}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph Query Engine for Compare & Contrast Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jreini/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.indices.composability import ComposableGraph\n",
    "from llama_index.indices.keyword_table.simple_base import SimpleKeywordTableIndex\n",
    "\n",
    "graph = ComposableGraph.from_indices(\n",
    "    SimpleKeywordTableIndex,\n",
    "    [index for _, index in city_indices.items()], \n",
    "    [summary for _, summary in index_summaries.items()],\n",
    "    max_keywords_per_chunk=50\n",
    ")\n",
    "\n",
    "from llama_index.indices.query.query_transform.base import DecomposeQueryTransform\n",
    "from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n",
    "\n",
    "decompose_transform = DecomposeQueryTransform(verbose=True)\n",
    "\n",
    "custom_query_engines = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    index = city_indices[wiki_title]\n",
    "    query_engine = index.as_query_engine()\n",
    "    query_engine = TransformQueryEngine(\n",
    "        query_engine,\n",
    "        query_transform=decompose_transform,\n",
    "        transform_extra_info={'index_summary': index_summaries[wiki_title]},\n",
    "    )\n",
    "    custom_query_engines[index.index_id] = query_engine\n",
    "\n",
    "custom_query_engines[graph.root_id] = graph.root_index.as_query_engine(\n",
    "    retriever_mode='simple',\n",
    "    response_mode='tree_summarize',\n",
    ")\n",
    "\n",
    "# with query decomposition in subindices\n",
    "query_engine = graph.as_query_engine(custom_query_engines=custom_query_engines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Seattle?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Seattle?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Houston?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Houston?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Toronto?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Toronto?\n",
      "\u001b[0mFinal Response: Seattle, Houston, and Toronto are all large cities\n",
      "with populations over 700,000. Seattle has the smallest population of\n",
      "the three cities, with 704,352 people according to the 2012–2016\n",
      "American Community Survey (ACS). Houston has the second largest\n",
      "population, with 2,304,580 people in 2020, and Toronto has the largest\n",
      "population, with 2,794,356 people in 2021. All three cities are\n",
      "diverse, with a variety of ethnicities and cultures represented.\n",
      "However, Houston and Toronto have larger immigrant populations than\n",
      "Seattle. Houston has a large Hispanic population, while Toronto has a\n",
      "large population of immigrants from South Asia. Additionally, Houston\n",
      "and Toronto have larger populations of people living in poverty than\n",
      "Seattle.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Compare and contrast the demographics in Seattle, Houston, and Toronto.\")\n",
    "\n",
    "from llama_index.response.pprint_utils import pprint_response\n",
    "\n",
    "pprint_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In language_match, input text1 will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In language_match, input text2 will be set to *.__record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    " # Imports main tools:\n",
    "from trulens_eval import TruLlama, Feedback, Huggingface, Tru\n",
    "tru = Tru()\n",
    "\n",
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on_input_output()\n",
    "# By default this will check language match on the main app input and main app\n",
    "# output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ app LlamaIndex_with_Pinecone_App1 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_932edec0af87df859606713ebfa3fde5 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "tru_query_engine = TruLlama(query_engine,\n",
    "    app_id='LlamaIndex_with_Pinecone_App1',\n",
    "    feedbacks=[f_lang_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Seattle?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Seattle?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Houston?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Houston?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Toronto?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Toronto?\n",
      "\u001b[0m\n",
      "Seattle, Houston, and Toronto are all large cities with populations over 700,000. Seattle has the smallest population of the three cities, with 704,352 people according to the 2012–2016 American Community Survey (ACS). Houston has the second largest population, with 2,304,580 people in 2020, and Toronto has the largest population, with 2,794,356 people in 2021. All three cities are diverse, with a variety of ethnicities and cultures represented. However, Houston and Toronto have larger immigrant populations than Seattle. Houston has a large Hispanic population, while Toronto has a large population of immigrants from South Asia. Additionally, Houston and Toronto have larger populations of people living in poverty than Seattle.\n",
      "✅ record record_hash_b0bfda41b7a0d6bcd40e3e90162e87b6 from LlamaIndex_with_Pinecone_App1 -> default.sqlite"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 44.49275207519531} (44.49275207519531) second(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 44.49275207519531} (44.49275207519531) second(s).\n"
     ]
    }
   ],
   "source": [
    "# Instrumented query engine can operate like the original:\n",
    "llm_response = tru_query_engine.query(\"Compare and contrast the demographics in Seattle, Houston, and Toronto.\")\n",
    "\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3657241a3944b085fc0dde8db1c8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.23:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('trulens')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "c633204c92f433e69d41413efde9db4a539ce972d10326abcceb024ad118839e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
