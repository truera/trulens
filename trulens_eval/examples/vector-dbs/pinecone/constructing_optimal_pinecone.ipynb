{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone Configuration Choices on Downstream App Performance\n",
    "There are a few important configuration choices to keep in mind when constructing a vector store, e.g. distance metric. In this example, we explore the downstream impact of these configuration choices on response quality, cost & latency of the downstream LLM app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"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\"\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"d5589ecb-e0dd-4768-b92b-5d5aad35d304\"\n",
    "os.environ[\"PINECONE_ENVIRONMENT\"] = \"us-west1-gcp-free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install -qU   langchain==0.0.162   openai==0.27.7   tiktoken==0.4.0   \"pinecone-client[grpc]\"==2.2.1   pinecone_datasets==\\'0.5.0rc10'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install -qU \\\n",
    "  langchain==0.0.162 \\\n",
    "  openai==0.27.7 \\\n",
    "  tiktoken==0.4.0 \\\n",
    "  \"pinecone-client[grpc]\"==2.2.1 \\\n",
    "  pinecone_datasets=='0.5.0rc10'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ðŸš¨ _Note: the above `pip install` is formatted for Jupyter notebooks. If running elsewhere you may need to drop the `!`._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download a pre-embedding dataset from pinecone-datasets. Allowing us to skip the embedding and preprocessing steps, if you'd rather work through those steps you can find the full notebook here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "      <th>blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-0</td>\n",
       "      <td>[-0.011254455894231796, -0.01698738895356655, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 0, 'source': 'https://simple.wikiped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1</td>\n",
       "      <td>[-0.0015197008615359664, -0.007858820259571075...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 1, 'source': 'https://simple.wikiped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-2</td>\n",
       "      <td>[-0.009930099360644817, -0.012211072258651257,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 2, 'source': 'https://simple.wikiped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-3</td>\n",
       "      <td>[-0.011600767262279987, -0.012608098797500134,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 3, 'source': 'https://simple.wikiped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-4</td>\n",
       "      <td>[-0.026462381705641747, -0.016362832859158516,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 4, 'source': 'https://simple.wikiped...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             values sparse_values  \\\n",
       "0  1-0  [-0.011254455894231796, -0.01698738895356655, ...          None   \n",
       "1  1-1  [-0.0015197008615359664, -0.007858820259571075...          None   \n",
       "2  1-2  [-0.009930099360644817, -0.012211072258651257,...          None   \n",
       "3  1-3  [-0.011600767262279987, -0.012608098797500134,...          None   \n",
       "4  1-4  [-0.026462381705641747, -0.016362832859158516,...          None   \n",
       "\n",
       "  metadata                                               blob  \n",
       "0     None  {'chunk': 0, 'source': 'https://simple.wikiped...  \n",
       "1     None  {'chunk': 1, 'source': 'https://simple.wikiped...  \n",
       "2     None  {'chunk': 2, 'source': 'https://simple.wikiped...  \n",
       "3     None  {'chunk': 3, 'source': 'https://simple.wikiped...  \n",
       "4     None  {'chunk': 4, 'source': 'https://simple.wikiped...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pinecone_datasets\n",
    "\n",
    "dataset = pinecone_datasets.load_dataset('wikipedia-simple-text-embedding-ada-002-100K')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll format the dataset ready for upsert and reduce what we use to a subset of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we drop sparse_values as they are not needed for this example\n",
    "dataset.documents.drop(['metadata'], axis=1, inplace=True)\n",
    "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
    "# we will use rows of the dataset up to index 30_000\n",
    "dataset.documents.drop(dataset.documents.index[30_000:], inplace=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPpcO-TwuQwD"
   },
   "source": [
    "Now we move on to initializing our Pinecone vector database.\n",
    "\n",
    "## Vector Database\n",
    "\n",
    "To create our vector database we first need a [free API key from Pinecone](https://app.pinecone.io). Then we initialize like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_v1 = 'langchain-rag-cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "# find API key in console at app.pinecone.io\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "# find ENV (cloud region) next to API key in console\n",
    "PINECONE_ENVIRONMENT = os.getenv('PINECONE_ENVIRONMENT')\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT\n",
    ")\n",
    "\n",
    "if index_name_v1 not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "        name=index_name_v1,\n",
    "        metric='cosine', # we'll try each distance metric here\n",
    "        dimension=1536,  # 1536 dim of text-embedding-ada-002\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index = pinecone.GRPCIndex(index_name_v1)\n",
    "# wait a moment for the index to be fully initialized\n",
    "time.sleep(1)\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset.iter_documents(batch_size=100):\n",
    "    index.upsert(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.3,\n",
       " 'namespaces': {'': {'vector_count': 30000}},\n",
       " 'total_vector_count': 30000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Vector Store and Querying\n",
    "\n",
    "Now that we've build our index we can switch over to LangChain. We need to initialize a LangChain vector store using the same index we just built. For this we will also need a LangChain embedding object, which we initialize like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a3ChSxlcwX8n"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# get openai api key from platform.openai.com\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8KGqv-rzEgH",
    "outputId": "b8a954b2-038c-4e00-8081-7f1c3934afb5"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "# switch back to normal index for langchain\n",
    "index = pinecone.Index(index_name_v1)\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCvtmREd0pdo"
   },
   "source": [
    "## Retrieval Augmented Generation (RAG)\n",
    "\n",
    "In RAG we take the query as a question that is to be answered by a LLM, but the LLM must answer the question based on the information it is seeing being returned from the `vectorstore`.\n",
    "\n",
    "To do this we initialize a `RetrievalQA` object like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "moCvQR-p0Zsb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No .env found in /Users/jreini/Desktop/development/trulens/trulens_eval/examples/vector-dbs/pinecone or its parents. You may need to specify secret keys in another manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In relevance, input prompt will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "âœ… In relevance, input response will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In qs_relevance, input question will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "âœ… In qs_relevance, input statement will be set to *.__record__.app.combine_documents_chain._call.args.inputs.input_documents[:].page_content .\n",
      "âœ… app Chain1_WikipediaQA -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_6376f76fb6b5ab13f1261d942e8d6729 -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_76c2c7a07a4a8578fe78fdbd173b3288 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# Imports main tools for eval\n",
    "from trulens_eval import TruChain, Feedback, Tru, feedback, Select\n",
    "import numpy as np\n",
    "tru = Tru()\n",
    "\n",
    "# OpenAI as feedback provider\n",
    "openai = feedback.OpenAI()\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# By default this will evaluate feedback on main app input and main app output.\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "qs_relevance = feedback.Feedback(openai.qs_relevance).on_input().on(\n",
    "    Select.Record.app.combine_documents_chain._call.args.inputs.input_documents[:].page_content\n",
    ").aggregate(np.mean)\n",
    "\n",
    "# wrap with TruLens\n",
    "truchain = TruChain(qa,\n",
    "    app_id='Chain1_WikipediaQA',\n",
    "    feedbacks=[qa_relevance, qs_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_171e789372a967655aa9543e657365dd from Chain1_WikipediaQA -> default.sqlite\n",
      "âœ… record record_hash_e86f8fc4d4486056370d152f51aacc64 from Chain1_WikipediaQA -> default.sqlite\n",
      "âœ… record record_hash_f0fcbca7a68bd436a8f43f64c805acc9 from Chain1_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_8a0921a2ada3b7a451bc223423ee9864 on record_hash_171e789372a967655aa9543e657365dd -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_7f20c76b7eee7cd2e04179eb792262b5 on record_hash_171e789372a967655aa9543e657365dd -> default.sqlite\n",
      "âœ… record record_hash_aa97cb2801475a19cddd764493e79608 from Chain1_WikipediaQA -> default.sqlite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many total major trophies has manchester united won?',\n",
       " 'result': 'Manchester United has won a total of 66 major trophies.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truchain(\"Name some famous dental floss brands?\")\n",
    "truchain(\"Which year did Cincinatti become the Capital of Ohio?\")\n",
    "truchain(\"Which year was Hawaii's state song written?\")\n",
    "truchain(\"How many countries are there in the world?\")\n",
    "truchain(\"How many total major trophies has manchester united won?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the TruLens Dashboard to view tracking and evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_e1475327c0a62466222db838cb977700 from Chain1_WikipediaQA -> default.sqlite\n",
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e0693c631042aba132728795c37b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.23:8505 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.delete_index(index_name_v1)\n",
    "time.sleep(30) # sleep for 30 seconds after deleting the index before creating a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_v2 = 'langchain-rag-euclidean'\n",
    "pinecone.create_index(\n",
    "        name=index_name_v2,\n",
    "        metric='euclidean',\n",
    "        dimension=1536,  # 1536 dim of text-embedding-ada-002\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.GRPCIndex(index_name_v2)\n",
    "# wait a moment for the index to be fully initialized\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… app Chain2_WikipediaQA -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_6376f76fb6b5ab13f1261d942e8d6729 -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_76c2c7a07a4a8578fe78fdbd173b3288 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "# qa still exists, and will now use our updated vector store\n",
    "\n",
    "# recreate qa from vector store\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# wrap with TruLens\n",
    "truchain = TruChain(qa,\n",
    "    app_id='Chain2_WikipediaQA',\n",
    "    feedbacks=[qa_relevance, qs_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_175f73a666abafaabba58a1a0b0a121a from Chain2_WikipediaQA -> default.sqlite\n",
      "âœ… record record_hash_d6ed647224bf101c6f4e265266c55a9c from Chain2_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_54b88250207666e46ceb0fc43aaf59d4 on record_hash_175f73a666abafaabba58a1a0b0a121a -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_b5966e85adf5cbbba70018fca5b4f00c on record_hash_175f73a666abafaabba58a1a0b0a121a -> default.sqlite\n",
      "âœ… record record_hash_c9051de489bee46561b9dc2786211414 from Chain2_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_f682ba43e0054dafd84f546a90b612c9 on record_hash_c9051de489bee46561b9dc2786211414 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_ac8915a34dd92474893581f64c693a68 on record_hash_c9051de489bee46561b9dc2786211414 -> default.sqlite\n",
      "âœ… record record_hash_3961d1db52a3db2d762b8ee1cdb4131c from Chain2_WikipediaQA -> default.sqlite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many total major trophies has manchester united won?',\n",
       " 'result': 'Manchester United has won a total of 66 major trophies.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_1e3663ba5074876b91386082ce0a9dc1 from Chain2_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_3035174c65658e70bb444482ce7b7553 on record_hash_3961d1db52a3db2d762b8ee1cdb4131c -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_6f19ade4a510f1eb47c1602202ff7b6e on record_hash_3961d1db52a3db2d762b8ee1cdb4131c -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_75c9f85ab2e694000596bf10d6df4899 on record_hash_1e3663ba5074876b91386082ce0a9dc1 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_58252ee6bb8b914a6fff8ca37e9f4af8 on record_hash_1e3663ba5074876b91386082ce0a9dc1 -> default.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai request failed <class 'openai.error.ServiceUnavailableError'>=The server is overloaded or not ready yet.. Retries=3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… feedback feedback_result_hash_333828424de0c468095e5c2eea55be55 on record_hash_d6ed647224bf101c6f4e265266c55a9c -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_6f1a58d86712dce5a755a5c86be4235e on record_hash_d6ed647224bf101c6f4e265266c55a9c -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "truchain(\"Name some famous dental floss brands?\")\n",
    "truchain(\"Which year did Cincinatti become the Capital of Ohio?\")\n",
    "truchain(\"Which year was Hawaii's state song written?\")\n",
    "truchain(\"How many countries are there in the world?\")\n",
    "truchain(\"How many total major trophies has manchester united won?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.delete_index(index_name_v2)\n",
    "time.sleep(30) # sleep for 30 seconds after deleting the index before creating a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_v3 = 'langchain-rag-dot'\n",
    "pinecone.create_index(\n",
    "        name=index_name_v3,\n",
    "        metric='dotproduct',\n",
    "        dimension=1536,  # 1536 dim of text-embedding-ada-002\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pinecone.GRPCIndex(index_name_v3)\n",
    "# wait a moment for the index to be fully initialized\n",
    "time.sleep(1)\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset.iter_documents(batch_size=100):\n",
    "    index.upsert(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… app Chain3_WikipediaQA -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_6376f76fb6b5ab13f1261d942e8d6729 -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_76c2c7a07a4a8578fe78fdbd173b3288 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "# switch back to normal index for langchain\n",
    "index = pinecone.Index(index_name_v3)\n",
    "\n",
    "# update vectorstore with new index\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")\n",
    "\n",
    "# recreate qa from vector store\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# wrap with TruLens\n",
    "truchain = TruChain(qa,\n",
    "    app_id='Chain3_WikipediaQA',\n",
    "    feedbacks=[qa_relevance, qs_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_34315e45987d717ce831a024177f613d from Chain3_WikipediaQA -> default.sqlite\n",
      "âœ… record record_hash_9f7fe3e6d2b6dc616b5e684f21d0685a from Chain3_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_964c4e49f12b368c78354afcc18c0210 on record_hash_9f7fe3e6d2b6dc616b5e684f21d0685a -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_4b8d75a89b85c02d3c37078b43fe2e57 on record_hash_9f7fe3e6d2b6dc616b5e684f21d0685a -> default.sqlite\n",
      "âœ… record record_hash_a441624e136ef679130100513619fd2e from Chain3_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_f500a1805826a0be3ca0e81a15575d48 on record_hash_34315e45987d717ce831a024177f613d -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_804a2c8f50149cabc2dcb576bd6abd45 on record_hash_34315e45987d717ce831a024177f613d -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_131d76fe5d6c7f8e2349207aae478020 on record_hash_a441624e136ef679130100513619fd2e -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_3d99bde6bf5e4a99c79dd8a89f0f64cb on record_hash_a441624e136ef679130100513619fd2e -> default.sqlite\n",
      "âœ… record record_hash_b6e663ef30177500b106f812912ab203 from Chain3_WikipediaQA -> default.sqlite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many total major trophies has manchester united won?',\n",
       " 'result': 'Manchester United has won a total of 66 major trophies.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_a8d363f88b734f4087cbe876dce51560 from Chain3_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_d35ed88a7157b5b5b52ef69a65ccb920 on record_hash_b6e663ef30177500b106f812912ab203 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_069bac33b69e891ac1ca34f7c54848ca on record_hash_b6e663ef30177500b106f812912ab203 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_53798f9bda9c540cf0d838e03e496293 on record_hash_a8d363f88b734f4087cbe876dce51560 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_2a2ae30122b62815ed000760bc5c2b81 on record_hash_a8d363f88b734f4087cbe876dce51560 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "truchain(\"Name some famous dental floss brands?\")\n",
    "truchain(\"Which year did Cincinatti become the Capital of Ohio?\")\n",
    "truchain(\"Which year was Hawaii's state song written?\")\n",
    "truchain(\"How many countries are there in the world?\")\n",
    "truchain(\"How many total major trophies has manchester united won?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our LLM app is performing the fastest with dot-product as our distance metric!\n",
    "\n",
    "However the app is still hallucinating floss brands that are not supported by context. Let's try a less powerful model with the same grounding approach to cut down on hallucination. This should reduce our token usage as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… app Chain4_WikipediaQA -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_6376f76fb6b5ab13f1261d942e8d6729 -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_76c2c7a07a4a8578fe78fdbd173b3288 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "# completion llm\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name='text-ada-001',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "qa_with_sources = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# wrap with TruLens\n",
    "truchain = TruChain(qa_with_sources,\n",
    "    app_id='Chain4_WikipediaQA',\n",
    "    feedbacks=[qa_relevance, qs_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_21704c168e004a6c39cce0d7bbec8d43 from Chain4_WikipediaQA -> default.sqlite\n",
      "âœ… record record_hash_1ab1ff9ca819234634d6a25f5188c313 from Chain4_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_87a5c7d0757453c1189342c0958b7a5a on record_hash_21704c168e004a6c39cce0d7bbec8d43 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_66bab915bd6dd75e86c4b73c88822a5f on record_hash_21704c168e004a6c39cce0d7bbec8d43 -> default.sqlite\n",
      "âœ… record record_hash_ec5faf1ee050b044ca2e91f40144974a from Chain4_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_21481b28953f4ba1faad2412cd9b3a5b on record_hash_1ab1ff9ca819234634d6a25f5188c313 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_5a12fe4b5ad441727ae21a5fb24c34d5 on record_hash_1ab1ff9ca819234634d6a25f5188c313 -> default.sqlite\n",
      "âœ… record record_hash_368b89f59db91b185e0e9b901fc374db from Chain4_WikipediaQA -> default.sqlite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many total major trophies has manchester united won?',\n",
       " 'result': ' manchester united has won a total of 20 league titles, 12 FA Cups, and 3 European Cups.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_9db722772ce5e624ddf4be907c4ce044 from Chain4_WikipediaQA -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_e080abb10a3731012ced4d4977b53607 on record_hash_ec5faf1ee050b044ca2e91f40144974a -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_d107f7fc7c3ffb2dbbbc3e7777b30245 on record_hash_ec5faf1ee050b044ca2e91f40144974a -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_9b31628f2aa8eee8aa500b9d8a9d54a4 on record_hash_368b89f59db91b185e0e9b901fc374db -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_c7826a828f32a03f81c317b3139d8ce0 on record_hash_368b89f59db91b185e0e9b901fc374db -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_397481cc1cdd6e070aa0422ac2997fff on record_hash_9db722772ce5e624ddf4be907c4ce044 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_d369f4e5edda663c3657e5de782feb42 on record_hash_9db722772ce5e624ddf4be907c4ce044 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "truchain(\"Name some famous dental floss brands?\")\n",
    "truchain(\"Which year did Cincinatti become the Capital of Ohio?\")\n",
    "truchain(\"Which year was Hawaii's state song written?\")\n",
    "truchain(\"How many countries are there in the world?\")\n",
    "truchain(\"How many total major trophies has manchester united won?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fails because the context exceeds what ada can handle! Let's reduce the \"top_k\", or the number of documents retrieved in order to reduce the context passed into ada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion llm\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "qa= RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(top_k = 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The way the top_k works with RetrievalQA is that the documents are still retrieved by our semantic search and but only the top_k are passed to the LLM. Howevever TruLens captures all of the context chunks that are being retrieved. In order to calculate an accurate QS Relevance metric that matches what's being passed to the LLM, we need to only calculate the relevance of the top context chunk retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In qs_relevance, input question will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "âœ… In qs_relevance, input statement will be set to *.__record__.app.combine_documents_chain._call.args.inputs.input_documents[:1:].page_content .\n",
      "âœ… app Chain5_WikipediaQA_topk=1_attempt2 -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_6376f76fb6b5ab13f1261d942e8d6729 -> default.sqlite\n",
      "âœ… feedback def. feedback_definition_hash_c60d655f0d9dfbb1aa880a4293fbca84 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qs_relevance = feedback.Feedback(openai.qs_relevance).on_input().on(\n",
    "    Select.Record.app.combine_documents_chain._call.args.inputs.input_documents[:1].page_content\n",
    ").aggregate(np.mean)\n",
    "\n",
    "# wrap with TruLens\n",
    "truchain = TruChain(qa,\n",
    "    app_id='Chain5_WikipediaQA',\n",
    "    feedbacks=[qa_relevance, qs_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_22199b2e9a384d3d86f804b442c4c222 from Chain5_WikipediaQA_topk=1_attempt2 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_b180ba1bab418a5a935157821f9123bb on record_hash_22199b2e9a384d3d86f804b442c4c222 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_4e5b962327c0279387e28997be837f6b on record_hash_22199b2e9a384d3d86f804b442c4c222 -> default.sqlite\n",
      "âœ… record record_hash_ef7c819bfa92a82877b8f879b14eb0e1 from Chain5_WikipediaQA_topk=1_attempt2 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_57570a013f182db42017438ac4829c46 on record_hash_ef7c819bfa92a82877b8f879b14eb0e1 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_47f7a32e6ac4c35ffa21d655ba5625a0 on record_hash_ef7c819bfa92a82877b8f879b14eb0e1 -> default.sqlite\n",
      "âœ… record record_hash_c1623ecae1dd8efdd0911a8c95c9437e from Chain5_WikipediaQA_topk=1_attempt2 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_d6a74271faa25221e618df22207be8ab on record_hash_c1623ecae1dd8efdd0911a8c95c9437e -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_c691fb0b0303b2bcafb4c4984b504b04 on record_hash_c1623ecae1dd8efdd0911a8c95c9437e -> default.sqlite\n",
      "âœ… record record_hash_accb6359bd6d0d3fca804b3cef6cc47d from Chain5_WikipediaQA_topk=1_attempt2 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_47c108102fa58dfe5df1514f13a645a9 on record_hash_accb6359bd6d0d3fca804b3cef6cc47d -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_2f919fd8a7d469332b4e9e0f063175b9 on record_hash_accb6359bd6d0d3fca804b3cef6cc47d -> default.sqlite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many total major trophies has manchester united won?',\n",
       " 'result': 'Manchester United has won a total of 66 major trophies.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… record record_hash_7570a2e9b01560b49af05ff6c671dddc from Chain5_WikipediaQA_topk=1_attempt2 -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_bdb07a6b84d813650ad30a6d640047aa on record_hash_7570a2e9b01560b49af05ff6c671dddc -> default.sqlite\n",
      "âœ… feedback feedback_result_hash_4dccf6585d344224eca4573aaaf39381 on record_hash_7570a2e9b01560b49af05ff6c671dddc -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "truchain(\"Name some famous dental floss brands?\")\n",
    "truchain(\"Which year did Cincinatti become the Capital of Ohio?\")\n",
    "truchain(\"Which year was Hawaii's state song written?\")\n",
    "truchain(\"How many countries are there in the world?\")\n",
    "truchain(\"How many total major trophies has manchester united won?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blazing fast!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 ('pinecone_example')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c68aa9cfa264c12f07062d08edcac5e8f20877de71ce1cea15160e4e8ae95e66"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "059918bb59744634aaa181dc4ec256a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28a553d3a3704b3aa8b061b71b1fe2ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee030d62f3a54f5288cccf954caa7d85",
       "IPY_MODEL_55cdb4e0b33a48b298f760e7ff2af0f9",
       "IPY_MODEL_9de7f27011b346f8b7a13fa649164ee7"
      ],
      "layout": "IPY_MODEL_f362a565ff90457f904233d4fc625119"
     }
    },
    "3c6290e0ee42461eb47dfcc5d5cd0629": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55cdb4e0b33a48b298f760e7ff2af0f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83ac28af70074e998663f6f247278a83",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c6290e0ee42461eb47dfcc5d5cd0629",
      "value": 10000
     }
    },
    "83ac28af70074e998663f6f247278a83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88a2b48b3b4f415797bab96eaa925aa7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9de7f27011b346f8b7a13fa649164ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88a2b48b3b4f415797bab96eaa925aa7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c241146f1475404282c35bc09e7cc945",
      "value": " 10000/10000 [03:52&lt;00:00, 79.57it/s]"
     }
    },
    "c241146f1475404282c35bc09e7cc945": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee030d62f3a54f5288cccf954caa7d85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_059918bb59744634aaa181dc4ec256a2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f762e8d37ab6441d87b2a66bfddd5239",
      "value": "100%"
     }
    },
    "f362a565ff90457f904233d4fc625119": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f762e8d37ab6441d87b2a66bfddd5239": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
