{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex + Pinecone + TruLens\n",
    "\n",
    "In this quickstart you will create a simple Llama Index App with Pinecone to answer complex queries over multiple data sources.  You will also log it with TruLens and get feedback on an LLM response.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/vector-dbs/pinecone/llama_index_pinecone_comparecontrast.ipynb)\n",
    "\n",
    "* While Pinecone provides a powerful and efficient retrieval engine, it remains challenging to answer complex questions that require multi-step reasoning and synthesis over many data sources.\n",
    "\n",
    "* With LlamaIndex, we combine the power of vector similiarty search and multi-step reasoning to delivery higher quality and richer responses.\n",
    "\n",
    "* On top of it all, TruLens allows us to get feedback track and manage our experiments and get feedback on the quality of our app.\n",
    "\n",
    "Here, we show 2 specific use-cases:\n",
    "\n",
    "1. compare and contrast queries over Wikipedia articles about different cities.\n",
    "\n",
    "2. temporal queries that require reasoning over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trulens\n",
      "  Using cached trulens-0.13.3-py3-none-any.whl (95 kB)\n",
      "Installing collected packages: trulens\n",
      "Successfully installed trulens-0.13.3\n"
     ]
    }
   ],
   "source": [
    "! pip install trulens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\"\n",
    "\n",
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_ENV = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from Pinecone, LlamaIndex and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jreini/opt/anaconda3/envs/trulens/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No .env found in /Users/jreini/Desktop/development/trulens/trulens_eval/examples/vector-dbs/llama_pinecone or its parents. You may need to specify secret keys manually.\n"
     ]
    }
   ],
   "source": [
    "# Pinecone\n",
    "import pinecone\n",
    "# TruLens\n",
    "from trulens_eval import TruLlama, Feedback, Huggingface, Tru\n",
    "tru = Tru()\n",
    "# LlamaIndex\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import StorageContext\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "from llama_index.indices.composability import ComposableGraph\n",
    "from llama_index.indices.keyword_table.simple_base import SimpleKeywordTableIndex\n",
    "from llama_index.indices.query.query_transform.base import DecomposeQueryTransform\n",
    "from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n",
    "\n",
    "# Others\n",
    "from pathlib import Path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key = PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "\n",
    "# create index if it does not already exist\n",
    "# dimensions are for text-embedding-ada-002\n",
    "pinecone.create_index(\"quickstart-index\",\n",
    "    dimension=1536,\n",
    "    metric=\"euclidean\",\n",
    "    pod_type=\"starter\")\n",
    "\n",
    "pinecone_index = pinecone.Index(\"quickstart-index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = [\"Toronto\", \"Seattle\", \"San Francisco\", \"Chicago\", \"Boston\", \"Washington, D.C.\", \"Cambridge, Massachusetts\", \"Houston\"]\n",
    "\n",
    "data_path = Path('data_wiki')\n",
    "\n",
    "for title in wiki_titles:\n",
    "    response = requests.get(\n",
    "        'https://en.wikipedia.org/w/api.php',\n",
    "        params={\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'titles': title,\n",
    "            'prop': 'extracts',\n",
    "            'explaintext': True,\n",
    "        }\n",
    "    ).json()\n",
    "    page = next(iter(response['query']['pages'].values()))\n",
    "    wiki_text = page['extract']\n",
    "\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path / f\"{title}.txt\", 'w') as fp:\n",
    "        fp.write(wiki_text)\n",
    "        \n",
    " # Load all wiki documents\n",
    "city_docs = {}\n",
    "all_docs = []\n",
    "for wiki_title in wiki_titles:\n",
    "    city_docs[wiki_title] = SimpleDirectoryReader(input_files=[data_path / f\"{wiki_title}.txt\"]).load_data()\n",
    "    all_docs.extend(city_docs[wiki_title])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Toronto\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b24a076a6840af959f6b9038f2e9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Seattle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d3d033880842f3934cfec167f2b2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for San Francisco\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d929269c6a5c46bbb16321d14cdeb04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Chicago\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb013333168412b8fdde1c648ddaaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Boston\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5900ef7cef484db9845a4717e31b1533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Washington, D.C.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f359541065fa404d991ada06541c687d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Cambridge, Massachusetts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04c59006f1548b4ae2b82266d17ecb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index for Houston\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4b9a53358d4732b6aec37940449fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build index for each city document\n",
    "city_indices = {}\n",
    "index_summaries = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    print(f\"Building index for {wiki_title}\")\n",
    "    # create storage context\n",
    "    vector_store = PineconeVectorStore(pinecone_index=pinecone_index, namespace=wiki_title)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "    # build index\n",
    "    city_indices[wiki_title] = VectorStoreIndex.from_documents(city_docs[wiki_title], storage_context=storage_context)\n",
    "\n",
    "    # set summary text for city\n",
    "    index_summaries[wiki_title] = f\"Wikipedia articles about {wiki_title}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph Query Engine for Compare & Contrast Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ComposableGraph.from_indices(\n",
    "    SimpleKeywordTableIndex,\n",
    "    [index for _, index in city_indices.items()], \n",
    "    [summary for _, summary in index_summaries.items()],\n",
    "    max_keywords_per_chunk=50\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "decompose_transform = DecomposeQueryTransform(verbose=True)\n",
    "\n",
    "custom_query_engines = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    index = city_indices[wiki_title]\n",
    "    query_engine = index.as_query_engine()\n",
    "    query_engine = TransformQueryEngine(\n",
    "        query_engine,\n",
    "        query_transform=decompose_transform,\n",
    "        transform_extra_info={'index_summary': index_summaries[wiki_title]},\n",
    "    )\n",
    "    custom_query_engines[index.index_id] = query_engine\n",
    "\n",
    "custom_query_engines[graph.root_id] = graph.root_index.as_query_engine(\n",
    "    retriever_mode='simple',\n",
    "    response_mode='tree_summarize',\n",
    ")\n",
    "\n",
    "# with query decomposition in subindices\n",
    "query_engine = graph.as_query_engine(custom_query_engines=custom_query_engines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Houston?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Houston?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Toronto?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Toronto?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Seattle?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Seattle?\n",
      "\u001b[0mFinal Response: Seattle, Houston, and Toronto are all large cities\n",
      "with diverse populations. Houston has the largest population of the\n",
      "three cities, with 2,304,580 people in 2020. Toronto has the second\n",
      "largest population, with 2,794,356 people in 2021. Seattle has the\n",
      "smallest population of the three cities, with approximately 704,352\n",
      "people according to the 2012–2016 American Community Survey (ACS). All\n",
      "three cities have a mix of different ethnicities, religions, and\n",
      "cultures. Houston is known for its large Hispanic population, while\n",
      "Toronto is known for its large immigrant population. Seattle is known\n",
      "for its large Asian population. All three cities have a mix of\n",
      "different economic backgrounds, with some areas being more affluent\n",
      "than others.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Compare and contrast the demographics in Seattle, Houston, and Toronto.\")\n",
    "\n",
    "from llama_index.response.pprint_utils import pprint_response\n",
    "\n",
    "pprint_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In language_match, input text1 will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In language_match, input text2 will be set to *.__record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on_input_output()\n",
    "# By default this will check language match on the main app input and main app\n",
    "# output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ app LlamaIndex_with_Pinecone_App1 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_81275c68ccfb6a7f48908e7d3841f7e0 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "tru_query_engine = TruLlama(query_engine,\n",
    "    app_id='LlamaIndex_with_Pinecone_App1',\n",
    "    feedbacks=[f_lang_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Houston?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Houston?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Toronto?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Toronto?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Seattle?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m> Current query: Compare and contrast the demographics in Seattle, Houston, and Toronto.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  What is the population of Seattle?\n",
      "\u001b[0m\n",
      "Seattle, Houston, and Toronto are all large cities with diverse populations. Houston has the largest population of the three cities, with 2,304,580 people in 2020. Toronto has the second largest population, with 2,794,356 people in 2021. Seattle has the smallest population of the three cities, with approximately 704,352 people according to the 2012–2016 American Community Survey (ACS). All three cities have a mix of different ethnicities, religions, and cultures. Houston is known for its large Hispanic population, while Toronto is known for its large immigrant population. Seattle is known for its large Asian population. All three cities have a mix of different economic backgrounds, with some areas being more affluent than others.\n",
      "✅ record record_hash_65004add3c3c8542df285687e3589f2d from LlamaIndex_with_Pinecone_App1 -> default.sqlite"
     ]
    }
   ],
   "source": [
    "# Instrumented query engine can operate like the original:\n",
    "llm_response = tru_query_engine.query(\"Compare and contrast the demographics in Seattle, Houston, and Toronto.\")\n",
    "\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c5e864815f4181b01be0adb9eb960a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 44.49275207519531} (44.49275207519531) second(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.23:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('trulens')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "c633204c92f433e69d41413efde9db4a539ce972d10326abcceb024ad118839e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
