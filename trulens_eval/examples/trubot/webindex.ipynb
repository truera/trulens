{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape websites to create document retrieval stores.\n",
    "\n",
    "## Additional requirements:\n",
    "\n",
    "```bash\n",
    "pip install humanize pdfreader url_normalize tabulate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install humanize pdfreader url_normalize tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))\n",
    "\n",
    "from trulens_eval.keys import *\n",
    "\n",
    "\"ignore me\"\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "from multiprocessing import Event\n",
    "from pathlib import Path\n",
    "from queue import Queue\n",
    "import sqlite3\n",
    "import tempfile\n",
    "from threading import Thread\n",
    "from time import sleep\n",
    "from typing import Callable, Iterable\n",
    "from urllib.parse import urljoin\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import humanize\n",
    "from langchain.document_loaders import PagedPDFSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, NLTKTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "import numpy as np\n",
    "import pdfreader\n",
    "import pinecone\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from url_normalize import url_normalize\n",
    "\n",
    "from trulens_eval.util import first\n",
    "from trulens_eval.util import UNICODE_CHECK\n",
    "\n",
    "TRUERA_BASE_URL = 'https://truera.com/'\n",
    "TRUERA_DOC_URL = 'https://docs.truera.com/1.34/public/'\n",
    "TRUERA_SUPPORT_URL = \"https://support.truera.com/hc/en-us/\"\n",
    "TRUERA_BLOG_URL = \"https://truera.com/ai-quality-blog/\"\n",
    "TRULENS_URL = \"https://trulens.org/\"\n",
    "TRUERA_URLS = [TRUERA_BASE_URL, TRUERA_DOC_URL, TRUERA_SUPPORT_URL, TRUERA_BLOG_URL, TRULENS_URL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScrape():\n",
    "    TABLE_PAGES = \"page\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename: Path = Path(\"scrape.sqlite\"),\n",
    "        n_threads: int = 8,\n",
    "        filters: Callable[[str], bool] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Web document downloader. Walks over links, collecting documents.\n",
    "\n",
    "        NOTE: This is not a serious scraper for large crawls.\n",
    "        \"\"\"\n",
    "\n",
    "        self.filename = filename\n",
    "        self.n_threads = n_threads\n",
    "        self._create_tables()\n",
    "\n",
    "        if isinstance(filters, str):\n",
    "            filter_func = lambda url: filters in url\n",
    "        elif isinstance(filters, Iterable):\n",
    "            filter_func = lambda url: any(map(lambda f: f in url, filters))\n",
    "        elif isinstance(filter, Callable):\n",
    "            filter_func = filters\n",
    "        else:\n",
    "            raise TypeError(f\"Unhandled filters type {type(filters)}\")\n",
    "\n",
    "        self.filter_func = filter_func\n",
    "\n",
    "    @staticmethod\n",
    "    def custom_normalize(url, base_url=None):\n",
    "        if url.startswith(\"tel:\"):\n",
    "            return url\n",
    "\n",
    "        if base_url is not None:\n",
    "            base_url = url_normalize(\n",
    "                urlparse(base_url)._replace(fragment=None, query=None).geturl()\n",
    "            )\n",
    "            if not base_url.endswith(\"/\"):\n",
    "                base_url += \"/\"\n",
    "            url = urljoin(base_url, url)\n",
    "        else:\n",
    "            url = urlparse(url)._replace(fragment=None, query=None).geturl()\n",
    "\n",
    "        url = url_normalize(url)\n",
    "\n",
    "        return url\n",
    "\n",
    "    def cursor(self):\n",
    "        connection = sqlite3.connect(self.filename)\n",
    "        cursor = connection.cursor()\n",
    "        return cursor, connection\n",
    "\n",
    "    def _create_tables(self):\n",
    "        c, conn = self.cursor()\n",
    "        c.execute(\n",
    "            f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {WebScrape.TABLE_PAGES} (\n",
    "                url VARCHAR(128),\n",
    "                type VARCHAR(64),\n",
    "                retrieved INTEGER,\n",
    "                content BYTES,\n",
    "                PRIMARY KEY (url)\n",
    "            )\n",
    "        \"\"\"\n",
    "        )\n",
    "        conn.commit()\n",
    "        c.close()\n",
    "\n",
    "    def get_urls(self) -> Iterable[sqlite3.Row]:\n",
    "        c, conn = self.cursor()\n",
    "\n",
    "        c.execute(\n",
    "            f\"\"\"\n",
    "            SELECT url\n",
    "            FROM {WebScrape.TABLE_PAGES}\n",
    "            \"\"\"\n",
    "        )\n",
    "        rows = c.fetchall()\n",
    "\n",
    "        c.close()\n",
    "\n",
    "        return map(first, rows)\n",
    "\n",
    "    def get_page(self, url: str) -> sqlite3.Row:\n",
    "        c, conn = self.cursor()\n",
    "\n",
    "        c.execute(\n",
    "            f\"\"\"\n",
    "            SELECT * \n",
    "            FROM {WebScrape.TABLE_PAGES} \n",
    "            WHERE url=?\"\"\", (url,)\n",
    "        )\n",
    "        row = c.fetchone()\n",
    "\n",
    "        c.close()\n",
    "        return row\n",
    "\n",
    "    def request(self, url: str):\n",
    "        return requests.get(url, stream=True)\n",
    "\n",
    "    def delete_page(self, url: str):\n",
    "        c, conn = self.cursor()\n",
    "\n",
    "        c.execute(\n",
    "            f\"\"\"\n",
    "            DELETE FROM {WebScrape.TABLE_PAGES}\n",
    "            WHERE url=?\n",
    "            \"\"\", (url,)\n",
    "        )\n",
    "        conn.commit()\n",
    "        c.close()\n",
    "\n",
    "        print(f\"page {url} deleted\")\n",
    "\n",
    "    def insert_page(self, url: str, type: str, content: bytes):\n",
    "        retrieved = datetime.datetime.now().timestamp()\n",
    "\n",
    "        c, conn = self.cursor()\n",
    "\n",
    "        size = len(content)\n",
    "\n",
    "        c.execute(\n",
    "            f\"\"\"\n",
    "            INSERT OR REPLACE \n",
    "            INTO {WebScrape.TABLE_PAGES} \n",
    "            VALUES (?, ?, ?, ?)\"\"\", (url, type, retrieved, content)\n",
    "        )\n",
    "        conn.commit()\n",
    "        c.close()\n",
    "\n",
    "        print(\n",
    "            f\"{UNICODE_CHECK} page {type} {humanize.naturalsize(size)} {url} -> {self.filename}\"\n",
    "        )\n",
    "\n",
    "    def scrape(self, url: str, redownload: bool = False):\n",
    "        q = Queue(maxsize=1024 * 1024)\n",
    "        q.put((url, None))\n",
    "\n",
    "        stopped = Event()\n",
    "        stopped.clear()\n",
    "\n",
    "        scraped = set()\n",
    "        threads = []\n",
    "\n",
    "        for _ in range(self.n_threads):\n",
    "            thread = Thread(\n",
    "                target=self._scrape,\n",
    "                kwargs=dict(\n",
    "                    queue=q,\n",
    "                    redownload=redownload,\n",
    "                    scraped=scraped,\n",
    "                    stopped=stopped\n",
    "                )\n",
    "            )\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        sleep(1)\n",
    "\n",
    "        while not q.empty():\n",
    "            print(\"queue size:\", q.qsize())\n",
    "            sleep(1)\n",
    "\n",
    "        print(\"queue empty\")\n",
    "        stopped.set()\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "    def _scrape(\n",
    "        self, queue: Queue, stopped: Event, redownload: bool, scraped: set\n",
    "    ):\n",
    "        while not stopped.is_set():\n",
    "            if not queue.empty():\n",
    "                (url, from_url) = queue.get()\n",
    "            else:\n",
    "                sleep(1)\n",
    "                continue\n",
    "\n",
    "            url = WebScrape.custom_normalize(url)\n",
    "\n",
    "            if url in scraped:\n",
    "                continue\n",
    "\n",
    "            scraped.add(url)\n",
    "\n",
    "            page = self.get_page(url)\n",
    "            if page is not None:\n",
    "                ctype = page[1]\n",
    "                content = page[3]\n",
    "\n",
    "            if page is None or redownload:\n",
    "                try:\n",
    "                    res = self.request(url)\n",
    "                except Exception as e:\n",
    "                    print(f\"WARNING: {url} from {from_url}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                if not res.ok:\n",
    "                    print(f\"WARNING: {url} from {from_url}: {res.status_code}\")\n",
    "                    continue\n",
    "\n",
    "                if \"content-type\" not in res.headers:\n",
    "                    print(\n",
    "                        f\"WARNING: {url} from {from_url} lacks needed headers:\\n{list(res.headers.keys())}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                ctype = res.headers['content-type']\n",
    "\n",
    "                if \"content-length\" in res.headers:\n",
    "                    size = int(res.headers['content-length'])\n",
    "                    if size > 100 * (1024**2):\n",
    "                        print(\n",
    "                            f\"WARNING: {url} from {from_url} is large {humanize.naturalsize(size)}\"\n",
    "                        )\n",
    "                        continue  # skipping\n",
    "\n",
    "                if ctype.startswith(\"image/\"):\n",
    "                    continue  # skipping\n",
    "\n",
    "                content = res.content\n",
    "                self.insert_page(url=url, type=ctype, content=res.content)\n",
    "\n",
    "            size = len(content)\n",
    "            if size > 100 * (1024**2):\n",
    "                print(\n",
    "                    f\"WARNING: {url} from {from_url}: is large: {humanize.naturalsize(size)}\"\n",
    "                )\n",
    "                pass\n",
    "\n",
    "            if ctype.startswith(\"text/html\"):\n",
    "                soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "                anchors = soup.findAll(\"a\")\n",
    "                sub_urls = [a.get(\"href\") for a in anchors]\n",
    "\n",
    "            elif ctype.startswith(\"application/pdf\"):\n",
    "\n",
    "                with io.BytesIO() as fh:\n",
    "                    fh.write(content)\n",
    "                    fh.seek(0)\n",
    "\n",
    "                    pdf = pdfreader.SimplePDFViewer(fh)\n",
    "\n",
    "                    sub_urls = []\n",
    "\n",
    "                    if pdf.annotations is not None:\n",
    "                        for annot in pdf.annotations:\n",
    "                            if annot.Subtype == \"Link\":\n",
    "                                sub_url = annot.A.URI\n",
    "                                if sub_url is not None:\n",
    "                                    sub_url = sub_url.decode('ascii')\n",
    "                                    if sub_url.startswith(\"http\"):\n",
    "                                        sub_urls.append(sub_url)\n",
    "\n",
    "            else:\n",
    "                print(\n",
    "                    f\"WARNING: {url} from {from_url}: unknown content type {ctype}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            for sub_url in sub_urls:\n",
    "                if sub_url in scraped:\n",
    "                    continue\n",
    "\n",
    "                if sub_url is None:\n",
    "                    continue\n",
    "\n",
    "                if sub_url.startswith(\"tel:\"):\n",
    "                    # print(f\"skip: {sub_url} from {url}: is tel\")\n",
    "                    scraped.add(sub_url)\n",
    "                    continue\n",
    "\n",
    "                sub_url = WebScrape.custom_normalize(sub_url, base_url=url)\n",
    "\n",
    "                if sub_url in scraped:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    parts = urlparse(sub_url)\n",
    "                    if parts.scheme is None:\n",
    "                        print(f\"WARNING: {sub_url} from {url}: no scheme\")\n",
    "                        scraped.add(sub_url)\n",
    "                        continue\n",
    "\n",
    "                    if parts.scheme not in [\"http\", \"https\"]:\n",
    "                        # print(f\"skip: {sub_url} from {url}: skip scheme {parts.scheme}\")\n",
    "                        scraped.add(sub_url)\n",
    "                        continue\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"WARNING: {sub_url} from {url}: {e}\")\n",
    "                    scraped.add(sub_url)\n",
    "                    continue\n",
    "\n",
    "                if self.filter_func(sub_url):\n",
    "                    # print(\"adding\", sub_url)\n",
    "                    queue.put((sub_url, url))\n",
    "                else:\n",
    "                    scraped.add(sub_url)\n",
    "                    pass\n",
    "\n",
    "    def get_documents(self):\n",
    "        docs = []\n",
    "\n",
    "        seen_texts = dict()\n",
    "\n",
    "        for url in tqdm(list(self.get_urls())):\n",
    "            canon_url = WebScrape.custom_normalize(url)\n",
    "            if url != canon_url:\n",
    "                s.delete_page(url=url)\n",
    "                continue\n",
    "\n",
    "            if url in {\n",
    "                    'https://truera.com/resources/',\n",
    "                    'https://truera.com/ai-quality-blog/',\n",
    "                    'https://truera.com/event/live-events/',\n",
    "                    'https://truera.com/ai-quality-research/ai-quality-education/',\n",
    "                    'https://medium.com/trulens/archive'\n",
    "            }:\n",
    "                print(\"skipping\", url)\n",
    "                continue\n",
    "            elif \"/page/\" in url:\n",
    "                print(\"skipping\", url)\n",
    "                continue\n",
    "            elif \"/category/\" in url:\n",
    "                print(\"skipping\", url)\n",
    "                continue\n",
    "            elif \"Datasheet\" in url and url.endswith(\".pdf\"):\n",
    "                print(\"skipping\", url)\n",
    "                continue\n",
    "            elif url.startswith(\"https://pypi.org/project/\"):\n",
    "                print(\"skipping\", url)\n",
    "                continue\n",
    "            elif \"trulens\" in url: # temporarily skipping anything with trulens\n",
    "                print(\"skipping\", url)\n",
    "                continue\n",
    "\n",
    "            row = s.get_page(url=url)\n",
    "            type = row[1]\n",
    "\n",
    "            if type.startswith(\"text/html\"):\n",
    "                loader = UnstructuredHTMLLoader\n",
    "            elif type.startswith(\"application/pdf\"):\n",
    "                loader = PagedPDFSplitter\n",
    "                # UnstructuredPDFLoader\n",
    "            elif type.startswith(\"image\"):\n",
    "                # s.delete_page(url=url)\n",
    "                continue\n",
    "            else:\n",
    "                # markdown: UnstructuredMarkdownLoader\n",
    "                # jupyter?\n",
    "                # github?\n",
    "                # print(url, type)\n",
    "                continue\n",
    "\n",
    "            content = row[3]\n",
    "            size = len(content)\n",
    "            if content is None:\n",
    "                raise ValueError(url)\n",
    "            if size == 0:\n",
    "                raise ValueError(f\"empty: {url}\")\n",
    "            if size >= 100 * (1024**2):\n",
    "                print(\n",
    "                    f\"WARNING: big content {url} {humanize.naturalsize(size)}\"\n",
    "                )\n",
    "\n",
    "            file = tempfile.NamedTemporaryFile(mode='bw')\n",
    "            file.write(row[3])\n",
    "            file.flush()\n",
    "\n",
    "            try:\n",
    "                new_docs = loader(file.name).load()\n",
    "                for new_doc in new_docs:\n",
    "                    new_doc.metadata['source'] = url\n",
    "\n",
    "                cont = new_doc.page_content\n",
    "\n",
    "                if cont in seen_texts:\n",
    "                    #print(\n",
    "                    #    f\"WARNING: {url} Already seen text in {seen_texts[cont]}. Skipping.\"\n",
    "                    #)\n",
    "                    continue\n",
    "                seen_texts[cont] = url\n",
    "\n",
    "                docs.append(new_doc)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"WARNING: {url} {type} {e}\")\n",
    "\n",
    "            file.close()\n",
    "\n",
    "        return docs\n",
    "\n",
    "\n",
    "s = WebScrape(\n",
    "    filters=lambda url: \n",
    "        (\"truera\" in url or \"trulens\" in url) \\\n",
    "        and \"github.com\" not in url \\\n",
    "        and \"support.truera.com\" not in url \\\n",
    "        and \"cbinsights.com\" not in url \\\n",
    "        and \"files.pythonhosted.org\" not in url \\\n",
    "        and \"libraries.io\" not in url\n",
    ")\n",
    "s.scrape(TRUERA_BASE_URL)\n",
    "s.scrape(TRUERA_DOC_URL)\n",
    "s.scrape(TRUERA_BLOG_URL)\n",
    "s.scrape(TRULENS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04964b4bbbf748df83e2e5e634a5f784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping http://trulens.org/\n",
      "skipping http://trulens.org/how-to-use.html\n",
      "skipping http://trulens.org/nn-explainability.html\n",
      "skipping http://trulens.org/trulens_eval/api/tru/\n",
      "skipping http://trulens.org/trulens_eval/api/tru_feedback/\n",
      "skipping http://trulens.org/trulens_eval/api/truchain/\n",
      "skipping http://trulens.org/trulens_eval/feedback_functions/\n",
      "skipping http://trulens.org/trulens_eval/install/\n",
      "skipping http://trulens.org/trulens_eval/logging/\n",
      "skipping http://trulens.org/trulens_eval/quickstart/\n",
      "skipping http://trulens.org/trulens_explain/api/attribution/\n",
      "skipping http://trulens.org/trulens_explain/api/distributions/\n",
      "skipping http://trulens.org/trulens_explain/api/model_wrappers/\n",
      "skipping http://trulens.org/trulens_explain/api/quantities/\n",
      "skipping http://trulens.org/trulens_explain/api/slices/\n",
      "skipping http://trulens.org/trulens_explain/api/visualizations/\n",
      "skipping http://trulens.org/trulens_explain/attribution_parameterization/\n",
      "skipping http://trulens.org/trulens_explain/install/\n",
      "skipping http://trulens.org/trulens_explain/quickstart/\n",
      "skipping http://trulens.org/welcome/\n",
      "skipping http://www.trulens.org/\n",
      "skipping http://www.trulens.org/how-to-use.html\n",
      "skipping http://www.trulens.org/nn-explainability.html\n",
      "skipping http://www.trulens.org/trulens_eval/api/tru/\n",
      "skipping http://www.trulens.org/trulens_eval/api/tru_feedback/\n",
      "skipping http://www.trulens.org/trulens_eval/api/truchain/\n",
      "skipping http://www.trulens.org/trulens_eval/feedback_functions/\n",
      "skipping http://www.trulens.org/trulens_eval/install/\n",
      "skipping http://www.trulens.org/trulens_eval/logging/\n",
      "skipping http://www.trulens.org/trulens_eval/quickstart/\n",
      "skipping http://www.trulens.org/trulens_explain/api/attribution/\n",
      "skipping http://www.trulens.org/trulens_explain/api/distributions/\n",
      "skipping http://www.trulens.org/trulens_explain/api/model_wrappers/\n",
      "skipping http://www.trulens.org/trulens_explain/api/quantities/\n",
      "skipping http://www.trulens.org/trulens_explain/api/slices/\n",
      "skipping http://www.trulens.org/trulens_explain/api/visualizations/\n",
      "skipping http://www.trulens.org/trulens_explain/attribution_parameterization/\n",
      "skipping http://www.trulens.org/trulens_explain/install/\n",
      "skipping http://www.trulens.org/trulens_explain/quickstart/\n",
      "skipping http://www.trulens.org/welcome/\n",
      "skipping https://blog.trulens.org/\n",
      "skipping https://join.slack.com/t/trulens/shared_invite/zt-kbaz6odu-kBWfqewcHMFLm_GNN8eqDA\n",
      "skipping https://join.slack.com/t/trulens/shared_invite/zt-kbaz6odu-kBWfqewcHMFLm_GNN8eqDA/\n",
      "skipping https://join.slack.com/t/trulens/shared_invite/zt-ur53m9ia-SgNAtWobrJ5Hn7GcmibaLg\n",
      "skipping https://join.slack.com/t/trulens/shared_invite/zt-ur53m9ia-SgNAtWobrJ5Hn7GcmibaLg/\n",
      "skipping https://medium.com/trulens\n",
      "skipping https://medium.com/trulens/a-hands-on-introduction-to-explaining-neural-networks-with-trulens-504bfab1a578\n",
      "skipping https://medium.com/trulens/a-hands-on-introduction-to-explaining-neural-networks-with-trulens-c807de0fe6b7\n",
      "skipping https://medium.com/trulens/about\n",
      "skipping https://medium.com/trulens/archive\n",
      "skipping https://medium.com/trulens/deep-dive-into-neural-network-explanations-with-integrated-gradients-af7257431741\n",
      "skipping https://medium.com/trulens/evaluate-and-track-your-llm-experiments-introducing-trulens-86028fe9b59a\n",
      "skipping https://medium.com/trulens/latest\n",
      "skipping https://medium.com/trulens/machine-learning-explainability-and-robustness-connected-at-the-hip-be420f796369\n",
      "skipping https://medium.com/trulens/overfitting-and-conceptual-soundness-in-neural-network-models-a704746c5cd7\n",
      "skipping https://medium.com/trulens/peer-deep-into-neural-networks-with-trulens-a813f22792f7\n",
      "skipping https://medium.com/trulens/tagged/artificial-intelligence\n",
      "skipping https://medium.com/trulens/tagged/deep-learning\n",
      "skipping https://medium.com/trulens/tagged/explainable-ai\n",
      "skipping https://medium.com/trulens/tagged/interpretable-ml\n",
      "skipping https://medium.com/trulens/tagged/machine-learning\n",
      "skipping https://medium.com/trulens/tagged/neural-networks\n",
      "skipping https://medium.com/trulens/trending\n",
      "skipping https://medium.com/trulens/trulens-is-coming-59246d82854d\n",
      "skipping https://pypi.org/project/truera/\n",
      "skipping https://pypi.org/project/truera/10.0.0/\n",
      "skipping https://pypi.org/project/truera/11.3.1/\n",
      "skipping https://pypi.org/project/truera/11.3.2/\n",
      "skipping https://pypi.org/project/truera/11.3.3/\n",
      "skipping https://pypi.org/project/truera/11.3.4/\n",
      "skipping https://pypi.org/project/truera/11.4.1/\n",
      "skipping https://pypi.org/project/truera/11.4.2/\n",
      "skipping https://pypi.org/project/truera/11.5.2/\n",
      "skipping https://pypi.org/project/truera/11.5.4/\n",
      "skipping https://pypi.org/project/truera/11.5.5/\n",
      "skipping https://pypi.org/project/truera/11.5.6/\n",
      "skipping https://pypi.org/project/truera/11.6.1/\n",
      "skipping https://pypi.org/project/truera/11.6.2/\n",
      "skipping https://pypi.org/project/truera/11.6.3/\n",
      "skipping https://pypi.org/project/truera/9.5.0/\n",
      "skipping https://pypi.org/project/truera/9.5.1/\n",
      "skipping https://pypi.org/project/truera/9.5.2/\n",
      "skipping https://pypi.org/project/truera/9.5.3/\n",
      "skipping https://pypi.org/project/truera/9.5.4/\n",
      "skipping https://pypi.org/project/truera/9.5.5/\n",
      "skipping https://pypi.org/project/truera/9.8.1/\n",
      "skipping https://pypi.org/project/truera/9.8.2/\n",
      "skipping https://pypi.org/project/truera/9.9.0/\n",
      "skipping https://pypi.org/project/trulens-eval/\n",
      "skipping https://pypi.org/project/trulens-eval/0.0.1/\n",
      "skipping https://pypi.org/project/trulens-eval/0.0.1a0/\n",
      "skipping https://pypi.org/project/trulens-eval/0.1.1/\n",
      "skipping https://pypi.org/project/trulens-eval/0.1.1a0/\n",
      "skipping https://pypi.org/project/trulens-eval/0.1.2/\n",
      "skipping https://pypi.org/project/trulens-eval/0.1.2a0/\n",
      "skipping https://pypi.org/project/trulens-eval/0.2.0/\n",
      "skipping https://pypi.org/project/trulens-eval/0.2.0a0/\n",
      "skipping https://pypi.org/project/trulens-eval/0.2.1/\n",
      "skipping https://pypi.org/project/trulens-eval/0.2.1a0/\n",
      "skipping https://pypi.org/project/trulens-eval/0.2.2/\n",
      "skipping https://pypi.org/project/trulens-eval/0.2.2a0/\n",
      "skipping https://pypi.org/project/trulens-eval/0.2.2b0/\n",
      "skipping https://pypi.org/project/trulens/\n",
      "skipping https://pypi.org/project/trulens/0.0.1/\n",
      "skipping https://pypi.org/project/trulens/0.0.10/\n",
      "skipping https://pypi.org/project/trulens/0.0.11/\n",
      "skipping https://pypi.org/project/trulens/0.0.12.1/\n",
      "skipping https://pypi.org/project/trulens/0.0.12/\n",
      "skipping https://pypi.org/project/trulens/0.0.2/\n",
      "skipping https://pypi.org/project/trulens/0.0.3/\n",
      "skipping https://pypi.org/project/trulens/0.0.4/\n",
      "skipping https://pypi.org/project/trulens/0.0.5/\n",
      "skipping https://pypi.org/project/trulens/0.0.6/\n",
      "skipping https://pypi.org/project/trulens/0.0.7/\n",
      "skipping https://pypi.org/project/trulens/0.0.8/\n",
      "skipping https://pypi.org/project/trulens/0.0.9/\n",
      "skipping https://pypi.org/project/trulens/0.12.1/\n",
      "skipping https://pypi.org/project/trulens/0.13.0/\n",
      "skipping https://pypi.org/project/trulens/0.13.1/\n",
      "skipping https://pypi.org/project/trulens/0.13.2/\n",
      "skipping https://pypi.org/project/trulens/0.13.3/\n",
      "skipping https://pypi.org/rss/project/trulens-eval/releases.xml\n",
      "skipping https://pypi.org/rss/project/trulens/releases.xml\n",
      "skipping https://truera.com/ai-quality-blog/\n",
      "skipping https://truera.com/ai-quality-blog/page/2/\n",
      "skipping https://truera.com/ai-quality-blog/page/3/\n",
      "skipping https://truera.com/ai-quality-blog/page/4/\n",
      "skipping https://truera.com/ai-quality-blog/page/5/\n",
      "skipping https://truera.com/ai-quality-blog/page/6/\n",
      "skipping https://truera.com/ai-quality-blog/page/7/\n",
      "skipping https://truera.com/ai-quality-blog/page/8/\n",
      "skipping https://truera.com/ai-quality-education/llms/evaluate-and-track-your-llm-experiments-with-trulens/\n",
      "skipping https://truera.com/ai-quality-research/ai-quality-education/\n",
      "skipping https://truera.com/category/ai-infrastructure/\n",
      "skipping https://truera.com/category/ai-quality/\n",
      "skipping https://truera.com/category/ai-regulation/\n",
      "skipping https://truera.com/category/business/\n",
      "skipping https://truera.com/category/business/banking/\n",
      "skipping https://truera.com/category/business/insurance/\n",
      "skipping https://truera.com/category/business/page/2/\n",
      "skipping https://truera.com/category/company-news/\n",
      "skipping https://truera.com/category/data-science/\n",
      "skipping https://truera.com/category/data-science/page/2/\n",
      "skipping https://truera.com/category/data-science/page/3/\n",
      "skipping https://truera.com/category/data-science/page/4/\n",
      "skipping https://truera.com/category/data-science/page/5/\n",
      "skipping https://truera.com/category/large-language-models/\n",
      "skipping https://truera.com/category/llms/\n",
      "skipping https://truera.com/category/ml-monitoring/\n",
      "skipping https://truera.com/category/ml-test-harness/\n",
      "skipping https://truera.com/category/mlops/\n",
      "skipping https://truera.com/category/partnerships/\n",
      "skipping https://truera.com/category/people/\n",
      "skipping https://truera.com/evaluate-and-track-your-llm-experiments-with-trulens\n",
      "skipping https://truera.com/evaluate-and-track-your-llm-experiments-with-trulens/\n",
      "skipping https://truera.com/event/live-events/\n",
      "skipping https://truera.com/event/live-events/page/2/\n",
      "skipping https://truera.com/event/webinars/page/2/\n",
      "skipping https://truera.com/events/page/2/\n",
      "skipping https://truera.com/events/page/3/\n",
      "skipping https://truera.com/events/page/4/\n",
      "skipping https://truera.com/resource/in-the-news/page/2/\n",
      "skipping https://truera.com/resource/in-the-news/page/3/\n",
      "skipping https://truera.com/resource/in-the-news/page/4/\n",
      "skipping https://truera.com/resource/in-the-news/page/5/\n",
      "skipping https://truera.com/resource/in-the-news/page/6/\n",
      "skipping https://truera.com/resource/in-the-news/page/7/\n",
      "skipping https://truera.com/resources/\n",
      "skipping https://truera.com/resources/page/10/\n",
      "skipping https://truera.com/resources/page/2/\n",
      "skipping https://truera.com/resources/page/3/\n",
      "skipping https://truera.com/resources/page/4/\n",
      "skipping https://truera.com/resources/page/5/\n",
      "skipping https://truera.com/resources/page/6/\n",
      "skipping https://truera.com/resources/page/7/\n",
      "skipping https://truera.com/resources/page/8/\n",
      "skipping https://truera.com/resources/page/9/\n",
      "skipping https://truera.com/resources/trulens-explainability-for-neural-networks/\n",
      "skipping https://truera.com/resources/trulens-for-llm-applications-launches-evaluate-and-track-large-language-model-application-experiments/\n",
      "skipping https://truera.com/wp-content/uploads/2021/05/TruEra-Banking-Datasheet-19-May-2021-121909.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2021/05/TruEra-Monitoring-Datasheet-19-May-2021-172808.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2021/09/TruEra-Government-Datasheet.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2022/03/AI-Regulation-in-Finance_TruEra-Datasheet.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2022/05/TruEra-for-Manufacturing-Datasheet.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2022/10/TruEra-Datasheet-Diagnostics-2-0.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2022/10/TruEra-HR-Datasheet-20221012.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2022/12/TruEra-Company-Product-Datasheet-2022.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2023/01/TruEra-MRM-Datasheet.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2023/04/TruEra-Monitoring-Datasheet-2023.pdf\n",
      "skipping https://truera.com/wp-content/uploads/2023/04/TruEra-Retail-and-Brands-Datasheet.pdf\n",
      "skipping https://truera.github.io/trulens/\n",
      "skipping https://truera.github.io/trulens/how-to-use.html\n",
      "skipping https://truera.github.io/trulens/nn-explainability.html\n",
      "skipping https://truera.github.io/trulens/trulens_eval/api/tru/\n",
      "skipping https://truera.github.io/trulens/trulens_eval/api/tru_feedback/\n",
      "skipping https://truera.github.io/trulens/trulens_eval/api/truchain/\n",
      "skipping https://truera.github.io/trulens/trulens_eval/feedback_functions/\n",
      "skipping https://truera.github.io/trulens/trulens_eval/install/\n",
      "skipping https://truera.github.io/trulens/trulens_eval/logging/\n",
      "skipping https://truera.github.io/trulens/trulens_eval/quickstart/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/api/attribution/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/api/distributions/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/api/model_wrappers/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/api/quantities/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/api/slices/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/api/visualizations/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/attribution_parameterization/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/install/\n",
      "skipping https://truera.github.io/trulens/trulens_explain/quickstart/\n",
      "skipping https://truera.github.io/trulens/welcome/\n",
      "skipping https://trulens.org/\n",
      "skipping https://trulens.org/how-to-use.html\n",
      "skipping https://trulens.org/nn-explainability.html\n",
      "skipping https://trulens.org/trulens_eval/api/tru/\n",
      "skipping https://trulens.org/trulens_eval/api/tru_feedback/\n",
      "skipping https://trulens.org/trulens_eval/api/truchain/\n",
      "skipping https://trulens.org/trulens_eval/feedback_functions/\n",
      "skipping https://trulens.org/trulens_eval/install/\n",
      "skipping https://trulens.org/trulens_eval/logging/\n",
      "skipping https://trulens.org/trulens_eval/quickstart/\n",
      "skipping https://trulens.org/trulens_explain/api/attribution/\n",
      "skipping https://trulens.org/trulens_explain/api/distributions/\n",
      "skipping https://trulens.org/trulens_explain/api/model_wrappers/\n",
      "skipping https://trulens.org/trulens_explain/api/quantities/\n",
      "skipping https://trulens.org/trulens_explain/api/slices/\n",
      "skipping https://trulens.org/trulens_explain/api/visualizations/\n",
      "skipping https://trulens.org/trulens_explain/attribution_parameterization/\n",
      "skipping https://trulens.org/trulens_explain/install/\n",
      "skipping https://trulens.org/trulens_explain/quickstart/\n",
      "skipping https://trulens.org/welcome/\n",
      "skipping https://twitter.com/trulensML\n",
      "skipping https://www.trulens.org/\n",
      "skipping https://www.trulens.org/how-to-use.html\n",
      "skipping https://www.trulens.org/nn-explainability.html\n",
      "skipping https://www.trulens.org/trulens_eval/api/tru/\n",
      "skipping https://www.trulens.org/trulens_eval/api/tru_feedback/\n",
      "skipping https://www.trulens.org/trulens_eval/api/truchain/\n",
      "skipping https://www.trulens.org/trulens_eval/feedback_functions/\n",
      "skipping https://www.trulens.org/trulens_eval/install/\n",
      "skipping https://www.trulens.org/trulens_eval/logging/\n",
      "skipping https://www.trulens.org/trulens_eval/quickstart/\n",
      "skipping https://www.trulens.org/trulens_explain/api/attribution/\n",
      "skipping https://www.trulens.org/trulens_explain/api/distributions/\n",
      "skipping https://www.trulens.org/trulens_explain/api/model_wrappers/\n",
      "skipping https://www.trulens.org/trulens_explain/api/quantities/\n",
      "skipping https://www.trulens.org/trulens_explain/api/slices/\n",
      "skipping https://www.trulens.org/trulens_explain/api/visualizations/\n",
      "skipping https://www.trulens.org/trulens_explain/attribution_parameterization/\n",
      "skipping https://www.trulens.org/trulens_explain/install/\n",
      "skipping https://www.trulens.org/trulens_explain/quickstart/\n",
      "skipping https://www.trulens.org/welcome/\n"
     ]
    }
   ],
   "source": [
    "docs = s.get_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.text_splitter:Created a chunk of size 535, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 557, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 527, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 590, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 553, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 717, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 554, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 525, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 688, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 536, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 756, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 532, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 553, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 587, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 6258, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 717, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 942, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 532, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 700, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 643, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 615, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 545, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 613, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 530, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 552, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 584, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 553, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 667, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 586, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 805, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 716, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 716, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1156, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1771, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1302, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 675, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1021, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 558, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 564, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 739, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 528, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 554, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 642, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 532, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1016, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 594, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 649, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 704, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1106, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 696, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 699, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 518, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 797, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 966, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 852, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1118, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 960, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 887, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 740, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 872, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1308, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1115, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 952, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 727, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 872, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 549, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 538, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 533, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 526, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 619, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 587, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 674, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 617, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 769, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 542, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1191, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1102, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 687, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 693, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 763, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 541, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 808, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 569, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 740, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 752, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1424, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 746, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 624, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 532, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 539, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 931, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 823, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 591, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1101, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 833, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 535, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 752, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 563, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 528, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 515, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 819, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 742, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 561, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 527, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 759, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 549, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 541, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 601, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 728, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 524, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 614, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 726, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 521, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 543, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 818, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 817, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 524, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 580, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 517, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 962, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 849, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 526, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 793, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 765, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 514, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 665, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 781, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 553, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 555, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 566, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 560, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 803, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 557, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 920, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 596, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 590, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1249, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 601, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 645, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 516, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 630, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 917, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 676, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 626, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 888, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 524, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 933, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 642, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 514, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 637, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 675, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 809, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 699, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 643, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 812, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 769, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 617, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 776, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 898, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 533, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 523, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 546, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 758, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 530, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 731, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 682, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 765, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 623, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 524, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 916, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 517, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 627, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 569, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 562, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 563, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 562, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 590, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 951, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 703, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 528, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 541, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1123, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 765, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 561, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 721, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 547, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 932, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 930, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 750, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 555, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 857, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 790, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 964, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 612, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 793, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 693, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 702, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 551, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 866, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1025, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 616, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 623, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 581, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 595, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 866, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 708, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 575, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 558, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 731, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 718, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 849, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 551, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 567, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1070, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 606, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 552, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 644, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 589, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 545, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 563, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 527, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 645, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 757, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 582, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1042, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 918, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 539, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 927, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 662, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 711, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 550, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 521, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 692, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 653, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 858, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 656, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 537, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 544, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 744, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 865, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 617, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 746, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 525, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 540, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 886, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 540, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 826, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 744, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 874, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 713, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 525, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 688, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 791, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 538, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 646, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 518, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 746, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 777, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 549, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 780, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 515, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 891, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 682, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 672, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 2267, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 523, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 726, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 830, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 597, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 527, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 615, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 577, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 535, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 639, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 742, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 514, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1012, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 615, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 624, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 562, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 715, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1023, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 548, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 610, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 672, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 681, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 555, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 604, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 622, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 649, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 614, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 631, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 585, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 875, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 690, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 675, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 651, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 539, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 526, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 635, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 537, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 519, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 662, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 555, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 640, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 673, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 515, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 585, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 765, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 710, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 660, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 537, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 653, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 600, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 609, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 518, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 675, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 620, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 613, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 729, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 621, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 515, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 533, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1034, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 546, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 562, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 753, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 675, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 626, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 783, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 702, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 801, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 555, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 611, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 653, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 537, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 853, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 675, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 690, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 592, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 628, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 602, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 557, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 577, which is longer than the specified 512\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 563, which is longer than the specified 512\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = NLTKTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_chunks = [c for c in chunks if len(c.page_content) >= 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_content = dict()\n",
    "unique_chunks = []\n",
    "for chunk in big_chunks:\n",
    "    content = chunk.page_content\n",
    "    #if content in seen_content:\n",
    "        #print(f\"{chunk.metadata} already seen in {seen_content[content]}\")\n",
    "        #continue\n",
    "    seen_content[content] = chunk.metadata\n",
    "    unique_chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Following the process outlined for CLI above, TruEra's Python SDK supports importing local data files or uploading pandas.DataFrames using the TrueraWorkspace.add_data_collection() and TrueraWorkspace.add_data_split() methods.\\n\\nClick Next below to continue.\" metadata={'source': 'https://docs.truera.com/1.34/public/local_data_ingestion/'}\n",
      "2333\n"
     ]
    }
   ],
   "source": [
    "# smallest chunk:\n",
    "print(unique_chunks[np.array([len(c.page_content) for c in unique_chunks]).argmin()])\n",
    "\n",
    "# number of chunks:\n",
    "print(len(unique_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model='text-embedding-ada-002')  # 1536 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import DocArrayHnswSearch, DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which chunks to write to vector db. Options here to play around with various\n",
    "# drawbacks.\n",
    "\n",
    "output_chunks = big_chunks # unique_chunks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To DocArrayHnswSearch\n",
    "\n",
    "This is a local document store and retriever that requires no additional api keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayHnswSearch.from_documents(\n",
    "    output_chunks,\n",
    "    embedding, work_dir='hnswlib_trubot',\n",
    "    n_dim=1536,\n",
    "    max_elements=int(len(unique_chunks) * 1.1)\n",
    ")\n",
    "db = DocArrayHnswSearch.from_params(\n",
    "    embedding=embedding,\n",
    "    work_dir='hnswlib_trubot',\n",
    "    n_dim=1536,\n",
    "    max_elements=int(len(unique_chunks) * 1.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "{'source': 'https://truera.com/ai-quality-leader/'}\n",
      "When Shayak started building production grade machine learning models for algorithmic trading 10 years ago, he realized the need for putting the ‘science’ back in ‘data science’. Since then, he has been building systems and leading research to make machine learning and big data systems more explainable, privacy compliant, and fair. Shayak’s research at Carnegie Mellon University introduced a number of pioneering breakthroughs to the field of explainable AI. Shayak obtained his PhD in Computer Science from Carnegie Mellon University and BTech in Computer Science from the Indian Institute of Technology, Delhi.\n",
      "====\n",
      "====\n",
      "{'source': 'https://truera.com/ai-quality-research/'}\n",
      "When Shayak started building production grade machine learning models for algorithmic trading 10 years ago, he realized the need for putting the ‘science’ back in ‘data science’. Since then, he has been building systems and leading research to make machine learning and big data systems more explainable, privacy compliant, and fair. Shayak’s research at Carnegie Mellon University introduced a number of pioneering breakthroughs to the field of explainable AI. Shayak obtained his PhD in Computer Science from Carnegie Mellon University and BTech in Computer Science from the Indian Institute of Technology, Delhi.\n",
      "====\n",
      "====\n",
      "{'source': 'https://truera.com/ai-quality-leader/'}\n",
      "Anupam is passionate about enabling responsible adoption of artificial intelligence. As a Professor of Electrical & Computer Engineering and Computer Science at Carnegie Mellon University for over a decade, he has led groundbreaking research in the areas of AI explainability and governance as well as privacy and data protection. Anupam obtained PhD and MS degrees from Stanford University and a BTech from the Indian Institute of Technology, Kharagpur, all in Computer Science.\n",
      "\n",
      "Linkedin\n",
      "\n",
      "Shayak Sen\n",
      "====\n",
      "====\n",
      "{'source': 'https://marketing.truera.com/webinar-eu-ai-law'}\n",
      "Most recently, Shameek was Group Chief Data Officer at Standard Chartered Bank, where he helped the bank explore and adopt AI in multiple areas (e.g., credit, financial crime compliance, customer analytics, surveillance), and shaped the bank’s internal approach to responsible AI\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "for doc in db.similarity_search(\"Who is Shayak?\"):\n",
    "    print(\"====\")\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content)\n",
    "    print(\"====\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import *\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_ENV   # next to api key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create / upload an index of the docs to pinecone\n",
    "\n",
    "index_name = \"llmdemo\"\n",
    "# Delete if already exists:\n",
    "# pinecone.delete_index(index_name)\n",
    "# pinecone.create_index(index_name, dimension=1536)\n",
    "Pinecone.from_documents(output_chunks, embedding, index_name=index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
