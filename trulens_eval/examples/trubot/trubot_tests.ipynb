{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruBot testing\n",
    "\n",
    "This notebook tests a conversation bot with vector-store context of TruEra website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))\n",
    "\n",
    "# Uncomment to get more debugging printouts:\n",
    "\n",
    "\"\"\"\n",
    "import logging\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.keys import check_or_set_keys\n",
    "\n",
    "check_or_set_keys(\n",
    "    OPENAI_API_KEY=\"to fill in\",\n",
    "    HUGGINGFACE_API_KEY=\"to fill in\",\n",
    "    PINECONE_API_KEY=\"to fill in\",\n",
    "    PINECONE_ENV=\"to fill in\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.trubot.trubot import get_or_make_app, get_answer, f_lang_match, f_qs_relevance\n",
    "from trulens_eval.util import TP\n",
    "from trulens_eval import Tru\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "# Reset the database if needed:\n",
    "Tru().reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = get_or_make_app(cid=None, selector=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the app components that got instrumented along with their categories.\n",
    "\n",
    "app.print_instrumented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Tru().start_dashboard(force=True, _dev=Path.cwd().parent.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = [0,1,3,4]\n",
    "messages = [\"Who is Shayak?\", \"Wer ist Shayak?\", \"Kim jest Shayak?\", \"¿Quién es Shayak?\", \"Was ist QII?\", \"Co jest QII?\"]\n",
    "\n",
    "selectors = selectors[2:3]\n",
    "messages = messages[2:3]\n",
    "\n",
    "def test_bot(selector, question):\n",
    "    print(selector, question)\n",
    "    app = get_or_make_app(cid=question + str(selector), selector=selector)\n",
    "    answer = get_answer(app=app, question=question)\n",
    "    return answer\n",
    "\n",
    "results = []\n",
    "\n",
    "for s in selectors:\n",
    "    for m in messages:\n",
    "        results.append(TP().promise(test_bot, selector=s, question=m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = Tru().start_evaluator(restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrumentation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "import os\n",
    "import unittest\n",
    "from unittest import main\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.callbacks import AsyncIteratorCallbackHandler\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema.messages import HumanMessage\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.keys import check_keys\n",
    "from trulens_eval.provider_apis import Endpoint\n",
    "from trulens_eval.provider_apis import OpenAIEndpoint\n",
    "from trulens_eval.tru_chain import TruChain\n",
    "import trulens_eval.utils.python  # makes sure asyncio gets instrumented\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\", \"HUGGINGFACE_API_KEY\", \"PINECONE_API_KEY\", \"PINECONE_ENV\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Honestly answer this question: {question}.\"\"\"\n",
    ")\n",
    "llm1 = OpenAI(temperature=0.0, streaming=False, cache=False)\n",
    "llm2 = OpenAI(temperature=0.0, streaming=False, cache=False)\n",
    "\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt)\n",
    "# tc1 = Tru().Chain(chain1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"question\",\n",
    "    llm=llm1, # same llm1 now appears in a different spot\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt, memory=memory)\n",
    "tc2 = Tru().Chain(chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc2.print_instrumented()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
