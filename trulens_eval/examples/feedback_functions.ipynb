{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691ec232",
   "metadata": {},
   "source": [
    "# Out-of-the-box Feedback Functions\n",
    "See: <https://www.trulens.org/trulens_eval/api/feedback/>\n",
    "\n",
    "## Relevance\n",
    "\n",
    "This evaluates the *relevance* of the LLM response to the given text by LLM prompting.\n",
    "\n",
    "Relevance is currently only available with OpenAI ChatCompletion API.\n",
    "\n",
    "## Sentiment\n",
    "\n",
    "This evaluates the *positive sentiment* of either the prompt or response.\n",
    "\n",
    "Sentiment is currently available to use with OpenAI, HuggingFace or Cohere as the model provider.\n",
    "\n",
    "* The OpenAI sentiment feedback function prompts a Chat Completion model to rate the sentiment from 1 to 10, and then scales the response down to 0-1.\n",
    "* The HuggingFace sentiment feedback function returns a raw score from 0 to 1.\n",
    "* The Cohere sentiment feedback function uses the classification endpoint and a small set of examples stored in `feedback_prompts.py` to return either a 0 or a 1.\n",
    "\n",
    "## Model Agreement\n",
    "\n",
    "Model agreement uses OpenAI to attempt an honest answer at your prompt with system prompts for correctness, and then evaluates the agreement of your LLM response to this model on a scale from 1 to 10. The agreement with each honest bot is then averaged and scaled from 0 to 1.\n",
    "\n",
    "## Language Match\n",
    "\n",
    "This evaluates if the language of the prompt and response match.\n",
    "\n",
    "Language match is currently only available to use with HuggingFace as the model provider. This feedback function returns a score in the range from 0 to 1, where 1 indicates match and 0 indicates mismatch.\n",
    "\n",
    "## Toxicity\n",
    "\n",
    "This evaluates the toxicity of the prompt or response.\n",
    "\n",
    "Toxicity is currently only available to be used with HuggingFace, and uses a classification endpoint to return a score from 0 to 1. The feedback function is negated as not_toxicity, and returns a 1 if not toxic and a 0 if toxic.\n",
    "\n",
    "## Moderation\n",
    "\n",
    "The OpenAI Moderation API is made available for use as feedback functions. This includes hate, hate/threatening, self-harm, sexual, sexual/minors, violence, and violence/graphic. Each is negated (ex: not_hate) so that a 0 would indicate that the moderation rule is violated. These feedback functions return a score in the range 0 to 1.\n",
    "\n",
    "# Adding new feedback functions\n",
    "\n",
    "Feedback functions are an extensible framework for evaluating LLMs. You can add your own feedback functions to evaluate the qualities required by your application by updating `trulens_eval/feedback.py`. If your contributions would be useful for others, we encourage you to contribute to TruLens!\n",
    "\n",
    "Feedback functions are organized by model provider into Provider classes.\n",
    "\n",
    "The process for adding new feedback functions is:\n",
    "1. Create a new Provider class or locate an existing one that applies to your feedback function. If your feedback function does not rely on a model provider, you can create a standalone class. Add the new feedback function method to your selected class. Your new method can either take a single text (str) as a parameter or both prompt (str) and response (str). It should return a float between 0 (worst) and 1 (best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ec934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Provider\n",
    "\n",
    "class StandAlone(Provider):\n",
    "    def my_custom_feedback(self, my_text_field: str) -> float:\n",
    "        \"\"\"\n",
    "        A dummy function of text inputs to float outputs.\n",
    "\n",
    "        Parameters:\n",
    "            my_text_field (str): Text to evaluate.\n",
    "\n",
    "        Returns:\n",
    "            float: square length of the text\n",
    "        \"\"\"\n",
    "        return 1.0 / (1.0 + len(my_text_field) * len(my_text_field))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056c677",
   "metadata": {},
   "source": [
    "2. Instantiate your provider and feedback functions. The feedback function is wrapped by the trulens-eval Feedback class which helps specify what will get sent to your function parameters (For example: Query.RecordInput or Query.RecordOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_standalone = StandAlone()\n",
    "my_feedback_function_standalone = Feedback(my_standalone.my_custom_feedback).on(\n",
    "    my_text_field=Query.RecordOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66987343",
   "metadata": {},
   "source": [
    "3. Your feedback function is now ready to use just like the out of the box feedback functions. Below is an example of it being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db425de",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[my_feedback_function_standalone]\n",
    ")\n",
    "tru.add_feedbacks(feedback_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
