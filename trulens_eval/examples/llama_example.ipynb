{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.resolve()))\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "# Uncomment to get more debugging printouts:\n",
    "\n",
    "import logging\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:21:56,903 - numexpr.utils - INFO - Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-06-16 17:21:56,927 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n",
      "KEY SET: OPENAI_API_KEY\n",
      "KEY SET: PINECONE_API_KEY\n",
      "KEY SET: PINECONE_ENV\n",
      "KEY SET: HUGGINGFACE_API_KEY\n",
      "KEY SET: SLACK_TOKEN\n",
      "KEY SET: SLACK_SIGNING_SECRET\n",
      "KEY SET: COHERE_API_KEY\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.keys import *\n",
    "set_openai_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import ModuleType\n",
    "from typing import Callable, Tuple, TypeVar\n",
    "from trulens_eval.util import get_local_in_call_stack\n",
    "\n",
    "import inspect\n",
    "import openai\n",
    "from langchain.schema import LLMResult\n",
    "from langchain.callbacks.openai_info import OpenAICallbackHandler\n",
    "import pydantic\n",
    "\n",
    "import logging\n",
    "from typing import Any\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "INSTRUMENT = \"__tru_instrument\"\n",
    "\n",
    "class Tracker(pydantic.BaseModel):\n",
    "    \"\"\"\n",
    "    Track api requests for usage.\n",
    "    \"\"\"\n",
    "\n",
    "    class Config:\n",
    "        pass\n",
    "\n",
    "    # Track costs not run inside \"track_cost\" here.\n",
    "    global_callback: Any\n",
    "    endpoint_name: str = \"api\"\n",
    "    callback_name: str\n",
    "    callback_class: type\n",
    "\n",
    "    def __init__(self, callback_class: type, endpoint_name: str = \"api\", *args, **kwargs):\n",
    "        kwargs['endpoint_name'] = endpoint_name\n",
    "        kwargs['global_callback'] = callback_class()\n",
    "        kwargs['callback_class'] = callback_class\n",
    "        kwargs['callback_name'] = f\"callback_{endpoint_name}\"\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def instrument(self, mod: ModuleType, method_name: str):\n",
    "        for m in dir(mod):\n",
    "            sub = getattr(mod, m)\n",
    "            \n",
    "            if hasattr(sub, method_name):\n",
    "                logger.debug(f\"Instrumenting {mod.__package__}.{method_name} for {self.endpoint_name}\")\n",
    "                func = getattr(sub, method_name)  \n",
    "                w = self.wrap_function(func)\n",
    "                setattr(sub, method_name, w)\n",
    "\n",
    "    def track_cost(self, thunk: Callable[[], T]) -> Tuple[T, Any]: # Any -> langchain llm callback handler\n",
    "        \"\"\"\n",
    "        Tally only the openai API usage performed within the execution of the\n",
    "        given thunk. Returns the thunk's result alongside the langchain callback\n",
    "        that includes the usage information.\n",
    "        \"\"\"\n",
    "\n",
    "        # Keep this here for access by wrappers higher in call stack.\n",
    "        cb = self.callback_class()\n",
    "        locals()[self.callback_name] = cb\n",
    "\n",
    "        return thunk(), cb\n",
    "\n",
    "    @staticmethod\n",
    "    def __find_tracker(f):\n",
    "        return id(f) == id(Tracker.track_cost.__code__)\n",
    "\n",
    "    def wrap_function(self, func):\n",
    "        if hasattr(func, INSTRUMENT):\n",
    "            # TODO: What if we want to instrument the same method for multiple\n",
    "            # endpoints?\n",
    "            logger.debug(f\"{func.__name__} already instrumented\")\n",
    "            return func\n",
    "\n",
    "        def wrapper(*args, **kwargs):\n",
    "            logger.debug(f\"Calling wrapped {func.__name__} for {self.endpoint_name}.\")\n",
    "            \n",
    "            res = func(*args, **kwargs)\n",
    "\n",
    "            model_name = None\n",
    "            if 'model' in kwargs:\n",
    "                model_name = kwargs['model']\n",
    "\n",
    "            usage = None\n",
    "            if 'usage' in res:\n",
    "                usage = res['usage']\n",
    "\n",
    "            llm_res = LLMResult(\n",
    "                generations=[[]],\n",
    "                llm_output=dict(token_usage=usage, model_name=model_name),\n",
    "                run=None\n",
    "            )\n",
    "\n",
    "            cb = get_local_in_call_stack(\n",
    "                key=self.callback_name,\n",
    "                func=self.__find_tracker,\n",
    "                offset=0\n",
    "            )\n",
    "\n",
    "            self.global_callback.on_llm_end(response=llm_res)\n",
    "            \n",
    "            if cb is not None:\n",
    "                cb.on_llm_end(response=llm_res)\n",
    "    \n",
    "            return res\n",
    "        \n",
    "        setattr(wrapper, INSTRUMENT, func)\n",
    "        wrapper.__name__ = func.__name__\n",
    "        wrapper.__signature__ = inspect.signature(func)\n",
    "\n",
    "        logger.debug(f\"Instrumenting {func.__name__} for {self.endpoint_name} .\")\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "class OpenAITracker(Tracker):\n",
    "    \"\"\"\n",
    "    Track openai uses. This makes use of langchain OpenAICallbackHandler for\n",
    "    extracting and tallying various openai API response content.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs['endpoint_name'] = \"openai\"\n",
    "        kwargs['callback_class'] = OpenAICallbackHandler\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        import openai\n",
    "        self.instrument(openai, \"create\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:21:58,577 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,578 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,578 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,578 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,579 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,579 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,579 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,580 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,580 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,580 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,580 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,581 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,581 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,581 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,581 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,582 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,582 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,582 - __main__ - DEBUG - Instrumenting create for openai .\n",
      "2023-06-16 17:21:58,582 - __main__ - DEBUG - Instrumenting openai.create for openai\n",
      "2023-06-16 17:21:58,583 - __main__ - DEBUG - Instrumenting create for openai .\n"
     ]
    }
   ],
   "source": [
    "oait = OpenAITracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:21:59,996 - trulens_eval.util - DEBUG - *** Creating new Endpoint singleton instance for name = openai ***\n",
      "2023-06-16 17:21:59,996 - trulens_eval.provider_apis - DEBUG - *** Creating openai endpoint ***\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3e27b9ec244a76bb040a6011bf92b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openai api: 0requests [00:00, ?requests/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trulens_eval import feedback\n",
    "provider_openai = feedback.OpenAI()\n",
    "# provider_openai.qs_relevance(\"Who is Piotr?\", \"Piotr is a person.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:22:01,016 - __main__ - DEBUG - Calling wrapped create for openai.\n",
      "2023-06-16 17:22:01,017 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "2023-06-16 17:22:01,017 - openai - DEBUG - api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"messages\": [{\"role\": \"system\", \"content\": \"You are a RELEVANCE classifier; providing the relevance of the given STATEMENT to the given QUESTION.\\\\nRespond only as a number from 1 to 10 where 1 is the least relevant and 10 is the most relevant.\\\\nNever elaborate.\\\\n\\\\nQUESTION: Who is Piotr?\\\\n\\\\nSTATEMENT: Piotr is a person.\\\\n\\\\nRELEVANCE: \"}]}' message='Post details'\n",
      "2023-06-16 17:22:01,018 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "2023-06-16 17:22:01,056 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443\n",
      "2023-06-16 17:22:01,636 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "2023-06-16 17:22:01,638 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=392 request_id=0491cb5b90671dda4d125d5eeac73477 response_code=200\n",
      "2023-06-16 17:22:01,860 - trulens_eval.util - DEBUG - <code object wrapper at 0x14fb1c450, file \"/var/folders/2j/xg0_cv993gl37s_8qs5qrdxm0000gn/T/ipykernel_40262/1868101118.py\", line 75>\n",
      "2023-06-16 17:22:01,860 - trulens_eval.util - DEBUG - *** Creating new TP singleton instance for name = None ***\n",
      "2023-06-16 17:22:01,962 - trulens_eval.util - DEBUG - <code object <lambda> at 0x13fe4ac90, file \"/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/feedback.py\", line 597>\n",
      "2023-06-16 17:22:01,963 - trulens_eval.util - DEBUG - <code object run_me at 0x14d83d2f0, file \"/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/provider_apis.py\", line 88>\n",
      "2023-06-16 17:22:01,963 - trulens_eval.util - DEBUG - <code object qs_relevance at 0x13fe4ad40, file \"/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/feedback.py\", line 582>\n",
      "2023-06-16 17:22:01,963 - trulens_eval.util - DEBUG - <code object make_request at 0x14fb19450, file \"/var/folders/2j/xg0_cv993gl37s_8qs5qrdxm0000gn/T/ipykernel_40262/4016703648.py\", line 1>\n",
      "2023-06-16 17:22:01,964 - trulens_eval.util - DEBUG - <code object track_cost at 0x14f5855b0, file \"/var/folders/2j/xg0_cv993gl37s_8qs5qrdxm0000gn/T/ipykernel_40262/1868101118.py\", line 51>\n",
      "2023-06-16 17:22:01,964 - trulens_eval.util - DEBUG - looking via __find_tracker; found FrameInfo(frame=<frame at 0x108158040, file '/var/folders/2j/xg0_cv993gl37s_8qs5qrdxm0000gn/T/ipykernel_40262/1868101118.py', line 62, code track_cost>, filename='/var/folders/2j/xg0_cv993gl37s_8qs5qrdxm0000gn/T/ipykernel_40262/1868101118.py', lineno=62, function='track_cost', code_context=['        return thunk(), cb\\n'], index=0)\n"
     ]
    }
   ],
   "source": [
    "def make_request():\n",
    "    return provider_openai.qs_relevance(\"Who is Piotr?\", \"Piotr is a person.\")\n",
    "\n",
    "res, cb = oait.track_cost(make_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokens Used: 82\n",
       "\tPrompt Tokens: 81\n",
       "\tCompletion Tokens: 1\n",
       "Successful Requests: 1\n",
       "Total Cost (USD): $0.000164"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    provider_openai.qs_relevance(\"Who is Piotr?\", \"Piotr is a person.\")\n",
    "    total_tokens = cb.total_tokens\n",
    "    total_cost = cb.total_cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tru().reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('llama_index/data').load_data()\n",
    "index = GPTVectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "# response = query_engine.query(\"What did the author do growing up?\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For aggregation,\n",
    "import numpy as np\n",
    "\n",
    "from trulens_eval import feedback, Feedback, Query, Tru\n",
    "\n",
    "# Construct feedback functions.\n",
    "\n",
    "hugs = feedback.Huggingface()\n",
    "openai = feedback.OpenAI()\n",
    "\n",
    "# Language match between question/answer.\n",
    "f_lang_match = Feedback(hugs.language_match).on(\n",
    "    text1=Query.RecordInput, text2=Query.RecordOutput\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on(\n",
    "    prompt=Query.RecordInput, response=Query.RecordOutput\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_qs_relevance = feedback.Feedback(openai.qs_relevance).on(\n",
    "    question=Query.RecordInput,\n",
    "    statement=Query.Record.model.retriever.retrieve.rets[:].node.text\n",
    ").aggregate(np.min)\n",
    "\n",
    "feedbacks = [\n",
    "#    f_lang_match, \n",
    "#    f_qa_relevance, \n",
    "#    f_qs_relevance\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Tru().Llama(engine=query_engine, feedbacks=feedbacks, chain_id=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(l.instrumented())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, record = l.query_with_record(\"Who is Shayak?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Tru().start_dashboard(force=True, _dev=Path.cwd().parent)\n",
    "# thread = Tru().start_evaluator(restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index\n",
    "dir(llama_index.llm_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(l.app._response_synthesizer._response_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
