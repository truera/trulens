{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(Path().cwd().parent.resolve()))\n",
    "\n",
    "# Uncomment for more debugging printouts.\n",
    "\"\"\"\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider.base import Feedback, GroundTruth, Groundedness, Sentiment, BinarySentiment, Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance\n",
      "   Subtype of Feedback.\n",
      "   Subtype of NaturalLanguage.\n",
      "      languages = None\n",
      "   Subtype of Semantics.\n",
      "\n",
      "Doc\n",
      "   \n",
      "   This evaluates the *relevance* of the LLM response to the given text by LLM\n",
      "   prompting.\n",
      "   \n",
      "   Relevance is currently only available with OpenAI ChatCompletion API.\n",
      "   \n",
      "   TruLens offers two particular flavors of relevance: 1. *Prompt response\n",
      "   relevance* is best for measuring the relationship of the final answer to the\n",
      "   user inputed question. This flavor of relevance is particularly optimized for\n",
      "   the following features:\n",
      "   \n",
      "       * Relevance requires adherence to the entire prompt.\n",
      "       * Responses that don't provide a definitive answer can still be relevant\n",
      "       * Admitting lack of knowledge and refusals are still relevant.\n",
      "       * Feedback mechanism should differentiate between seeming and actual\n",
      "         relevance.\n",
      "       * Relevant but inconclusive statements should get increasingly high scores\n",
      "         as they are more helpful for answering the query.\n",
      "   \n",
      "       You can read more information about the performance of prompt response\n",
      "       relevance by viewing its [smoke test results](../pr_relevance_smoke_tests/).\n",
      "   \n",
      "   2. *Question statement relevance*, sometimes known as context relevance, is best\n",
      "      for measuring the relationship of a provided context to the user inputed\n",
      "      question. This flavor of relevance is optimized for a slightly different set\n",
      "      of features:\n",
      "       * Relevance requires adherence to the entire query.\n",
      "       * Long context with small relevant chunks are relevant.\n",
      "       * Context that provides no answer can still be relevant.\n",
      "       * Feedback mechanism should differentiate between seeming and actual\n",
      "         relevance.\n",
      "       * Relevant but inconclusive statements should get increasingly high scores\n",
      "         as they are more helpful for answering the query.\n",
      "   \n",
      "       You can read more information about the performance of question statement\n",
      "       relevance by viewing its [smoke test results](../context_relevance_smoke_tests/).\n",
      "       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(Relevance()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinarySentiment\n",
      "   Subtype of Feedback.\n",
      "   Subtype of NaturalLanguage.\n",
      "      languages = None\n",
      "   Subtype of Semantics.\n",
      "   Subtype of Sentiment.\n",
      "\n",
      "Doc\n",
      "   \n",
      "       A discrete form of sentiment with only \"positive\" (1) and \"negative\" (0) classification.\n",
      "       \n",
      "\n",
      "Examples:\n",
      "   Example(text='The order came 5 days early', label='1')\n",
      "   Example(text=\"I just got a promotion at work and I'm so excited!\", label='1')\n",
      "   Example(text=\"My best friend surprised me with tickets to my favorite band's concert.\", label='1')\n",
      "   Example(text=\"I'm so grateful for my family's support during a difficult time.\", label='1')\n",
      "   Example(text=\"It's kind of grungy, but the pumpkin pie slaps\", label='1')\n",
      "   Example(text='I love spending time in nature and feeling connected to the earth.', label='1')\n",
      "   Example(text='I had an amazing meal at the new restaurant in town', label='1')\n",
      "   Example(text='The pizza is good, but the staff is horrible to us', label='0')\n",
      "   Example(text='The package was damaged', label='0')\n",
      "   Example(text=\"I'm feeling really sick and can't seem to shake it off\", label='0')\n",
      "   Example(text='I got into a car accident and my car is completely totaled.', label='0')\n",
      "   Example(text='My boss gave me a bad performance review and I might get fired', label='0')\n",
      "   Example(text='I got into a car accident and my car is completely totaled.', label='0')\n",
      "   Example(text=\"I'm so disapointed in myself for not following through on my goals\", label='0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(BinarySentiment()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness\n",
      "   Subtype of Feedback.\n",
      "   Subtype of NaturalLanguage.\n",
      "      languages = None\n",
      "   Subtype of Semantics.\n",
      "\n",
      "Prompt: of ['hypothesis', 'premise']\n",
      "   You are a INFORMATION OVERLAP classifier; providing the overlap of information between two statements.\n",
      "   Respond only as a number from 1 to 10 where 1 is no information overlap and 10 is all information is overlapping.\n",
      "   Never elaborate.\n",
      "   \n",
      "   STATEMENT 1: {premise}\n",
      "   \n",
      "   STATEMENT 2: {hypothesis}\n",
      "   \n",
      "   INFORMATION OVERLAP: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(Groundedness()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
