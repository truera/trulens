{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Human Feedback\n",
    "\n",
    "In many situations, it can be useful to log human feedback from your users about your LLM app's performance. Combining human feedback along with automated feedback can help you drill down on subsets of your app that underperform, and uncover new failure modes. This example will walk you through a simple example of recording human feedback with TruLens.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/human_feedback.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval==0.19.2 openai==1.3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval import TruChain\n",
    "\n",
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Keys\n",
    "\n",
    "For this example, you need an OpenAI key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your app\n",
    "\n",
    "Here we set up a custom application using just an OpenAI chat completion. The process for logging human feedback is the same however you choose to set up your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()\n",
    "\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "class APP:\n",
    "    @instrument\n",
    "    def completion(self, prompt):\n",
    "        completion = oai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages=\n",
    "                [\n",
    "                    {\"role\": \"user\",\n",
    "                    \"content\": \n",
    "                    f\"Please answer the question: {prompt}\"\n",
    "                    }\n",
    "                ]\n",
    "                ).choices[0].message.content\n",
    "        return completion\n",
    "    \n",
    "llm_app = APP()\n",
    "\n",
    "# add trulens as a context manager for llm_app\n",
    "from trulens_eval import TruCustomApp\n",
    "tru_app = TruCustomApp(llm_app, app_id = 'LLM App v1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_app as recording:\n",
    "    llm_app.completion(\"Give me 10 names for a colorful sock company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the `record_id` that you will log human feedback to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"LLM App v1\"])\n",
    "record_id = records.record_id[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mechamism for recording human feedback.\n",
    "\n",
    "Be sure to click an emoji in the record to record `human_feedback` to log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Button, HBox, VBox\n",
    "\n",
    "thumbs_up_button = Button(description='üëç')\n",
    "thumbs_down_button = Button(description='üëé')\n",
    "\n",
    "human_feedback = None\n",
    "\n",
    "def on_thumbs_up_button_clicked(b):\n",
    "    global human_feedback\n",
    "    human_feedback = 1\n",
    "\n",
    "def on_thumbs_down_button_clicked(b):\n",
    "    global human_feedback\n",
    "    human_feedback = 0\n",
    "\n",
    "thumbs_up_button.on_click(on_thumbs_up_button_clicked)\n",
    "thumbs_down_button.on_click(on_thumbs_down_button_clicked)\n",
    "\n",
    "HBox([thumbs_up_button, thumbs_down_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the human feedback to a particular app and record\n",
    "tru.add_feedback(\n",
    "            name=\"Human Feedack\",\n",
    "            record_id=record_id,\n",
    "            app_id=tru_app.app_id,\n",
    "            result=human_feedback\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the result logged with your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[tru_app.app_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens18_release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
