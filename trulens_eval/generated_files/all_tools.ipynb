{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "In this quickstart you will create a simple LLM Chain and learn how to log it and get feedback on an LLM response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from LangChain and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "# Imports main tools:\n",
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru, Query\n",
    "tru = Tru()\n",
    "\n",
    "# imports from langchain to build app\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple LLM Application\n",
    "\n",
    "This example uses a LangChain framework and OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\n",
    "        \"Provide a helpful response with relevant background information for the following: {prompt}\",\n",
    "        input_variables=[\"prompt\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
    "\n",
    "llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=chat_prompt_template, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send your first request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input = '¿que hora es?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Provide a helpful response with relevant background information for the following: ¿que hora es?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': '¿que hora es?',\n",
       " 'text': '\\n\\nLa hora actual en tu ubicación depende de la zona horaria en la que te encuentras. Para averiguar la hora en tu zona, puedes usar una herramienta de conversión de zonas horarias en línea para encontrar la hora actual. También puedes consultar la zona horaria en tu dispositivo para obtener información precisa.'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_response = chain(prompt_input)\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810894aa53204e539a8eed77d93c952f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "huggingface api: 0requests [00:00, ?requests/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on(\n",
    "    text1=Query.RecordInput, text2=Query.RecordOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chain Chain3_ChatApplication -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ef50204d7ba1af7567641ca2fffb444c -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "truchain = TruChain(chain,\n",
    "    chain_id='Chain3_ChatApplication',\n",
    "    feedbacks=[f_lang_match],\n",
    "    tru = tru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': '¿que hora es?',\n",
       " 'text': '\\n\\nLa hora actual es [hora en la zona horaria actual]. El mundo se divide en 24 zonas horarias diferentes, con una hora diferente para cada lugar. Para encontrar la hora exacta en la zona horaria actual, consulte una herramienta de hora local como el reloj mundial en línea.'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ record record_hash_a2919b3a75a800dcca0d166c9af7d2ed from Chain3_ChatApplication -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "# Instrumented chain can operate like the original:\n",
    "llm_response = truchain(prompt_input)\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.run_dashboard(_dev=True) # if running from repo\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Leaderboard\n",
    "\n",
    "Understand how your LLM application is performing at a glance. Once you've set up logging and evaluation in your application, you can view key performance statistics including cost and average feedback value across all of your LLM apps using the chain leaderboard. As you iterate new versions of your LLM application, you can compare their performance across all of the different quality metrics you've set up.\n",
    "\n",
    "Note: Average feedback values are returned and displayed in a range from 0 (worst) to 1 (best).\n",
    "\n",
    "![Chain Leaderboard](https://www.trulens.org/Assets/image/Leaderboard.png)\n",
    "\n",
    "To dive deeper on a particular chain, click \"Select Chain\".\n",
    "\n",
    "### Understand chain performance with Evaluations\n",
    " \n",
    "To learn more about the performance of a particular chain or LLM model, we can select it to view its evaluations at the record level. LLM quality is assessed through the use of feedback functions. Feedback functions are extensible methods for determining the quality of LLM responses and can be applied to any downstream LLM task. Out of the box we provide a number of feedback functions for assessing model agreement, sentiment, relevance and more.\n",
    "\n",
    "The evaluations tab provides record-level metadata and feedback on the quality of your LLM application.\n",
    "\n",
    "![Evaluations](https://www.trulens.org/Assets/image/Leaderboard.png)\n",
    "\n",
    "### Deep dive into full chain metadata\n",
    "\n",
    "Click on a record to dive deep into all of the details of your chain stack and underlying LLM, captured by tru_chain.\n",
    "\n",
    "![Explore a Chain](https://www.trulens.org/Assets/image/Chain_Explore.png)\n",
    "\n",
    "If you prefer the raw format, you can quickly get it using the \"Display full chain json\" or \"Display full record json\" buttons at the bottom of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or view results directly in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>record_json</th>\n",
       "      <th>tags</th>\n",
       "      <th>ts</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>chain_json</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>language_match</th>\n",
       "      <th>language_match_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record_hash_016d5d7f77bb9da0881d4149fdd4dd92</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be logged by deferred evaluator.</td>\n",
       "      <td>\\n\\nDeferred Evaluator is an automated scoring...</td>\n",
       "      <td>{\"record_id\": \"record_hash_016d5d7f77bb9da0881...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:42:51.602106</td>\n",
       "      <td>{\"n_tokens\": 134, \"cost\": 0.00268}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>134</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.992349</td>\n",
       "      <td>[{'args': {'text1': 'This will be logged by de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record_hash_1c188102dd1b2349cdb67882fe3d8d8a</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>que hora es?</td>\n",
       "      <td>\\n\\nLa hora actual es 12:35.</td>\n",
       "      <td>{\"record_id\": \"record_hash_1c188102dd1b2349cdb...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:42:41.008099</td>\n",
       "      <td>{\"n_tokens\": 30, \"cost\": 0.0006000000000000001}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>[{'args': {'text1': 'que hora es?', 'text2': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record_hash_783160580bb6a9798f76e1fb0495061d</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be automatically logged.</td>\n",
       "      <td>\\n\\nThis means that the action you are taking ...</td>\n",
       "      <td>{\"record_id\": \"record_hash_783160580bb6a9798f7...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:42:39.554762</td>\n",
       "      <td>{\"n_tokens\": 85, \"cost\": 0.0017}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>85</td>\n",
       "      <td>0.00170</td>\n",
       "      <td>0.989833</td>\n",
       "      <td>[{'args': {'text1': 'This will be automaticall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record_hash_9865e5b6907c71e9de97fa6a6e5807bb</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be automatically logged.</td>\n",
       "      <td>\\n\\nIn order to keep your records organized an...</td>\n",
       "      <td>{\"record_id\": \"record_hash_9865e5b6907c71e9de9...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:38:05.778958</td>\n",
       "      <td>{\"n_tokens\": 116, \"cost\": 0.00232}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>116</td>\n",
       "      <td>0.00232</td>\n",
       "      <td>0.994001</td>\n",
       "      <td>[{'args': {'text1': 'This will be automaticall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record_hash_a002097b06f96f8a6e7cf476888901ee</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be automatically logged.</td>\n",
       "      <td>\\n\\nThis means that any time you perform an ac...</td>\n",
       "      <td>{\"record_id\": \"record_hash_a002097b06f96f8a6e7...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:02:47.324103</td>\n",
       "      <td>{\"n_tokens\": 85, \"cost\": 0.0017}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>85</td>\n",
       "      <td>0.00170</td>\n",
       "      <td>0.997430</td>\n",
       "      <td>[{'args': {'text1': 'This will be automaticall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>record_hash_a2919b3a75a800dcca0d166c9af7d2ed</td>\n",
       "      <td>Chain3_ChatApplication</td>\n",
       "      <td>¿que hora es?</td>\n",
       "      <td>\\n\\nLa hora actual es [hora en la zona horaria...</td>\n",
       "      <td>{\"record_id\": \"record_hash_a2919b3a75a800dcca0...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:10:22.818910</td>\n",
       "      <td>{\"n_tokens\": 114, \"cost\": 0.00228}</td>\n",
       "      <td>{\"chain_id\": \"Chain3_ChatApplication\", \"feedba...</td>\n",
       "      <td>114</td>\n",
       "      <td>0.00228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>record_hash_a8897f746a480e35f8ce33bd11821cf8</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>que hora es?</td>\n",
       "      <td>\\n\\nRespuesta: Actualmente, dependiendo de la ...</td>\n",
       "      <td>{\"record_id\": \"record_hash_a8897f746a480e35f8c...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:02:58.328323</td>\n",
       "      <td>{\"n_tokens\": 93, \"cost\": 0.00186}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.997064</td>\n",
       "      <td>[{'args': {'text1': 'que hora es?', 'text2': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>record_hash_ae39fd378185b4ba992212110024860b</td>\n",
       "      <td>Chain3_ChatApplication</td>\n",
       "      <td>¿que hora es?</td>\n",
       "      <td>\\n\\nLa hora actual es las 11:30pm.</td>\n",
       "      <td>{\"record_id\": \"record_hash_ae39fd378185b4ba992...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:42:30.386223</td>\n",
       "      <td>{\"n_tokens\": 34, \"cost\": 0.00068}</td>\n",
       "      <td>{\"chain_id\": \"Chain3_ChatApplication\", \"feedba...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>[{'args': {'text1': '¿que hora es?', 'text2': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>record_hash_b2bc294ccddc92e7d4fffc0276a0ae78</td>\n",
       "      <td>Chain3_ChatApplication</td>\n",
       "      <td>¿que hora es?</td>\n",
       "      <td>\\n\\nLa hora actual depende de la ubicación. Si...</td>\n",
       "      <td>{\"record_id\": \"record_hash_b2bc294ccddc92e7d4f...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:37:55.874846</td>\n",
       "      <td>{\"n_tokens\": 120, \"cost\": 0.0024}</td>\n",
       "      <td>{\"chain_id\": \"Chain3_ChatApplication\", \"feedba...</td>\n",
       "      <td>120</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.994190</td>\n",
       "      <td>[{'args': {'text1': '¿que hora es?', 'text2': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>record_hash_ba1041598fdeecf93759b73c2c7b5343</td>\n",
       "      <td>Chain3_ChatApplication</td>\n",
       "      <td>¿que hora es?</td>\n",
       "      <td>\\n\\nLa hora actual es la hora del reloj del si...</td>\n",
       "      <td>{\"record_id\": \"record_hash_ba1041598fdeecf9375...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:06:03.861315</td>\n",
       "      <td>{\"n_tokens\": 96, \"cost\": 0.00192}</td>\n",
       "      <td>{\"chain_id\": \"Chain3_ChatApplication\", \"feedba...</td>\n",
       "      <td>96</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>0.994699</td>\n",
       "      <td>[{'args': {'text1': '¿que hora es?', 'text2': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>record_hash_ba4bd26c4d1d75207c0913096e1712f1</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be automatically logged.</td>\n",
       "      <td>\\n\\nThis means that any activities will be tra...</td>\n",
       "      <td>{\"record_id\": \"record_hash_ba4bd26c4d1d75207c0...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:06:12.685336</td>\n",
       "      <td>{\"n_tokens\": 70, \"cost\": 0.0014}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.999519</td>\n",
       "      <td>[{'args': {'text1': 'This will be automaticall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>record_hash_c4be9d29d225b98c5775a65375acc0e1</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>que hora es?</td>\n",
       "      <td>\\n\\nLa hora actual es la 1:48 pm (horario del ...</td>\n",
       "      <td>{\"record_id\": \"record_hash_c4be9d29d225b98c577...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:38:08.635894</td>\n",
       "      <td>{\"n_tokens\": 51, \"cost\": 0.00102}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00102</td>\n",
       "      <td>0.962084</td>\n",
       "      <td>[{'args': {'text1': 'que hora es?', 'text2': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>record_hash_ca80df4fef5529b10c0f62ee368caa89</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be logged by deferred evaluator.</td>\n",
       "      <td>\\n\\nDeferred evaluator is a feature of Java Pl...</td>\n",
       "      <td>{\"record_id\": \"record_hash_ca80df4fef5529b10c0...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:39:03.025656</td>\n",
       "      <td>{\"n_tokens\": 95, \"cost\": 0.0018999999999999998}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.00190</td>\n",
       "      <td>0.997747</td>\n",
       "      <td>[{'args': {'text1': 'This will be logged by de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>record_hash_d01c3cba3aba060589ef45a21edb29a9</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be logged by deferred evaluator.</td>\n",
       "      <td>\\n\\nDeferred evaluator is a type of computer p...</td>\n",
       "      <td>{\"record_id\": \"record_hash_d01c3cba3aba060589e...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:06:32.610699</td>\n",
       "      <td>{\"n_tokens\": 104, \"cost\": 0.0020800000000000003}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>104</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>record_hash_d6c360c6054d757b466b51c40559d492</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be automatically logged.</td>\n",
       "      <td>\\n\\nYes, this action will be automatically lo...</td>\n",
       "      <td>{\"record_id\": \"record_hash_d6c360c6054d757b466...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:37:59.042334</td>\n",
       "      <td>{\"n_tokens\": 62, \"cost\": 0.00124}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>62</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>record_hash_dc3b6ffb2612a7027d57e5ea8e50b21d</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be automatically logged.</td>\n",
       "      <td>\\n\\nThis log entry will be saved in your accou...</td>\n",
       "      <td>{\"record_id\": \"record_hash_dc3b6ffb2612a7027d5...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 09:42:33.134843</td>\n",
       "      <td>{\"n_tokens\": 57, \"cost\": 0.00114}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>record_hash_e7d04a60380f601aba25f9f61f763211</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be automatically logged.</td>\n",
       "      <td>\\n\\nYes, this will be automatically logged. Al...</td>\n",
       "      <td>{\"record_id\": \"record_hash_e7d04a60380f601aba2...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:06:08.056405</td>\n",
       "      <td>{\"n_tokens\": 54, \"cost\": 0.00108}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.00108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>record_hash_eab1cf7cb795c00991c5f0334bc4b7e6</td>\n",
       "      <td>Chain3_ChatApplication</td>\n",
       "      <td>¿que hora es?</td>\n",
       "      <td>\\n\\nLa hora actual depende de su ubicación. En...</td>\n",
       "      <td>{\"record_id\": \"record_hash_eab1cf7cb795c00991c...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:02:36.095685</td>\n",
       "      <td>{\"n_tokens\": 107, \"cost\": 0.00214}</td>\n",
       "      <td>{\"chain_id\": \"Chain3_ChatApplication\", \"feedba...</td>\n",
       "      <td>107</td>\n",
       "      <td>0.00214</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>[{'args': {'text1': '¿que hora es?', 'text2': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>record_hash_ede76ca835c119b110e80ee1d3bc5622</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>que hora es?</td>\n",
       "      <td>\\n\\nEn este momento, dependiendo de tu ubicaci...</td>\n",
       "      <td>{\"record_id\": \"record_hash_ede76ca835c119b110e...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:06:18.121747</td>\n",
       "      <td>{\"n_tokens\": 75, \"cost\": 0.0015}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.996967</td>\n",
       "      <td>[{'args': {'text1': 'que hora es?', 'text2': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>record_hash_f78623a3df335ad1640b4551d2d5c1d7</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be automatically logged.</td>\n",
       "      <td>\\n\\nThis message indicates that the action or ...</td>\n",
       "      <td>{\"record_id\": \"record_hash_f78623a3df335ad1640...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:02:43.349272</td>\n",
       "      <td>{\"n_tokens\": 97, \"cost\": 0.00194}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>97</td>\n",
       "      <td>0.00194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>record_hash_f9169869ef4bce865de40b9bab8fad14</td>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>This will be logged by deferred evaluator.</td>\n",
       "      <td>\\n\\nDeferred evaluator is a feature in JavaScr...</td>\n",
       "      <td>{\"record_id\": \"record_hash_f9169869ef4bce865de...</td>\n",
       "      <td></td>\n",
       "      <td>2023-06-08 14:03:06.857671</td>\n",
       "      <td>{\"n_tokens\": 101, \"cost\": 0.00202}</td>\n",
       "      <td>{\"chain_id\": \"Chain1_ChatApplication\", \"feedba...</td>\n",
       "      <td>101</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.999164</td>\n",
       "      <td>[{'args': {'text1': 'This will be logged by de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       record_id                chain_id   \n",
       "0   record_hash_016d5d7f77bb9da0881d4149fdd4dd92  Chain1_ChatApplication  \\\n",
       "1   record_hash_1c188102dd1b2349cdb67882fe3d8d8a  Chain1_ChatApplication   \n",
       "2   record_hash_783160580bb6a9798f76e1fb0495061d  Chain1_ChatApplication   \n",
       "3   record_hash_9865e5b6907c71e9de97fa6a6e5807bb  Chain1_ChatApplication   \n",
       "4   record_hash_a002097b06f96f8a6e7cf476888901ee  Chain1_ChatApplication   \n",
       "5   record_hash_a2919b3a75a800dcca0d166c9af7d2ed  Chain3_ChatApplication   \n",
       "6   record_hash_a8897f746a480e35f8ce33bd11821cf8  Chain1_ChatApplication   \n",
       "7   record_hash_ae39fd378185b4ba992212110024860b  Chain3_ChatApplication   \n",
       "8   record_hash_b2bc294ccddc92e7d4fffc0276a0ae78  Chain3_ChatApplication   \n",
       "9   record_hash_ba1041598fdeecf93759b73c2c7b5343  Chain3_ChatApplication   \n",
       "10  record_hash_ba4bd26c4d1d75207c0913096e1712f1  Chain1_ChatApplication   \n",
       "11  record_hash_c4be9d29d225b98c5775a65375acc0e1  Chain1_ChatApplication   \n",
       "12  record_hash_ca80df4fef5529b10c0f62ee368caa89  Chain1_ChatApplication   \n",
       "13  record_hash_d01c3cba3aba060589ef45a21edb29a9  Chain1_ChatApplication   \n",
       "14  record_hash_d6c360c6054d757b466b51c40559d492  Chain1_ChatApplication   \n",
       "15  record_hash_dc3b6ffb2612a7027d57e5ea8e50b21d  Chain1_ChatApplication   \n",
       "16  record_hash_e7d04a60380f601aba25f9f61f763211  Chain1_ChatApplication   \n",
       "17  record_hash_eab1cf7cb795c00991c5f0334bc4b7e6  Chain3_ChatApplication   \n",
       "18  record_hash_ede76ca835c119b110e80ee1d3bc5622  Chain1_ChatApplication   \n",
       "19  record_hash_f78623a3df335ad1640b4551d2d5c1d7  Chain1_ChatApplication   \n",
       "20  record_hash_f9169869ef4bce865de40b9bab8fad14  Chain1_ChatApplication   \n",
       "\n",
       "                                         input   \n",
       "0   This will be logged by deferred evaluator.  \\\n",
       "1                                 que hora es?   \n",
       "2           This will be automatically logged.   \n",
       "3           This will be automatically logged.   \n",
       "4           This will be automatically logged.   \n",
       "5                                ¿que hora es?   \n",
       "6                                 que hora es?   \n",
       "7                                ¿que hora es?   \n",
       "8                                ¿que hora es?   \n",
       "9                                ¿que hora es?   \n",
       "10          This will be automatically logged.   \n",
       "11                                que hora es?   \n",
       "12  This will be logged by deferred evaluator.   \n",
       "13  This will be logged by deferred evaluator.   \n",
       "14          This will be automatically logged.   \n",
       "15          This will be automatically logged.   \n",
       "16          This will be automatically logged.   \n",
       "17                               ¿que hora es?   \n",
       "18                                que hora es?   \n",
       "19          This will be automatically logged.   \n",
       "20  This will be logged by deferred evaluator.   \n",
       "\n",
       "                                               output   \n",
       "0   \\n\\nDeferred Evaluator is an automated scoring...  \\\n",
       "1                        \\n\\nLa hora actual es 12:35.   \n",
       "2   \\n\\nThis means that the action you are taking ...   \n",
       "3   \\n\\nIn order to keep your records organized an...   \n",
       "4   \\n\\nThis means that any time you perform an ac...   \n",
       "5   \\n\\nLa hora actual es [hora en la zona horaria...   \n",
       "6   \\n\\nRespuesta: Actualmente, dependiendo de la ...   \n",
       "7                  \\n\\nLa hora actual es las 11:30pm.   \n",
       "8   \\n\\nLa hora actual depende de la ubicación. Si...   \n",
       "9   \\n\\nLa hora actual es la hora del reloj del si...   \n",
       "10  \\n\\nThis means that any activities will be tra...   \n",
       "11  \\n\\nLa hora actual es la 1:48 pm (horario del ...   \n",
       "12  \\n\\nDeferred evaluator is a feature of Java Pl...   \n",
       "13  \\n\\nDeferred evaluator is a type of computer p...   \n",
       "14   \\n\\nYes, this action will be automatically lo...   \n",
       "15  \\n\\nThis log entry will be saved in your accou...   \n",
       "16  \\n\\nYes, this will be automatically logged. Al...   \n",
       "17  \\n\\nLa hora actual depende de su ubicación. En...   \n",
       "18  \\n\\nEn este momento, dependiendo de tu ubicaci...   \n",
       "19  \\n\\nThis message indicates that the action or ...   \n",
       "20  \\n\\nDeferred evaluator is a feature in JavaScr...   \n",
       "\n",
       "                                          record_json tags   \n",
       "0   {\"record_id\": \"record_hash_016d5d7f77bb9da0881...       \\\n",
       "1   {\"record_id\": \"record_hash_1c188102dd1b2349cdb...        \n",
       "2   {\"record_id\": \"record_hash_783160580bb6a9798f7...        \n",
       "3   {\"record_id\": \"record_hash_9865e5b6907c71e9de9...        \n",
       "4   {\"record_id\": \"record_hash_a002097b06f96f8a6e7...        \n",
       "5   {\"record_id\": \"record_hash_a2919b3a75a800dcca0...        \n",
       "6   {\"record_id\": \"record_hash_a8897f746a480e35f8c...        \n",
       "7   {\"record_id\": \"record_hash_ae39fd378185b4ba992...        \n",
       "8   {\"record_id\": \"record_hash_b2bc294ccddc92e7d4f...        \n",
       "9   {\"record_id\": \"record_hash_ba1041598fdeecf9375...        \n",
       "10  {\"record_id\": \"record_hash_ba4bd26c4d1d75207c0...        \n",
       "11  {\"record_id\": \"record_hash_c4be9d29d225b98c577...        \n",
       "12  {\"record_id\": \"record_hash_ca80df4fef5529b10c0...        \n",
       "13  {\"record_id\": \"record_hash_d01c3cba3aba060589e...        \n",
       "14  {\"record_id\": \"record_hash_d6c360c6054d757b466...        \n",
       "15  {\"record_id\": \"record_hash_dc3b6ffb2612a7027d5...        \n",
       "16  {\"record_id\": \"record_hash_e7d04a60380f601aba2...        \n",
       "17  {\"record_id\": \"record_hash_eab1cf7cb795c00991c...        \n",
       "18  {\"record_id\": \"record_hash_ede76ca835c119b110e...        \n",
       "19  {\"record_id\": \"record_hash_f78623a3df335ad1640...        \n",
       "20  {\"record_id\": \"record_hash_f9169869ef4bce865de...        \n",
       "\n",
       "                            ts   \n",
       "0   2023-06-08 09:42:51.602106  \\\n",
       "1   2023-06-08 09:42:41.008099   \n",
       "2   2023-06-08 09:42:39.554762   \n",
       "3   2023-06-08 09:38:05.778958   \n",
       "4   2023-06-08 14:02:47.324103   \n",
       "5   2023-06-08 14:10:22.818910   \n",
       "6   2023-06-08 14:02:58.328323   \n",
       "7   2023-06-08 09:42:30.386223   \n",
       "8   2023-06-08 09:37:55.874846   \n",
       "9   2023-06-08 14:06:03.861315   \n",
       "10  2023-06-08 14:06:12.685336   \n",
       "11  2023-06-08 09:38:08.635894   \n",
       "12  2023-06-08 09:39:03.025656   \n",
       "13  2023-06-08 14:06:32.610699   \n",
       "14  2023-06-08 09:37:59.042334   \n",
       "15  2023-06-08 09:42:33.134843   \n",
       "16  2023-06-08 14:06:08.056405   \n",
       "17  2023-06-08 14:02:36.095685   \n",
       "18  2023-06-08 14:06:18.121747   \n",
       "19  2023-06-08 14:02:43.349272   \n",
       "20  2023-06-08 14:03:06.857671   \n",
       "\n",
       "                                           cost_json   \n",
       "0                 {\"n_tokens\": 134, \"cost\": 0.00268}  \\\n",
       "1    {\"n_tokens\": 30, \"cost\": 0.0006000000000000001}   \n",
       "2                   {\"n_tokens\": 85, \"cost\": 0.0017}   \n",
       "3                 {\"n_tokens\": 116, \"cost\": 0.00232}   \n",
       "4                   {\"n_tokens\": 85, \"cost\": 0.0017}   \n",
       "5                 {\"n_tokens\": 114, \"cost\": 0.00228}   \n",
       "6                  {\"n_tokens\": 93, \"cost\": 0.00186}   \n",
       "7                  {\"n_tokens\": 34, \"cost\": 0.00068}   \n",
       "8                  {\"n_tokens\": 120, \"cost\": 0.0024}   \n",
       "9                  {\"n_tokens\": 96, \"cost\": 0.00192}   \n",
       "10                  {\"n_tokens\": 70, \"cost\": 0.0014}   \n",
       "11                 {\"n_tokens\": 51, \"cost\": 0.00102}   \n",
       "12   {\"n_tokens\": 95, \"cost\": 0.0018999999999999998}   \n",
       "13  {\"n_tokens\": 104, \"cost\": 0.0020800000000000003}   \n",
       "14                 {\"n_tokens\": 62, \"cost\": 0.00124}   \n",
       "15                 {\"n_tokens\": 57, \"cost\": 0.00114}   \n",
       "16                 {\"n_tokens\": 54, \"cost\": 0.00108}   \n",
       "17                {\"n_tokens\": 107, \"cost\": 0.00214}   \n",
       "18                  {\"n_tokens\": 75, \"cost\": 0.0015}   \n",
       "19                 {\"n_tokens\": 97, \"cost\": 0.00194}   \n",
       "20                {\"n_tokens\": 101, \"cost\": 0.00202}   \n",
       "\n",
       "                                           chain_json  total_tokens   \n",
       "0   {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...           134  \\\n",
       "1   {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            30   \n",
       "2   {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            85   \n",
       "3   {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...           116   \n",
       "4   {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            85   \n",
       "5   {\"chain_id\": \"Chain3_ChatApplication\", \"feedba...           114   \n",
       "6   {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            93   \n",
       "7   {\"chain_id\": \"Chain3_ChatApplication\", \"feedba...            34   \n",
       "8   {\"chain_id\": \"Chain3_ChatApplication\", \"feedba...           120   \n",
       "9   {\"chain_id\": \"Chain3_ChatApplication\", \"feedba...            96   \n",
       "10  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            70   \n",
       "11  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            51   \n",
       "12  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            95   \n",
       "13  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...           104   \n",
       "14  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            62   \n",
       "15  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            57   \n",
       "16  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            54   \n",
       "17  {\"chain_id\": \"Chain3_ChatApplication\", \"feedba...           107   \n",
       "18  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            75   \n",
       "19  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...            97   \n",
       "20  {\"chain_id\": \"Chain1_ChatApplication\", \"feedba...           101   \n",
       "\n",
       "    total_cost  language_match   \n",
       "0      0.00268        0.992349  \\\n",
       "1      0.00060        0.007279   \n",
       "2      0.00170        0.989833   \n",
       "3      0.00232        0.994001   \n",
       "4      0.00170        0.997430   \n",
       "5      0.00228             NaN   \n",
       "6      0.00186        0.997064   \n",
       "7      0.00068        0.996550   \n",
       "8      0.00240        0.994190   \n",
       "9      0.00192        0.994699   \n",
       "10     0.00140        0.999519   \n",
       "11     0.00102        0.962084   \n",
       "12     0.00190        0.997747   \n",
       "13     0.00208             NaN   \n",
       "14     0.00124             NaN   \n",
       "15     0.00114             NaN   \n",
       "16     0.00108             NaN   \n",
       "17     0.00214        0.994595   \n",
       "18     0.00150        0.996967   \n",
       "19     0.00194             NaN   \n",
       "20     0.00202        0.999164   \n",
       "\n",
       "                                 language_match_calls  \n",
       "0   [{'args': {'text1': 'This will be logged by de...  \n",
       "1   [{'args': {'text1': 'que hora es?', 'text2': '...  \n",
       "2   [{'args': {'text1': 'This will be automaticall...  \n",
       "3   [{'args': {'text1': 'This will be automaticall...  \n",
       "4   [{'args': {'text1': 'This will be automaticall...  \n",
       "5                                                 NaN  \n",
       "6   [{'args': {'text1': 'que hora es?', 'text2': '...  \n",
       "7   [{'args': {'text1': '¿que hora es?', 'text2': ...  \n",
       "8   [{'args': {'text1': '¿que hora es?', 'text2': ...  \n",
       "9   [{'args': {'text1': '¿que hora es?', 'text2': ...  \n",
       "10  [{'args': {'text1': 'This will be automaticall...  \n",
       "11  [{'args': {'text1': 'que hora es?', 'text2': '...  \n",
       "12  [{'args': {'text1': 'This will be logged by de...  \n",
       "13                                                 []  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17  [{'args': {'text1': '¿que hora es?', 'text2': ...  \n",
       "18  [{'args': {'text1': 'que hora es?', 'text2': '...  \n",
       "19                                                NaN  \n",
       "20  [{'args': {'text1': 'This will be logged by de...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_records_and_feedback(chain_ids=[])[0] # pass an empty list of chain_ids to get all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging\n",
    "\n",
    "## Automatic Logging\n",
    "\n",
    "The simplest method for logging with TruLens is by wrapping with TruChain and including the tru argument, as shown in the quickstart.\n",
    "\n",
    "This is done like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chain Chain1_ChatApplication -> default.sqlite\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "⚡ feedback feedback_result_hash_bc6fdabde84b50adee5539f41e4b5cda on record_hash_a2919b3a75a800dcca0d166c9af7d2ed -> default.sqlite\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'This will be automatically logged.',\n",
       " 'text': '\\n\\nThis means the data or information that you enter into the application will be securely stored and tracked. This includes any changes or updates that are made to the data or information. Logging this information helps with tracking and improving user experience, since you can analyze the information to identify potential areas for improvement. It can also help you easily access specific information and keep your system secure.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truchain = TruChain(\n",
    "    chain,\n",
    "    chain_id='Chain1_ChatApplication',\n",
    "    tru=tru\n",
    ")\n",
    "truchain(\"This will be automatically logged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback functions can also be logged automatically by providing them in a list to the feedbacks arg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ record record_hash_72334ec4f5e07d9ae580f6435d6832c1 from Chain1_ChatApplication -> default.sqlite\n",
      "✅ chain Chain1_ChatApplication -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ef50204d7ba1af7567641ca2fffb444c -> default.sqlite\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'This will be automatically logged.',\n",
       " 'text': '\\n\\nSure thing! All your interactions with our chatbot will be automatically logged and stored securely. This helps us improve our service and provide you with the most up to date and accurate information.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ record record_hash_cc2b453d49b048c5d224984627207dba from Chain1_ChatApplication -> default.sqlite"
     ]
    }
   ],
   "source": [
    "truchain = TruChain(\n",
    "    chain,\n",
    "    chain_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_lang_match], # feedback functions\n",
    "    tru=tru\n",
    ")\n",
    "truchain(\"This will be automatically logged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Logging\n",
    "\n",
    "### Wrap with TruChain to instrument your chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`feedback_mode` is FeedbackMode.WITH_CHAIN_THREAD but `tru` was not specified. Reverting to FeedbackMode.NONE .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TruChain(chain, chain_id='Chain1_ChatApplication')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logging and instrumentation\n",
    "\n",
    "Making the first call to your wrapped LLM Application will now also produce a log or \"record\" of the chain execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "⚡ feedback feedback_result_hash_cf92f0820b94232543823684516f0dae on record_hash_cc2b453d49b048c5d224984627207dba -> default.sqlite\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt_input = 'que hora es?'\n",
    "gpt3_response, record = tc.call_with_record(prompt_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can log the records but first we need to log the chain itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chain Chain1_ChatApplication -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "tru.add_chain(chain=truchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can log the record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ record record_hash_f884d5a92e02dc17fb432696199662b2 from Chain1_ChatApplication -> default.sqlite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'record_hash_f884d5a92e02dc17fb432696199662b2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.add_record(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Quality\n",
    "\n",
    "Following the request to your app, you can then evaluate LLM quality using feedback functions. This is completed in a sequential call to minimize latency for your application, and evaluations will also be logged to your local machine.\n",
    "\n",
    "To get feedback on the quality of your LLM, you can use any of the provided feedback functions or add your own.\n",
    "\n",
    "To assess your LLM quality, you can provide the feedback functions to `tru.run_feedback()` in a list provided to `feedback_functions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeedbackResult(feedback_result_id='feedback_result_hash_1fc6f5b6e992197dd723e5edf8e1f3a7', record_id='record_hash_f884d5a92e02dc17fb432696199662b2', chain_id='Chain1_ChatApplication', feedback_definition_id='feedback_definition_hash_ef50204d7ba1af7567641ca2fffb444c', last_ts=datetime.datetime(2023, 6, 8, 14, 10, 39, 728403), status=<FeedbackResultStatus.DONE: 'done'>, cost=Cost(n_tokens=0, cost=0.0), tags='', name='language_match', calls=[FeedbackCall(args={'text1': 'que hora es?', 'text2': '\\n\\nLa hora actual es la hora del reloj en la ubicación en la que te encuentras. Si deseas saber la hora exacta en la zona horaria actual, también puedes consultar la hora mundial en línea.'}, ret=0.9977105877696886)], result=0.9977105877696886, error=None)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[f_lang_match]\n",
    ")\n",
    "display(feedback_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After capturing feedback, you can then log it to your local database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(implementation=Method(obj=Obj(cls=Class(name='Huggingface', module=Module(package_name='trulens_eval', module_name='trulens_eval.tru_feedback')), id=4930116176, init_kwargs={}), name='language_match'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_ef50204d7ba1af7567641ca2fffb444c', selectors={'text1': JSONPath().__record__.main_input, 'text2': JSONPath().__record__.main_output}, imp=<bound method Huggingface.language_match of Huggingface(endpoint=<trulens_eval.provider_apis.Endpoint object at 0x125db9c50>)>, agg=<function mean at 0x110d7f100>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_lang_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeedbackResult(feedback_result_id='feedback_result_hash_1fc6f5b6e992197dd723e5edf8e1f3a7', record_id='record_hash_f884d5a92e02dc17fb432696199662b2', chain_id='Chain1_ChatApplication', feedback_definition_id='feedback_definition_hash_ef50204d7ba1af7567641ca2fffb444c', last_ts=datetime.datetime(2023, 6, 8, 14, 10, 39, 728403), status=<FeedbackResultStatus.DONE: 'done'>, cost=Cost(n_tokens=0, cost=0.0), tags='', name='language_match', calls=[FeedbackCall(args={'text1': 'que hora es?', 'text2': '\\n\\nLa hora actual es la hora del reloj en la ubicación en la que te encuentras. Si deseas saber la hora exacta en la zona horaria actual, también puedes consultar la hora mundial en línea.'}, ret=0.9977105877696886)], result=0.9977105877696886, error=None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ feedback feedback_result_hash_1fc6f5b6e992197dd723e5edf8e1f3a7 on record_hash_f884d5a92e02dc17fb432696199662b2 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-band Feedback evaluation\n",
    "\n",
    "In the above example, the feedback function evaluation is done in the same process as the chain evaluation. The alternative approach is the use the provided persistent evaluator started via `tru.start_deferred_feedback_evaluator`. Then specify the `feedback_mode` for `TruChain` as `deferred` to let the evaluator handle the feedback functions.\n",
    "\n",
    "For demonstration purposes, we start the evaluator here but it can be started in another process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chain Chain1_ChatApplication -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ef50204d7ba1af7567641ca2fffb444c -> default.sqlite\n",
      "Looking for things to do. Stop me with `tru.stop_evaluator()`.\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Starting run for row 15.\n",
      "⚡ feedback feedback_result_hash_f4208386b9fa850d92c39e345800cccc on record_hash_d01c3cba3aba060589ef45a21edb29a9 -> default.sqlite\n",
      "⚡ feedback feedback_result_hash_f4208386b9fa850d92c39e345800cccc on record_hash_d01c3cba3aba060589ef45a21edb29a9 -> default.sqlite\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Evaluator stopped.\n",
      "✅ record record_hash_96fec64040783dcbba8e79fe0e11fddc from Chain1_ChatApplication -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "truchain: TruChain = TruChain(\n",
    "    chain,\n",
    "    chain_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_lang_match],\n",
    "    tru=tru,\n",
    "    feedback_mode=\"deferred\"\n",
    ")\n",
    "\n",
    "tru.start_evaluator()\n",
    "truchain(\"This will be logged by deferred evaluator.\")\n",
    "tru.stop_evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-the-box Feedback Functions\n",
    "See: <https://www.trulens.org/trulens_eval/api/tru_feedback/>\n",
    "\n",
    "## Relevance\n",
    "\n",
    "This evaluates the *relevance* of the LLM response to the given text by LLM prompting.\n",
    "\n",
    "Relevance is currently only available with OpenAI ChatCompletion API.\n",
    "\n",
    "## Sentiment\n",
    "\n",
    "This evaluates the *positive sentiment* of either the prompt or response.\n",
    "\n",
    "Sentiment is currently available to use with OpenAI, HuggingFace or Cohere as the model provider.\n",
    "\n",
    "* The OpenAI sentiment feedback function prompts a Chat Completion model to rate the sentiment from 1 to 10, and then scales the response down to 0-1.\n",
    "* The HuggingFace sentiment feedback function returns a raw score from 0 to 1.\n",
    "* The Cohere sentiment feedback function uses the classification endpoint and a small set of examples stored in `feedback_prompts.py` to return either a 0 or a 1.\n",
    "\n",
    "## Model Agreement\n",
    "\n",
    "Model agreement uses OpenAI to attempt an honest answer at your prompt with system prompts for correctness, and then evaluates the agreement of your LLM response to this model on a scale from 1 to 10. The agreement with each honest bot is then averaged and scaled from 0 to 1.\n",
    "\n",
    "## Language Match\n",
    "\n",
    "This evaluates if the language of the prompt and response match.\n",
    "\n",
    "Language match is currently only available to use with HuggingFace as the model provider. This feedback function returns a score in the range from 0 to 1, where 1 indicates match and 0 indicates mismatch.\n",
    "\n",
    "## Toxicity\n",
    "\n",
    "This evaluates the toxicity of the prompt or response.\n",
    "\n",
    "Toxicity is currently only available to be used with HuggingFace, and uses a classification endpoint to return a score from 0 to 1. The feedback function is negated as not_toxicity, and returns a 1 if not toxic and a 0 if toxic.\n",
    "\n",
    "## Moderation\n",
    "\n",
    "The OpenAI Moderation API is made available for use as feedback functions. This includes hate, hate/threatening, self-harm, sexual, sexual/minors, violence, and violence/graphic. Each is negated (ex: not_hate) so that a 0 would indicate that the moderation rule is violated. These feedback functions return a score in the range 0 to 1.\n",
    "\n",
    "# Adding new feedback functions\n",
    "\n",
    "Feedback functions are an extensible framework for evaluating LLMs. You can add your own feedback functions to evaluate the qualities required by your application by updating `trulens_eval/tru_feedback.py`. If your contributions would be useful for others, we encourage you to contribute to TruLens!\n",
    "\n",
    "Feedback functions are organized by model provider into Provider classes.\n",
    "\n",
    "The process for adding new feedback functions is:\n",
    "1. Create a new Provider class or locate an existing one that applies to your feedback function. If your feedback function does not rely on a model provider, you can create a standalone class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ feedback feedback_result_hash_d92a5b53e3a79222f35777b3dc2385ea on record_hash_96fec64040783dcbba8e79fe0e11fddc -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Provider\n",
    "\n",
    "class StandAlone(Provider):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add a new feedback function method to your selected class. Your new method can either take a single text (str) as a parameter or both prompt (str) and response (str). It should return a float between 0 (worst) and 1 (best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback(self, text: str) -> float:\n",
    "        \"\"\"\n",
    "        Describe how the model works\n",
    "\n",
    "        Parameters:\n",
    "            text (str): Text to evaluate.\n",
    "            Can also be prompt (str) and response (str).\n",
    "\n",
    "        Returns:\n",
    "            float: A value between 0 (worst) and 1 (best).\n",
    "        \"\"\"\n",
    "        return float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gpt3_response, record = tc.call_with_record(prompt_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record(record_id='record_hash_6f1f4bfc9032e183b94a35dac69149f6', chain_id='Chain1_ChatApplication', cost=Cost(n_tokens=62, cost=0.00124), ts=datetime.datetime(2023, 6, 8, 14, 10, 48, 530952), tags='', main_input='que hora es?', main_output='\\n\\nLa hora actual es [ time ]. Esto se determina por la rotación de la Tierra alrededor del Sol y se mide en Zona Horaria Universal (UTC).', main_error='None', calls=[RecordChainCall(chain_stack=(RecordChainCallMethod(path=JSONPath().chain, method=MethodIdent(module_name='langchain.chains.llm', class_name='LLMChain', method_name='_call')),), args={'inputs': {'prompt': 'que hora es?'}}, rets={'text': '\\n\\nLa hora actual es [ time ]. Esto se determina por la rotación de la Tierra alrededor del Sol y se mide en Zona Horaria Universal (UTC).'}, error=None, start_time=datetime.datetime(2023, 6, 8, 14, 10, 45, 329934), end_time=datetime.datetime(2023, 6, 8, 14, 10, 48, 530740), pid=44277, tid=39466436)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lang_match = Feedback(hugs.language_match).on(\n",
    "    text1=Query.RecordInput, text2=Query.RecordOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[f_lang_match]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeedbackResult(feedback_result_id='feedback_result_hash_13b60d050cd1e0912dddb0851ca60915', record_id='record_hash_6f1f4bfc9032e183b94a35dac69149f6', chain_id='Chain1_ChatApplication', feedback_definition_id='feedback_definition_hash_ef50204d7ba1af7567641ca2fffb444c', last_ts=datetime.datetime(2023, 6, 8, 14, 10, 48, 653412), status=<FeedbackResultStatus.DONE: 'done'>, cost=Cost(n_tokens=0, cost=0.0), tags='', name='language_match', calls=[FeedbackCall(args={'text1': 'que hora es?', 'text2': '\\n\\nLa hora actual es [ time ]. Esto se determina por la rotación de la Tierra alrededor del Sol y se mide en Zona Horaria Universal (UTC).'}, ret=0.9979190410085721)], result=0.9979190410085721, error=None)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ feedback feedback_result_hash_13b60d050cd1e0912dddb0851ca60915 on record_hash_6f1f4bfc9032e183b94a35dac69149f6 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Working Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "✅ record record_hash_391870bd47cf45dd9d62a058a27e7c83 from Chain1_ChatApplication -> default.sqlite\n",
      "⚡ feedback feedback_result_hash_f6374fbb47e521daebcccad1264e1eeb on record_hash_391870bd47cf45dd9d62a058a27e7c83 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "z=truchain(\"This will be automatically logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'This will be automatically logged.',\n",
       " 'text': '\\n\\nThis response is referring to data which is being kept and tracked automatically. This type of data logging is commonly used in software programs or applications in which the data collected is used to track and analyze user activity, trends, or other factors. By logging certain data points, businesses and organizations can have a better understanding of how their users interact with their systems.'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chain1_ChatApplication'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.record_id\n",
    "tc.chain_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ feedback feedback_result_hash_31e6dc231f64b9274854ceaa0a1f5801 on record_hash_391870bd47cf45dd9d62a058a27e7c83 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.schema import FeedbackResult\n",
    "# Simple Feedback add\n",
    "tru.db.insert_feedback(FeedbackResult(name=\"thumbs up result\", \n",
    "                                      record_id=\"record_hash_391870bd47cf45dd9d62a058a27e7c83\",\n",
    "                                      chain_id=\"Chain1_ChatApplication\", \n",
    "                                      result=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Network URL: http://192.168.0.168:8564\n",
      "  External URL: http://96.60.0.140:8564\n",
      "\n",
      "  For better performance, install the Watchdog module:\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "openai api: 0requests [00:00, ?requests/s]\n",
      "\r",
      "huggingface api: 0requests [00:00, ?requests/s]\u001b[A\n",
      "\n",
      "\r",
      "cohere api: 0requests [00:00, ?requests/s]\u001b[A\u001b[A2023-06-08 16:59:36.389 Serialization of dataframe to Arrow table was unsuccessful due to: (\"Could not convert <FeedbackResultStatus.NONE: 'none'> with type FeedbackResultStatus: did not recognize Python value type when inferring an Arrow data type\", 'Conversion failed for column status with type object'). Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n"
     ]
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chain myapp -> default.sqlite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'myapp'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.db.insert_chain_id(\"myapp\")\n",
    "#tru._insert_or_replace_vals(table=self.TABLE_CHAINS, vals=(\"myapp\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record(record_id='record_hash_6f1f4bfc9032e183b94a35dac69149f6', chain_id='Chain1_ChatApplication', cost=Cost(n_tokens=62, cost=0.00124), ts=datetime.datetime(2023, 6, 8, 14, 10, 48, 530952), tags='', main_input='que hora es?', main_output='\\n\\nLa hora actual es [ time ]. Esto se determina por la rotación de la Tierra alrededor del Sol y se mide en Zona Horaria Universal (UTC).', main_error='None', calls=[RecordChainCall(chain_stack=(RecordChainCallMethod(path=JSONPath().chain, method=MethodIdent(module_name='langchain.chains.llm', class_name='LLMChain', method_name='_call')),), args={'inputs': {'prompt': 'que hora es?'}}, rets={'text': '\\n\\nLa hora actual es [ time ]. Esto se determina por la rotación de la Tierra alrededor del Sol y se mide en Zona Horaria Universal (UTC).'}, error=None, start_time=datetime.datetime(2023, 6, 8, 14, 10, 45, 329934), end_time=datetime.datetime(2023, 6, 8, 14, 10, 48, 530740), pid=44277, tid=39466436)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is a record: Needed because it is something that can be serialized by us\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Record\n",
    "# Need to intiate my record\n",
    "# Need to explain Records are serialized class dictionaries\n",
    "# need to disseminate main_input and main_output are the first class items\n",
    "\n",
    "# record id should be assigned\n",
    "my_record = Record(record_id=\"1234\", \n",
    "                   chain_id=\"myapp\", \n",
    "                   main_input=\"This is an input query?\", \n",
    "                   main_output=\"This is the LLM App output response\", \n",
    "                   my_thumbs_field=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Provider\n",
    "\n",
    "class StandAlone(Provider):\n",
    "    pass\n",
    "    def my_human_feedback(self, text: str, thumbs:bool) -> float:\n",
    "        \"\"\"\n",
    "        Describe how the model works\n",
    "\n",
    "        Parameters:\n",
    "            text (str): Text to evaluate.\n",
    "            Can also be prompt (str) and response (str).\n",
    "\n",
    "        Returns:\n",
    "            float: A value between 0 (worst) and 1 (best).\n",
    "        \"\"\"\n",
    "        len(text) + int(thumbs)\n",
    "        return float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHugs(Huggingface):\n",
    "    # https://huggingface.co/models\n",
    "    # https://huggingface.co/ProsusAI/finbert\n",
    "    # show hosted_ingerence_api on model card\n",
    "\n",
    "\n",
    "    def my_hugs_feedback(self, text1: str, text2: str) -> float:\n",
    "        HUGS_SENTIMENT_API_URL = \"https://api-inference.huggingface.co/models/ProsusAI/finbert\"\n",
    "\n",
    "        def get_scores(text):\n",
    "            payload = {\"inputs\": text}\n",
    "            hf_response = self.endpoint.post(\n",
    "                url=HUGS_LANGUAGE_API_URL, payload=payload, timeout=30\n",
    "            )\n",
    "            return {r['label']: r['score'] for r in hf_response}\n",
    "\n",
    "        scores: AsyncResult[Dict] = TP().promise(\n",
    "            get_scores, text=text1[:max_length]\n",
    "        )\n",
    "        return scores\n",
    "\n",
    "        return l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hugs = MyHugs()\n",
    "my_standalone = StandAlone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feedback_function_hugs = Feedback(my_hugs.my_hugs_feedback).on(\n",
    "    text1=Query.RecordInput, text2=Query.RecordOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feedback_function_standalone = Feedback(my_standalone.my_human_feedback).on(\n",
    "    text=Query.RecordOutput, thumbs=Query.Record.my_thumb_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feedback_results \u001b[38;5;241m=\u001b[39m tru\u001b[38;5;241m.\u001b[39mrun_feedback_functions(\n\u001b[1;32m      2\u001b[0m     record\u001b[38;5;241m=\u001b[39mmy_record,\n\u001b[1;32m      3\u001b[0m     feedback_functions\u001b[38;5;241m=\u001b[39m[my_feedback_function_standalone, my_feedback_function_hugs]\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/trulens/trulens_eval/trulens_eval/tru.py:118\u001b[0m, in \u001b[0;36mTru.run_feedback_functions\u001b[0;34m(self, record, feedback_functions, chain)\u001b[0m\n\u001b[1;32m    115\u001b[0m chain_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mchain_id\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     chain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb\u001b[38;5;241m.\u001b[39mget_chain(chain_id\u001b[38;5;241m=\u001b[39mchain_id)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain \u001b[39m\u001b[38;5;132;01m{chain_id}\u001b[39;00m\u001b[38;5;124m not present in db. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither add it with `tru.add_chain` or provide `chain_json` to `tru.run_feedback_functions`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         )\n",
      "File \u001b[0;32m~/trulens/trulens_eval/trulens_eval/tru_db.py:532\u001b[0m, in \u001b[0;36mLocalSQLite.get_chain\u001b[0;34m(self, chain_id)\u001b[0m\n\u001b[1;32m    529\u001b[0m result \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mfetchone()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    530\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens-llm-3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens-llm-3/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens-llm-3/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=my_record,\n",
    "    feedback_functions=[my_feedback_function_standalone, my_feedback_function_hugs]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a feedback_results: Needed because it is something that can be serialized by us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Ideal Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Provider\n",
    "\n",
    "class StandAlone(Provider):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback(self, text: str) -> float:\n",
    "        \"\"\"\n",
    "        Describe how the model works\n",
    "\n",
    "        Parameters:\n",
    "            text (str): Text to evaluate.\n",
    "            Can also be prompt (str) and response (str).\n",
    "\n",
    "        Returns:\n",
    "            float: A value between 0 (worst) and 1 (best).\n",
    "        \"\"\"\n",
    "        return float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feedback_function_standalone = Feedback(standalone.my_human_feedback).on(\n",
    "    text1=Query.RecordInput, text2=Query.RecordOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feedback_function_hugs = Feedback(hugs.my_hugs_feedback).on(\n",
    "    text1=Query.RecordInput, text2=Query.RecordOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[my_feedback_function]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens-llm-3",
   "language": "python",
   "name": "trulens-llm-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5737f6101ac92451320b0e41890107145710b89f85909f3780d702e7818f973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
