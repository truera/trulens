{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruBot testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY SET: OPENAI_API_KEY\n",
      "KEY SET: PINECONE_API_KEY\n",
      "KEY SET: PINECONE_ENV\n",
      "KEY SET: HUGGINGFACE_API_KEY\n",
      "KEY SET: SLACK_TOKEN\n",
      "KEY SET: SLACK_SIGNING_SECRET\n",
      "KEY SET: COHERE_API_KEY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac89397a734240f58dc4e87e5d6c812e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "huggingface api: 0requests [00:00, ?requests/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e9f28b2db842b7b5251d45aeb5e982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openai api: 0requests [00:00, ?requests/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trulens_eval.keys import *\n",
    "from trulens_eval.slackbot import get_or_make_chain, get_answer\n",
    "from trulens_eval.util import TP\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_feedback import Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tru().start_dashboard(_dev=True)\n",
    "# Tru().stop_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = Tru().start_evaluator()\n",
    "# Tru().stop_evaluator()\n",
    "# Tru().reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Who is Shayak?\n",
      "'Starting a new conversation with 0/default.'\n",
      "0 Wer ist Shayak?\n",
      "'Starting a new conversation with 0/default.'\n",
      "0 Kim jest Shayak?\n",
      "'Starting a new conversation with 0/default.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ¿Quién es Shayak?\n",
      "'Starting a new conversation with 0/default.'\n",
      "0 Was ist QII?\n",
      "'Starting a new conversation with 0/default.'\n",
      "0 Co jest QII?\n",
      "'Starting a new conversation with 0/default.'\n",
      "1 Who is Shayak?\n",
      "'Starting a new conversation with 1/lang_prompt.'\n",
      "1 Wer ist Shayak?\n",
      "'Starting a new conversation with 1/lang_prompt.'\n",
      "1 Kim jest Shayak?\n",
      "'Starting a new conversation with 1/lang_prompt.'\n",
      "1 ¿Quién es Shayak?\n",
      "'Starting a new conversation with 1/lang_prompt.'\n",
      "1 Was ist QII?\n",
      "'Starting a new conversation with 1/lang_prompt.'\n",
      "1 Co jest QII?\n",
      "'Starting a new conversation with 1/lang_prompt.'\n",
      "3 Who is Shayak?\n",
      "'Starting a new conversation with 3/filtered_context.'\n",
      "3 Wer ist Shayak?\n",
      "'Starting a new conversation with 3/filtered_context.'\n",
      "✅ chain 0/default -> default.sqlite\n",
      "3 Kim jest Shayak?\n",
      "'Starting a new conversation with 3/filtered_context.'\n",
      "3 ¿Quién es Shayak?\n",
      "'Starting a new conversation with 3/filtered_context.'\n",
      "3 Was ist QII?\n",
      "'Starting a new conversation with 3/filtered_context.'\n",
      "✅ chain 0/default -> default.sqlite\n",
      "✅ chain 1/lang_prompt -> default.sqlite\n",
      "3 Co jest QII?\n",
      "'Starting a new conversation with 3/filtered_context.'\n",
      "4 Who is Shayak?\n",
      "'Starting a new conversation with 4/filtered_context_and_lang_prompt.'\n",
      "4 Wer ist Shayak?\n",
      "'Starting a new conversation with 4/filtered_context_and_lang_prompt.'\n",
      "4 Kim jest Shayak?\n",
      "'Starting a new conversation with 4/filtered_context_and_lang_prompt.'\n",
      "4 ¿Quién es Shayak?\n",
      "'Starting a new conversation with 4/filtered_context_and_lang_prompt.'\n",
      "✅ chain 0/default -> default.sqlite\n",
      "4 Was ist QII?\n",
      "'Starting a new conversation with 4/filtered_context_and_lang_prompt.'\n",
      "4 Co jest QII?\n",
      "'Starting a new conversation with 4/filtered_context_and_lang_prompt.'\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ chain 0/default -> default.sqlite\n",
      "✅ chain 3/filtered_context -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ chain 1/lang_prompt -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ chain 0/default -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ chain 0/default -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ chain 3/filtered_context -> default.sqlite\n",
      "✅ chain 4/filtered_context_and_lang_prompt -> default.sqlite\n",
      "✅ chain 4/filtered_context_and_lang_prompt -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ chain 3/filtered_context -> default.sqlite\n",
      "✅ chain 4/filtered_context_and_lang_prompt -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ chain 3/filtered_context -> default.sqlite\n",
      "✅ chain 4/filtered_context_and_lang_prompt -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ chain 4/filtered_context_and_lang_prompt -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ chain 3/filtered_context -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ chain 1/lang_prompt -> default.sqlite\n",
      "✅ chain 1/lang_prompt -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ chain 4/filtered_context_and_lang_prompt -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ chain 1/lang_prompt -> default.sqlite\n",
      "✅ chain 3/filtered_context -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n",
      "✅ chain 1/lang_prompt -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_f59b41cfed0dee9c33d3b60392e8d07c -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_ccd4e97ffe2aeaf3ddb7a80dd2e20198 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_59b3cf85b09a398d397e22fa600d7d58 -> default.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "ERROR:root:openai request failed <class 'openai.error.RateLimitError'>=That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d225cda3e6a0507efcf73c3d2bf2306d in your message.). Retries=3.\n"
     ]
    }
   ],
   "source": [
    "selectors = [0,1,3,4]\n",
    "messages = [\"Who is Shayak?\", \"Wer ist Shayak?\", \"Kim jest Shayak?\", \"¿Quién es Shayak?\", \"Was ist QII?\", \"Co jest QII?\"]\n",
    "\n",
    "def test_bot(selector, question):\n",
    "    print(selector, question)\n",
    "    chain = get_or_make_chain(cid=question + str(selector), selector=selector)\n",
    "    answer = get_answer(chain=chain, question=question)\n",
    "    return answer\n",
    "\n",
    "results = []\n",
    "\n",
    "for s in selectors:\n",
    "    for m in messages:\n",
    "        results.append(TP().promise(test_bot, selector=s, question=m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import ConversationChain, HuggingFacePipeline\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, pipeline\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"chavinlo/alpaca-native\")\n",
    "\n",
    "base_model = LlamaForCausalLM.from_pretrained(\"chavinlo/alpaca-native\", device_map='auto')\n",
    "\n",
    "# Convert the model's parameters to a higher precision data type\n",
    "base_model = base_model.float()\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=256,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# We are going to set the memory to go back 4 turns\n",
    "# window_memory = ConversationBufferWindowMemory(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=local_llm, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some feedback functions.\n",
    "\n",
    "from trulens_eval import tru_feedback\n",
    "from trulens_eval.tru_db import Record\n",
    "import numpy as np\n",
    "\n",
    "hugs = tru_feedback.Huggingface()\n",
    "openai = tru_feedback.OpenAI()\n",
    "\n",
    "# Toxicity (of the response):\n",
    "f_toxic = tru_feedback.Feedback(hugs.not_toxic).on_response()\n",
    "\n",
    "# Language match (between prompt and response):\n",
    "f_lang_match = tru_feedback.Feedback(hugs.language_match).on(\n",
    "    text1=\"prompt\", text2=\"response\"\n",
    ")\n",
    "\n",
    "# Question to answer relevance:\n",
    "f_relevance = tru_feedback.Feedback(openai.relevance).on(\n",
    "    prompt=\"input\", response=\"output\"\n",
    ")\n",
    "\n",
    "# Question to context piece relevance:\n",
    "#f_qs_relevance = tru_feedback.Feedback(openai.qs_relevance).on(\n",
    "#    question=\"input\",\n",
    "#    statement=Record.chain.combine_docs_chain._call.args.inputs.input_documents\n",
    "#).on_multiple(\n",
    "#    multiarg=\"statement\", each_query=Record.page_content, agg=np.min\n",
    "#)\n",
    "\n",
    "feedbacks=[\n",
    "    # f_toxic, \n",
    "    f_lang_match, \n",
    "    # f_relevance, \n",
    "    # f_qs_relevance\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = Tru().Chain(conversation, chain_id=\"llama-7b-hf-convo\", feedbacks=feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, record = tc.call_with_record(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, record = tc.call_with_record(\"Who is Nora?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
