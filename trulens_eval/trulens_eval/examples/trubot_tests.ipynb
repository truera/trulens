{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruBot testing\n",
    "\n",
    "This notebook tests a conversation bot with vector-store context of TruEra website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport logging\\n\\nroot = logging.getLogger()\\nroot.setLevel(logging.DEBUG)\\n\\nhandler = logging.StreamHandler(sys.stdout)\\nhandler.setLevel(logging.DEBUG)\\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\\nhandler.setFormatter(formatter)\\nroot.addHandler(handler)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))\n",
    "\n",
    "\"\"\"\n",
    "import logging\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY SET: OPENAI_API_KEY\n",
      "KEY SET: PINECONE_API_KEY\n",
      "KEY SET: PINECONE_ENV\n",
      "KEY SET: HUGGINGFACE_API_KEY\n",
      "KEY SET: SLACK_TOKEN\n",
      "KEY SET: SLACK_SIGNING_SECRET\n",
      "KEY SET: COHERE_API_KEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface api: 0requests [00:00, ?requests/s]"
     ]
    }
   ],
   "source": [
    "from trulens_eval.keys import *\n",
    "from trulens_eval.slackbot import get_or_make_chain, get_answer\n",
    "from trulens_eval.util import TP\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_feedback import Huggingface\n",
    "Tru().reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pydantic model of type <class 'trulens_eval.tru_chain.TruChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain'> refuses to be turned into dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Starting a new conversation with 0/default.'\n",
      "✅ chain 0/default -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_fcc4831b4fe8b1a95047b2c509754872 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_61ef5175a13829ca6995d41921f2adae -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_6ddf51a5adb08c74609dac1132b3baef -> default.sqlite\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n",
      "dict already instrumented\n"
     ]
    }
   ],
   "source": [
    "chain = get_or_make_chain(cid=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pydantic model of type <class 'trulens_eval.tru_chain.TruChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.memory.summary_buffer.ConversationSummaryBufferMemory'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.llms.openai.OpenAI'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.prompts.prompt.PromptTemplate'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.memory.chat_message_histories.in_memory.ChatMessageHistory'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.combine_documents.stuff.StuffDocumentsChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.llm.LLMChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.prompts.prompt.PromptTemplate'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.llms.openai.OpenAI'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.prompts.prompt.PromptTemplate'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.llm.LLMChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.prompts.prompt.PromptTemplate'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.llms.openai.OpenAI'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.vectorstores.base.VectorStoreRetriever'> refuses to be turned into dict.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['class_info',\n",
       " 'chain_id',\n",
       " 'feedback_mode',\n",
       " 'recording',\n",
       " 'feedback_definitions',\n",
       " 'memory',\n",
       " 'callbacks',\n",
       " 'callback_manager',\n",
       " 'verbose',\n",
       " 'chain',\n",
       " 'feedbacks',\n",
       " 'tru',\n",
       " 'db']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chain.dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pydantic model of type <class 'trulens_eval.tru_chain.TruChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.memory.summary_buffer.ConversationSummaryBufferMemory'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.llms.openai.OpenAI'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.prompts.prompt.PromptTemplate'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.memory.chat_message_histories.in_memory.ChatMessageHistory'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.combine_documents.stuff.StuffDocumentsChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.llm.LLMChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.prompts.prompt.PromptTemplate'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.llms.openai.OpenAI'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.prompts.prompt.PromptTemplate'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.chains.llm.LLMChain'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.prompts.prompt.PromptTemplate'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.llms.openai.OpenAI'> refuses to be turned into dict.\n",
      "pydantic model of type <class 'langchain.vectorstores.base.VectorStoreRetriever'> refuses to be turned into dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* <class 'trulens_eval.util.Class'>\n",
      "['chain']\n",
      "Cannot create query for Iterable types like set at query *.chain.memory.llm.allowed_special. Convert the iterable to a sequence first.\n",
      "Cannot create query for Iterable types like set at query *.chain.combine_docs_chain.llm_chain.llm.allowed_special. Convert the iterable to a sequence first.\n",
      "Cannot create query for Iterable types like set at query *.chain.question_generator.llm.allowed_special. Convert the iterable to a sequence first.\n",
      "Unhandled object type default.sqlite <class 'pathlib.PosixPath'>\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.util import instrumented_classes\n",
    "from trulens_eval.util import Obj, ObjSerial, Method, FunctionOrMethod, all_objects, Class\n",
    "import json\n",
    "import pydantic\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "# jstr = chain.feedbacks[0].implementation.json()\n",
    "# j = json.loads(jstr)#FunctionOrMethod.parse_raw(j)\n",
    "\n",
    "from trulens_eval.utils.langchain import Is\n",
    "\n",
    "tests = [Is.chain, Is.vector_store, Is.llm, Is.prompt, Is.retriever, Is.memory, Is.chathistory]\n",
    "\n",
    "for q, ci, obj in instrumented_classes(chain.dict()):\n",
    "    print(q, type(ci))\n",
    "\n",
    "    assert isinstance(ci, Class), f\"class_info was not a Class object, was {ci}, {type(ci)}.\"\n",
    "\n",
    "    print(list(Is.what(ci)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Tru().start_dashboard(force=True, _dev=Path.cwd().parent.parent)\n",
    "thread = Tru().start_evaluator(restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = [0,1,3,4]\n",
    "messages = [\"Who is Shayak?\", \"Wer ist Shayak?\", \"Kim jest Shayak?\", \"¿Quién es Shayak?\", \"Was ist QII?\", \"Co jest QII?\"]\n",
    "\n",
    "selectors = selectors[2:3]\n",
    "messages = messages[2:3]\n",
    "\n",
    "def test_bot(selector, question):\n",
    "    print(selector, question)\n",
    "    chain = get_or_make_chain(cid=question + str(selector), selector=selector)\n",
    "    answer = get_answer(chain=chain, question=question)\n",
    "    return answer\n",
    "\n",
    "results = []\n",
    "\n",
    "for s in selectors:\n",
    "    for m in messages:\n",
    "        results.append(TP().promise(test_bot, selector=s, question=m))\n",
    "\n",
    "TP().finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import ConversationChain, HuggingFacePipeline\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, pipeline\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"chavinlo/alpaca-native\")\n",
    "\n",
    "base_model = LlamaForCausalLM.from_pretrained(\"chavinlo/alpaca-native\", device_map='auto')\n",
    "\n",
    "# Convert the model's parameters to a higher precision data type\n",
    "base_model = base_model.float()\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=256,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# We are going to set the memory to go back 4 turns\n",
    "# window_memory = ConversationBufferWindowMemory(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=local_llm, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
