{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruBot\n",
    "\n",
    "Example setup and monitoring of a conversational bot with context made up of the TruEra website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/examples/trubot_example.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/examples/trubot_example.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/examples/trubot_example.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Imports main tools:\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/examples/trubot_example.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m \u001b[39mimport\u001b[39;00m Feedback\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/examples/trubot_example.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m \u001b[39mimport\u001b[39;00m Huggingface\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/piotrm/repos/trulens/trulens_eval/trulens_eval/examples/trubot_example.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m \u001b[39mimport\u001b[39;00m Query\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/__init__.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Imports of most common parts of the library.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m    - util.py keys.py\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtru_chain\u001b[39;00m \u001b[39mimport\u001b[39;00m TruChain\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtru_feedback\u001b[39;00m \u001b[39mimport\u001b[39;00m Feedback\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtru_feedback\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/tru_chain.py:95\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mschema\u001b[39;00m \u001b[39mimport\u001b[39;00m RecordChainCallMethod\n\u001b[1;32m     94\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mschema\u001b[39;00m \u001b[39mimport\u001b[39;00m Cost\n\u001b[0;32m---> 95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtru_db\u001b[39;00m \u001b[39mimport\u001b[39;00m Query\n\u001b[1;32m     96\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtru_db\u001b[39;00m \u001b[39mimport\u001b[39;00m TruDB\n\u001b[1;32m     97\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrulens_eval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtru_feedback\u001b[39;00m \u001b[39mimport\u001b[39;00m Feedback\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/tru_db.py:48\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m NoneType \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m pp \u001b[39m=\u001b[39m PrettyPrinter()\n\u001b[0;32m---> 48\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mQuery\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m     \u001b[39m# Typing for type hints.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     Query \u001b[39m=\u001b[39m JSONPath\n\u001b[1;32m     53\u001b[0m     \u001b[39m# Instance for constructing queries for record json like `Record.chain.llm`.\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/tru_db.py:54\u001b[0m, in \u001b[0;36mQuery\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m Query \u001b[39m=\u001b[39m JSONPath\n\u001b[1;32m     53\u001b[0m \u001b[39m# Instance for constructing queries for record json like `Record.chain.llm`.\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m Record \u001b[39m=\u001b[39m Query()\u001b[39m.\u001b[39m__record__\n\u001b[1;32m     56\u001b[0m \u001b[39m# Instance for constructing queries for chain json.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m Chain \u001b[39m=\u001b[39m Query()\u001b[39m.\u001b[39m__chain__\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:785\u001b[0m, in \u001b[0;36mJSONPath.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, path: Optional[Tuple[Step, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 785\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(path\u001b[39m=\u001b[39;49mpath \u001b[39mor\u001b[39;49;00m ())\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:482\u001b[0m, in \u001b[0;36mSerialModel.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 482\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(_ \u001b[39m=\u001b[39m Class\u001b[39m.\u001b[39;49mof_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:1007\u001b[0m, in \u001b[0;36mClass.of_class\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m   1005\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mof_class\u001b[39m(\u001b[39mcls\u001b[39m: \u001b[39mtype\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1006\u001b[0m     \u001b[39mreturn\u001b[39;00m Class(\n\u001b[0;32m-> 1007\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, module\u001b[39m=\u001b[39mModule\u001b[39m.\u001b[39;49mof_module_name(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__module__\u001b[39;49m)\n\u001b[1;32m   1008\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:987\u001b[0m, in \u001b[0;36mModule.of_module_name\u001b[0;34m(module_name)\u001b[0m\n\u001b[1;32m    985\u001b[0m mod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(module_name)\n\u001b[1;32m    986\u001b[0m package_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m__package__\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m Module(package_name\u001b[39m=\u001b[39;49mpackage_name, module_name\u001b[39m=\u001b[39;49mmodule_name)\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:482\u001b[0m, in \u001b[0;36mSerialModel.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 482\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(_ \u001b[39m=\u001b[39m Class\u001b[39m.\u001b[39;49mof_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:1007\u001b[0m, in \u001b[0;36mClass.of_class\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m   1005\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mof_class\u001b[39m(\u001b[39mcls\u001b[39m: \u001b[39mtype\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1006\u001b[0m     \u001b[39mreturn\u001b[39;00m Class(\n\u001b[0;32m-> 1007\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, module\u001b[39m=\u001b[39mModule\u001b[39m.\u001b[39;49mof_module_name(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__module__\u001b[39;49m)\n\u001b[1;32m   1008\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:987\u001b[0m, in \u001b[0;36mModule.of_module_name\u001b[0;34m(module_name)\u001b[0m\n\u001b[1;32m    985\u001b[0m mod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(module_name)\n\u001b[1;32m    986\u001b[0m package_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m__package__\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m Module(package_name\u001b[39m=\u001b[39;49mpackage_name, module_name\u001b[39m=\u001b[39;49mmodule_name)\n",
      "    \u001b[0;31m[... skipping similar frames: SerialModel.__init__ at line 482 (733 times), Class.of_class at line 1007 (733 times), Module.of_module_name at line 987 (732 times)]\u001b[0m\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:987\u001b[0m, in \u001b[0;36mModule.of_module_name\u001b[0;34m(module_name)\u001b[0m\n\u001b[1;32m    985\u001b[0m mod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(module_name)\n\u001b[1;32m    986\u001b[0m package_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m__package__\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m Module(package_name\u001b[39m=\u001b[39;49mpackage_name, module_name\u001b[39m=\u001b[39;49mmodule_name)\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:482\u001b[0m, in \u001b[0;36mSerialModel.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 482\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(_ \u001b[39m=\u001b[39m Class\u001b[39m.\u001b[39;49mof_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:1007\u001b[0m, in \u001b[0;36mClass.of_class\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m   1005\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mof_class\u001b[39m(\u001b[39mcls\u001b[39m: \u001b[39mtype\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1006\u001b[0m     \u001b[39mreturn\u001b[39;00m Class(\n\u001b[0;32m-> 1007\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, module\u001b[39m=\u001b[39mModule\u001b[39m.\u001b[39;49mof_module_name(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__module__\u001b[39;49m)\n\u001b[1;32m   1008\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/trulens/trulens_eval/trulens_eval/util.py:985\u001b[0m, in \u001b[0;36mModule.of_module_name\u001b[0;34m(module_name)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mof_module_name\u001b[39m(module_name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 985\u001b[0m     mod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(module_name)\n\u001b[1;32m    986\u001b[0m     package_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m__package__\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m Module(package_name\u001b[39m=\u001b[39mpackage_name, module_name\u001b[39m=\u001b[39mmodule_name)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py38_trulens/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:988\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:148\u001b[0m, in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:163\u001b[0m, in \u001b[0;36m_get_module_lock\u001b[0;34m(name)\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "from pprint import PrettyPrinter\n",
    "from typing import Sequence\n",
    "\n",
    "from IPython.display import JSON\n",
    "# imports from langchain to build app\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain.prompts.chat import PromptTemplate\n",
    "from langchain.vectorstores import DocArrayHnswSearch\n",
    "import numpy as np\n",
    "\n",
    "# Imports main tools:\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval import Huggingface\n",
    "from trulens_eval import Query\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval import tru_feedback\n",
    "from trulens_eval import TruChain\n",
    "from trulens_eval.keys import *\n",
    "from trulens_eval.tru_db import Query\n",
    "from trulens_eval.tru_db import Record\n",
    "from trulens_eval.tru_feedback import Feedback\n",
    "from trulens_eval.tru_feedback import Huggingface\n",
    "from trulens_eval.util import Step\n",
    "from trulens_eval.utils.langchain import WithFilterDocuments\n",
    "\n",
    "# if using Pinecone vectordb:\n",
    "# from langchain.vectorstores import Pinecone\n",
    "# import pinecone\n",
    "\n",
    "tru = Tru()\n",
    "pp = PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "chain_id = \"TruBot\"\n",
    "\n",
    "# Pinecone configuration if using pinecone.\n",
    "# pinecone.init(\n",
    "#    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "#    environment=PINECONE_ENV  # next to api key in console\n",
    "#)\n",
    "#docsearch = Pinecone.from_existing_index(\n",
    "#    index_name=\"llmdemo\", embedding=embedding\n",
    "#)\n",
    "\n",
    "# LLM for completing prompts, and other tasks.\n",
    "llm = OpenAI(temperature=0, max_tokens=256)\n",
    "\n",
    "openai = tru_feedback.OpenAI()\n",
    "\n",
    "def new_conversation(\n",
    "    lang_prompt_fix: bool = False,\n",
    "    context_prompt_fix: bool = False,\n",
    "    context_filter_fix: bool = False,\n",
    "    feedbacks: Sequence[Feedback] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a chain for a new conversation (blank memory). Set flags to enable\n",
    "    adjustments to prompts or add context filtering.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert not(lang_prompt_fix and context_prompt_fix), \"Cannot use both prompt fixes at the same time.\"\n",
    "\n",
    "    # Embedding needed for Pinecone vector db.\n",
    "    embedding = OpenAIEmbeddings(model='text-embedding-ada-002')  # 1536 dims\n",
    "\n",
    "    # Conversation memory.\n",
    "    memory = ConversationSummaryBufferMemory(\n",
    "        max_token_limit=650,\n",
    "        llm=llm,\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key='answer'\n",
    "    )\n",
    "\n",
    "    # Pinecone alternative. Requires precomputed 'hnswlib_truera' folder.\n",
    "    docsearch = DocArrayHnswSearch.from_params(\n",
    "        embedding=embedding,\n",
    "        work_dir='hnswlib_trubot',\n",
    "        n_dim=1536,\n",
    "        max_elements=1024\n",
    "    )\n",
    "    retriever = docsearch.as_retriever()\n",
    "\n",
    "    # Better contexts fix, filter contexts with relevance:\n",
    "    if context_filter_fix: \n",
    "        def filter_by_relevance(query, doc):\n",
    "            return openai.qs_relevance(\n",
    "                question=query, statement=doc.page_content\n",
    "            ) > 0.5\n",
    "\n",
    "        retriever = WithFilterDocuments.of_retriever(\n",
    "            retriever=retriever, filter_func=filter_by_relevance\n",
    "        )\n",
    "\n",
    "    # Conversational chain puts it all together.\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        memory=memory,\n",
    "        get_chat_history=lambda a: a,\n",
    "        max_tokens_limit=4096\n",
    "    )\n",
    "\n",
    "    # Need to copy these otherwise various chains will feature templates that\n",
    "    # point to the same objects.\n",
    "    chain.combine_docs_chain.llm_chain.prompt = \\\n",
    "        chain.combine_docs_chain.llm_chain.prompt.copy()\n",
    "    chain.combine_docs_chain.document_prompt = \\\n",
    "        chain.combine_docs_chain.document_prompt.copy()\n",
    "\n",
    "    # Language mismatch fix:\n",
    "    if lang_prompt_fix:\n",
    "        chain.combine_docs_chain.llm_chain.prompt.template = \\\n",
    "            \"Use the following pieces of context to answer the question at the end \" \\\n",
    "            \"in the same language as the question. If you don't know the answer, \" \\\n",
    "            \"just say that you don't know, don't try to make up an answer.\\n\\n\" \\\n",
    "            \"{context}\\n\\n\" \\\n",
    "            \"Question: {question}\\n\" \\\n",
    "            \"Helpful Answer: \"\n",
    "\n",
    "    # Poor contexts fix using prompts:\n",
    "    elif context_prompt_fix:\n",
    "        chain.combine_docs_chain.llm_chain.prompt.template = \\\n",
    "            \"Use only the relevant contexts to answer the question at the end \" \\\n",
    "            \". Some pieces of context may not be relevant. If you don't know the answer, \" \\\n",
    "            \"just say that you don't know, don't try to make up an answer.\\n\\n\" \\\n",
    "            \"Contexts: \\n{context}\\n\\n\" \\\n",
    "            \"Question: {question}\\n\" \\\n",
    "            \"Helpful Answer: \"\n",
    "        chain.combine_docs_chain.document_prompt.template = \"\\tContext: {page_content}\"\n",
    "\n",
    "    # Trulens instrumentation.\n",
    "    tc = Tru().Chain(chain=chain, feedbacks=feedbacks, verbose=True)\n",
    "\n",
    "    return tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct feedback functions.\n",
    "\n",
    "hugs = tru_feedback.Huggingface()\n",
    "openai = tru_feedback.OpenAI()\n",
    "\n",
    "# Language match between question/answer.\n",
    "f_lang_match = Feedback(hugs.language_match).on(\n",
    "    text1=Query.RecordInput, text2=Query.RecordOutput\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on(\n",
    "    prompt=Query.RecordInput, response=Query.RecordOutput\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_qs_relevance = tru_feedback.Feedback(openai.qs_relevance).on(\n",
    "    question=Query.RecordInput,\n",
    "    statement=Query.Record.chain.combine_docs_chain._call.args.inputs.\n",
    "    input_documents[:].page_content\n",
    ").aggregate(np.min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a chain\n",
    "\n",
    "tc = new_conversation(\n",
    "    feedbacks=[f_lang_match],\n",
    "    # context_filter_fix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the chain\n",
    "\n",
    "res, record = tc.call_with_record(\"Who is Shayak?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
