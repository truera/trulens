{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY SET: OPENAI_API_KEY\n",
      "KEY SET: PINECONE_API_KEY\n",
      "KEY SET: PINECONE_ENV\n",
      "KEY SET: HUGGINGFACE_API_KEY\n",
      "KEY SET: SLACK_TOKEN\n",
      "KEY SET: SLACK_SIGNING_SECRET\n",
      "KEY SET: COHERE_API_KEY\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import JSON\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.vectorstores import DocArrayHnswSearch\n",
    "import numpy as np\n",
    "\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval import tru_feedback\n",
    "from trulens_eval.keys import *\n",
    "from trulens_eval.tru_db import Query\n",
    "from trulens_eval.tru_db import Record\n",
    "from trulens_eval.tru_feedback import Huggingface\n",
    "from trulens_eval.utils.langchain import WithFilterDocuments\n",
    "\n",
    "# if using Pinecone vectordb:\n",
    "# from langchain.vectorstores import Pinecone\n",
    "# import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPT-3 model\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "chain_id = \"TruBot\"\n",
    "\n",
    "identity = lambda h: h\n",
    "\n",
    "# Embedding needed for Pinecone vector db.\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-ada-002')  # 1536 dims\n",
    "\n",
    "# Pinecone configuration if using pinecone.\n",
    "# pinecone.init(\n",
    "#    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "#    environment=PINECONE_ENV  # next to api key in console\n",
    "#)\n",
    "#docsearch = Pinecone.from_existing_index(\n",
    "#    index_name=\"llmdemo\", embedding=embedding\n",
    "#)\n",
    "\n",
    "# Pinecone alternative. Requires precomputed 'hnswlib_truera' folder.\n",
    "docsearch = DocArrayHnswSearch.from_params(\n",
    "    embedding=embedding,\n",
    "    work_dir='hnswlib_truera',\n",
    "    n_dim=1536,\n",
    "    max_elements=1024\n",
    ")\n",
    "\n",
    "retriever = docsearch.as_retriever()\n",
    "\n",
    "# LLM for completing prompts, and other tasks.\n",
    "llm = OpenAI(temperature=0, max_tokens=128)\n",
    "\n",
    "# Conversation memory.\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    max_token_limit=650,\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    output_key='answer'\n",
    ")\n",
    "\n",
    "# Language mismatch fix:\n",
    "\"\"\"\n",
    "chain.combine_docs_chain.llm_chain.prompt.template = \\\n",
    "    \"Use the following pieces of context to answer the question at the end \" \\\n",
    "    \"in the same language as the question. If you don't know the answer, \" \\\n",
    "    \"just say that you don't know, don't try to make up an answer.\\n\\n\" \\\n",
    "    \"{context}\\n\\n\" \\\n",
    "    \"Question: {question}\\n\" \\\n",
    "    \"Helpful Answer: \"\n",
    "\"\"\"\n",
    "\n",
    "# Poor contexts fix using prompts:\n",
    "\"\"\"\n",
    "chain.combine_docs_chain.llm_chain.prompt.template = \\\n",
    "    \"Use only the relevant contexts to answer the question at the end \" \\\n",
    "    \". Some pieces of context may not be relevant. If you don't know the answer, \" \\\n",
    "    \"just say that you don't know, don't try to make up an answer.\\n\\n\" \\\n",
    "    \"Contexts: \\n{context}\\n\\n\" \\\n",
    "    \"Question: {question}\\n\" \\\n",
    "    \"Helpful Answer: \"\n",
    "chain.combine_docs_chain.document_prompt.template=\"\\tContext: {page_content}\"\n",
    "\"\"\"\n",
    "\n",
    "# Better contexts fix, filter contexts with relevance:\n",
    "\"\"\"\n",
    "def filter_by_relevance(query, doc):\n",
    "    return openai.qs_relevance(question=query, statement=doc.page_content) > 0.5\n",
    "\n",
    "retriever = WithFilterDocuments.of_retriever(\n",
    "    retriever=retriever, filter_func=filter_by_relevance\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Conversational chain puts it all together.\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    get_chat_history=identity,\n",
    "    max_tokens_limit=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705ffea400d4436e82c576608e377448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "huggingface api: 0requests [00:00, ?requests/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4441dc67dbbb4f1d9ee2a8ee8503055a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openai api: 0requests [00:00, ?requests/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feedbacl functions.\n",
    "\n",
    "hugs = tru_feedback.Huggingface()\n",
    "openai = tru_feedback.OpenAI()\n",
    "\n",
    "f_toxic = tru_feedback.Feedback(hugs.not_toxic).on_response()\n",
    "f_lang_match = tru_feedback.Feedback(hugs.language_match).on(\n",
    "    text1=\"prompt\", text2=\"response\"\n",
    ")\n",
    "f_relevance = tru_feedback.Feedback(openai.relevance).on(\n",
    "    prompt=\"input\", response=\"output\"\n",
    ")\n",
    "f_qs_relevance = tru_feedback.Feedback(openai.qs_relevance).on(\n",
    "    question=\"input\",\n",
    "    statement=Record.chain.combine_docs_chain._call.args.inputs.input_documents\n",
    ").on_multiple(\n",
    "    multiarg=\"statement\", each_query=Record.page_content, agg=np.min\n",
    ")\n",
    "\n",
    "feedbacks=[f_toxic, f_lang_match, f_relevance, f_qs_relevance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chain TruBot -> default.sqlite\n",
      "✅ feedback def. feedback_hash_c479553ae6ae61dc58f9b9c1d609ca40 -> default.sqlite\n",
      "✅ feedback def. feedback_hash_26c84c76d907d808c36028e024af63c0 -> default.sqlite\n",
      "✅ feedback def. feedback_hash_90b443be1347d732ededd19cd3968c72 -> default.sqlite\n",
      "✅ feedback def. feedback_hash_b9475c84f84aee5e117ba7ec7aab7e25 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "# Trulens instrumentation.\n",
    "\n",
    "tc = Tru().Chain(\n",
    "    chain,\n",
    "    chain_id=chain_id,\n",
    "    feedbacks=feedbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, record = tc.call_with_record(\"Who is Shayak?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ record record_hash_09f84e4ac1efde5fd79ef442a1610be8 from TruBot -> default.sqlite\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "answer": " Shayak Sen is the Co-Founder and Chief Technology Officer of TruEra. He obtained his PhD in Computer Science from Carnegie Mellon University and BTech in Computer Science from the Indian Institute of Technology, Delhi. He has been building systems and leading research to make machine learning and big data systems more explainable, privacy compliant, and fair. His research at Carnegie Mellon University introduced a number of pioneering breakthroughs to the field of explainable AI.",
       "chat_history": "",
       "question": "Who is Shayak?",
       "source_documents": [
        [
         [
          "page_content",
          "Linkedin\n\nShayak Sen\n\nCo-Founder and Chief Technology Officer\n\nWhen Shayak started building production grade machine learning models for algorithmic trading 10 years ago, he realized the need for putting the ‘science’ back in ‘data science’.\n\nSince then, he has been building systems and leading research to make machine learning and big data systems more explainable, privacy compliant, and fair.\n\nShayak’s research at Carnegie Mellon University introduced a number of pioneering breakthroughs to the field of explainable AI.\n\nShayak obtained his PhD in Computer Science from Carnegie Mellon University and BTech in Computer Science from the Indian Institute of Technology, Delhi."
         ],
         [
          "metadata",
          {
           "source": "https://truera.com/ai-quality-leader/"
          }
         ]
        ],
        [
         [
          "page_content",
          "Shayak obtained his PhD in Computer Science from Carnegie Mellon University and BTech in Computer Science from the Indian Institute of Technology, Delhi.\n\nLinkedin\n\nWebsite\n\nRick Shih\n\nResearch and Engineering\n\nRick Shih is a founding engineer at TruEra, where he focuses on creating explanation technology for deep neural networks and gradient boosted machines.\n\nHe holds a Bachelor's degree in computer science from University of Maryland, College Park and a Master’s degree in machine learning from the University of California, San Diego.\n\nHe was a staff machine learning and full stack engineer at Bloomreach, where he implemented and deployed the first production ML projects at the company.\n\nRick led multiple efforts in search ranking, search recall, personalization, content management, merchandising tools, and diagnostic tools.\n\nLinkedin"
         ],
         [
          "metadata",
          {
           "source": "https://truera.com/ai-quality-research/"
          }
         ]
        ],
        [
         [
          "page_content",
          "He holds Bachelor’s and Master’s degrees from the Worcester Polytechnic Institute and a PhD in computer science from University of Maryland, College Park.\n\nHe has conducted post-doctoral research at Carnegie Mellon University, as well as taught classes in trustworthy machine learning at Stanford University and machine learning privacy and security at Carnegie Mellon University.\n\nLinkedin\n\nShayak Sen\n\nCo-Founder and Chief Technology Officer\n\nWhen Shayak started building production grade machine learning models for algorithmic trading 10 years ago, he realized the need for putting the ‘science’ back in ‘data science’.\n\nSince then, he has been building systems and leading research to make machine learning and big data systems more explainable, privacy compliant, and fair.\n\nShayak’s research at Carnegie Mellon University introduced a number of pioneering breakthroughs to the field of explainable AI."
         ],
         [
          "metadata",
          {
           "source": "https://truera.com/ai-quality-research/"
          }
         ]
        ],
        [
         [
          "page_content",
          "The results of this test when asked the question “Who is Shayak?” are shown in Figure 10.\n\nThe vector database returned 4 context chunks — the first two were individually relevant to the question (they were about Shayak) and the last two were not relevant to the question (they were about a different TruEra employee — Shameek).\n\nThe final response was affected by the irrelevant chunks — the last sentence in the response includes information about Shameek in answering the question about Shayak.\n\nNotice that the feedback function correctly gave high relevance scores to the first two chunks and low relevance scores to the last two chunks.\n\nThis information can be used to only send the first two chunks for summarization, thus improving the quality of the final response.\n\nFigure 12: Feedback function scores of qs_relevance, i.e.\n\nhow relevant individual chunks are to the question."
         ],
         [
          "metadata",
          {
           "source": "https://medium.com/trulens/evaluate-and-track-your-llm-experiments-introducing-trulens-86028fe9b59a"
          }
         ]
        ]
       ]
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ feedback feedback_hash_c479553ae6ae61dc58f9b9c1d609ca40 on record_hash_09f84e4ac1efde5fd79ef442a1610be8 -> default.sqlite\n",
      "✅ feedback feedback_hash_26c84c76d907d808c36028e024af63c0 on record_hash_09f84e4ac1efde5fd79ef442a1610be8 -> default.sqlite\n",
      "✅ feedback feedback_hash_90b443be1347d732ededd19cd3968c72 on record_hash_09f84e4ac1efde5fd79ef442a1610be8 -> default.sqlite\n",
      "✅ feedback feedback_hash_b9475c84f84aee5e117ba7ec7aab7e25 on record_hash_09f84e4ac1efde5fd79ef442a1610be8 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "feedback = Tru().run_feedback_functions(record_json=record, feedback_functions=feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_success': True,\n",
       " 'feedback_id': 'feedback_hash_b9475c84f84aee5e117ba7ec7aab7e25',\n",
       " 'record_id': 'record_hash_09f84e4ac1efde5fd79ef442a1610be8',\n",
       " 'qs_relevance': 0.1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_qs_relevance.run_on_record(record_json=record, chain_json=tc.json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
