{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groundedness Evaluations\n",
    "\n",
    "In many ways, feedbacks can be thought of as LLM apps themselves. Given text, they return some result. Thinking in this way, we can use TruLens to evaluate and track our feedback quality. We can even do this for different models (e.g. gpt-3.5 and gpt-4) or prompting schemes (such as chain-of-thought reasoning).\n",
    "\n",
    "This notebook follows an evaluation of a set of test cases generated from human annotated datasets. In particular, we generate test cases from [SummEval](https://arxiv.org/abs/2007.12626).\n",
    "\n",
    "SummEval is one of the datasets dedicated to automated evaluations on summarization tasks, which are closely related to the groundedness evaluation in RAG with the retrieved context (i.e. the source) and response (i.e. the summary). It contains human annotation of numerical score (**1** to **5**) comprised of scoring from 3 human expert annotators and 5 croweded-sourced annotators. There are 16 models being used for generation in total for 100 paragraphs in the test set, so there are a total of 16,000 machine-generated summaries. Each paragraph also has several human-written summaries for comparative analysis. \n",
    "\n",
    "\n",
    "For evaluating groundedness feedback functions, we compute the annotated \"consistency\" scores, a measure of whether the summarized resposne is factually consisntent with the source texts and hence can be used as a proxy to evaluate groundedness in our RAG triad, and normalized to **0** to **1** score as our **expected_score** and u to match the output of feedback functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai.openai_object'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import groundedness feedback function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GroundTruthAgreement, Groundedness\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruBasicApp, Feedback, Tru, Select\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtest_cases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_summeval_groundedness_golden_set\n",
      "File \u001b[0;32m~/git/trulens/trulens_eval/trulens_eval/__init__.py:83\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m# Trulens-eval LLM Evaluation Library\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.18.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bedrock\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Feedback\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Huggingface\n",
      "File \u001b[0;32m~/git/trulens/trulens_eval/trulens_eval/feedback/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m AggCallable \u001b[38;5;241m=\u001b[39m Callable[[Iterable[\u001b[38;5;28mfloat\u001b[39m]], \u001b[38;5;28mfloat\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Specific feedback functions:\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Main class holding and running feedback functions:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Feedback\n",
      "File \u001b[0;32m~/git/trulens/trulens_eval/trulens_eval/feedback/embeddings.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Tuple, Union\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ServiceContext\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrivateAttr\n",
      "File \u001b[0;32m~/miniconda3/envs/demo3/lib/python3.10/site-packages/llama_index/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_structs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_type\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexStructType\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# embeddings\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangchainEmbedding\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbedding\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# indices\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/demo3/lib/python3.10/site-packages/llama_index/embeddings/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgoogle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleUnivSentEncoderEmbedding\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangchainEmbedding\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbedding\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     LinearAdapterEmbeddingModel,\n\u001b[1;32m      8\u001b[0m     AdapterEmbeddingModel,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     resolve_embed_model,\n\u001b[1;32m     12\u001b[0m     DEFAULT_HUGGINGFACE_EMBEDDING_MODEL,\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/demo3/lib/python3.10/site-packages/llama_index/embeddings/openai.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackManager\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_EMBED_BATCH_SIZE, BaseEmbedding\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_openai_api_key\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOpenAIEmbeddingMode\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m, Enum):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"OpenAI embedding mode.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/demo3/lib/python3.10/site-packages/llama_index/llms/__init__.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmonsterapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MonsterLLM\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlitellm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LiteLLM\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PaLM\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredibase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PredibaseLLM\n",
      "File \u001b[0;32m~/miniconda3/envs/demo3/lib/python3.10/site-packages/llama_index/llms/litellm.py:29\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     LLM,\n\u001b[1;32m      8\u001b[0m     ChatMessage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     llm_completion_callback,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     achat_to_completion_decorator,\n\u001b[1;32m     21\u001b[0m     acompletion_to_chat_decorator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     stream_completion_to_chat_decorator,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlitellm_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     acompletion_with_retry,\n\u001b[1;32m     31\u001b[0m     completion_with_retry,\n\u001b[1;32m     32\u001b[0m     from_openai_message_dict,\n\u001b[1;32m     33\u001b[0m     is_chat_model,\n\u001b[1;32m     34\u001b[0m     is_function_calling_model,\n\u001b[1;32m     35\u001b[0m     openai_modelname_to_contextsize,\n\u001b[1;32m     36\u001b[0m     to_openai_message_dicts,\n\u001b[1;32m     37\u001b[0m     validate_litellm_api_key,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLiteLLM\u001b[39;00m(LLM):\n\u001b[1;32m     42\u001b[0m     class_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/demo3/lib/python3.10/site-packages/llama_index/llms/litellm_utils.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_object\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIObject\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Sequence, Type\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbridge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai.openai_object'"
     ]
    }
   ],
   "source": [
    "# Import groundedness feedback function\n",
    "from trulens_eval.feedback import GroundTruthAgreement, Groundedness\n",
    "from trulens_eval import TruBasicApp, Feedback, Tru, Select\n",
    "from test_cases import generate_summeval_groundedness_golden_set\n",
    "\n",
    "Tru().reset_database()\n",
    "\n",
    "# generator for groundedness golden set\n",
    "test_cases_gen = generate_summeval_groundedness_golden_set(\"./datasets/summeval_test_100.json\")\n",
    "                                            \n",
    "total_num_test_cases = sum(1 for _ in test_cases_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_test_cases # 1600 test samples in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of test cases we want to run the smoke test on\n",
    "groundedness_golden_set = []\n",
    "for i in range(100):\n",
    "    groundedness_golden_set.append(next(test_cases_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundedness_golden_set[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking various Groundedness feedback function providers (OpenAI GPT-3.5-turbo vs GPT-4 vs Huggingface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider.hugs import Huggingface\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "huggingface_provider = Huggingface()\n",
    "groundedness_hug = Groundedness(groundedness_provider=huggingface_provider)\n",
    "f_groundedness_hug = Feedback(groundedness_hug.groundedness_measure, name = \"Groundedness Huggingface\").on_input().on_output().aggregate(groundedness_hug.grounded_statements_aggregator)\n",
    "def wrapped_groundedness_hug(input, output):\n",
    "    return np.mean(list(f_groundedness_hug(input, output)[0].values()))\n",
    "     \n",
    "    \n",
    "    \n",
    "groundedness_openai = Groundedness(groundedness_provider=OpenAI(model_engine=\"gpt-3.5-turbo\"))  # GPT-3.5-turbot being the default model if not specified\n",
    "f_groundedness_openai = Feedback(groundedness_openai.groundedness_measure, name = \"Groundedness OpenAI GPT-3.5\").on_input().on_output().aggregate(groundedness_openai.grounded_statements_aggregator)\n",
    "def wrapped_groundedness_openai(input, output):\n",
    "    return f_groundedness_openai(input, output)[0]['full_doc_score']\n",
    "\n",
    "groundedness_openai_gpt4 = Groundedness(groundedness_provider=OpenAI(model_engine=\"gpt-4\"))\n",
    "f_groundedness_openai_gpt4 = Feedback(groundedness_openai_gpt4.groundedness_measure, name = \"Groundedness OpenAI GPT-4\").on_input().on_output().aggregate(groundedness_openai_gpt4.grounded_statements_aggregator)\n",
    "def wrapped_groundedness_openai_gpt4(input, output):\n",
    "    return f_groundedness_openai_gpt4(input, output)[0]['full_doc_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Feedback object using the numeric_difference method of the ground_truth object\n",
    "ground_truth = GroundTruthAgreement(groundedness_golden_set)\n",
    "# Call the numeric_difference method with app and record and aggregate to get the mean absolute error\n",
    "f_mae = Feedback(ground_truth.mae, name = \"Mean Absolute Error\").on(Select.Record.calls[0].args.args[0]).on(Select.Record.calls[0].args.args[1]).on_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_wrapped_groundedness_hug = TruBasicApp(wrapped_groundedness_hug, app_id = \"groundedness huggingface\", feedbacks=[f_mae])\n",
    "tru_wrapped_groundedness_openai = TruBasicApp(wrapped_groundedness_openai, app_id = \"groundedness openai gpt-3.5\", feedbacks=[f_mae])\n",
    "tru_wrapped_groundedness_openai_gpt4 = TruBasicApp(wrapped_groundedness_openai_gpt4, app_id = \"groundedness openai gpt-4\", feedbacks=[f_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(groundedness_golden_set)):\n",
    "    source = groundedness_golden_set[i][\"query\"]\n",
    "    response = groundedness_golden_set[i][\"response\"]\n",
    "    with tru_wrapped_groundedness_hug as recording:\n",
    "        tru_wrapped_groundedness_hug.app(source, response)\n",
    "    with tru_wrapped_groundedness_openai as recording:\n",
    "        tru_wrapped_groundedness_openai.app(source, response)\n",
    "    with tru_wrapped_groundedness_openai_gpt4 as recording:\n",
    "        tru_wrapped_groundedness_openai_gpt4.app(source, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tru().get_leaderboard(app_ids=[]).sort_values(by=\"Mean Absolute Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
