,record,event_id,record_attributes,record_type,resource_attributes,start_timestamp,timestamp,trace
0,"{'name': 'root', 'kind': 1, 'parent_span_id': '', 'status': 'STATUS_CODE_UNSET'}",5887968720136174172,"{'name': 'root', 'ai.observability.span_type': 'record_root', 'ai.observability.domain': 'module', 'ai.observability.app_name': 'Simple RAG', 'ai.observability.app_version': 'v1', 'ai.observability.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef', 'ai.observability.run_name': 'test run', 'ai.observability.input_id': '42', 'ai.observability.record_root.app_name': 'Simple RAG', 'ai.observability.record_root.app_version': 'v1', 'ai.observability.record_root.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef'}",EventRecordType.SPAN,"{'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.28.2', 'service.name': 'trulens'}",2025-01-31 23:38:58.366658,2025-01-31 23:38:58.369803,"{'trace_id': '255439363642418968380653185129978420609', 'parent_id': '', 'span_id': '5887968720136174172'}"
1,"{'name': 'llama_index.core.base.base_query_engine.BaseQueryEngine.query', 'kind': 1, 'parent_span_id': '5887968720136174172', 'status': 'STATUS_CODE_UNSET'}",17641412338220404646,"{'name': 'llama_index.core.base.base_query_engine.BaseQueryEngine.query', 'ai.observability.span_type': 'main', 'ai.observability.domain': 'module', 'ai.observability.app_name': 'Simple RAG', 'ai.observability.app_version': 'v1', 'ai.observability.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef', 'ai.observability.run_name': 'test run', 'ai.observability.input_id': '42', 'ai.observability.call.return': 'Context information is below.\n---------------------\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].\n\npage_label: 3\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nTo facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.\n\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is multi-headed attention?\nAnswer: ', 'ai.observability.call.stack': '  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/bin/pytest"", line 8, in <module>\n    sys.exit(console_main())\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 201, in console_main\n    code = main()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 175, in main\n    ret: ExitCode | int = config.hook.pytest_cmdline_main(config=config)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 330, in pytest_cmdline_main\n    return wrap_session(config, _main)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 283, in wrap_session\n    session.exitstatus = doit(config, session) or 0\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 337, in _main\n    config.hook.pytest_runtestloop(session=session)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 362, in pytest_runtestloop\n    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 113, in pytest_runtest_protocol\n    runtestprotocol(item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 132, in runtestprotocol\n    reports.append(call_and_report(item, ""call"", log))\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 241, in call_and_report\n    call = CallInfo.from_call(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 341, in from_call\n    result: TResult | None = func()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 242, in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 174, in pytest_runtest_call\n    item.runtest()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/unittest.py"", line 351, in runtest\n    testcase(result=self)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 678, in __call__\n    return self.run(*args, **kwds)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 623, in run\n    self._callTestMethod(testMethod)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 579, in _callTestMethod\n    if method() is not None:\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/tests/unit/test_otel_tru_llama.py"", line 64, in test_smoke\n    rag.query(""What is multi-headed attention?"")\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 178, in sync_wrapper\n    next(ret)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 212, in convert_to_generator\n    _set_span_attributes(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 109, in _set_span_attributes\n    set_function_call_attributes(span, ret, func_exception, all_kwargs)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/experimental/otel_tracing/core/span.py"", line 152, in set_function_call_attributes\n    span, SpanAttributes.CALL.STACK, ""\\n"".join(traceback.format_stack())\n', 'ai.observability.call.kwargs.str_or_query_bundle': 'What is multi-headed attention?', 'ai.observability.main.main_input': 'What is multi-headed attention?', 'ai.observability.main.main_output': 'Context information is below.\n---------------------\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].\n\npage_label: 3\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nTo facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.\n\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is multi-headed attention?\nAnswer: '}",EventRecordType.SPAN,"{'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.28.2', 'service.name': 'trulens'}",2025-01-31 23:38:58.366692,2025-01-31 23:38:58.369792,"{'trace_id': '255439363642418968380653185129978420609', 'parent_id': '5887968720136174172', 'span_id': '17641412338220404646'}"
2,"{'name': 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine.retrieve', 'kind': 1, 'parent_span_id': '17641412338220404646', 'status': 'STATUS_CODE_UNSET'}",15738249367402767593,"{'name': 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine.retrieve', 'ai.observability.span_type': 'retrieval', 'ai.observability.domain': 'module', 'ai.observability.app_name': 'Simple RAG', 'ai.observability.app_version': 'v1', 'ai.observability.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef', 'ai.observability.run_name': 'test run', 'ai.observability.input_id': '42', 'ai.observability.call.return': ['Node ID: 72c3b743-1435-40ba-9c21-5cf7cff20928\nText: Recent work has achieved significant improvements in\ncomputational efficiency through factorization tricks [21] and\nconditional computation [32], while also improving model performance\nin case of the latter. The fundamental constraint of sequential\ncomputation, however, remains. Attention mechanisms have become an\nintegral part of compelling seq...\nScore:  0.900\n', 'Node ID: 736e8c72-142b-4ee7-933d-13f3c353ddd9\nText: To facilitate these residual connections, all sub-layers in the\nmodel, as well as the embedding layers, produce outputs of dimension\ndmodel = 512. Decoder: The decoder is also composed of a stack of N =\n6identical layers. In addition to the two sub-layers in each encoder\nlayer, the decoder inserts a third sub-layer, which performs multi-\nhead att...\nScore:  0.891\n', 'Node ID: 82e66789-04c9-498c-805e-7815bfddf3b7\nText: Recurrent models typically factor computation along the symbol\npositions of the input and output sequences. Aligning the positions to\nsteps in computation time, they generate a sequence of hidden states\nht, as a function of the previous hidden state htâˆ’1 and the input for\nposition t. This inherently sequential nature precludes\nparallelization wi...\nScore:  0.880\n'], 'ai.observability.call.stack': '  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/bin/pytest"", line 8, in <module>\n    sys.exit(console_main())\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 201, in console_main\n    code = main()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 175, in main\n    ret: ExitCode | int = config.hook.pytest_cmdline_main(config=config)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 330, in pytest_cmdline_main\n    return wrap_session(config, _main)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 283, in wrap_session\n    session.exitstatus = doit(config, session) or 0\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 337, in _main\n    config.hook.pytest_runtestloop(session=session)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 362, in pytest_runtestloop\n    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 113, in pytest_runtest_protocol\n    runtestprotocol(item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 132, in runtestprotocol\n    reports.append(call_and_report(item, ""call"", log))\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 241, in call_and_report\n    call = CallInfo.from_call(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 341, in from_call\n    result: TResult | None = func()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 242, in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 174, in pytest_runtest_call\n    item.runtest()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/unittest.py"", line 351, in runtest\n    testcase(result=self)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 678, in __call__\n    return self.run(*args, **kwds)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 623, in run\n    self._callTestMethod(testMethod)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 579, in _callTestMethod\n    if method() is not None:\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/tests/unit/test_otel_tru_llama.py"", line 64, in test_smoke\n    rag.query(""What is multi-headed attention?"")\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py"", line 52, in query\n    query_result = self._query(str_or_query_bundle)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py"", line 178, in _query\n    nodes = self.retrieve(query_bundle)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 178, in sync_wrapper\n    next(ret)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 212, in convert_to_generator\n    _set_span_attributes(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 109, in _set_span_attributes\n    set_function_call_attributes(span, ret, func_exception, all_kwargs)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/experimental/otel_tracing/core/span.py"", line 152, in set_function_call_attributes\n    span, SpanAttributes.CALL.STACK, ""\\n"".join(traceback.format_stack())\n', 'ai.observability.call.kwargs.query_bundle': 'What is multi-headed attention?', 'ai.observability.retrieval.retrieved_contexts': ['Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].', 'To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.', 'Recurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.'], 'ai.observability.retrieval.query_text': 'What is multi-headed attention?'}",EventRecordType.SPAN,"{'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.28.2', 'service.name': 'trulens'}",2025-01-31 23:38:58.366790,2025-01-31 23:38:58.368281,"{'trace_id': '255439363642418968380653185129978420609', 'parent_id': '17641412338220404646', 'span_id': '15738249367402767593'}"
3,"{'name': 'llama_index.core.base.base_retriever.BaseRetriever.retrieve', 'kind': 1, 'parent_span_id': '15738249367402767593', 'status': 'STATUS_CODE_UNSET'}",6923169634336580652,"{'name': 'llama_index.core.base.base_retriever.BaseRetriever.retrieve', 'ai.observability.span_type': 'retrieval', 'ai.observability.domain': 'module', 'ai.observability.app_name': 'Simple RAG', 'ai.observability.app_version': 'v1', 'ai.observability.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef', 'ai.observability.run_name': 'test run', 'ai.observability.input_id': '42', 'ai.observability.call.return': ['Node ID: 72c3b743-1435-40ba-9c21-5cf7cff20928\nText: Recent work has achieved significant improvements in\ncomputational efficiency through factorization tricks [21] and\nconditional computation [32], while also improving model performance\nin case of the latter. The fundamental constraint of sequential\ncomputation, however, remains. Attention mechanisms have become an\nintegral part of compelling seq...\nScore:  0.900\n', 'Node ID: 736e8c72-142b-4ee7-933d-13f3c353ddd9\nText: To facilitate these residual connections, all sub-layers in the\nmodel, as well as the embedding layers, produce outputs of dimension\ndmodel = 512. Decoder: The decoder is also composed of a stack of N =\n6identical layers. In addition to the two sub-layers in each encoder\nlayer, the decoder inserts a third sub-layer, which performs multi-\nhead att...\nScore:  0.891\n', 'Node ID: 82e66789-04c9-498c-805e-7815bfddf3b7\nText: Recurrent models typically factor computation along the symbol\npositions of the input and output sequences. Aligning the positions to\nsteps in computation time, they generate a sequence of hidden states\nht, as a function of the previous hidden state htâˆ’1 and the input for\nposition t. This inherently sequential nature precludes\nparallelization wi...\nScore:  0.880\n'], 'ai.observability.call.stack': '  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/bin/pytest"", line 8, in <module>\n    sys.exit(console_main())\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 201, in console_main\n    code = main()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 175, in main\n    ret: ExitCode | int = config.hook.pytest_cmdline_main(config=config)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 330, in pytest_cmdline_main\n    return wrap_session(config, _main)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 283, in wrap_session\n    session.exitstatus = doit(config, session) or 0\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 337, in _main\n    config.hook.pytest_runtestloop(session=session)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 362, in pytest_runtestloop\n    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 113, in pytest_runtest_protocol\n    runtestprotocol(item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 132, in runtestprotocol\n    reports.append(call_and_report(item, ""call"", log))\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 241, in call_and_report\n    call = CallInfo.from_call(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 341, in from_call\n    result: TResult | None = func()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 242, in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 174, in pytest_runtest_call\n    item.runtest()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/unittest.py"", line 351, in runtest\n    testcase(result=self)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 678, in __call__\n    return self.run(*args, **kwds)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 623, in run\n    self._callTestMethod(testMethod)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 579, in _callTestMethod\n    if method() is not None:\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/tests/unit/test_otel_tru_llama.py"", line 64, in test_smoke\n    rag.query(""What is multi-headed attention?"")\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py"", line 52, in query\n    query_result = self._query(str_or_query_bundle)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py"", line 178, in _query\n    nodes = self.retrieve(query_bundle)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py"", line 133, in retrieve\n    nodes = self._retriever.retrieve(query_bundle)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 178, in sync_wrapper\n    next(ret)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 212, in convert_to_generator\n    _set_span_attributes(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 109, in _set_span_attributes\n    set_function_call_attributes(span, ret, func_exception, all_kwargs)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/experimental/otel_tracing/core/span.py"", line 152, in set_function_call_attributes\n    span, SpanAttributes.CALL.STACK, ""\\n"".join(traceback.format_stack())\n', 'ai.observability.call.kwargs.str_or_query_bundle': 'What is multi-headed attention?', 'ai.observability.retrieval.retrieved_contexts': ['Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].', 'To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.', 'Recurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.'], 'ai.observability.retrieval.query_text': 'What is multi-headed attention?'}",EventRecordType.SPAN,"{'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.28.2', 'service.name': 'trulens'}",2025-01-31 23:38:58.366855,2025-01-31 23:38:58.368036,"{'trace_id': '255439363642418968380653185129978420609', 'parent_id': '15738249367402767593', 'span_id': '6923169634336580652'}"
4,"{'name': 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever._retrieve', 'kind': 1, 'parent_span_id': '6923169634336580652', 'status': 'STATUS_CODE_UNSET'}",4665056147687423919,"{'name': 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever._retrieve', 'ai.observability.span_type': 'retrieval', 'ai.observability.domain': 'module', 'ai.observability.app_name': 'Simple RAG', 'ai.observability.app_version': 'v1', 'ai.observability.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef', 'ai.observability.run_name': 'test run', 'ai.observability.input_id': '42', 'ai.observability.call.return': ['Node ID: 72c3b743-1435-40ba-9c21-5cf7cff20928\nText: Recent work has achieved significant improvements in\ncomputational efficiency through factorization tricks [21] and\nconditional computation [32], while also improving model performance\nin case of the latter. The fundamental constraint of sequential\ncomputation, however, remains. Attention mechanisms have become an\nintegral part of compelling seq...\nScore:  0.900\n', 'Node ID: 736e8c72-142b-4ee7-933d-13f3c353ddd9\nText: To facilitate these residual connections, all sub-layers in the\nmodel, as well as the embedding layers, produce outputs of dimension\ndmodel = 512. Decoder: The decoder is also composed of a stack of N =\n6identical layers. In addition to the two sub-layers in each encoder\nlayer, the decoder inserts a third sub-layer, which performs multi-\nhead att...\nScore:  0.891\n', 'Node ID: 82e66789-04c9-498c-805e-7815bfddf3b7\nText: Recurrent models typically factor computation along the symbol\npositions of the input and output sequences. Aligning the positions to\nsteps in computation time, they generate a sequence of hidden states\nht, as a function of the previous hidden state htâˆ’1 and the input for\nposition t. This inherently sequential nature precludes\nparallelization wi...\nScore:  0.880\n'], 'ai.observability.call.stack': '  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/bin/pytest"", line 8, in <module>\n    sys.exit(console_main())\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 201, in console_main\n    code = main()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 175, in main\n    ret: ExitCode | int = config.hook.pytest_cmdline_main(config=config)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 330, in pytest_cmdline_main\n    return wrap_session(config, _main)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 283, in wrap_session\n    session.exitstatus = doit(config, session) or 0\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 337, in _main\n    config.hook.pytest_runtestloop(session=session)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 362, in pytest_runtestloop\n    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 113, in pytest_runtest_protocol\n    runtestprotocol(item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 132, in runtestprotocol\n    reports.append(call_and_report(item, ""call"", log))\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 241, in call_and_report\n    call = CallInfo.from_call(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 341, in from_call\n    result: TResult | None = func()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 242, in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 174, in pytest_runtest_call\n    item.runtest()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/unittest.py"", line 351, in runtest\n    testcase(result=self)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 678, in __call__\n    return self.run(*args, **kwds)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 623, in run\n    self._callTestMethod(testMethod)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 579, in _callTestMethod\n    if method() is not None:\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/tests/unit/test_otel_tru_llama.py"", line 64, in test_smoke\n    rag.query(""What is multi-headed attention?"")\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py"", line 52, in query\n    query_result = self._query(str_or_query_bundle)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py"", line 178, in _query\n    nodes = self.retrieve(query_bundle)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py"", line 133, in retrieve\n    nodes = self._retriever.retrieve(query_bundle)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/base/base_retriever.py"", line 245, in retrieve\n    nodes = self._retrieve(query_bundle)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 178, in sync_wrapper\n    next(ret)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 212, in convert_to_generator\n    _set_span_attributes(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 109, in _set_span_attributes\n    set_function_call_attributes(span, ret, func_exception, all_kwargs)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/experimental/otel_tracing/core/span.py"", line 152, in set_function_call_attributes\n    span, SpanAttributes.CALL.STACK, ""\\n"".join(traceback.format_stack())\n', 'ai.observability.call.kwargs.query_bundle': 'What is multi-headed attention?', 'ai.observability.retrieval.retrieved_contexts': ['Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].', 'To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.', 'Recurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.'], 'ai.observability.retrieval.query_text': 'What is multi-headed attention?'}",EventRecordType.SPAN,"{'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.28.2', 'service.name': 'trulens'}",2025-01-31 23:38:58.366906,2025-01-31 23:38:58.367734,"{'trace_id': '255439363642418968380653185129978420609', 'parent_id': '6923169634336580652', 'span_id': '4665056147687423919'}"
5,"{'name': 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine.get_response', 'kind': 1, 'parent_span_id': '17641412338220404646', 'status': 'STATUS_CODE_UNSET'}",17180097468732959058,"{'name': 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine.get_response', 'ai.observability.span_type': 'unknown', 'ai.observability.domain': 'module', 'ai.observability.app_name': 'Simple RAG', 'ai.observability.app_version': 'v1', 'ai.observability.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef', 'ai.observability.run_name': 'test run', 'ai.observability.input_id': '42', 'ai.observability.call.return': 'Context information is below.\n---------------------\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].\n\npage_label: 3\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nTo facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.\n\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is multi-headed attention?\nAnswer: ', 'ai.observability.call.stack': '  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/bin/pytest"", line 8, in <module>\n    sys.exit(console_main())\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 201, in console_main\n    code = main()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 175, in main\n    ret: ExitCode | int = config.hook.pytest_cmdline_main(config=config)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 330, in pytest_cmdline_main\n    return wrap_session(config, _main)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 283, in wrap_session\n    session.exitstatus = doit(config, session) or 0\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 337, in _main\n    config.hook.pytest_runtestloop(session=session)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 362, in pytest_runtestloop\n    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 113, in pytest_runtest_protocol\n    runtestprotocol(item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 132, in runtestprotocol\n    reports.append(call_and_report(item, ""call"", log))\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 241, in call_and_report\n    call = CallInfo.from_call(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 341, in from_call\n    result: TResult | None = func()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 242, in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 174, in pytest_runtest_call\n    item.runtest()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/unittest.py"", line 351, in runtest\n    testcase(result=self)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 678, in __call__\n    return self.run(*args, **kwds)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 623, in run\n    self._callTestMethod(testMethod)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 579, in _callTestMethod\n    if method() is not None:\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/tests/unit/test_otel_tru_llama.py"", line 64, in test_smoke\n    rag.query(""What is multi-headed attention?"")\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py"", line 52, in query\n    query_result = self._query(str_or_query_bundle)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py"", line 179, in _query\n    response = self._response_synthesizer.synthesize(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py"", line 241, in synthesize\n    response_str = self.get_response(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 178, in sync_wrapper\n    next(ret)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 212, in convert_to_generator\n    _set_span_attributes(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 109, in _set_span_attributes\n    set_function_call_attributes(span, ret, func_exception, all_kwargs)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/experimental/otel_tracing/core/span.py"", line 152, in set_function_call_attributes\n    span, SpanAttributes.CALL.STACK, ""\\n"".join(traceback.format_stack())\n', 'ai.observability.call.kwargs.query_str': 'What is multi-headed attention?', 'ai.observability.call.kwargs.text_chunks': ['page_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].', 'page_label: 3\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nTo facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.', 'page_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.']}",EventRecordType.SPAN,"{'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.28.2', 'service.name': 'trulens'}",2025-01-31 23:38:58.368351,2025-01-31 23:38:58.369628,"{'trace_id': '255439363642418968380653185129978420609', 'parent_id': '17641412338220404646', 'span_id': '17180097468732959058'}"
6,"{'name': 'llama_index.core.response_synthesizers.refine.Refine.get_response', 'kind': 1, 'parent_span_id': '17180097468732959058', 'status': 'STATUS_CODE_UNSET'}",17990976206266681157,"{'name': 'llama_index.core.response_synthesizers.refine.Refine.get_response', 'ai.observability.span_type': 'unknown', 'ai.observability.domain': 'module', 'ai.observability.app_name': 'Simple RAG', 'ai.observability.app_version': 'v1', 'ai.observability.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef', 'ai.observability.run_name': 'test run', 'ai.observability.input_id': '42', 'ai.observability.call.return': 'Context information is below.\n---------------------\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].\n\npage_label: 3\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nTo facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.\n\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is multi-headed attention?\nAnswer: ', 'ai.observability.call.stack': '  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/bin/pytest"", line 8, in <module>\n    sys.exit(console_main())\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 201, in console_main\n    code = main()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 175, in main\n    ret: ExitCode | int = config.hook.pytest_cmdline_main(config=config)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 330, in pytest_cmdline_main\n    return wrap_session(config, _main)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 283, in wrap_session\n    session.exitstatus = doit(config, session) or 0\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 337, in _main\n    config.hook.pytest_runtestloop(session=session)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 362, in pytest_runtestloop\n    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 113, in pytest_runtest_protocol\n    runtestprotocol(item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 132, in runtestprotocol\n    reports.append(call_and_report(item, ""call"", log))\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 241, in call_and_report\n    call = CallInfo.from_call(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 341, in from_call\n    result: TResult | None = func()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 242, in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 174, in pytest_runtest_call\n    item.runtest()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/unittest.py"", line 351, in runtest\n    testcase(result=self)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 678, in __call__\n    return self.run(*args, **kwds)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 623, in run\n    self._callTestMethod(testMethod)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 579, in _callTestMethod\n    if method() is not None:\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/tests/unit/test_otel_tru_llama.py"", line 64, in test_smoke\n    rag.query(""What is multi-headed attention?"")\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py"", line 52, in query\n    query_result = self._query(str_or_query_bundle)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py"", line 179, in _query\n    response = self._response_synthesizer.synthesize(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py"", line 241, in synthesize\n    response_str = self.get_response(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py"", line 43, in get_response\n    return super().get_response(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 178, in sync_wrapper\n    next(ret)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 212, in convert_to_generator\n    _set_span_attributes(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 109, in _set_span_attributes\n    set_function_call_attributes(span, ret, func_exception, all_kwargs)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/experimental/otel_tracing/core/span.py"", line 152, in set_function_call_attributes\n    span, SpanAttributes.CALL.STACK, ""\\n"".join(traceback.format_stack())\n', 'ai.observability.call.kwargs.query_str': 'What is multi-headed attention?', 'ai.observability.call.kwargs.text_chunks': ['page_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].\n\npage_label: 3\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nTo facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.\n\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.']}",EventRecordType.SPAN,"{'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.28.2', 'service.name': 'trulens'}",2025-01-31 23:38:58.368792,2025-01-31 23:38:58.369502,"{'trace_id': '255439363642418968380653185129978420609', 'parent_id': '17180097468732959058', 'span_id': '17990976206266681157'}"
7,"{'name': 'llama_index.core.llms.mock.MockLLM.complete', 'kind': 1, 'parent_span_id': '17990976206266681157', 'status': 'STATUS_CODE_UNSET'}",9585962140623235081,"{'name': 'llama_index.core.llms.mock.MockLLM.complete', 'ai.observability.span_type': 'unknown', 'ai.observability.domain': 'module', 'ai.observability.app_name': 'Simple RAG', 'ai.observability.app_version': 'v1', 'ai.observability.record_id': '2d076907-f15c-4fe4-9a44-0fbd54d162ef', 'ai.observability.run_name': 'test run', 'ai.observability.input_id': '42', 'ai.observability.call.return': 'Context information is below.\n---------------------\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].\n\npage_label: 3\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nTo facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.\n\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is multi-headed attention?\nAnswer: ', 'ai.observability.call.stack': '  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/bin/pytest"", line 8, in <module>\n    sys.exit(console_main())\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 201, in console_main\n    code = main()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 175, in main\n    ret: ExitCode | int = config.hook.pytest_cmdline_main(config=config)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 330, in pytest_cmdline_main\n    return wrap_session(config, _main)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 283, in wrap_session\n    session.exitstatus = doit(config, session) or 0\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 337, in _main\n    config.hook.pytest_runtestloop(session=session)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/main.py"", line 362, in pytest_runtestloop\n    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 113, in pytest_runtest_protocol\n    runtestprotocol(item, nextitem=nextitem)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 132, in runtestprotocol\n    reports.append(call_and_report(item, ""call"", log))\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 241, in call_and_report\n    call = CallInfo.from_call(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 341, in from_call\n    result: TResult | None = func()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 242, in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103, in _multicall\n    res = hook_impl.function(*args)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/runner.py"", line 174, in pytest_runtest_call\n    item.runtest()\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/_pytest/unittest.py"", line 351, in runtest\n    testcase(result=self)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 678, in __call__\n    return self.run(*args, **kwds)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 623, in run\n    self._callTestMethod(testMethod)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/unittest/case.py"", line 579, in _callTestMethod\n    if method() is not None:\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/tests/unit/test_otel_tru_llama.py"", line 64, in test_smoke\n    rag.query(""What is multi-headed attention?"")\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py"", line 52, in query\n    query_result = self._query(str_or_query_bundle)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py"", line 179, in _query\n    response = self._response_synthesizer.synthesize(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py"", line 241, in synthesize\n    response_str = self.get_response(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py"", line 43, in get_response\n    return super().get_response(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 173, in sync_wrapper\n    if next(ret) == ""is_not_generator"":\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 193, in convert_to_generator\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py"", line 179, in get_response\n    response = self._give_response_single(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py"", line 241, in _give_response_single\n    program(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py"", line 85, in __call__\n    answer = self._llm.predict(\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py"", line 311, in wrapper\n    result = func(*args, **kwargs)\n\n  File ""/Users/dkurokawa/miniconda3/envs/trulens_3_11/lib/python3.11/site-packages/llama_index/core/llms/llm.py"", line 600, in predict\n    response = self.complete(formatted_prompt, formatted=True)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 178, in sync_wrapper\n    next(ret)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 212, in convert_to_generator\n    _set_span_attributes(\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/core/otel/instrument.py"", line 109, in _set_span_attributes\n    set_function_call_attributes(span, ret, func_exception, all_kwargs)\n\n  File ""/Users/dkurokawa/Work/code/trulens/trulens/src/core/trulens/experimental/otel_tracing/core/span.py"", line 152, in set_function_call_attributes\n    span, SpanAttributes.CALL.STACK, ""\\n"".join(traceback.format_stack())\n', 'ai.observability.call.kwargs.formatted': True, 'ai.observability.call.kwargs.args': ['Context information is below.\n---------------------\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19].\n\npage_label: 3\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nTo facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack.\n\npage_label: 2\nfile_path: tests/unit/data/attention_is_all_you_need.pdf\n\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is multi-headed attention?\nAnswer: '], 'ai.observability.call.kwargs.kwargs': ""{'formatted': True}""}",EventRecordType.SPAN,"{'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.28.2', 'service.name': 'trulens'}",2025-01-31 23:38:58.369136,2025-01-31 23:38:58.369347,"{'trace_id': '255439363642418968380653185129978420609', 'parent_id': '17990976206266681157', 'span_id': '9585962140623235081'}"
