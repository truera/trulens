{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keys import *\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import pinecone\n",
    "import requests\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.chains import (ConversationalRetrievalChain,\n",
    "                              SimpleSequentialChain)\n",
    "from langchain.document_loaders import (PagedPDFSplitter, TextLoader,\n",
    "                                        UnstructuredHTMLLoader,\n",
    "                                        UnstructuredMarkdownLoader,\n",
    "                                        UnstructuredPDFLoader)\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline, OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "from keys import HUGGINGFACE_HEADERS\n",
    "from slackbot import chain\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "# https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html?highlight=pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel():\n",
    "    def __init__(self):\n",
    "        # llm = OpenAI()\n",
    "       \n",
    "        self.llm_model_id = \"gpt2\"\n",
    "        # This model is pretty bad but using it for tests because it is free and\n",
    "        # relatively small.\n",
    "\n",
    "        # model_id = \"decapoda-research/llama-7b-hf\"\n",
    "        # model_id = \"decapoda-research/llama-13b-hf\"\n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.llm_model_id,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            local_files_only=True)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.llm_model_id,\n",
    "                                                       local_files_only=True)\n",
    "\n",
    "        self.pipe = pipeline(\"text-generation\",\n",
    "                             model=self.model,\n",
    "                             tokenizer=self.tokenizer,\n",
    "                             max_new_tokens=16,\n",
    "                             device_map=\"auto\",\n",
    "                             early_stopping=True)\n",
    "\n",
    "        self.llm = HuggingFacePipeline(pipeline=self.pipe)\n",
    "\n",
    "        template = \"\"\"Q: {question} A:\"\"\"\n",
    "        self.prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "        self.llm_chain = LLMChain(prompt=self.prompt, llm=self.llm, verbose=True)\n",
    "\n",
    "t = TestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tru_chain import TruChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_2303234/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1176469821.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_2303234/1176469821.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/piotrm/repos/llm-experiments/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tru_chain.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">302</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">299 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">300 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dict()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">301 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>302 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.models.insert(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.json())                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">303 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">304 │   # Chain requirement</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">305 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@property</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'dict'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'json'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_2303234/\u001b[0m\u001b[1;33m1176469821.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_2303234/1176469821.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/piotrm/repos/llm-experiments/\u001b[0m\u001b[1;33mtru_chain.py\u001b[0m:\u001b[94m302\u001b[0m in \u001b[92m__init__\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.model = \u001b[96mself\u001b[0m.dict()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m301 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m302 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.models.insert(\u001b[96mself\u001b[0m.model.json())                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m303 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m304 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Chain requirement\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m305 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'dict'\u001b[0m object has no attribute \u001b[32m'json'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tc = TruChain(t.llm_chain)\n",
    "tc(\"hello there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'verbose': False,\n",
       " 'chain': {'memory': None,\n",
       "  'verbose': True,\n",
       "  'prompt': {'input_variables': ['question'],\n",
       "   'output_parser': None,\n",
       "   'partial_variables': {},\n",
       "   'template': 'Q: {question} A:',\n",
       "   'template_format': 'f-string',\n",
       "   'validate_template': True,\n",
       "   '_type': 'prompt'},\n",
       "  'llm': {'model_id': 'gpt2',\n",
       "   'model_kwargs': None,\n",
       "   '_type': 'huggingface_pipeline'},\n",
       "  'output_key': 'text',\n",
       "  '_type': 'llm_chain'},\n",
       " 'recording': False,\n",
       " 'records': [],\n",
       " 'db': <TinyDB tables=['records'], tables_count=1, default_table_documents_count=0, all_tables_documents_count=['records=4']>,\n",
       " 'table_records': <Table name='records', total=4, storage=<tinydb.storages.JSONStorage object at 0x7f053615b0a0>>,\n",
       " 'table_models': <Table name='models', total=0, storage=<tinydb.storages.JSONStorage object at 0x7f053615b0a0>>,\n",
       " 'model': None,\n",
       " 'model_dict': None,\n",
       " '_type': 'TruChain'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    obj_id = id(obj)\n",
    "    print(obj_id)\n",
    "\n",
    "    if obj_id in self.encoded:\n",
    "        return super().encode({'_ref': obj_id})\n",
    "    \n",
    "    # temporary reference\n",
    "    self.encoded[obj_id] = {'_ref': obj_id}\n",
    "\n",
    "    if isinstance(obj, Dict):\n",
    "        ret = {}\n",
    "        for k, v in obj.items():\n",
    "            ret[k] = self.encode(v)\n",
    "\n",
    "    elif isinstance(obj, Sequence):\n",
    "        ret = []\n",
    "        for v in obj:\n",
    "            ret.append(self.encode(v))\n",
    "    else:\n",
    "        print(type(obj))\n",
    "        ret = self.default(obj)\n",
    "        # ret = super().encode(obj)\n",
    "\n",
    "    self.encoded[obj_id] = ret\n",
    "\n",
    "    return super().encode(ret)\n",
    "\"\"\"\n",
    "\n",
    "import langchain\n",
    "\n",
    "class TestModel(pydantic.BaseModel):\n",
    "    \n",
    "    chain: langchain.chains.base.Chain\n",
    "\n",
    "\n",
    "        \n",
    "        #json_encoders = {\n",
    "        #    TestModel: encoder.encode\n",
    "        #}\n",
    "        #json_dumps = lambda o, default: Config.encoder.encode(o)\n",
    "\n",
    "LLMChain.Config = TestModel.Config\n",
    "tm = TestModel(chain=t.llm_chain)\n",
    "\n",
    "# json.dumps(tc.model, default=default)\n",
    "\"\"\"\n",
    "@jsonpickle.handlers.register(pydantic.BaseModel, base=True)\n",
    "class FooHandler(jsonpickle.handlers.BaseHandler):\n",
    "    def flatten(self, obj, data):\n",
    "        print(\"pydantic\", obj, data)\n",
    "        h = jsonpickle.handlers.get(dict)#(self.context)\n",
    "        print(h)\n",
    "        h = h(self.context)\n",
    "        h.flatten(obj.dict(), data)\n",
    "        #if isinstance(obj, pydantic.BaseModel):\n",
    "        #    # h = jsonpickle.handlers.BaseHandler(self.context)\n",
    "        #    \n",
    "        #    print(h)\n",
    "        #    h.flatten(obj, data)\n",
    "        #else:\n",
    "        #    pass\n",
    "\n",
    "\n",
    "@jsonpickle.handlers.register(object, base=True)\n",
    "class FooHandler(jsonpickle.handlers.BaseHandler):\n",
    "    def flatten(self, obj, data):\n",
    "        print(\"default\", obj, data)\n",
    "        pass    \n",
    "\"\"\"\n",
    "        \n",
    "# jsonpickle.handlers.register(object, )\n",
    "\n",
    "#temp = jsonpickle.dumps(tc.chain)\n",
    "\n",
    "# temp = jsonpickle.encode(tc.model)\n",
    "\n",
    "# enc = MaybeJSONEncoder(check_circular=False)\n",
    "# dec = MaybeJSONDecoder()\n",
    "\n",
    "# dump = json.dumps(enc.encode(tc.chain))\n",
    "\n",
    "# dec.decode(dump)\n",
    "# print(dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.llm_chain.save(\"temp.json\")\n",
    "llm_chain2 = langchain.chains.loading.load_chain_from_config(t.llm_chain.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm_chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tm))\n",
    "encoded = tm.json(models_as_dict=False)\n",
    "print(encoded)\n",
    "TestModel.parse_raw(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tru_chain import Selection\n",
    "\n",
    "tc._select(select=[\n",
    "    Selection(param=(\"chain\", \"prompt\", \"template\")),\n",
    "    Selection(param=(\"chain\", \"llm\", \"model_id\")),\n",
    "    Selection(record=(\"input\", \"inputs\", \"question\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Q: {question} A:\"\"\"\n",
    "prompt = PromptTemplate(template=template,\n",
    "                        input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=t.llm)\n",
    "\n",
    "template_2 = \"\"\"Reverse this sentence: {sentence}.\"\"\"\n",
    "prompt_2 = PromptTemplate(template=template_2,\n",
    "                            input_variables=[\"sentence\"])\n",
    "llm_chain_2 = LLMChain(prompt=prompt_2, llm=t.llm)\n",
    "\n",
    "seq_chain = SimpleSequentialChain(chains=[llm_chain, llm_chain_2],\n",
    "                                    input_key=\"question\",\n",
    "                                    output_key=\"answer\")\n",
    "\n",
    "tc = TruChain(seq_chain)\n",
    "tc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc(\"hello there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc._get_obj_at_address(address=(\"chains\", 0, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "1. Langchain does not have support for classification models: https://python.langchain.com/en/latest/modules/models.html\n",
    "\n",
    "    - Will have to figure out out-of-band retrieval and execution of feedback models that are not LLM's.\n",
    "\n",
    "2. Can add steps to chain to capture text at various points in a chain: https://python.langchain.com/en/latest/reference/modules/chains.html#langchain.chains.SequentialChain .\n",
    "\n",
    "\n",
    "# Links\n",
    "\n",
    "- https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/llama#transformers.LlamaForCausalLM\n",
    "\n",
    "- https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "\n",
    "\n",
    "# Pinecone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slackbot import chain\n",
    "import langchain\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import (ConversationalRetrievalChain,\n",
    "                              SimpleSequentialChain)\n",
    "\n",
    "verb = False\n",
    "\n",
    "template = \"\"\"Q: {question} A:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=t.llm, verbose=verb)\n",
    "\n",
    "template_2 = \"\"\"Reverse this sentence: {sentence}.\"\"\"\n",
    "prompt_2 = PromptTemplate(template=template_2, input_variables=[\"sentence\"])\n",
    "llm_chain_2 = LLMChain(prompt=prompt_2, llm=t.llm, verbose=verb)\n",
    "\n",
    "# print(llm_chain.run(question=\"What is the average air speed velocity of a laden swallow?\"))\n",
    "\n",
    "print(llm_chain_2.run(sentence=\"How are you doing?\"))\n",
    "\n",
    "seq_chain = SimpleSequentialChain(chains=[llm_chain, llm_chain_2], input_key=\"question\", output_key=\"answer\")\n",
    "seq_chain.run(question=\"What is the average air speed velocity of a laden swallow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_chain_2 = TruChain(seq_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chain.run(question=\"What is the average air speed velocity of a laden swallow? again\")\n",
    "tru_chain_2.run(question=\"What is the average air speed velocity of a laden swallow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in tru_chain_2.records:\n",
    "    print(pp.pformat(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_chain_2.run(question=\"What is the average air speed velocity of a laden swallow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_chain_2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "for frame_info in inspect.stack():\n",
    "    frame = frame_info.frame\n",
    "    print(frame_info.function)\n",
    "    # print(frame.f_code)\n",
    "    print(frame.f_locals.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = TinyDB(\"db.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = db.table(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
