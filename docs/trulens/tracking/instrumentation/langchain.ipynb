{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì ü¶úÔ∏èüîó _LangChain_ Integration\n",
    "\n",
    "TruLens provides TruChain, a deep integration with _LangChain_ to allow you to\n",
    "inspect and evaluate the internals of your application built using _LangChain_.\n",
    "This is done through the instrumentation of key _LangChain_ classes. To see a list\n",
    "of classes instrumented, see *Appendix: Instrumented _LangChain_ Classes and\n",
    "Methods*.\n",
    "\n",
    "In addition to the default instrumentation, TruChain exposes the\n",
    "*select_context* method for evaluations that require access to retrieved\n",
    "context. Exposing *select_context* bypasses the need to know the json structure\n",
    "of your app ahead of time, and makes your evaluations reusable across different\n",
    "apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "To demonstrate usage, we'll create a standard RAG defined with LCEL.\n",
    "\n",
    "First, this requires loading data into a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define the retriever chain using LCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To instrument an LLM chain, all that's required is to wrap it using TruChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.instrument.langchain import TruChain\n",
    "\n",
    "# instrument with TruChain\n",
    "tru_recorder = TruChain(rag_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly evaluate LLM apps we often need to point our evaluation at an\n",
    "internal step of our application, such as the retrieved context. Doing so allows\n",
    "us to evaluate for metrics including context relevance and groundedness.\n",
    "\n",
    "For LangChain applications where the BaseRetriever is used, `select_context` can\n",
    "be used to access the retrieved text for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "provider = OpenAI()\n",
    "\n",
    "context = TruChain.select_context(rag_chain)\n",
    "\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For added flexibility, the select_context method is also made available through\n",
    "`trulens.core.app.App`. This allows you to switch between frameworks without\n",
    "changing your context selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = TruChain.select_context(rag_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the full quickstart available here: [LangChain Quickstart](../../getting_started/quickstarts/langchain_quickstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Support\n",
    "\n",
    "TruChain also provides async support for _LangChain_ through the `acall` method. This allows you to track and evaluate async and streaming _LangChain_ applications.\n",
    "\n",
    "As an example, below is an LLM chain set up with an async callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import AsyncIteratorCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from trulens.instrument.langchain import TruChain\n",
    "\n",
    "# Set up an async callback.\n",
    "callback = AsyncIteratorCallbackHandler()\n",
    "\n",
    "# Setup a simple question/answer chain with streaming ChatOpenAI.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Honestly answer this question: {question}.\"\n",
    ")\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    streaming=True,  # important\n",
    "    callbacks=[callback],\n",
    ")\n",
    "async_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created the async LLM chain you can instrument it just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_tc_recorder = TruChain(async_chain)\n",
    "\n",
    "with async_tc_recorder as recording:\n",
    "    await async_chain.ainvoke(\n",
    "        input=dict(question=\"What is 1+2? Explain your answer.\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more usage examples, check out the [LangChain examples directory](https://github.com/truera/trulens/tree/main/examples/expositional/frameworks/langchain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Instrumented LangChain Classes and Methods\n",
    "\n",
    "The modules, classes, and methods that trulens instruments can be retrieved from\n",
    "the appropriate Instrument subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.instrument.langchain import LangChainInstrument\n",
    "\n",
    "LangChainInstrument().print_instrumentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrumenting other classes/methods.\n",
    "Additional classes and methods can be instrumented by use of the\n",
    "`trulens.core.instruments.Instrument` methods and decorators. Examples of\n",
    "such usage can be found in the custom app used in the `custom_example.ipynb`\n",
    "notebook which can be found in\n",
    "`examples/expositional/end2end_apps/custom_app/custom_app.py`. More\n",
    "information about these decorators can be found in the\n",
    "`docs/tracking/instrumentation/index.ipynb` notebook.\n",
    "\n",
    "### Inspecting instrumentation\n",
    "The specific objects (of the above classes) and methods instrumented for a\n",
    "particular app can be inspected using the `App.print_instrumented` as\n",
    "exemplified in the next cell. Unlike `Instrument.print_instrumentation`, this\n",
    "function only shows what in an app was actually instrumented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_tc_recorder.print_instrumented()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d153714b979d5e6d08dd8ec90712dd93bff2c9b6c1f0c118169738af3430cd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
