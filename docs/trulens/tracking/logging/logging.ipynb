{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454903c2",
   "metadata": {},
   "source": [
    "# Logging Methods\n",
    "\n",
    "## Automatic Logging\n",
    "\n",
    "The simplest method for logging with TruLens is by wrapping with TruChain and\n",
    "including the tru argument, as shown in the quickstart.\n",
    "\n",
    "This is done like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports main tools:\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import OpenAI\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import TruSession\n",
    "from trulens.instrument.langchain import TruChain\n",
    "from trulens.providers.huggingface import Huggingface\n",
    "\n",
    "tru = TruSession()\n",
    "\n",
    "TruSession().migrate_database()\n",
    "\n",
    "full_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"Provide a helpful response with relevant background information for the following: {prompt}\",\n",
    "        input_variables=[\"prompt\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
    "\n",
    "llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=chat_prompt_template, verbose=True)\n",
    "\n",
    "truchain = TruChain(\n",
    "    chain, app_name=\"ChatApplication\", app_version=\"Chain1\", tru=tru\n",
    ")\n",
    "with truchain:\n",
    "    chain(\"This will be automatically logged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d382033",
   "metadata": {},
   "source": [
    "Feedback functions can also be logged automatically by providing them in a list\n",
    "to the feedbacks arg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d382034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on_input_output()\n",
    "# By default this will check language match on the main app input and main app\n",
    "# output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9152cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "truchain = TruChain(\n",
    "    chain,\n",
    "    app_name=\"ChatApplication\",\n",
    "    app_version=\"Chain1\",\n",
    "    feedbacks=[f_lang_match],  # feedback functions\n",
    "    tru=tru,\n",
    ")\n",
    "with truchain:\n",
    "    chain(\"This will be automatically logged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a562298",
   "metadata": {},
   "source": [
    "## Manual Logging\n",
    "\n",
    "### Wrap with TruChain to instrument your chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TruChain(chain, app_name=\"ChatApplication\", app_version=\"Chain2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25e0f9",
   "metadata": {},
   "source": [
    "### Set up logging and instrumentation\n",
    "\n",
    "Making the first call to your wrapped LLM Application will now also produce a log or \"record\" of the chain execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input = \"que hora es?\"\n",
    "gpt3_response, record = tc.with_record(chain.__call__, prompt_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a9435",
   "metadata": {},
   "source": [
    "We can log the records but first we need to log the chain itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.add_app(app=truchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381d0f1",
   "metadata": {},
   "source": [
    "Then we can log the record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.add_record(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d94f6",
   "metadata": {},
   "source": [
    "### Log App Feedback\n",
    "Capturing app feedback such as user feedback of the responses can be added with\n",
    "one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thumb_result = True\n",
    "tru.add_feedback(\n",
    "    name=\"üëç (1) or üëé (0)\", record_id=record.record_id, result=thumb_result\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0b62c",
   "metadata": {},
   "source": [
    "### Evaluate Quality\n",
    "\n",
    "Following the request to your app, you can then evaluate LLM quality using\n",
    "feedback functions. This is completed in a sequential call to minimize latency\n",
    "for your application, and evaluations will also be logged to your local machine.\n",
    "\n",
    "To get feedback on the quality of your LLM, you can use any of the provided\n",
    "feedback functions or add your own.\n",
    "\n",
    "To assess your LLM quality, you can provide the feedback functions to\n",
    "`tru.run_feedback()` in a list provided to `feedback_functions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record, feedback_functions=[f_lang_match]\n",
    ")\n",
    "for result in feedback_results:\n",
    "    display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ace16",
   "metadata": {},
   "source": [
    "After capturing feedback, you can then log it to your local database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a23831",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ecdc2b",
   "metadata": {},
   "source": [
    "### Out-of-band Feedback evaluation\n",
    "\n",
    "In the above example, the feedback function evaluation is done in the same\n",
    "process as the chain evaluation. The alternative approach is the use the\n",
    "provided persistent evaluator started via\n",
    "`tru.start_deferred_feedback_evaluator`. Then specify the `feedback_mode` for\n",
    "`TruChain` as `deferred` to let the evaluator handle the feedback functions.\n",
    "\n",
    "For demonstration purposes, we start the evaluator here but it can be started in\n",
    "another process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "truchain: TruChain = TruChain(\n",
    "    chain,\n",
    "    app_name=\"ChatApplication\",\n",
    "    app_version=\"chain_1\",\n",
    "    feedbacks=[f_lang_match],\n",
    "    tru=tru,\n",
    "    feedback_mode=\"deferred\",\n",
    ")\n",
    "\n",
    "with truchain:\n",
    "    chain(\"This will be logged by deferred evaluator.\")\n",
    "\n",
    "tru.start_evaluator()\n",
    "# tru.stop_evaluator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
