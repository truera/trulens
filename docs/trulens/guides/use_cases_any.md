# TruLens for any application

This section highlights different end-to-end use cases that TruLens can help with for any LLM application. For each use case, we not only motivate the use case but also discuss which components are most helpful for solving that use case.

!!! info "[Model Selection](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/model_comparison.ipynb)"
    Use TruLens to choose the most performant and efficient model for your application.

!!! info "[Moderation and Safety](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/moderation.ipynb)"
    Monitor your LLM application responses against a set of moderation and safety checks.

!!! info "[Language Verification](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/language_verification.ipynb)"
    Verify your LLM application responds in the same language it is prompted.

!!! info "[PII Detection](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/pii_detection.ipynb)"
    Detect PII in prompts or LLM response to prevent unintended leaks.
