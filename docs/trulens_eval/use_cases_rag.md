
# For Retrieval Augmented Generation (RAG)
This section highlights different end-to-end use cases that TruLens can help with when building RAG applications. For each use case, we not only motivate the use case but also discuss which components are most helpful for solving that use case.

!!! info "[Detect and Mitigate Hallucination](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/quickstart.ipynb)"
    Use the RAG Triad to ensure that your LLM responds using only the information retrieved from a verified knowledge source.

!!! info "[Improve Retrieval Quality](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/frameworks/llama_index/llama_index_retrievalquality.ipynb)"
    Measure and identify ways to improve the quality of retrieval for your RAG.

!!! info "[Optimize App Configuration](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/vector-dbs/pinecone/pinecone_evals_build_better_rags.ipynb)"
    Iterate through a set of configuration options for your RAG including different metrics, parameters, models and more; find the most performant with TruLens.

!!! info "[Verify the Summarization Quality](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/summarization_eval.ipynb)"
    Ensure that LLM summarizations contain the key points from source documents.