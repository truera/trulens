{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "In this quickstart you will create a simple LLM Chain and learn how to log it and get feedback on an LLM response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from LangChain and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "# Imports main tools:\n",
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "tru = Tru()\n",
    "\n",
    "# imports from langchain to build app\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple LLM Application\n",
    "\n",
    "This example uses a LangChain framework and OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\n",
    "        \"Provide a helpful response with relevant background information for the following: {prompt}\",\n",
    "        input_variables=[\"prompt\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
    "\n",
    "llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=chat_prompt_template, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send your first request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input = '¿que hora es?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Provide a helpful response with relevant background information for the following: ¿que hora es?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': '¿que hora es?',\n",
       " 'text': '\\n\\nLa hora actual es [hora actual]. La hora es la medida en que la Tierra se divide en 24 horas del día. Una hora es un intervalo de tiempo que equivale a 60 minutos. Un minuto es una fracción de 60 segundos. El tiempo es medido en relojes, relojes digitales, teléfonos celulares y otros dispositivos.'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_response = chain(prompt_input)\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0cc1a9578c492a96f8680b2e8babe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "huggingface api: 0requests [00:00, ?requests/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on(\n",
    "    text1=\"prompt\", text2=\"response\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chain Chain3_ChatApplication -> default.sqlite\n",
      "✅ feedback def. feedback_hash_26c84c76d907d808c36028e024af63c0 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "truchain = TruChain(chain,\n",
    "    chain_id='Chain3_ChatApplication',\n",
    "    feedbacks=[f_lang_match],\n",
    "    tru = tru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': '¿que hora es?',\n",
       " 'text': '\\n\\nLa hora actual es la hora exacta del reloj. Dependiendo de dónde te encuentres, la hora puede ser diferente porque hay diferentes husos horarios en diferentes partes del mundo.'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ record record_hash_c6e856f362dc9a30bc823182eeb335b4 from Chain3_ChatApplication -> default.sqlite"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ feedback feedback_hash_26c84c76d907d808c36028e024af63c0 on record_hash_c6e856f362dc9a30bc823182eeb335b4 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "# Instrumented chain can operate like the original:\n",
    "llm_response = truchain(prompt_input)\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Network URL: http://192.168.4.23:8502\n",
      "  External URL: http://100.36.49.61:8502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.run_dashboard(_dev=True) # if running from repo\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Leaderboard\n",
    "\n",
    "Understand how your LLM application is performing at a glance. Once you've set up logging and evaluation in your application, you can view key performance statistics including cost and average feedback value across all of your LLM apps using the chain leaderboard. As you iterate new versions of your LLM application, you can compare their performance across all of the different quality metrics you've set up.\n",
    "\n",
    "Note: Average feedback values are returned and displayed in a range from 0 (worst) to 1 (best).\n",
    "\n",
    "![Chain Leaderboard](Assets/image/Leaderboard.png)\n",
    "\n",
    "To dive deeper on a particular chain, click \"Select Chain\".\n",
    "\n",
    "### Understand chain performance with Evaluations\n",
    " \n",
    "To learn more about the performance of a particular chain or LLM model, we can select it to view its evaluations at the record level. LLM quality is assessed through the use of feedback functions. Feedback functions are extensible methods for determining the quality of LLM responses and can be applied to any downstream LLM task. Out of the box we provide a number of feedback functions for assessing model agreement, sentiment, relevance and more.\n",
    "\n",
    "The evaluations tab provides record-level metadata and feedback on the quality of your LLM application.\n",
    "\n",
    "![Evaluations](Assets/image/Leaderboard.png)\n",
    "\n",
    "### Deep dive into full chain metadata\n",
    "\n",
    "Click on a record to dive deep into all of the details of your chain stack and underlying LLM, captured by tru_chain.\n",
    "\n",
    "![Explore a Chain](Assets/image/Chain_Explore.png)\n",
    "\n",
    "If you prefer the raw format, you can quickly get it using the \"Display full chain json\" or \"Display full record json\" buttons at the bottom of the page."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or view results directly in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>record_json</th>\n",
       "      <th>tags</th>\n",
       "      <th>ts</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>chain_json</th>\n",
       "      <th>feedback_id</th>\n",
       "      <th>language_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record_hash_c6e856f362dc9a30bc823182eeb335b4</td>\n",
       "      <td>Chain3_ChatApplication</td>\n",
       "      <td>¿que hora es?</td>\n",
       "      <td>\\n\\nLa hora actual es la hora exacta del reloj...</td>\n",
       "      <td>{\"chain\": {\"_call\": {\"args\": {\"inputs\": {\"prom...</td>\n",
       "      <td>dev</td>\n",
       "      <td>2023-05-30 13:31:25.534667</td>\n",
       "      <td>84</td>\n",
       "      <td>0.00168</td>\n",
       "      <td>{\"memory\": null, \"callbacks\": null, \"callback_...</td>\n",
       "      <td>feedback_hash_26c84c76d907d808c36028e024af63c0</td>\n",
       "      <td>0.993324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      record_id                chain_id   \n",
       "0  record_hash_c6e856f362dc9a30bc823182eeb335b4  Chain3_ChatApplication  \\\n",
       "\n",
       "           input                                             output   \n",
       "0  ¿que hora es?  \\n\\nLa hora actual es la hora exacta del reloj...  \\\n",
       "\n",
       "                                         record_json tags   \n",
       "0  {\"chain\": {\"_call\": {\"args\": {\"inputs\": {\"prom...  dev  \\\n",
       "\n",
       "                           ts  total_tokens  total_cost   \n",
       "0  2023-05-30 13:31:25.534667            84     0.00168  \\\n",
       "\n",
       "                                          chain_json   \n",
       "0  {\"memory\": null, \"callbacks\": null, \"callback_...  \\\n",
       "\n",
       "                                      feedback_id  language_match  \n",
       "0  feedback_hash_26c84c76d907d808c36028e024af63c0        0.993324  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_records_and_feedback(chain_ids=[])[0] # pass an empty list of chain_ids to get all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5737f6101ac92451320b0e41890107145710b89f85909f3780d702e7818f973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
