{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì _LangChain_ Quickstart\n",
    "\n",
    "In this quickstart you will create a simple LCEL Chain and learn how to log it and get feedback on an LLM response.\n",
    "\n",
    "For evaluation, we will leverage the RAG triad of groundedness, context relevance and answer relevance.\n",
    "\n",
    "You'll also learn how to use feedbacks for guardrails, via filtering retrieved context.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/langchain_quickstart.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval openai langchain langchain-openai langchain_community faiss-cpu bs4 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from LangChain and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/snowday/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶ë Tru initialized with db url sqlite:///default.sqlite .\n",
      "üõë Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "# Imports main tools:\n",
    "from trulens_eval import TruChain, Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "# Imports from LangChain to build app\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/snowday/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send your first request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is a technique that breaks down complex tasks into smaller and simpler steps to enhance model performance. It involves transforming big tasks into manageable tasks by decomposing them into multiple steps. Task decomposition can be achieved through various methods, such as using simple prompting, task-specific instructions, or relying on external classical planners.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Groundedness, input source will be set to __record__.app.first.steps__.context.first.invoke.rets[:].page_content.collect() .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.first.steps__.context.first.invoke.rets[:].page_content .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval import Feedback\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rag_chain)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rag_chain,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_answer_relevance, f_context_relevance, f_groundedness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is a technique that breaks down complex tasks into smaller and simpler steps to enhance model performance. It involves transforming big tasks into manageable tasks by decomposing them into multiple steps. Task decomposition can be achieved through various methods, such as using simple prompting, task-specific instructions, or relying on external classical planners.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rag_chain.invoke(\"What is Task Decomposition?\")\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chain1_ChatApplication</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Answer Relevance  Groundedness  Context Relevance  \\\n",
       "app_id                                                                      \n",
       "Chain1_ChatApplication               0.9           1.0                0.6   \n",
       "\n",
       "                        latency  total_cost  \n",
       "app_id                                       \n",
       "Chain1_ChatApplication      2.0    0.004985  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking closer at context relevance, we see that our retriever is returning irrelevant context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>Fig. 1. Overview of a LLM-powered autonomous a...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>Fig. 10. A picture of a sea otter using rock t...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>(3) Task execution: Expert models execute on t...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>Fig. 6. Illustration of how Algorithm Distilla...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      question  \\\n",
       "0  What is Task Decomposition?   \n",
       "1  What is Task Decomposition?   \n",
       "2  What is Task Decomposition?   \n",
       "3  What is Task Decomposition?   \n",
       "\n",
       "                                             context  ret  \n",
       "0  Fig. 1. Overview of a LLM-powered autonomous a...  0.8  \n",
       "1  Fig. 10. A picture of a sea otter using rock t...  0.4  \n",
       "2  (3) Task execution: Expert models execute on t...  0.4  \n",
       "3  Fig. 6. Illustration of how Algorithm Distilla...  0.8  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use guardrails\n",
    "\n",
    "In addition to making informed iteration, we can also directly use feedback results as guardrails at inference time. In particular, here we show how to use the context relevance score as a guardrail to filter out irrelevant context before it gets passed to the LLM. This both reduces hallucination and improves efficiency.\n",
    "\n",
    "Below, you can see the TruLens feedback display of each context relevance chunk retrieved by our RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wouldn't it be great if we could automatically filter out context chunks with relevance scores below 0.5?\n",
    "\n",
    "We can do so with the TruLens guardrail, *WithFeedbackFilterDocuments*. All we have to do is use the method `of_retriever` to create a new filtered retriever, passing in the original retriever along with the feedback function and threshold we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.guardrails.langchain import WithFeedbackFilterDocuments\n",
    "\n",
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance)\n",
    ")\n",
    "\n",
    "filtered_retriever = WithFeedbackFilterDocuments.of_retriever(\n",
    "        retriever=retriever,\n",
    "        feedback=f_context_relevance_score,\n",
    "        threshold=0.75\n",
    "    )\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": filtered_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can operate as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tru_recorder = TruChain(rag_chain,\n",
    "    app_id='Chain1_ChatApplication_Filtered',\n",
    "    feedbacks=[f_answer_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    llm_response = rag_chain.invoke(\"What is Task Decomposition?\")\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the power of context filters!\n",
    "\n",
    "If we inspect the context relevance of our retreival now, you see only relevant context chunks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>Fig. 1. Overview of a LLM-powered autonomous a...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      question  \\\n",
       "0  What is Task Decomposition?   \n",
       "\n",
       "                                             context  ret  \n",
       "0  Fig. 1. Overview of a LLM-powered autonomous a...  0.8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03498a4bf944abf8e93cd957cebe2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.206:1236 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve records and feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record(record_id='record_hash_b58260de958b6a44f38e92067bd75220', app_id='Chain1_ChatApplication_Filtered', cost=Cost(n_requests=6, n_successful_requests=21, n_classes=0, n_tokens=15902, n_stream_chunks=0, n_prompt_tokens=15823, n_completion_tokens=79, cost=0.023838500000000002), perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 168333), end_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 718205)), ts=datetime.datetime(2024, 7, 3, 5, 51, 13, 718234), tags='-', meta=None, main_input='What is Task Decomposition?', main_output='Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', main_error=None, calls=[RecordAppCall(call_id='201a07bb-6b2f-4616-ae75-0320ec1bc97b', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.question, method=Method(obj=Obj(cls=langchain_core.runnables.passthrough.RunnablePassthrough, id=6209785744, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13729026896, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='What is Task Decomposition?', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 320329), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 340951)), pid=54862, tid=6435954), RecordAppCall(call_id='213e417f-c348-4f97-aae7-7be4a78594ba', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=langchain_core.vectorstores.VectorStoreRetriever, id=13728093840, init_bindings=None), name='_get_relevant_documents'))], args={'query': 'What is Task Decomposition?', 'run_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManagerForRetrieverRun', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728753936, 'init_bindings': None}}}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for ‚ÄúModular Reasoning, Knowledge and Language‚Äù, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of ‚Äúexpert‚Äù modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the ‚ÄúExternal APIs‚Äù section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent‚Äôs tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API‚Äôs description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user‚Äôs requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\", 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 359885), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 572243)), pid=54862, tid=6435953), RecordAppCall(call_id='15a79df3-d358-42b9-88c9-53ea69d4a05d', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=15142675120, init_bindings=None), name='__call__'))], args={'args': ['What is Task Decomposition?', 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.']}, rets=0.8, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 579728), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 910319)), pid=54862, tid=6435956), RecordAppCall(call_id='97f870cf-22d6-4b09-8c35-3f8eeeb89272', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=15142675120, init_bindings=None), name='__call__'))], args={'args': ['What is Task Decomposition?', 'Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for ‚ÄúModular Reasoning, Knowledge and Language‚Äù, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of ‚Äúexpert‚Äù modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the ‚ÄúExternal APIs‚Äù section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.']}, rets=0.4, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 583334), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 926111)), pid=54862, tid=6435957), RecordAppCall(call_id='ba9d8945-aedf-450d-b117-11e076671be5', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=15142675120, init_bindings=None), name='__call__'))], args={'args': ['What is Task Decomposition?', \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent‚Äôs tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API‚Äôs description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user‚Äôs requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\"]}, rets=0.7, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 587395), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 962103)), pid=54862, tid=6435958), RecordAppCall(call_id='1d661575-b055-4a76-a521-93d75e128e7b', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=15142675120, init_bindings=None), name='__call__'))], args={'args': ['What is Task Decomposition?', 'Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.']}, rets=0.7, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 588874), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 96782)), pid=54862, tid=6435959), RecordAppCall(call_id='116aef8b-819d-4c8f-97ef-7c7cf9bbf679', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents'))], args={'query': 'What is Task Decomposition?', 'run_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManagerForRetrieverRun', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728753936, 'init_bindings': None}}}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 344589), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 97110)), pid=54862, tid=6435953), RecordAppCall(call_id='d142197e-7eb5-4f9a-903b-709ee271b41a', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 14945277584, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 323578), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 97315)), pid=54862, tid=6435953), RecordAppCall(call_id='a41025a7-e33a-41a3-8fb2-c5750cad6820', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 15143364304, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 298906), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 97865)), pid=54862, tid=6435953), RecordAppCall(call_id='fa15611c-5c96-42ed-a9bb-ab7128b4598d', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728000272, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'context': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'question': 'What is Task Decomposition?'}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 241491), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 98091)), pid=54862, tid=6435330), RecordAppCall(call_id='b917c04f-9f13-4771-8c83-ea5bcd954f73', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.middle[0], method=Method(obj=Obj(cls=langchain_core.prompts.chat.ChatPromptTemplate, id=15129453584, init_bindings=None), name='invoke'))], args={'input': {'context': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'question': 'What is Task Decomposition?'}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13726364240, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'messages': [{'content': 'You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is Task Decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results. \\nAnswer:', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}]}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 178202), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 215342)), pid=54862, tid=6435330), RecordAppCall(call_id='72a5680b-5c89-47ba-8e2d-2c00bf28bb46', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.middle[1], method=Method(obj=Obj(cls=langchain_community.chat_models.openai.ChatOpenAI, id=15122144848, init_bindings=None), name='invoke'))], args={'input': {'messages': [{'content': 'You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is Task Decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results. \\nAnswer:', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}]}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 15145143184, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'content': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 65, 'prompt_tokens': 836, 'total_tokens': 901}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-05f3d6ee-fc3a-4a3f-aaf1-812eb7375cb9-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 310321), end_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 631697)), pid=54862, tid=6435330), RecordAppCall(call_id='7b1114dd-b7f8-4de4-993f-06dda4194d33', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.last, method=Method(obj=Obj(cls=langchain_core.output_parsers.string.StrOutputParser, id=13724810128, init_bindings=None), name='invoke'))], args={'input': {'content': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 65, 'prompt_tokens': 836, 'total_tokens': 901}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-05f3d6ee-fc3a-4a3f-aaf1-812eb7375cb9-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13727989648, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 690211), end_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 718171)), pid=54862, tid=6435330), RecordAppCall(call_id='c74b4da5-6555-4647-ae00-115a614e701d', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?'}, rets='Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 168333), end_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 718205)), pid=54862, tid=6435330)], feedback_and_future_results=[(FeedbackDefinition(Answer Relevance,\n",
       "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       "), <Future at 0x3854f7990 state=finished returned FeedbackResult>), (FeedbackDefinition(Context Relevance,\n",
       "\tselectors={'question': Lens().__record__.main_input, 'context': Lens().__record__.app.first.steps__.context.first.invoke.rets[:].page_content},\n",
       "\tif_exists=None\n",
       "), <Future at 0x386ba6b90 state=finished returned FeedbackResult>), (FeedbackDefinition(Groundedness,\n",
       "\tselectors={'source': Lens().__record__.app.first.steps__.context.first.invoke.rets[:].page_content.collect(), 'statement': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       "), <Future at 0x386b55010 state=finished returned FeedbackResult>)], feedback_results=[<Future at 0x3854f7990 state=finished returned FeedbackResult>, <Future at 0x386ba6b90 state=finished returned FeedbackResult>, <Future at 0x386b55010 state=finished returned FeedbackResult>])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "# recs = recording.records # use .records if multiple\n",
    "\n",
    "display(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Relevance 0.9\n",
      "Context Relevance 0.8\n",
      "Groundedness 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# The results of the feedback functions can be rertrieved from\n",
    "# `Record.feedback_results` or using the `wait_for_feedback_result` method. The\n",
    "# results if retrieved directly are `Future` instances (see\n",
    "# `concurrent.futures`). You can use `as_completed` to wait until they have\n",
    "# finished evaluating or use the utility method:\n",
    "\n",
    "for feedback, feedback_result in rec.wait_for_feedback_results().items():\n",
    "    print(feedback.name, feedback_result.result)\n",
    "\n",
    "# See more about wait_for_feedback_results:\n",
    "# help(rec.wait_for_feedback_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruChain\", \"modul...</td>\n",
       "      <td>RunnableSequence(langchain_core.runnables.base)</td>\n",
       "      <td>record_hash_402adfcfca139d116e6a0dd79b7813c8</td>\n",
       "      <td>\"What is Task Decomposition?\"</td>\n",
       "      <td>\"Task Decomposition is a technique that breaks...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_402adfcfca139d116e6...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 3, ...</td>\n",
       "      <td>{\"start_time\": \"2024-07-03T05:50:39.251674\", \"...</td>\n",
       "      <td>2024-07-03T05:50:41.272357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'source': ['Fig. 1. Overview of a L...</td>\n",
       "      <td>[{'args': {'question': 'What is Task Decomposi...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Task Decompositi...</td>\n",
       "      <td>2</td>\n",
       "      <td>3314</td>\n",
       "      <td>0.004985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chain1_ChatApplication_Filtered</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruChain\", \"modul...</td>\n",
       "      <td>RunnableSequence(langchain_core.runnables.base)</td>\n",
       "      <td>record_hash_b58260de958b6a44f38e92067bd75220</td>\n",
       "      <td>\"What is Task Decomposition?\"</td>\n",
       "      <td>\"Task decomposition is a technique used to bre...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_b58260de958b6a44f38...</td>\n",
       "      <td>{\"n_requests\": 6, \"n_successful_requests\": 21,...</td>\n",
       "      <td>{\"start_time\": \"2024-07-03T05:51:11.168333\", \"...</td>\n",
       "      <td>2024-07-03T05:51:13.718234</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'source': ['Fig. 1. Overview of a L...</td>\n",
       "      <td>[{'args': {'question': 'What is Task Decomposi...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Task Decompositi...</td>\n",
       "      <td>2</td>\n",
       "      <td>15902</td>\n",
       "      <td>0.023839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            app_id  \\\n",
       "0           Chain1_ChatApplication   \n",
       "1  Chain1_ChatApplication_Filtered   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruChain\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruChain\", \"modul...   \n",
       "\n",
       "                                              type  \\\n",
       "0  RunnableSequence(langchain_core.runnables.base)   \n",
       "1  RunnableSequence(langchain_core.runnables.base)   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_402adfcfca139d116e6a0dd79b7813c8   \n",
       "1  record_hash_b58260de958b6a44f38e92067bd75220   \n",
       "\n",
       "                           input  \\\n",
       "0  \"What is Task Decomposition?\"   \n",
       "1  \"What is Task Decomposition?\"   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Task Decomposition is a technique that breaks...    -   \n",
       "1  \"Task decomposition is a technique used to bre...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_402adfcfca139d116e6...   \n",
       "1  {\"record_id\": \"record_hash_b58260de958b6a44f38...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 2, \"n_successful_requests\": 3, ...   \n",
       "1  {\"n_requests\": 6, \"n_successful_requests\": 21,...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-07-03T05:50:39.251674\", \"...   \n",
       "1  {\"start_time\": \"2024-07-03T05:51:11.168333\", \"...   \n",
       "\n",
       "                           ts  Groundedness  Context Relevance  \\\n",
       "0  2024-07-03T05:50:41.272357      1.000000                0.6   \n",
       "1  2024-07-03T05:51:13.718234      0.966667                0.8   \n",
       "\n",
       "   Answer Relevance                                 Groundedness_calls  \\\n",
       "0               0.9  [{'args': {'source': ['Fig. 1. Overview of a L...   \n",
       "1               0.9  [{'args': {'source': ['Fig. 1. Overview of a L...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'question': 'What is Task Decomposi...   \n",
       "1  [{'args': {'question': 'What is Task Decomposi...   \n",
       "\n",
       "                              Answer Relevance_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'prompt': 'What is Task Decompositi...        2          3314   \n",
       "1  [{'args': {'prompt': 'What is Task Decompositi...        2         15902   \n",
       "\n",
       "   total_cost  \n",
       "0    0.004985  \n",
       "1    0.023839  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chain1_ChatApplication</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chain1_ChatApplication_Filtered</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.023839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Answer Relevance  Groundedness  \\\n",
       "app_id                                                            \n",
       "Chain1_ChatApplication                        0.9      1.000000   \n",
       "Chain1_ChatApplication_Filtered               0.9      0.966667   \n",
       "\n",
       "                                 Context Relevance  latency  total_cost  \n",
       "app_id                                                                   \n",
       "Chain1_ChatApplication                         0.6      2.0    0.004985  \n",
       "Chain1_ChatApplication_Filtered                0.8      2.0    0.023839  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn more about the call stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_like = last_record.layout_calls_as_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Munch({'record_id': 'record_hash_b58260de958b6a44f38e92067bd75220', 'app_id': 'Chain1_ChatApplication_Filtered', 'cost': {'n_requests': 6, 'n_successful_requests': 21, 'n_classes': 0, 'n_tokens': 15902, 'n_stream_chunks': 0, 'n_prompt_tokens': 15823, 'n_completion_tokens': 79, 'cost': 0.023838500000000002}, 'perf': {'start_time': '2024-07-03T05:51:11.168333', 'end_time': '2024-07-03T05:51:13.718205'}, 'ts': '2024-07-03T05:51:13.718234', 'tags': '-', 'meta': None, 'main_input': 'What is Task Decomposition?', 'main_output': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'main_error': None, 'calls': [{'call_id': '201a07bb-6b2f-4616-ae75-0320ec1bc97b', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.question', 'method': {'obj': {'cls': {'name': 'RunnablePassthrough', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.passthrough'}, 'bases': None}, 'id': 6209785744, 'init_bindings': None}, 'name': 'invoke'}}], 'args': {'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13729026896, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, 'rets': 'What is Task Decomposition?', 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.320329', 'end_time': '2024-07-03T05:51:11.340951'}, 'pid': 54862, 'tid': 6435954}, {'call_id': '213e417f-c348-4f97-aae7-7be4a78594ba', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': '_get_relevant_documents'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'VectorStoreRetriever', 'module': {'package_name': 'langchain_core', 'module_name': 'langchain_core.vectorstores'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': '_get_relevant_documents'}}], 'args': {'query': 'What is Task Decomposition?', 'run_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManagerForRetrieverRun', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728753936, 'init_bindings': None}}}, 'rets': [{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for ‚ÄúModular Reasoning, Knowledge and Language‚Äù, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of ‚Äúexpert‚Äù modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the ‚ÄúExternal APIs‚Äù section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent‚Äôs tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API‚Äôs description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user‚Äôs requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\", 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.359885', 'end_time': '2024-07-03T05:51:11.572243'}, 'pid': 54862, 'tid': 6435953}, {'call_id': '15a79df3-d358-42b9-88c9-53ea69d4a05d', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': '_get_relevant_documents'}}, {'path': 'app.first.steps__.context.first.feedback', 'method': {'obj': {'cls': {'name': 'Feedback', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.feedback'}, 'bases': None}, 'id': 15142675120, 'init_bindings': None}, 'name': '__call__'}}], 'args': {'args': ['What is Task Decomposition?', 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.']}, 'rets': 0.8, 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.579728', 'end_time': '2024-07-03T05:51:11.910319'}, 'pid': 54862, 'tid': 6435956}, {'call_id': '97f870cf-22d6-4b09-8c35-3f8eeeb89272', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': '_get_relevant_documents'}}, {'path': 'app.first.steps__.context.first.feedback', 'method': {'obj': {'cls': {'name': 'Feedback', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.feedback'}, 'bases': None}, 'id': 15142675120, 'init_bindings': None}, 'name': '__call__'}}], 'args': {'args': ['What is Task Decomposition?', 'Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for ‚ÄúModular Reasoning, Knowledge and Language‚Äù, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of ‚Äúexpert‚Äù modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the ‚ÄúExternal APIs‚Äù section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.']}, 'rets': 0.4, 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.583334', 'end_time': '2024-07-03T05:51:11.926111'}, 'pid': 54862, 'tid': 6435957}, {'call_id': 'ba9d8945-aedf-450d-b117-11e076671be5', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': '_get_relevant_documents'}}, {'path': 'app.first.steps__.context.first.feedback', 'method': {'obj': {'cls': {'name': 'Feedback', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.feedback'}, 'bases': None}, 'id': 15142675120, 'init_bindings': None}, 'name': '__call__'}}], 'args': {'args': ['What is Task Decomposition?', \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent‚Äôs tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API‚Äôs description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user‚Äôs requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\"]}, 'rets': 0.7, 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.587395', 'end_time': '2024-07-03T05:51:11.962103'}, 'pid': 54862, 'tid': 6435958}, {'call_id': '1d661575-b055-4a76-a521-93d75e128e7b', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': '_get_relevant_documents'}}, {'path': 'app.first.steps__.context.first.feedback', 'method': {'obj': {'cls': {'name': 'Feedback', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.feedback'}, 'bases': None}, 'id': 15142675120, 'init_bindings': None}, 'name': '__call__'}}], 'args': {'args': ['What is Task Decomposition?', 'Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.']}, 'rets': 0.7, 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.588874', 'end_time': '2024-07-03T05:51:12.096782'}, 'pid': 54862, 'tid': 6435959}, {'call_id': '116aef8b-819d-4c8f-97ef-7c7cf9bbf679', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': '_get_relevant_documents'}}], 'args': {'query': 'What is Task Decomposition?', 'run_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManagerForRetrieverRun', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728753936, 'init_bindings': None}}}, 'rets': [{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.344589', 'end_time': '2024-07-03T05:51:12.097110'}, 'pid': 54862, 'tid': 6435953}, {'call_id': 'd142197e-7eb5-4f9a-903b-709ee271b41a', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context.first', 'method': {'obj': {'cls': {'name': 'WithFeedbackFilterDocuments', 'module': {'package_name': 'trulens_eval.guardrails', 'module_name': 'trulens_eval.guardrails.langchain'}, 'bases': None}, 'id': 13728093840, 'init_bindings': None}, 'name': 'invoke'}}], 'args': {'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 14945277584, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, 'rets': [{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.323578', 'end_time': '2024-07-03T05:51:12.097315'}, 'pid': 54862, 'tid': 6435953}, {'call_id': 'a41025a7-e33a-41a3-8fb2-c5750cad6820', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first.steps__.context', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}], 'args': {'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 15143364304, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, 'rets': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.298906', 'end_time': '2024-07-03T05:51:12.097865'}, 'pid': 54862, 'tid': 6435953}, {'call_id': 'fa15611c-5c96-42ed-a9bb-ab7128b4598d', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.first', 'method': {'obj': {'cls': {'name': 'RunnableParallel', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 13726547408, 'init_bindings': None}, 'name': 'invoke'}}], 'args': {'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728000272, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, 'rets': {'context': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'question': 'What is Task Decomposition?'}, 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.241491', 'end_time': '2024-07-03T05:51:12.098091'}, 'pid': 54862, 'tid': 6435330}, {'call_id': 'b917c04f-9f13-4771-8c83-ea5bcd954f73', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.middle[0]', 'method': {'obj': {'cls': {'name': 'ChatPromptTemplate', 'module': {'package_name': 'langchain_core.prompts', 'module_name': 'langchain_core.prompts.chat'}, 'bases': None}, 'id': 15129453584, 'init_bindings': None}, 'name': 'invoke'}}], 'args': {'input': {'context': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'question': 'What is Task Decomposition?'}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13726364240, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, 'rets': {'messages': [{'content': 'You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is Task Decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results. \\nAnswer:', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}]}, 'error': None, 'perf': {'start_time': '2024-07-03T05:51:12.178202', 'end_time': '2024-07-03T05:51:12.215342'}, 'pid': 54862, 'tid': 6435330}, {'call_id': '72a5680b-5c89-47ba-8e2d-2c00bf28bb46', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.middle[1]', 'method': {'obj': {'cls': {'name': 'ChatOpenAI', 'module': {'package_name': 'langchain_community.chat_models', 'module_name': 'langchain_community.chat_models.openai'}, 'bases': None}, 'id': 15122144848, 'init_bindings': None}, 'name': 'invoke'}}], 'args': {'input': {'messages': [{'content': 'You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is Task Decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results. \\nAnswer:', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}]}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 15145143184, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, 'rets': {'content': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 65, 'prompt_tokens': 836, 'total_tokens': 901}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-05f3d6ee-fc3a-4a3f-aaf1-812eb7375cb9-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}, 'error': None, 'perf': {'start_time': '2024-07-03T05:51:12.310321', 'end_time': '2024-07-03T05:51:13.631697'}, 'pid': 54862, 'tid': 6435330}, {'call_id': '7b1114dd-b7f8-4de4-993f-06dda4194d33', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}, {'path': 'app.last', 'method': {'obj': {'cls': {'name': 'StrOutputParser', 'module': {'package_name': 'langchain_core.output_parsers', 'module_name': 'langchain_core.output_parsers.string'}, 'bases': None}, 'id': 13724810128, 'init_bindings': None}, 'name': 'invoke'}}], 'args': {'input': {'content': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 65, 'prompt_tokens': 836, 'total_tokens': 901}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-05f3d6ee-fc3a-4a3f-aaf1-812eb7375cb9-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13727989648, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, 'rets': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'error': None, 'perf': {'start_time': '2024-07-03T05:51:13.690211', 'end_time': '2024-07-03T05:51:13.718171'}, 'pid': 54862, 'tid': 6435330}, {'call_id': 'c74b4da5-6555-4647-ae00-115a614e701d', 'stack': [{'path': 'app', 'method': {'obj': {'cls': {'name': 'RunnableSequence', 'module': {'package_name': 'langchain_core.runnables', 'module_name': 'langchain_core.runnables.base'}, 'bases': None}, 'id': 6209315280, 'init_bindings': None}, 'name': 'invoke'}}], 'args': {'input': 'What is Task Decomposition?'}, 'rets': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'error': None, 'perf': {'start_time': '2024-07-03T05:51:11.168333', 'end_time': '2024-07-03T05:51:13.718205'}, 'pid': 54862, 'tid': 6435330}], 'app': {'first': {'steps__': {'question': {'invoke': [RecordAppCall(call_id='201a07bb-6b2f-4616-ae75-0320ec1bc97b', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.question, method=Method(obj=Obj(cls=langchain_core.runnables.passthrough.RunnablePassthrough, id=6209785744, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13729026896, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='What is Task Decomposition?', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 320329), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 340951)), pid=54862, tid=6435954)]}, 'context': {'first': {'_get_relevant_documents': [RecordAppCall(call_id='213e417f-c348-4f97-aae7-7be4a78594ba', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=langchain_core.vectorstores.VectorStoreRetriever, id=13728093840, init_bindings=None), name='_get_relevant_documents'))], args={'query': 'What is Task Decomposition?', 'run_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManagerForRetrieverRun', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728753936, 'init_bindings': None}}}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for ‚ÄúModular Reasoning, Knowledge and Language‚Äù, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of ‚Äúexpert‚Äù modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the ‚ÄúExternal APIs‚Äù section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent‚Äôs tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API‚Äôs description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user‚Äôs requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\", 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 359885), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 572243)), pid=54862, tid=6435953), RecordAppCall(call_id='116aef8b-819d-4c8f-97ef-7c7cf9bbf679', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents'))], args={'query': 'What is Task Decomposition?', 'run_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManagerForRetrieverRun', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728753936, 'init_bindings': None}}}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 344589), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 97110)), pid=54862, tid=6435953)], 'feedback': {'__call__': [RecordAppCall(call_id='15a79df3-d358-42b9-88c9-53ea69d4a05d', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=15142675120, init_bindings=None), name='__call__'))], args={'args': ['What is Task Decomposition?', 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.']}, rets=0.8, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 579728), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 910319)), pid=54862, tid=6435956), RecordAppCall(call_id='97f870cf-22d6-4b09-8c35-3f8eeeb89272', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=15142675120, init_bindings=None), name='__call__'))], args={'args': ['What is Task Decomposition?', 'Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for ‚ÄúModular Reasoning, Knowledge and Language‚Äù, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of ‚Äúexpert‚Äù modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the ‚ÄúExternal APIs‚Äù section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.']}, rets=0.4, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 583334), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 926111)), pid=54862, tid=6435957), RecordAppCall(call_id='ba9d8945-aedf-450d-b117-11e076671be5', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=15142675120, init_bindings=None), name='__call__'))], args={'args': ['What is Task Decomposition?', \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent‚Äôs tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API‚Äôs description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user‚Äôs requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\"]}, rets=0.7, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 587395), end_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 962103)), pid=54862, tid=6435958), RecordAppCall(call_id='1d661575-b055-4a76-a521-93d75e128e7b', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='_get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=15142675120, init_bindings=None), name='__call__'))], args={'args': ['What is Task Decomposition?', 'Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.']}, rets=0.7, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 588874), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 96782)), pid=54862, tid=6435959)]}, 'invoke': [RecordAppCall(call_id='d142197e-7eb5-4f9a-903b-709ee271b41a', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context.first, method=Method(obj=Obj(cls=trulens_eval.guardrails.langchain.WithFeedbackFilterDocuments, id=13728093840, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 14945277584, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 323578), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 97315)), pid=54862, tid=6435953)]}, 'invoke': [RecordAppCall(call_id='a41025a7-e33a-41a3-8fb2-c5750cad6820', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps__.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 15143364304, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 298906), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 97865)), pid=54862, tid=6435953)]}}, 'invoke': [RecordAppCall(call_id='fa15611c-5c96-42ed-a9bb-ab7128b4598d', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=13726547408, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13728000272, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'context': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'question': 'What is Task Decomposition?'}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 241491), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 98091)), pid=54862, tid=6435330)]}, 'middle': [{'invoke': [RecordAppCall(call_id='b917c04f-9f13-4771-8c83-ea5bcd954f73', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.middle[0], method=Method(obj=Obj(cls=langchain_core.prompts.chat.ChatPromptTemplate, id=15129453584, init_bindings=None), name='invoke'))], args={'input': {'context': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', 'question': 'What is Task Decomposition?'}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13726364240, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'messages': [{'content': 'You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is Task Decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results. \\nAnswer:', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}]}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 178202), end_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 215342)), pid=54862, tid=6435330)]}, {'invoke': [RecordAppCall(call_id='72a5680b-5c89-47ba-8e2d-2c00bf28bb46', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.middle[1], method=Method(obj=Obj(cls=langchain_community.chat_models.openai.ChatOpenAI, id=15122144848, init_bindings=None), name='invoke'))], args={'input': {'messages': [{'content': 'You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is Task Decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results. \\nAnswer:', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}]}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 15145143184, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'content': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 65, 'prompt_tokens': 836, 'total_tokens': 901}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-05f3d6ee-fc3a-4a3f-aaf1-812eb7375cb9-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 12, 310321), end_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 631697)), pid=54862, tid=6435330)]}], 'last': {'invoke': [RecordAppCall(call_id='7b1114dd-b7f8-4de4-993f-06dda4194d33', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.last, method=Method(obj=Obj(cls=langchain_core.output_parsers.string.StrOutputParser, id=13724810128, init_bindings=None), name='invoke'))], args={'input': {'content': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 65, 'prompt_tokens': 836, 'total_tokens': 901}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-05f3d6ee-fc3a-4a3f-aaf1-812eb7375cb9-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 13727989648, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 690211), end_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 718171)), pid=54862, tid=6435330)]}, 'invoke': [RecordAppCall(call_id='c74b4da5-6555-4647-ae00-115a614e701d', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=6209315280, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?'}, rets='Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be achieved through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions. Task decomposition can also involve outsourcing the planning step to an external classical planner, as seen in the LLM+P approach.', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 51, 11, 168333), end_time=datetime.datetime(2024, 7, 3, 5, 51, 13, 718205)), pid=54862, tid=6435330)]}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2552da4cfcf04dbbb13d1a5a68707116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tree(nodes=(Node(name='Record ID: record_hash_b58260de958b6a44f38e92067bd75220'), Node(name='App ID: Chain1_Ch‚Ä¶"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipytree import Tree, Node\n",
    "\n",
    "def display_call_stack(data):\n",
    "    tree = Tree()\n",
    "    tree.add_node(Node('Record ID: {}'.format(data['record_id'])))\n",
    "    tree.add_node(Node('App ID: {}'.format(data['app_id'])))\n",
    "    tree.add_node(Node('Cost: {}'.format(data['cost'])))\n",
    "    tree.add_node(Node('Performance: {}'.format(data['perf'])))\n",
    "    tree.add_node(Node('Timestamp: {}'.format(data['ts'])))\n",
    "    tree.add_node(Node('Tags: {}'.format(data['tags'])))\n",
    "    tree.add_node(Node('Main Input: {}'.format(data['main_input'])))\n",
    "    tree.add_node(Node('Main Output: {}'.format(data['main_output'])))\n",
    "    tree.add_node(Node('Main Error: {}'.format(data['main_error'])))\n",
    "    \n",
    "    calls_node = Node('Calls')\n",
    "    tree.add_node(calls_node)\n",
    "    \n",
    "    for call in data['calls']:\n",
    "        call_node = Node('Call')\n",
    "        calls_node.add_node(call_node)\n",
    "        \n",
    "        for step in call['stack']:\n",
    "            step_node = Node('Step: {}'.format(step['path']))\n",
    "            call_node.add_node(step_node)\n",
    "            if 'expanded' in step:\n",
    "                expanded_node = Node('Expanded')\n",
    "                step_node.add_node(expanded_node)\n",
    "                for expanded_step in step['expanded']:\n",
    "                    expanded_step_node = Node('Step: {}'.format(expanded_step['path']))\n",
    "                    expanded_node.add_node(expanded_step_node)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Usage\n",
    "tree = display_call_stack(json_like)\n",
    "tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì LlamaIndex Quickstart\n",
    "\n",
    "In this quickstart you will create a simple Llama Index app and learn how to log it and get feedback on an LLM response.\n",
    "\n",
    "You'll also learn how to use feedbacks for guardrails, via filtering retrieved context.\n",
    "\n",
    "For evaluation, we will leverage the RAG triad of groundedness, context relevance and answer relevance.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/llama_index_quickstart.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies\n",
    "Let's install some of the dependencies for this notebook if we don't have them already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install trulens_eval llama_index openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add API keys\n",
    "For this quickstart, you will need an Open AI key. The OpenAI key is used for embeddings, completion and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶ë Tru initialized with db url sqlite:///default.sqlite .\n",
      "üõë Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "This example uses the text of Paul Graham‚Äôs essay, [‚ÄúWhat I Worked On‚Äù](https://paulgraham.com/worked.html), and is the canonical llama-index example.\n",
    "\n",
    "The easiest way to get it is to [download it via this link](https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt) and save it in a folder called data. You can do so with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\"\n",
    "file_path = 'data/paul_graham_essay.txt'\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    urllib.request.urlretrieve(url, file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple LLM Application\n",
    "\n",
    "This example uses LlamaIndex which internally uses an OpenAI LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "Settings.chunk_size = 128\n",
    "Settings.chunk_overlap = 16\n",
    "Settings.llm = OpenAI()\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send your first request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author worked on writing and programming outside of school before college.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text.collect() .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval import Feedback\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(query_engine)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument app for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama\n",
    "tru_query_engine_recorder = TruLlama(query_engine,\n",
    "    app_id='LlamaIndex_App1',\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or as context manager\n",
    "with tru_query_engine_recorder as recording:\n",
    "    query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use guardrails\n",
    "\n",
    "In addition to making informed iteration, we can also directly use feedback results as guardrails at inference time. In particular, here we show how to use the context relevance score as a guardrail to filter out irrelevant context before it gets passed to the LLM. This both reduces hallucination and improves efficiency.\n",
    "\n",
    "Below, you can see the TruLens feedback display of each context relevance chunk retrieved by our RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wouldn't it be great if we could automatically filter out context chunks with relevance scores below 0.5?\n",
    "\n",
    "We can do so with the TruLens guardrail, *WithFeedbackFilterNodes*. All we have to do is use the method `of_query_engine` to create a new filtered retriever, passing in the original retriever along with the feedback function and threshold we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.guardrails.llama import WithFeedbackFilterNodes\n",
    "\n",
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = Feedback(provider.context_relevance)\n",
    "\n",
    "filtered_query_engine = WithFeedbackFilterNodes(query_engine, feedback=f_context_relevance_score, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can operate as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The author focused on writing and programming outside of school before college. Specifically, the author wrote short stories, which were described as having characters with strong feelings but lacking in plot.', source_nodes=[NodeWithScore(node=TextNode(id_='a98829e7-c59e-4906-9ec8-d1a84ab231e4', embedding=None, metadata={'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='01d1924b-a1ae-4a1b-a728-02c0d2076cdd', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, hash='1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ac44aacc-cb1f-48db-9581-1ccbc3305a4e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e99647d69b84b0a13c59268b58406bb00652b41196a27d7b46b56e5d713018ed')}, text=\"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\", mimetype='text/plain', start_char_idx=2, end_char_idx=373, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8208121222994761)], metadata={'a98829e7-c59e-4906-9ec8-d1a84ab231e4': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tru_recorder = TruLlama(filtered_query_engine,\n",
    "    app_id='LlamaIndex_App1_Filtered',\n",
    "    feedbacks=[f_answer_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    llm_response = filtered_query_engine.query(\"What did the author do growing up?\")\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the power of context filters!\n",
    "\n",
    "If we inspect the context relevance of our retreival now, you see only relevant context chunks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LlamaIndex_App1_Filtered</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LlamaIndex_App1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Groundedness  Context Relevance  Answer Relevance  \\\n",
       "app_id                                                                        \n",
       "LlamaIndex_App1_Filtered           1.0                0.8               0.8   \n",
       "LlamaIndex_App1                    0.8                0.4               0.8   \n",
       "\n",
       "                          latency  total_cost  \n",
       "app_id                                         \n",
       "LlamaIndex_App1_Filtered      1.0    0.005268  \n",
       "LlamaIndex_App1               1.0    0.000713  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve records and feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record(record_id='record_hash_9f960b879e7fbb4c48a58b1cdfb87b3f', app_id='LlamaIndex_App1_Filtered', cost=Cost(n_requests=5, n_successful_requests=15, n_classes=0, n_tokens=3537, n_stream_chunks=0, n_prompt_tokens=3493, n_completion_tokens=44, cost=0.005267500000000001), perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 20, 778856), end_time=datetime.datetime(2024, 7, 3, 5, 47, 22, 824169)), ts=datetime.datetime(2024, 7, 3, 5, 47, 22, 824425), tags='-', meta=None, main_input='What did the author do growing up?', main_output='The author focused on writing and programming outside of school before college. Specifically, the author wrote short stories, which were described as having characters with strong feelings but lacking in plot.', main_error=None, calls=[RecordAppCall(call_id='74117bff-ce0f-4fd8-9f34-d299e7a8d80f', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.query_engine, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=14295036320, init_bindings=None), name='retrieve')), RecordAppCallMethod(path=Lens().app.query_engine._retriever, method=Method(obj=Obj(cls=llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever, id=4348938384, init_bindings=None), name='retrieve')), RecordAppCallMethod(path=Lens().app.query_engine._retriever, method=Method(obj=Obj(cls=llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever, id=4348938384, init_bindings=None), name='_retrieve'))], args={'query_bundle': {'query_str': 'What did the author do growing up?', 'image_path': None, 'custom_embedding_strs': None, 'embedding': [0.012144206091761589, -0.015698930248618126, 0.007664461154490709, -0.010062908753752708, -0.021275486797094345, 0.02139441855251789, -0.006689885165542364, -0.01778683438897133, -0.027882780879735947, -0.03047283925116062, 0.024301627650856972, 0.0009704462718218565, 0.0025801481679081917, 0.01097471546381712, 0.003690173616632819, 0.01857971027493477, 0.03898303583264351, -0.009613612666726112, -0.0009795313235372305, -0.019055435433983803, -0.0023604556918144226, 0.010723638348281384, 0.0035844568628817797, -0.008569660596549511, -0.003151679178699851, 0.006812119856476784, 0.025041643530130386, -0.028543509542942047, 0.023363390937447548, -0.0033779789227992296, 0.011450440622866154, -0.013901746831834316, -0.008450728841125965, -0.005563341546803713, -0.024883069097995758, -0.009395572356879711, -0.016082152724266052, -0.014469973742961884, 0.0017724066274240613, 0.00755874440073967, 0.016095368191599846, -0.0030955171678215265, -0.013888532295823097, -0.0018087467178702354, 0.02201550267636776, 0.007327489089220762, -0.010360237210988998, -0.0012966814683750272, -0.016068939119577408, -0.0013982686214148998, 0.03425221145153046, 0.013406199403107166, -0.004350902978330851, -0.024103408679366112, -0.019491517916321754, 0.0012314344057813287, 0.0026974277570843697, 0.014099964872002602, 0.0016691676573827863, -0.021275486797094345, -0.007023553363978863, 0.022174078971147537, -0.00299640791490674, 0.007413383573293686, -0.024750923737883568, 0.0007007861277088523, -0.013194765895605087, -0.005199940409511328, -0.008424299769103527, -0.0153157077729702, 0.035996537655591965, 0.00011222076136618853, -0.009904333390295506, -0.0027948853094130754, 0.019002577289938927, -0.010941678658127785, -0.00964004173874855, -0.007367132697254419, -0.009957191534340382, 0.010611314326524734, -0.00785607285797596, -0.0219230018556118, -0.0064322007820010185, 0.009560754522681236, 0.01099453680217266, -0.005642629228532314, 0.016808954998850822, 0.029627105221152306, -0.020257962867617607, -0.01844756491482258, -0.0026214439421892166, 0.017601830884814262, 0.01657109335064888, 0.015130703337490559, 0.014773909002542496, 0.0032887805718928576, -0.01564607210457325, 0.01129186525940895, -0.008840559050440788, -0.003425881965085864, -0.005804507527500391, 0.0041592917405068874, -0.007195343263447285, -0.012401890940964222, -0.01877792924642563, 0.013036190532147884, -0.0062967510893940926, -0.021909786388278008, 0.028305647894740105, -0.03242859989404678, -0.014086750335991383, 0.0202711783349514, 0.02759205922484398, -0.05277906358242035, -0.008543231524527073, -0.025226648896932602, 0.0007338225841522217, 0.000338417332386598, 0.008952883072197437, 0.0009630130953155458, 0.007968396879732609, 0.001654301187954843, 0.021962644532322884, -0.010399880819022655, 0.00944182276725769, -0.0012454749085009098, -0.015897149220108986, -0.00881412997841835, -0.011126683093607426, -0.007102841045707464, 0.017469685524702072, -0.0016848599771037698, 0.012481178157031536, -0.013478879816830158, -0.017667904496192932, 0.016610736027359962, -0.019029006361961365, 0.015342136844992638, -0.021473705768585205, -0.02525307796895504, 0.020482610911130905, 0.022914094850420952, -0.008179829455912113, 0.002928683068603277, 0.006983909755945206, 0.018473993986845016, 0.030552126467227936, 0.039062321186065674, 0.01008273009210825, -0.018698642030358315, 0.017469685524702072, -0.0025884073693305254, 0.007089626509696245, -0.008457336574792862, 0.01437747199088335, 0.035071514546871185, -0.015381780453026295, 0.012540644034743309, -0.016002865508198738, -0.01994081400334835, 0.0209319069981575, 0.025689158588647842, 0.0221476498991251, -0.008212866261601448, -0.01170151773840189, 0.03816372901201248, 0.023416249081492424, 0.014958913438022137, 0.0028097517788410187, -0.012679397128522396, -0.024050550535321236, 0.012593502178788185, -0.03351219370961189, 0.009435215964913368, 0.007281237747520208, 0.024235554039478302, -0.0026924721896648407, 0.015540354885160923, -0.01706003211438656, -0.003908214159309864, -0.012666182592511177, 0.001992099219933152, 0.02501521445810795, 0.04424244165420532, -0.008622518740594387, -0.00881412997841835, 0.00861591100692749, 0.008080720901489258, -0.004327777307480574, 0.0031896710861474276, -0.012124384753406048, 0.024473417550325394, -0.012501000426709652, -0.02449984662234783, -0.66982102394104, -0.012752077542245388, -0.0032127967569977045, -0.01967652142047882, 0.01149008423089981, 0.022755520418286324, -0.002528941724449396, 0.0365779809653759, -0.0306314155459404, 0.004301348235458136, -0.007320881821215153, 0.03858659788966179, 0.026719896122813225, 0.0004080004000570625, 0.011866699904203415, -0.011476869694888592, 0.010109160095453262, -0.02218729257583618, 0.00853001605719328, -0.015342136844992638, 0.00508431252092123, 0.02073368802666664, -0.007624817080795765, -0.0062571074813604355, 0.008576267398893833, 0.010743459686636925, 0.008992526680231094, -0.03311575576663017, 0.013835673220455647, 0.02571558766067028, -0.017839694395661354, 0.028807802125811577, 0.03647226095199585, 0.025794874876737595, 0.05513126030564308, -0.012322602793574333, -0.008378048427402973, 0.03536223620176315, 0.005566644947975874, 0.04387243092060089, -0.02062797173857689, -0.016676809638738632, 0.015619643032550812, 0.014205682091414928, 0.007710712030529976, -0.01119275577366352, 0.039564475417137146, 0.0032887805718928576, 0.035071514546871185, 0.019266869872808456, -0.005854062270373106, -0.001008438179269433, -0.001815353985875845, -0.007922145538032055, -0.0007602517725899816, -0.006504880730062723, 0.0012182198697701097, 0.015421424061059952, 0.007294452283531427, 0.017800049856305122, -0.006389253307133913, 0.03715942054986954, -0.023033026605844498, 0.004704393446445465, -0.0033829344902187586, 0.02241194061934948, -0.016544664278626442, 0.026204528287053108, -0.005606289021670818, -0.022636588662862778, 0.009778794832527637, 0.007585173472762108, -0.015289277769625187, -0.009474859572947025, 0.01335334125906229, 0.010538633912801743, 0.03274574875831604, 0.005295746028423309, -0.002448002342134714, -0.006716314237564802, -0.027023831382393837, -0.0037000845186412334, -0.04067450016736984, -0.010849176906049252, 0.02205514721572399, 0.006448718719184399, -0.03023497760295868, 0.007922145538032055, -0.003838837845250964, 0.007677675690501928, -0.01026773452758789, 0.03277217969298363, -0.007690890226513147, -0.026019522920250893, -0.012540644034743309, 0.009811831638216972, -0.013445843011140823, -0.001188487047329545, 0.0007317577837966383, 0.002581800101324916, 0.010611314326524734, -0.002264650072902441, 0.010221484117209911, 0.011338116601109505, 0.00550387566909194, 0.000641320482827723, 0.012434926815330982, 0.025530584156513214, 0.03927375376224518, -0.018923290073871613, 0.005708701908588409, 0.0009473207755945623, 0.0013354993425309658, -0.002353848423808813, -0.007869287393987179, -0.023151958361268044, 0.014033892191946507, 0.008292153477668762, 0.011001144535839558, -0.013459057547152042, -0.0014023981057107449, 0.010413095355033875, -0.00911145843565464, -0.018209701403975487, -0.005014935974031687, 0.023455893620848656, -0.009197353385388851, 0.010703816078603268, -0.011357937939465046, 0.0007561221718788147, -0.0007342355675064027, -0.010023265145719051, 0.013300483115017414, -0.01910829357802868, 0.013769600540399551, 0.0031285537406802177, -0.003805801272392273, -0.0061943382024765015, 0.00477707339450717, -0.00725480867549777, -0.020509039983153343, 0.004998418036848307, -0.005209851078689098, -0.003214448457583785, -0.017152534797787666, -0.02046939730644226, 0.01117293443530798, -0.002784974407404661, -0.012765292078256607, 0.02152656391263008, 0.003366416320204735, -0.013518523424863815, -0.022517656907439232, -0.015883933752775192, -0.01828899048268795, -0.016201084479689598, 0.01265957485884428, -0.005351908039301634, -0.01431139837950468, 0.009085029363632202, -0.0023109009489417076, 0.03628725931048393, -0.010928464122116566, 0.010155410505831242, -0.014218896627426147, 0.01036684401333332, 0.013181551359593868, 0.012296173721551895, 0.010868998244404793, -0.008701805956661701, 0.011272042989730835, -0.016148226335644722, 0.0034490074031054974, -0.005170207470655441, -0.007446420378983021, 0.012652968056499958, 0.0008837255882099271, -0.002722205128520727, -0.008477157913148403, 0.004420279525220394, -0.004479745402932167, -0.007902323268353939, -0.007882501929998398, -0.011575979180634022, 0.023706970736384392, -0.009382357820868492, 0.0012628190452232957, 0.03245502710342407, 0.016201084479689598, 0.03227002173662186, 7.371262472588569e-05, 0.014536046423017979, 0.006762565113604069, 0.009058600291609764, -0.0006429722998291254, -0.009461645036935806, 0.030049972236156464, 0.007049982436001301, 0.009930762462317944, 0.00785607285797596, -0.026191312819719315, 0.026191312819719315, 0.01399424858391285, 0.0019755808170884848, 0.017245037481188774, -0.037317994982004166, -0.004004020243883133, -0.02023153379559517, -0.008219473995268345, 0.0025223344564437866, 0.003528294852003455, -0.008153400383889675, 0.006025852169841528, -0.018989363685250282, -0.01437747199088335, 0.006141479592770338, -0.018077556043863297, 0.017152534797787666, -0.01047916803508997, 0.001551062217913568, 0.017932195216417313, -0.011873307637870312, -0.004704393446445465, -0.001744325621984899, -0.015223205089569092, 0.019861524924635887, 0.001973929116502404, -0.019385799765586853, 0.006937658414244652, -0.022068360820412636, -0.004836539272218943, -0.004796895198523998, 0.01090864185243845, 0.01802469789981842, -0.005242887884378433, 0.021143341436982155, 0.02218729257583618, -0.01544785313308239, 0.01835506223142147, -0.011675088666379452, -0.00881412997841835, 0.016861815005540848, 0.024737708270549774, -0.005655843764543533, 0.030552126467227936, -0.011959201656281948, 0.017773620784282684, -0.021169770509004593, -0.011893128976225853, -0.0057483455166220665, 0.003977591171860695, -0.012084740214049816, 0.0026743023190647364, -0.023680541664361954, 0.006250500213354826, 0.007895716466009617, 0.005355211906135082, -0.004192328080534935, 0.00868198461830616, 0.02957424707710743, -0.0042352755554020405, 0.009626827202737331, -0.003957768902182579, 0.01706003211438656, 0.0014511268818750978, 0.013703527860343456, -0.009659864008426666, -0.005081009119749069, -0.03219073638319969, -0.0105782775208354, -0.022755520418286324, -0.010644350200891495, 0.006716314237564802, -0.02126227132976055, 0.010743459686636925, 0.007307667285203934, -0.00924360379576683, -0.004988506902009249, 0.00911145843565464, -0.0010546892881393433, -0.02261015959084034, -0.0025702372658997774, 0.022821594029664993, 0.01716575026512146, 0.0043608141131699085, -0.007003731559962034, -0.007076411973685026, 0.0016361312009394169, -0.014033892191946507, -0.0004860490735154599, 0.005262709688395262, -0.002244828036054969, 0.0026528285816311836, -0.010849176906049252, 0.0041592917405068874, 0.016465377062559128, 0.03020854853093624, -0.023588038980960846, 0.023521967232227325, -0.02099798060953617, -0.03345933556556702, -0.009177531115710735, -0.022359082475304604, 0.0017509328899905086, 0.02838493511080742, 0.005150385666638613, -0.014641763642430305, -0.013095656409859657, -0.007003731559962034, -0.007023553363978863, -0.012302781455218792, 0.0009704462718218565, 0.0061447834596037865, 0.01338637713342905, 0.010360237210988998, -0.011278650723397732, -0.014694621786475182, -0.006039066705852747, 0.015936793759465218, 0.0032028856221586466, -0.026415960863232613, -0.021275486797094345, -0.029124950990080833, 0.012104562483727932, 0.1068795844912529, 0.014403901062905788, -0.01564607210457325, 0.015077845193445683, 0.009785402566194534, -0.011424011550843716, -0.016161441802978516, -0.021804070100188255, 0.01004969421774149, -0.0018682123627513647, -0.00121904572006315, -0.011873307637870312, 0.01411317940801382, -0.013716742396354675, -0.007076411973685026, -0.0016295238165184855, -3.1307215976994485e-05, -0.025755232200026512, -0.01523641962558031, -0.021315129473805428, 0.003528294852003455, 0.026230957359075546, 0.010095945559442043, 0.022636588662862778, 0.007809821516275406, -0.006267018150538206, 0.004080004058778286, 0.0010505596874281764, 0.0286492258310318, -0.01076328195631504, 0.00599281582981348, 0.0006190208368934691, 0.009461645036935806, -0.015513925813138485, 0.006415682379156351, 0.04109736904501915, 0.014086750335991383, 0.0287549439817667, 0.02525307796895504, -0.0040106275118887424, 0.031635724008083344, -0.009428608231246471, 0.014205682091414928, -0.0352565199136734, 0.014060321263968945, -0.026363102719187737, 0.0026974277570843697, 0.028173500671982765, 0.0040866113267838955, 0.0007334096007980406, 0.0024314841721206903, -0.0022894274443387985, -0.0057483455166220665, -0.007684282958507538, 0.014998557046055794, -0.00549726840108633, 0.013848887756466866, -0.0032161003910005093, -0.0018748196307569742, 0.02627060003578663, -0.010849176906049252, -0.031609293073415756, 0.009283248335123062, -0.026257386431097984, 0.007301060017198324, -0.02719562128186226, -0.013207980431616306, 0.0042716157622635365, -0.009501288644969463, -0.002657783916220069, -0.009236996993422508, -0.00550387566909194, -0.038110870867967606, -0.015831075608730316, 0.024024121463298798, 0.01835506223142147, 0.039564475417137146, -0.004829932004213333, -0.008424299769103527, 0.00785607285797596, -0.0031615900807082653, -0.02994425594806671, 0.018500423058867455, -0.018764715641736984, 0.00019966416584793478, 0.024830210953950882, -0.0059201354160904884, -0.01450961735099554, -0.020614756271243095, 0.008741449564695358, 0.0012396934907883406, 0.00745963491499424, -0.004582158289849758, -0.04244525730609894, -0.012798327952623367, -0.023218030110001564, -0.010670779272913933, 0.01257367990911007, 0.01641251891851425, -0.014443544670939445, 0.0061943382024765015, -0.023257674649357796, -0.028702083975076675, -0.006554435472935438, -0.0042484900914132595, -0.0007796607096679509, -0.005758256651461124, 0.019293298944830894, -0.022914094850420952, -0.02851708047091961, 0.03766157478094101, -0.006554435472935438, 0.0002335265453439206, 0.017588617280125618, 0.015791432932019234, 0.0345957912504673, -0.0055104829370975494, 0.008113756775856018, 0.0038586596492677927, -0.011324902065098286, -0.002576844533905387, -0.02644238993525505, 0.020680829882621765, 0.018460778519511223, -0.037873007357120514, -0.009085029363632202, -0.008060898631811142, -0.02225336618721485, -0.018870431929826736, -0.005137171130627394, 0.0004455793823581189, 0.02745991386473179, -0.031239286065101624, -0.013769600540399551, -0.012157420627772808, 0.00023311359109357, -0.007935360074043274, -5.884621259610867e-06, 0.002801492577418685, 0.0002467411395628005, -0.023482322692871094, -0.01690145768225193, -0.005612896289676428, -0.018619354814291, 0.002233265433460474, -0.02706347592175007, -0.003321816911920905, -0.006931051146239042, -0.012712433934211731, 0.03874517232179642, -0.008477157913148403, 0.0021110305096954107, 0.010003442876040936, 0.017918981611728668, -0.026521677151322365, -0.02571558766067028, -0.008721628226339817, 0.020125817507505417, 0.04067450016736984, -0.0031467238441109657, 0.019332941621541977, -0.00912467297166586, 0.03462221845984459, 0.008259117603302002, -0.00028266830486245453, 0.01584429107606411, 0.0076578538864851, 0.0031037763692438602, -0.005315567832440138, 0.03895660489797592, 0.014932484365999699, 0.0211565550416708, -0.0019425443606451154, 0.0017311109695583582, 0.007135877385735512, 0.024843424558639526, 0.0022084880620241165, -0.004228668287396431, -9.100515308091417e-05, -0.03557366877794266, 0.005692183505743742, 0.014218896627426147, -0.007109448313713074, 0.011252221651375294, 0.008622518740594387, 0.002487646182999015, 0.03425221145153046, 0.005391551647335291, 0.010545240715146065, -0.02267623320221901, 0.02231943979859352, -0.015302492305636406, 0.03382934629917145, -0.018170058727264404, -0.005325478967279196, -0.014575690031051636, -0.017311109229922295, -0.02119619958102703, 0.012421712279319763, 0.02161906659603119, 0.007836250588297844, 0.008358227089047432, -0.00020957511151209474, -0.013558167032897472, -0.00010520051000639796, -0.016082152724266052, 0.008371441625058651, 9.972884436137974e-05, 0.015209990553557873, 0.005536912474781275, 0.018196487799286842, -0.04149380698800087, -0.007505885791033506, -0.01712610572576523, 0.0013462360948324203, -0.01857971027493477, -0.018170058727264404, 0.023786257952451706, 0.0035745459608733654, -0.00955414678901434, -0.022914094850420952, -0.010750067420303822, 0.030974993482232094, -0.005814418662339449, 0.002353848423808813, -0.01875150017440319, -0.02194943092763424, -0.005705398507416248, 0.010717030614614487, 0.002978237811475992, -0.01326744630932808, 0.012692611664533615, 0.011794019490480423, 0.01437747199088335, -0.006904622074216604, 0.005127259995788336, 0.018341848626732826, -0.026455605402588844, -0.01613501086831093, -0.00467796390876174, 0.006508184596896172, -0.025966664776206017, 0.012395283207297325, -0.008219473995268345, -0.021605851128697395, 0.02666703797876835, -0.005768167786300182, -0.008543231524527073, -0.008800915442407131, -0.017945410683751106, -0.016068939119577408, 0.0101355891674757, 0.01584429107606411, 0.00632978742942214, -0.01809077151119709, 0.01089542731642723, -0.005470839329063892, -0.029257098212838173, 0.015355351381003857, 0.014258540235459805, -0.013571381568908691, 0.0068319421261549, 0.0018533458933234215, 0.02013903111219406, 0.0037661574315279722, -0.0012809891486540437, 0.0025355489924550056, -0.017733976244926453, -0.024209124967455864, 0.026402747258543968, 0.00548075046390295, -0.005021543242037296, -0.02036367915570736, 0.01242832001298666, 0.0077701774425804615, 0.026521677151322365, -0.018923290073871613, -0.009884512051939964, 0.016690025106072426, -0.009303069673478603, 0.010888820514082909, 0.004321170039474964, -0.03562653064727783, 0.009098243899643421, -0.009382357820868492, -0.018302204087376595, -0.014892840757966042, -0.011457047425210476, 0.012884222902357578, -0.031609293073415756, -0.04247168451547623, -0.0033251207787543535, 0.011014359071850777, 0.012553858570754528, -0.03647226095199585, -0.003501865779981017, 0.015738574787974358, 0.0273277685046196, -0.029759252443909645, 0.012606716714799404, -0.007228379603475332, -0.013412807136774063, -0.007677675690501928, 0.005880491808056831, -0.012699219398200512, -0.008444122038781643, 0.039035893976688385, -0.0013478879118338227, -0.025160575285553932, -0.009316284209489822, -0.0010183491976931691, -0.013201373629271984, -0.022570516914129257, -0.009580575861036777, -0.023521967232227325, 0.008933061733841896, -0.008767878636717796, -0.02849065139889717, -0.008193044923245907, 0.010188447311520576, 0.004208846017718315, -0.004070092923939228, 0.004790287930518389, -0.004780377261340618, -0.004453316330909729, 0.0062934476882219315, -0.003538205986842513, -0.0028543509542942047, -0.024975571781396866, 0.004783680662512779, 0.0001777775032678619, 0.014575690031051636, -0.022861236706376076, 0.00725480867549777, -0.02069404534995556, 0.002936942270025611, -0.0015444549499079585, 0.03364434093236923, 0.021975859999656677, 0.0025124235544353724, -0.003954465501010418, 0.028702083975076675, 0.005563341546803713, 0.012454749085009098, 0.01544785313308239, -0.009858082979917526, -0.0027106422930955887, 0.000394372851587832, -0.04323813319206238, -0.01038005854934454, 0.016346445307135582, 0.036392975598573685, 0.009904333390295506, -0.01277189888060093, -0.01957080513238907, -0.012296173721551895, -0.03821658715605736, -0.00755213713273406, 0.00736052542924881, 0.0006103487685322762, 0.017271466553211212, -0.008510194718837738, -0.007043375167995691, 0.007915537804365158, -0.017271466553211212, -0.0021870143245905638, -0.0005079357069917023, -0.010802925564348698, -0.020416539162397385, 0.01014880370348692, 0.01877792924642563, -0.001067077973857522, -0.0005087616154924035, -0.004076700191944838, 0.0007639683899469674, -0.011675088666379452, -0.002487646182999015, -0.02304624207317829, -0.01034702267497778, -0.002573540899902582, -0.009633434936404228, 0.03575867414474487, 0.013009761460125446, 0.00035803273203782737, 0.004268311895430088, -0.0286492258310318, -0.00962022040039301, -0.0018748196307569742, -0.020654400810599327, -0.0026511766482144594, -0.010062908753752708, 0.016623951494693756, -0.004195631481707096, 0.008675376884639263, 0.008232688531279564, -0.014932484365999699, 0.0153157077729702, 0.014284969307482243, 0.027116334065794945, -0.020773332566022873, -0.01881757378578186, 0.025134146213531494, -0.00631326949223876, -0.01242832001298666, -0.022663017734885216, 0.021711567416787148, -0.00233072298578918, -0.0020135727245360613, -0.014456759206950665, -0.03597010672092438, 0.014747479930520058, 0.00012626126408576965, -0.004995114170014858, -0.006785690784454346, 0.004674660507589579, -0.0038322305772453547, -0.0015279367798939347, 0.011113468557596207, 0.012593502178788185, -0.0002702796191442758, -0.019266869872808456, 0.006729528773576021, 0.013901746831834316, -0.006138176191598177, -0.00716230645775795, -0.0254512969404459, 0.02538522332906723, -0.024090193212032318, -0.021037623286247253, 0.005877187941223383, -0.013042798265814781, -0.0022217025980353355, -0.017522543668746948, 0.012481178157031536, -0.0006355390651151538, 0.004017234779894352, 0.24145695567131042, 0.006864978466182947, -0.0040866113267838955, 0.011364545673131943, -0.023984476923942566, 0.007188735995441675, 0.03734442591667175, 0.00950789637863636, -0.028702083975076675, 0.015672501176595688, -0.01670323871076107, -0.021605851128697395, 0.01712610572576523, 0.0035844568628817797, 0.007340703625231981, -0.011556156910955906, -0.029653534293174744, -0.0013875317526981235, -0.002456261543557048, -0.025808090344071388, 0.01828899048268795, -0.011853485368192196, -0.029098521918058395, -0.015461067669093609, 0.01877792924642563, 0.036260828375816345, 0.001434608711861074, 0.0008007214055396616, 0.010604706592857838, 0.005728523712605238, -0.0016047465614974499, -0.009871297515928745, 0.0009522762265987694, -0.011945987120270729, -0.027644917368888855, 0.0025983182713389397, 0.018738284707069397, -0.003311906009912491, -0.003343290649354458, -0.007049982436001301, 0.01822291687130928, 0.0036868699826300144, 0.011483476497232914, -0.007915537804365158, -0.021235842257738113, 0.05407409369945526, -0.01617465540766716, 0.0019029006361961365, -0.004714304115623236, 0.02056189812719822, -0.004892701283097267, -0.002264650072902441, 0.01961044780910015, 0.01904222182929516, -0.024962356314063072, 0.0018219612538814545, 0.011615622788667679, 0.007829642854630947, -0.007466242182999849, 0.01398103404790163, 0.00755213713273406, 0.02009938843548298, -0.02432805672287941, 0.01046595349907875, 0.00507440185174346, 0.012481178157031536, -0.011311687529087067, -0.004631713032722473, -0.0025933629367500544, -0.04506174474954605, -0.0015923578757792711, -0.008549838326871395, -0.021737996488809586, 0.00784285832196474, -0.026812398806214333, -0.014853197149932384, 0.004948863293975592, 0.03102785162627697, 0.018526852130889893, 0.026852043345570564, -0.0036241007037460804, -0.006055585108697414, 0.006878193002194166, -0.0007602517725899816, -0.0319528728723526, -0.04545818269252777, 0.01411317940801382, 0.0045359074138104916, -0.006713010836392641, -0.02756563015282154, 0.0008073287317529321, -0.0030294442549347878, -0.006765868980437517, 0.003452311037108302, 0.002398447599261999, -0.012071525678038597, -0.015209990553557873, 0.03385577350854874, -0.00861591100692749, -0.005451017525047064, -0.014562475495040417, -0.009177531115710735, 0.0221476498991251, 0.009375750087201595, -0.010043086484074593, 0.013505308888852596, 0.0018450868083164096, 0.01795862428843975, 0.0042848302982747555, -0.028464222326874733, -0.0039610727690160275, -0.032957181334495544, -0.0020251355599611998, 0.0030459624249488115, 0.008153400383889675, -0.0034853476099669933, -0.0031731529161334038, -0.021381203085184097, 0.006422289647161961, -0.005599681753665209, -0.03340647742152214, -0.001721200067549944, 0.002978237811475992, 0.018923290073871613, -0.003947858233004808, -0.003125250106677413, -0.019993672147393227, -0.002821314614266157, 0.005527001339942217, -0.046594638377428055, 0.01637287437915802, -0.015989651903510094, 0.003059177193790674, 0.00932289194315672, -0.012606716714799404, 0.01842113584280014, -0.010043086484074593, 0.001954107079654932, 0.0023241157177835703, 0.017324324697256088, 0.012375461868941784, -0.022068360820412636, 0.01736396923661232, 0.00045342554221861064, 0.007849465124309063, -0.03541509434580803, 0.012983332388103008, 0.02185692824423313, 0.004020538181066513, -0.029600676149129868, -0.008252509869635105, -0.004611891228705645, -0.012976725585758686, 0.01213099155575037, 0.010360237210988998, -0.04413672164082527, -0.04458601772785187, -0.027644917368888855, -0.011258828453719616, -0.009058600291609764, -0.007466242182999849, 0.012487785890698433, 0.018632568418979645, 0.010413095355033875, -0.0025173788890242577, -0.00808732770383358, -0.1692524403333664, 0.02666703797876835, 0.023429464548826218, -0.020376894623041153, 0.005873884540051222, -0.0025751928333193064, 0.033195044845342636, -0.01036684401333332, -0.01672966778278351, 0.024750923737883568, 0.019319728016853333, 0.006128265056759119, -0.02013903111219406, 0.02284802310168743, -0.007512493059039116, 0.013009761460125446, -0.014588904567062855, 0.03290432319045067, 0.019399015232920647, 0.0063694315031170845, 0.03182072937488556, 0.008536623790860176, 0.012798327952623367, 0.002411662368103862, 0.01339959166944027, 0.01505141519010067, 0.003465525573119521, 0.0018913379171863198, 0.0018748196307569742, -0.005150385666638613, 0.008734842762351036, -8.58432031236589e-05, -0.006950873415917158, -0.022623375058174133, 0.0300764013081789, 0.008820737712085247, -0.00755874440073967, -0.002223354298621416, 0.001600616960786283, 0.015897149220108986, 0.02970639429986477, 0.02089226432144642, 0.007789999712258577, 0.008093935437500477, -0.011424011550843716, 0.026230957359075546, 0.014086750335991383, -0.002994755981490016, 0.01379602961242199, -0.02013903111219406, 0.01437747199088335, -0.023099100217223167, -0.0015428031329065561, 0.00021948604262433946, 0.014879626221954823, -0.005137171130627394, 0.015817862004041672, 0.025279507040977478, -0.007611602544784546, -0.014549260959029198, 0.009435215964913368, -0.02227979525923729, 0.029098521918058395, 0.010307378135621548, 0.008503586985170841, -0.013056012801826, -0.014813552610576153, -0.015804646536707878, -0.03205858916044235, 0.021182984113693237, -0.02023153379559517, -0.008100542239844799, 0.01297011785209179, -0.0009754017810337245, 0.0031235981732606888, 0.004443405196070671, -0.004707696847617626, -0.027777064591646194, 0.0005570774665102363, 0.03594367951154709, -0.017086463049054146, 0.013320304453372955, -0.008021255023777485, 0.004902611952275038, -0.010703816078603268, 0.025279507040977478, -0.013505308888852596, 0.015461067669093609, -0.00882734451442957, -0.013379770331084728, 0.023482322692871094, -0.018936503678560257, -0.029600676149129868, -0.012421712279319763, 0.026164883747696877, 0.009910941123962402, 0.004843146540224552, 0.0033019951079040766, 0.0022117916960269213, -0.022517656907439232, 0.007796606980264187, -0.026759540662169456, 0.01180062722414732, -0.020218320190906525, 0.032296452671289444, 0.003075695363804698, 0.011298472993075848, 0.00964004173874855, 0.033353619277477264, -0.010300771333277225, -0.001560147269628942, -0.004195631481707096, 0.004839842673391104, 0.007268023211508989, -0.016544664278626442, 0.0378994382917881, -0.006105139385908842, -0.007083019241690636, 0.0019227225566282868, -0.005424588453024626, 0.058778487145900726, 0.014443544670939445, -0.027222050353884697, 0.001443693763576448, 0.0004645753651857376, 0.0009390616323798895, -0.12326567620038986, -0.004929041489958763, 0.0027453305665403605, -0.0024446987081319094, 0.01943865790963173, 0.00436411751434207, -0.0273277685046196, -0.014496402814984322, -0.009283248335123062, 0.009692899882793427, -0.009362535551190376, -0.013511915691196918, 0.0024678243789821863, -0.019782237708568573, -0.0015386735321953893, -0.010545240715146065, 0.01891007460653782, -0.02412983775138855, -0.01692788675427437, 0.040330920368433, -0.006898014806210995, -0.005543519742786884, -0.010902035050094128, -0.012633145786821842, 0.004862968344241381, -0.01894971914589405, -0.03456936031579971, 0.0010034827282652259, 0.006818727124482393, 0.005305657163262367, -0.0012760336976498365, -0.025557013228535652, 0.0017740584444254637, -0.013102264143526554, 0.0159764364361763, -0.00862912554293871, -0.01150329876691103, 0.011919558048248291, 0.012395283207297325, -0.01868542656302452, -0.0021407632157206535, 0.01168830320239067, 0.01954437606036663, -0.05092902109026909, -0.003052569692954421, -0.00014876735804136842, -0.020614756271243095, 0.017773620784282684, 0.008992526680231094, -0.014760694466531277, -0.017733976244926453, 0.016280371695756912, -0.025160575285553932, -0.013928175903856754, -0.007717319298535585, 0.0004459923366084695, 0.01024791318923235, 0.009527717716991901, 0.008444122038781643, 0.021909786388278008, -0.01577821746468544, -0.0107963178306818, -0.005705398507416248, -0.019055435433983803, 0.015394994989037514, -0.007968396879732609, -0.004935648757964373, -0.0021143341436982155, -0.014060321263968945, -0.05248834192752838, -0.030393552035093307, -0.004734125919640064, -0.028702083975076675, 0.0042484900914132595, 0.0007197820814326406, -0.000820130342617631, -0.013967819511890411, 0.0022745609749108553, 0.011714732274413109, -0.02597988024353981, -0.010175232775509357, -0.004843146540224552, 0.009732544422149658, -0.028147071599960327, 0.015791432932019234, 0.0016509975539520383, 0.0004214214568492025, 0.009646649472415447, -0.0008011343888938427, 0.00010509727144381031, -0.03205858916044235, 0.028332076966762543, -0.00036567242932505906, -0.013743171468377113, -0.007102841045707464, 0.007426598574966192, -0.001273555913940072, -0.0031103836372494698, 0.009091636165976524, -0.0016782527090981603, -0.0084837656468153, 0.0016485198866575956, -0.03895660489797592, 0.021909786388278008, -0.009712722152471542, -0.01256046537309885, 0.0153157077729702, -0.004810110200196505, 0.004344295710325241, -0.025504155084490776, -0.03523009270429611, 0.006055585108697414, -0.009877904318273067, 0.02743348479270935, 0.021235842257738113, -0.016848599538207054, -0.0143246129155159, -0.021473705768585205, 0.005804507527500391, 0.025755232200026512, 0.007003731559962034, 0.02238551154732704, 0.0013412806438282132, -0.009712722152471542, 0.026323458179831505, 0.009930762462317944, -0.010320592671632767, 0.0041758096776902676, -0.022398727014660835, 0.015751788392663002, -0.014020677655935287, -0.0041758096776902676, 0.0028411364182829857, -0.02397126331925392, 0.009085029363632202, 0.020852619782090187, 0.019399015232920647, 0.008008040487766266, 0.004093218594789505, 0.026112025603652, 0.016597522422671318, 0.06099853664636612, -0.009065207093954086, -0.01683538407087326, -0.005424588453024626, -0.03721227869391441, 0.023033026605844498, -0.010915249586105347, -0.02954781800508499, 0.019055435433983803, 0.025557013228535652, 0.004823324736207724, 0.02142084762454033, 0.011397582478821278, -0.006898014806210995, -0.007122662849724293, -0.0038751778192818165, -0.037238709628582, 0.0024446987081319094, 0.008120364509522915, -0.01150329876691103, -0.015024986118078232, 0.03179429844021797, -0.010948286391794682, 0.001663386239670217, -0.02373339980840683, 0.015461067669093609, -0.016399303451180458, 0.01044613216072321, 0.012818150222301483, -0.006871585734188557, -0.033750057220458984, -0.010571670718491077, -0.002182058757171035, 0.011542942374944687, 0.03208502009510994, 0.01110686082392931, 0.0022084880620241165, -0.001183531479910016, 0.03803158551454544, -0.005236280616372824, 0.02944210171699524, -0.009137887507677078, 0.01119275577366352, -0.0027189014945179224, 0.021777641028165817, 0.023521967232227325, 0.0235748253762722, 0.010320592671632767, -0.0016832081601023674, -0.002233265433460474, 0.003980894573032856, -0.003282173303887248, -0.01047916803508997, 0.004853057209402323, -0.01173455361276865, -0.002753589767962694, 0.02716919220983982, -0.007499278523027897, 0.008245903067290783, 0.01924044080078602, 0.01505141519010067, 0.015950007364153862, -0.01472105085849762, 0.009078421629965305, -0.015091059729456902, -0.022174078971147537, 0.04191667214035988, -0.0032408777624368668, -0.028305647894740105, 0.003954465501010418, 0.021103696897625923, 0.005384944379329681, -0.0009572317358106375, -0.010637743398547173, 0.0107963178306818, -0.015077845193445683, 0.018923290073871613, -0.0033862381242215633, -0.013307089917361736, -0.010789711028337479, 0.034410785883665085, -0.00445661973208189, 0.004189024213701487, 0.009547539986670017, -0.022028718143701553, -0.012732255272567272, 0.0244602020829916, 0.012210278771817684, 0.0038091049063950777, 0.006210856139659882, -0.018989363685250282, -0.009098243899643421, -0.01604251004755497, -0.010056301020085812, -0.008126971311867237, 0.011774198152124882, -0.011457047425210476, -0.0014808597043156624, 0.019887953996658325, -0.036234401166439056, 0.02089226432144642, -0.002771759871393442, -0.006891407538205385, -0.011014359071850777, 0.013089049607515335, 0.01961044780910015, 0.014126394875347614, -0.007968396879732609, -0.012203671969473362, -0.0037496392615139484, 0.015011771582067013, -0.0013957908377051353, 0.029785681515932083, -0.028939947485923767, -0.033591482788324356, -0.012012060731649399, 0.009018956683576107, -0.006191034335643053, 0.015157132409512997, 0.023482322692871094, 0.018315419554710388, 0.008642340078949928, 0.02327089011669159, 0.011001144535839558, -0.021011194214224815, 0.0073539181612432, 0.037978727370500565, -0.017271466553211212, -0.006696492433547974, -0.038507308810949326, -0.004694482311606407, 0.005943261086940765, -0.0559769943356514, -0.024869853630661964, 0.01431139837950468, -0.03377648815512657, -0.009805223904550076, -0.027089904993772507, -0.0004559032677207142, 0.013128693215548992, -0.012534036301076412, 0.003640618873760104, -0.02175121195614338, 0.0084837656468153, 0.004426886793226004, -0.003792586736381054, -0.004998418036848307, -0.0017971839988604188, -0.02838493511080742]}}, rets=[{'node': {'id_': 'ee3bc977-bc7e-4393-9e00-9bd7719f7c1b', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '538dc6fd-bdfd-42da-b1c2-17ea82554a7d', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '5042ef58fa439b89369e3a10cacb784e1845e881271729a3261403a515d7134b'}, <NodeRelationship.NEXT: '3'>: {'node_id': '62d8a138-8b16-402a-a7cf-2e6dab6633f2', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '0b4f822ad12b07d089691e8fe465cfd1a8eb40b43de3358e4fe2ed3606b289e6'}}, 'text': 'I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with some problem involving continuations while I watched them play in the tide pools. It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\\n\\nIn the summer of 2016 we moved to England.', 'mimetype': 'text/plain', 'start_char_idx': 65997, 'end_char_idx': 66402, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8211530782069452}, {'node': {'id_': 'a98829e7-c59e-4906-9ec8-d1a84ab231e4', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'ac44aacc-cb1f-48db-9581-1ccbc3305a4e', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'e99647d69b84b0a13c59268b58406bb00652b41196a27d7b46b56e5d713018ed'}}, 'text': \"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\", 'mimetype': 'text/plain', 'start_char_idx': 2, 'end_char_idx': 373, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8208121222994761}, {'node': {'id_': '3cd01a17-a792-4362-8540-74b68300057f', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'c2e92735-3b1c-4d3c-b571-65269e82bbe0', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '0d52c8f8a9f4f6e5d12fdb04b0af0688a87b7cccf5b7337fb595f5e69c4fe2fe'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'f4b10549-f491-4b63-ba16-66a0ae6817b3', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '3779908c352fae99eed78144efa64e8a8a6e91708317acae776ad913bbcc456c'}}, 'text': \"Idelle was in New York at least, and there were other people trying to paint there, even though I didn't know any of them.\\n\\nWhen I got back to New York I resumed my old life, except now I was rich. It was as weird as it sounds. I resumed all my old patterns, except now there were doors where there hadn't been.\", 'mimetype': 'text/plain', 'start_char_idx': 38502, 'end_char_idx': 38813, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8174469441429402}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 20, 916429), end_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 110019)), pid=54744, tid=6433686), RecordAppCall(call_id='0a2e0a57-48a4-4b6d-ab10-edf0630ac895', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.query_engine, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=14295036320, init_bindings=None), name='retrieve')), RecordAppCallMethod(path=Lens().app.query_engine._retriever, method=Method(obj=Obj(cls=llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever, id=4348938384, init_bindings=None), name='retrieve'))], args={'str_or_query_bundle': 'What did the author do growing up?'}, rets=[{'node': {'id_': 'ee3bc977-bc7e-4393-9e00-9bd7719f7c1b', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '538dc6fd-bdfd-42da-b1c2-17ea82554a7d', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '5042ef58fa439b89369e3a10cacb784e1845e881271729a3261403a515d7134b'}, <NodeRelationship.NEXT: '3'>: {'node_id': '62d8a138-8b16-402a-a7cf-2e6dab6633f2', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '0b4f822ad12b07d089691e8fe465cfd1a8eb40b43de3358e4fe2ed3606b289e6'}}, 'text': 'I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with some problem involving continuations while I watched them play in the tide pools. It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\\n\\nIn the summer of 2016 we moved to England.', 'mimetype': 'text/plain', 'start_char_idx': 65997, 'end_char_idx': 66402, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8211530782069452}, {'node': {'id_': 'a98829e7-c59e-4906-9ec8-d1a84ab231e4', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'ac44aacc-cb1f-48db-9581-1ccbc3305a4e', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'e99647d69b84b0a13c59268b58406bb00652b41196a27d7b46b56e5d713018ed'}}, 'text': \"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\", 'mimetype': 'text/plain', 'start_char_idx': 2, 'end_char_idx': 373, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8208121222994761}, {'node': {'id_': '3cd01a17-a792-4362-8540-74b68300057f', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'c2e92735-3b1c-4d3c-b571-65269e82bbe0', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '0d52c8f8a9f4f6e5d12fdb04b0af0688a87b7cccf5b7337fb595f5e69c4fe2fe'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'f4b10549-f491-4b63-ba16-66a0ae6817b3', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '3779908c352fae99eed78144efa64e8a8a6e91708317acae776ad913bbcc456c'}}, 'text': \"Idelle was in New York at least, and there were other people trying to paint there, even though I didn't know any of them.\\n\\nWhen I got back to New York I resumed my old life, except now I was rich. It was as weird as it sounds. I resumed all my old patterns, except now there were doors where there hadn't been.\", 'mimetype': 'text/plain', 'start_char_idx': 38502, 'end_char_idx': 38813, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8174469441429402}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 20, 869873), end_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 110648)), pid=54744, tid=6433686), RecordAppCall(call_id='7289fbe3-de0c-4585-aef3-33917f8e5e31', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.query_engine, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=14295036320, init_bindings=None), name='retrieve'))], args={'query_bundle': 'What did the author do growing up?'}, rets=[{'node': {'id_': 'ee3bc977-bc7e-4393-9e00-9bd7719f7c1b', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '538dc6fd-bdfd-42da-b1c2-17ea82554a7d', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '5042ef58fa439b89369e3a10cacb784e1845e881271729a3261403a515d7134b'}, <NodeRelationship.NEXT: '3'>: {'node_id': '62d8a138-8b16-402a-a7cf-2e6dab6633f2', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '0b4f822ad12b07d089691e8fe465cfd1a8eb40b43de3358e4fe2ed3606b289e6'}}, 'text': 'I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with some problem involving continuations while I watched them play in the tide pools. It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\\n\\nIn the summer of 2016 we moved to England.', 'mimetype': 'text/plain', 'start_char_idx': 65997, 'end_char_idx': 66402, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8211530782069452}, {'node': {'id_': 'a98829e7-c59e-4906-9ec8-d1a84ab231e4', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'ac44aacc-cb1f-48db-9581-1ccbc3305a4e', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'e99647d69b84b0a13c59268b58406bb00652b41196a27d7b46b56e5d713018ed'}}, 'text': \"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\", 'mimetype': 'text/plain', 'start_char_idx': 2, 'end_char_idx': 373, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8208121222994761}, {'node': {'id_': '3cd01a17-a792-4362-8540-74b68300057f', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'c2e92735-3b1c-4d3c-b571-65269e82bbe0', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '0d52c8f8a9f4f6e5d12fdb04b0af0688a87b7cccf5b7337fb595f5e69c4fe2fe'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'f4b10549-f491-4b63-ba16-66a0ae6817b3', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '3779908c352fae99eed78144efa64e8a8a6e91708317acae776ad913bbcc456c'}}, 'text': \"Idelle was in New York at least, and there were other people trying to paint there, even though I didn't know any of them.\\n\\nWhen I got back to New York I resumed my old life, except now I was rich. It was as weird as it sounds. I resumed all my old patterns, except now there were doors where there hadn't been.\", 'mimetype': 'text/plain', 'start_char_idx': 38502, 'end_char_idx': 38813, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8174469441429402}], error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 20, 824101), end_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 111179)), pid=54744, tid=6433686), RecordAppCall(call_id='92e4a4ba-0436-4746-b45f-941794d40632', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=14289375296, init_bindings=None), name='__call__'))], args={'args': ['What did the author do growing up?', 'I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with some problem involving continuations while I watched them play in the tide pools. It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\\n\\nIn the summer of 2016 we moved to England.']}, rets=0.2, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 130574), end_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 573124)), pid=54744, tid=6433903), RecordAppCall(call_id='cd51f080-0c42-47b2-9aec-5c6d0ec2acbc', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=14289375296, init_bindings=None), name='__call__'))], args={'args': ['What did the author do growing up?', \"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\"]}, rets=0.7, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 147557), end_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 574162)), pid=54744, tid=6433904), RecordAppCall(call_id='f35d0781-dec3-4d9a-a3fe-d7e5f499d49d', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.feedback, method=Method(obj=Obj(cls=trulens_eval.feedback.feedback.Feedback, id=14289375296, init_bindings=None), name='__call__'))], args={'args': ['What did the author do growing up?', \"Idelle was in New York at least, and there were other people trying to paint there, even though I didn't know any of them.\\n\\nWhen I got back to New York I resumed my old life, except now I was rich. It was as weird as it sounds. I resumed all my old patterns, except now there were doors where there hadn't been.\"]}, rets=0.2, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 161520), end_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 625062)), pid=54744, tid=6433905), RecordAppCall(call_id='257e0aa3-3fc4-4db2-9b05-250fcbb1e719', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.query_engine, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=14295036320, init_bindings=None), name='synthesize')), RecordAppCallMethod(path=Lens().app.query_engine._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine, id=14250860400, init_bindings=None), name='get_response')), RecordAppCallMethod(path=Lens().app.query_engine._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.refine.Refine, id=14250860400, init_bindings=None), name='get_response')), RecordAppCallMethod(path=Lens().app.query_engine._response_synthesizer._llm, method=Method(obj=Obj(cls=llama_index.llms.openai.base.OpenAI, id=14245284944, init_bindings=None), name='chat'))], args={'_self': {'callback_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'llama_index.core.callbacks', 'module_name': 'llama_index.core.callbacks.base'}, 'bases': None}, 'id': 4348938480, 'init_bindings': None}}, 'system_prompt': None, 'messages_to_prompt': {'__tru_non_serialized_object': {'cls': {'name': 'function', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}, 'id': 14230775392, 'init_bindings': None}}, 'completion_to_prompt': {'__tru_non_serialized_object': {'cls': {'name': 'function', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}, 'id': 14231686816, 'init_bindings': None}}, 'output_parser': None, 'pydantic_program_mode': <PydanticProgramMode.DEFAULT: 'default'>, 'query_wrapper_prompt': None, 'model': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': None, 'logprobs': None, 'top_logprobs': 0, 'additional_kwargs': {}, 'max_retries': 3, 'timeout': 60.0, 'default_headers': None, 'reuse_client': True, 'api_key': 'sk-...', 'api_base': 'https://api.openai.com/v1', 'api_version': ''}, 'messages': [{'role': <MessageRole.SYSTEM: 'system'>, 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\", 'additional_kwargs': {}}, {'role': <MessageRole.USER: 'user'>, 'content': \"Context information is below.\\n---------------------\\nfile_path: /Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt\\n\\nWhat I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What did the author do growing up?\\nAnswer: \", 'additional_kwargs': {}}]}, rets={'message': {'role': <MessageRole.ASSISTANT: 'assistant'>, 'content': 'The author focused on writing and programming outside of school before college. Specifically, the author wrote short stories, which were described as having characters with strong feelings but lacking in plot.', 'additional_kwargs': {}}, 'raw': {'id': 'chatcmpl-9gqs6yDON4VhKRDOBRcUgAJP543EK', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'The author focused on writing and programming outside of school before college. Specifically, the author wrote short stories, which were described as having characters with strong feelings but lacking in plot.', 'role': 'assistant', 'function_call': None, 'tool_calls': None}}], 'created': 1720000042, 'model': 'gpt-3.5-turbo-0125', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 35, 'prompt_tokens': 229, 'total_tokens': 264}}, 'delta': None, 'logprobs': None, 'additional_kwargs': {}}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 821695), end_time=datetime.datetime(2024, 7, 3, 5, 47, 22, 823213)), pid=54744, tid=6433686), RecordAppCall(call_id='d5a88e11-e700-4ddf-88b1-935ec6d0464a', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.query_engine, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=14295036320, init_bindings=None), name='synthesize')), RecordAppCallMethod(path=Lens().app.query_engine._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine, id=14250860400, init_bindings=None), name='get_response')), RecordAppCallMethod(path=Lens().app.query_engine._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.refine.Refine, id=14250860400, init_bindings=None), name='get_response'))], args={'query_str': 'What did the author do growing up?', 'text_chunks': [\"file_path: /Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt\\n\\nWhat I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\"], 'prev_response': None}, rets='The author focused on writing and programming outside of school before college. Specifically, the author wrote short stories, which were described as having characters with strong feelings but lacking in plot.', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 770613), end_time=datetime.datetime(2024, 7, 3, 5, 47, 22, 823532)), pid=54744, tid=6433686), RecordAppCall(call_id='5ca98c63-7d95-4b17-9d24-61a557a2428a', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.query_engine, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=14295036320, init_bindings=None), name='synthesize')), RecordAppCallMethod(path=Lens().app.query_engine._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine, id=14250860400, init_bindings=None), name='get_response'))], args={'query_str': 'What did the author do growing up?', 'text_chunks': [\"file_path: /Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt\\n\\nWhat I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\"]}, rets='The author focused on writing and programming outside of school before college. Specifically, the author wrote short stories, which were described as having characters with strong feelings but lacking in plot.', error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 723704), end_time=datetime.datetime(2024, 7, 3, 5, 47, 22, 823575)), pid=54744, tid=6433686), RecordAppCall(call_id='0c19816c-f709-46ae-8a4a-e097d61d6b87', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app.query_engine, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=14295036320, init_bindings=None), name='synthesize'))], args={'query_bundle': 'What did the author do growing up?', 'nodes': [{'node': {'id_': 'a98829e7-c59e-4906-9ec8-d1a84ab231e4', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'ac44aacc-cb1f-48db-9581-1ccbc3305a4e', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'e99647d69b84b0a13c59268b58406bb00652b41196a27d7b46b56e5d713018ed'}}, 'text': \"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\", 'mimetype': 'text/plain', 'start_char_idx': 2, 'end_char_idx': 373, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8208121222994761}]}, rets={'response': 'The author focused on writing and programming outside of school before college. Specifically, the author wrote short stories, which were described as having characters with strong feelings but lacking in plot.', 'source_nodes': [{'node': {'id_': 'a98829e7-c59e-4906-9ec8-d1a84ab231e4', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'ac44aacc-cb1f-48db-9581-1ccbc3305a4e', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'e99647d69b84b0a13c59268b58406bb00652b41196a27d7b46b56e5d713018ed'}}, 'text': \"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\", 'mimetype': 'text/plain', 'start_char_idx': 2, 'end_char_idx': 373, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8208121222994761}], 'metadata': {'a98829e7-c59e-4906-9ec8-d1a84ab231e4': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}}}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 21, 671166), end_time=datetime.datetime(2024, 7, 3, 5, 47, 22, 823932)), pid=54744, tid=6433686), RecordAppCall(call_id='e8bcc27d-ff8d-433d-96c1-4aec55ab0151', stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=trulens_eval.guardrails.llama.WithFeedbackFilterNodes, id=14295036320, init_bindings=None), name='query'))], args={'query': 'What did the author do growing up?'}, rets={'response': 'The author focused on writing and programming outside of school before college. Specifically, the author wrote short stories, which were described as having characters with strong feelings but lacking in plot.', 'source_nodes': [{'node': {'id_': 'a98829e7-c59e-4906-9ec8-d1a84ab231e4', 'embedding': None, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '01d1924b-a1ae-4a1b-a728-02c0d2076cdd', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}, 'hash': '1d33ee4442f7d67aae21ae67e94898c45dfefa62763fbe8fa24976ca2c963512'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'ac44aacc-cb1f-48db-9581-1ccbc3305a4e', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'e99647d69b84b0a13c59268b58406bb00652b41196a27d7b46b56e5d713018ed'}}, 'text': \"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\", 'mimetype': 'text/plain', 'start_char_idx': 2, 'end_char_idx': 373, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8208121222994761}], 'metadata': {'a98829e7-c59e-4906-9ec8-d1a84ab231e4': {'file_path': '/Users/jreini/Desktop/development/trulens/trulens_eval/examples/quickstart/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-07-03', 'last_modified_date': '2024-07-03'}}}, error=None, perf=Perf(start_time=datetime.datetime(2024, 7, 3, 5, 47, 20, 778856), end_time=datetime.datetime(2024, 7, 3, 5, 47, 22, 824169)), pid=54744, tid=6433686)], feedback_and_future_results=[(FeedbackDefinition(Answer Relevance,\n",
       "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       "), <Future at 0x35116b8f0 state=finished returned FeedbackResult>), (FeedbackDefinition(Context Relevance,\n",
       "\tselectors={'question': Lens().__record__.main_input, 'context': Lens().__record__.app.query.rets.source_nodes[:].node.text},\n",
       "\tif_exists=None\n",
       "), <Future at 0x350bc6960 state=finished returned FeedbackResult>), (FeedbackDefinition(Groundedness,\n",
       "\tselectors={'source': Lens().__record__.app.query.rets.source_nodes[:].node.text.collect(), 'statement': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       "), <Future at 0x351143f80 state=finished returned FeedbackResult>)], feedback_results=[<Future at 0x35116b8f0 state=finished returned FeedbackResult>, <Future at 0x350bc6960 state=finished returned FeedbackResult>, <Future at 0x351143f80 state=finished returned FeedbackResult>])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "# recs = recording.records # use .records if multiple\n",
    "\n",
    "display(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Relevance 0.8\n",
      "Context Relevance 0.8\n",
      "Groundedness 1.0\n"
     ]
    }
   ],
   "source": [
    "# The results of the feedback functions can be rertireved from\n",
    "# `Record.feedback_results` or using the `wait_for_feedback_result` method. The\n",
    "# results if retrieved directly are `Future` instances (see\n",
    "# `concurrent.futures`). You can use `as_completed` to wait until they have\n",
    "# finished evaluating or use the utility method:\n",
    "\n",
    "for feedback, feedback_result in rec.wait_for_feedback_results().items():\n",
    "    print(feedback.name, feedback_result.result)\n",
    "\n",
    "# See more about wait_for_feedback_results:\n",
    "# help(rec.wait_for_feedback_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LlamaIndex_App1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_d8d7b57e2f4927576f58e09f26469c42</td>\n",
       "      <td>\"What did the author do growing up?\"</td>\n",
       "      <td>\"The author worked on writing and programming ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_d8d7b57e2f4927576f5...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 3, ...</td>\n",
       "      <td>{\"start_time\": \"2024-07-03T05:47:14.007165\", \"...</td>\n",
       "      <td>2024-07-03T05:47:15.029467</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[{'args': {'source': ['I remember taking the b...</td>\n",
       "      <td>[{'args': {'prompt': 'What did the author do g...</td>\n",
       "      <td>[{'args': {'question': 'What did the author do...</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LlamaIndex_App1_Filtered</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>WithFeedbackFilterNodes(trulens_eval.guardrail...</td>\n",
       "      <td>record_hash_9f960b879e7fbb4c48a58b1cdfb87b3f</td>\n",
       "      <td>\"What did the author do growing up?\"</td>\n",
       "      <td>\"The author focused on writing and programming...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_9f960b879e7fbb4c48a...</td>\n",
       "      <td>{\"n_requests\": 5, \"n_successful_requests\": 15,...</td>\n",
       "      <td>{\"start_time\": \"2024-07-03T05:47:20.778856\", \"...</td>\n",
       "      <td>2024-07-03T05:47:22.824425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[{'args': {'source': [\"What I Worked On\\n\\nFeb...</td>\n",
       "      <td>[{'args': {'prompt': 'What did the author do g...</td>\n",
       "      <td>[{'args': {'question': 'What did the author do...</td>\n",
       "      <td>1</td>\n",
       "      <td>3537</td>\n",
       "      <td>0.005268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     app_id  \\\n",
       "0           LlamaIndex_App1   \n",
       "1  LlamaIndex_App1_Filtered   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  WithFeedbackFilterNodes(trulens_eval.guardrail...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_d8d7b57e2f4927576f58e09f26469c42   \n",
       "1  record_hash_9f960b879e7fbb4c48a58b1cdfb87b3f   \n",
       "\n",
       "                                  input  \\\n",
       "0  \"What did the author do growing up?\"   \n",
       "1  \"What did the author do growing up?\"   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"The author worked on writing and programming ...    -   \n",
       "1  \"The author focused on writing and programming...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_d8d7b57e2f4927576f5...   \n",
       "1  {\"record_id\": \"record_hash_9f960b879e7fbb4c48a...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 2, \"n_successful_requests\": 3, ...   \n",
       "1  {\"n_requests\": 5, \"n_successful_requests\": 15,...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-07-03T05:47:14.007165\", \"...   \n",
       "1  {\"start_time\": \"2024-07-03T05:47:20.778856\", \"...   \n",
       "\n",
       "                           ts  Groundedness  Answer Relevance  \\\n",
       "0  2024-07-03T05:47:15.029467           0.8               0.8   \n",
       "1  2024-07-03T05:47:22.824425           1.0               0.8   \n",
       "\n",
       "   Context Relevance                                 Groundedness_calls  \\\n",
       "0                0.4  [{'args': {'source': ['I remember taking the b...   \n",
       "1                0.8  [{'args': {'source': [\"What I Worked On\\n\\nFeb...   \n",
       "\n",
       "                              Answer Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What did the author do g...   \n",
       "1  [{'args': {'prompt': 'What did the author do g...   \n",
       "\n",
       "                             Context Relevance_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'question': 'What did the author do...        1           487   \n",
       "1  [{'args': {'question': 'What did the author do...        1          3537   \n",
       "\n",
       "   total_cost  \n",
       "0    0.000713  \n",
       "1    0.005268  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LlamaIndex_App1_Filtered</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LlamaIndex_App1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Answer Relevance  Context Relevance  Groundedness  \\\n",
       "app_id                                                                        \n",
       "LlamaIndex_App1_Filtered               0.8                0.8           1.0   \n",
       "LlamaIndex_App1                        0.8                0.4           0.8   \n",
       "\n",
       "                          latency  total_cost  \n",
       "app_id                                         \n",
       "LlamaIndex_App1_Filtered      2.0    0.005268  \n",
       "LlamaIndex_App1               2.0    0.000713  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì TruLens Quickstart\n",
    "\n",
    "In this quickstart you will create a RAG from scratch and learn how to log it and get feedback on an LLM response.\n",
    "\n",
    "For evaluation, we will leverage the \"hallucination triad\" of groundedness, context relevance and answer relevance.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval chromadb openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "In this case, we'll just initialize some simple text in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_info = \"\"\"\n",
    "The University of Washington, founded in 1861 in Seattle, is a public research university\n",
    "with over 45,000 students across three campuses in Seattle, Tacoma, and Bothell.\n",
    "As the flagship institution of the six public universities in Washington state,\n",
    "UW encompasses over 500 buildings and 20 million square feet of space,\n",
    "including one of the largest library systems in the world.\n",
    "\"\"\"\n",
    "\n",
    "wsu_info = \"\"\"\n",
    "Washington State University, commonly known as WSU, founded in 1890, is a public research university in Pullman, Washington.\n",
    "With multiple campuses across the state, it is the state's second largest institution of higher education.\n",
    "WSU is known for its programs in veterinary medicine, agriculture, engineering, architecture, and pharmacy.\n",
    "\"\"\"\n",
    "\n",
    "seattle_info = \"\"\"\n",
    "Seattle, a city on Puget Sound in the Pacific Northwest, is surrounded by water, mountains and evergreen forests, and contains thousands of acres of parkland.\n",
    "It's home to a large tech industry, with Microsoft and Amazon headquartered in its metropolitan area.\n",
    "The futuristic Space Needle, a legacy of the 1962 World's Fair, is its most iconic landmark.\n",
    "\"\"\"\n",
    "\n",
    "starbucks_info = \"\"\"\n",
    "Starbucks Corporation is an American multinational chain of coffeehouses and roastery reserves headquartered in Seattle, Washington.\n",
    "As the world's largest coffeehouse chain, Starbucks is seen to be the main representation of the United States' second wave of coffee culture.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Store\n",
    "\n",
    "Create a chromadb vector store in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(api_key=os.environ.get('OPENAI_API_KEY'),\n",
    "                                             model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(name=\"Washington\",\n",
    "                                                      embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Populate the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_store.add(\"uw_info\", documents=uw_info)\n",
    "vector_store.add(\"wsu_info\", documents=wsu_info)\n",
    "vector_store.add(\"seattle_info\", documents=seattle_info)\n",
    "vector_store.add(\"starbucks_info\", documents=starbucks_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG from scratch\n",
    "\n",
    "Build a custom RAG from scratch, and add TruLens custom instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶ë Tru initialized with db url sqlite:///default.sqlite .\n",
      "üõë Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()\n",
    "\n",
    "class RAG_from_scratch:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(\n",
    "            query_texts=query,\n",
    "            n_results=4\n",
    "        )\n",
    "        # Flatten the list of lists into a single list\n",
    "        return [doc for sublist in results['documents'] for doc in sublist]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        messages=\n",
    "        [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\": \n",
    "            f\"We have provided context information below. \\n\"\n",
    "            f\"---------------------\\n\"\n",
    "            f\"{context_str}\"\n",
    "            f\"\\n---------------------\\n\"\n",
    "            f\"Given this information, please answer the question: {query}\"\n",
    "            }\n",
    "        ]\n",
    "        ).choices[0].message.content\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        completion = self.generate_completion(query, context_str)\n",
    "        return completion\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up feedback functions.\n",
    "\n",
    "Here we'll use groundedness, answer relevance and context relevance to detect hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.retrieve.rets[:] .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback.provider.openai import OpenAI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "provider = OpenAI(model_engine=\"gpt-4o\")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets[:])\n",
    "    .aggregate(np.mean) # choose a different aggregation method if you wish\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the app\n",
    "Wrap the custom RAG with TruCustomApp, add list of feedbacks for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'RAG v1',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app\n",
    "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    rag.query(\"When was the University of Washington founded?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results\n",
    "\n",
    "We can view results in the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        latency  total_cost\n",
       "app_id                     \n",
       "RAG v1      3.0    0.000511"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When was the University of Washington founded?</td>\n",
       "      <td>\\nThe University of Washington, founded in 186...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When was the University of Washington founded?</td>\n",
       "      <td>\\nWashington State University, commonly known ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When was the University of Washington founded?</td>\n",
       "      <td>\\nSeattle, a city on Puget Sound in the Pacifi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When was the University of Washington founded?</td>\n",
       "      <td>\\nStarbucks Corporation is an American multina...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "0  When was the University of Washington founded?   \n",
       "1  When was the University of Washington founded?   \n",
       "2  When was the University of Washington founded?   \n",
       "3  When was the University of Washington founded?   \n",
       "\n",
       "                                             context  ret  \n",
       "0  \\nThe University of Washington, founded in 186...  1.0  \n",
       "1  \\nWashington State University, commonly known ...  0.0  \n",
       "2  \\nSeattle, a city on Puget Sound in the Pacifi...  0.0  \n",
       "3  \\nStarbucks Corporation is an American multina...  0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use guardrails\n",
    "\n",
    "In addition to making informed iteration, we can also directly use feedback results as guardrails at inference time. In particular, here we show how to use the context relevance score as a guardrail to filter out irrelevant context before it gets passed to the LLM. This both reduces hallucination and improves efficiency.\n",
    "\n",
    "To do so, we'll rebuild our RAG using the @context-filter decorator on the method we want to filter, and pass in the feedback function and threshold to use for guardrailing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    ")\n",
    "\n",
    "from trulens_eval.guardrails.base import context_filter\n",
    "\n",
    "class filtered_RAG_from_scratch:\n",
    "    @instrument\n",
    "    @context_filter(f_context_relevance_score, 0.75, keyword_for_prompt=\"query\")\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(\n",
    "        query_texts=query,\n",
    "        n_results=4\n",
    "    )\n",
    "        return [doc for sublist in results['documents'] for doc in sublist]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        messages=\n",
    "        [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\": \n",
    "            f\"We have provided context information below. \\n\"\n",
    "            f\"---------------------\\n\"\n",
    "            f\"{context_str}\"\n",
    "            f\"\\n---------------------\\n\"\n",
    "            f\"Given this information, please answer the question: {query}\"\n",
    "            }\n",
    "        ]\n",
    "        ).choices[0].message.content\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query=query)\n",
    "        completion = self.generate_completion(query=query, context_str=context_str)\n",
    "        return completion\n",
    "\n",
    "filtered_rag = filtered_RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record and operate as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "filtered_tru_rag = TruCustomApp(filtered_rag,\n",
    "    app_id = 'RAG v2',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])\n",
    "\n",
    "with filtered_tru_rag as recording:\n",
    "    filtered_rag.query(query=\"when was the university of washington founded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG v2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Answer Relevance  Groundedness  Context Relevance  latency  total_cost\n",
       "app_id                                                                        \n",
       "RAG v2               1.0           1.0               1.00      1.0    0.000203\n",
       "RAG v1               1.0           1.0               0.25      1.0    0.000511"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the power of filtering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when was the university of washington founded?</td>\n",
       "      <td>\\nThe University of Washington, founded in 186...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "0  when was the university of washington founded?   \n",
       "\n",
       "                                             context  ret  \n",
       "0  \\nThe University of Washington, founded in 186...  1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008c8387461047f9a05d09e92758e3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.206:3453 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard(port=3453, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Evals\n",
    "This notebook shows the use of the dummy feedback function provider which\n",
    "behaves like the huggingface provider except it does not actually perform any\n",
    "network calls and just produces constant results. It can be used to prototype\n",
    "feedback function wiring for your apps before invoking potentially slow (to\n",
    "run/to load) feedback functions.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/prototype_evals.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Feedback\n",
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()\n",
    "\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "class APP:\n",
    "    @instrument\n",
    "    def completion(self, prompt):\n",
    "        completion = oai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages=\n",
    "                [\n",
    "                    {\"role\": \"user\",\n",
    "                    \"content\": \n",
    "                    f\"Please answer the question: {prompt}\"\n",
    "                    }\n",
    "                ]\n",
    "                ).choices[0].message.content\n",
    "        return completion\n",
    "    \n",
    "llm_app = APP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy feedback\n",
    "\n",
    "By setting the provider as `Dummy()`, you can erect your evaluation suite and then easily substitute in a real model provider (e.g. OpenAI) later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider.hugs import Dummy\n",
    "\n",
    "# hugs = Huggingface()\n",
    "hugs = Dummy()\n",
    "\n",
    "f_positive_sentiment = Feedback(hugs.positive_sentiment).on_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add trulens as a context manager for llm_app with dummy feedback\n",
    "from trulens_eval import TruCustomApp\n",
    "tru_app = TruCustomApp(llm_app,\n",
    "                       app_id = 'LLM App v1',\n",
    "                       feedbacks = [f_positive_sentiment])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_app as recording:\n",
    "    llm_app.completion('give me a good name for a colorful sock company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[tru_app.app_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì Logging Human Feedback\n",
    "\n",
    "In many situations, it can be useful to log human feedback from your users about your LLM app's performance. Combining human feedback along with automated feedback can help you drill down on subsets of your app that underperform, and uncover new failure modes. This example will walk you through a simple example of recording human feedback with TruLens.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/human_feedback.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval import TruCustomApp\n",
    "\n",
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Keys\n",
    "\n",
    "For this example, you need an OpenAI key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your app\n",
    "\n",
    "Here we set up a custom application using just an OpenAI chat completion. The process for logging human feedback is the same however you choose to set up your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()\n",
    "\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "class APP:\n",
    "    @instrument\n",
    "    def completion(self, prompt):\n",
    "        completion = oai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages=\n",
    "                [\n",
    "                    {\"role\": \"user\",\n",
    "                    \"content\": \n",
    "                    f\"Please answer the question: {prompt}\"\n",
    "                    }\n",
    "                ]\n",
    "                ).choices[0].message.content\n",
    "        return completion\n",
    "    \n",
    "llm_app = APP()\n",
    "\n",
    "# add trulens as a context manager for llm_app\n",
    "tru_app = TruCustomApp(llm_app, app_id = 'LLM App v1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_app as recording:\n",
    "    llm_app.completion(\"Give me 10 names for a colorful sock company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the record to add the feedback to.\n",
    "record = recording.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mechamism for recording human feedback.\n",
    "\n",
    "Be sure to click an emoji in the record to record `human_feedback` to log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Button, HBox, VBox\n",
    "\n",
    "thumbs_up_button = Button(description='üëç')\n",
    "thumbs_down_button = Button(description='üëé')\n",
    "\n",
    "human_feedback = None\n",
    "\n",
    "def on_thumbs_up_button_clicked(b):\n",
    "    global human_feedback\n",
    "    human_feedback = 1\n",
    "\n",
    "def on_thumbs_down_button_clicked(b):\n",
    "    global human_feedback\n",
    "    human_feedback = 0\n",
    "\n",
    "thumbs_up_button.on_click(on_thumbs_up_button_clicked)\n",
    "thumbs_down_button.on_click(on_thumbs_down_button_clicked)\n",
    "\n",
    "HBox([thumbs_up_button, thumbs_down_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the human feedback to a particular app and record\n",
    "tru.add_feedback(\n",
    "    name=\"Human Feedack\",\n",
    "    record_id=record.record_id,\n",
    "    app_id=tru_app.app_id,\n",
    "    result=human_feedback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the result logged with your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[tru_app.app_id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì Ground Truth Evaluations\n",
    "\n",
    "In this quickstart you will create a evaluate a _LangChain_ app using ground truth. Ground truth evaluation can be especially useful during early LLM experiments when you have a small set of example queries that are critical to get right.\n",
    "\n",
    "Ground truth evaluation works by comparing the similarity of an LLM response compared to its matching verified response.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/groundtruth_evals.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add API keys\n",
    "For this quickstart, you will need Open AI keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple LLM Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()\n",
    "\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "class APP:\n",
    "    @instrument\n",
    "    def completion(self, prompt):\n",
    "        completion = oai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages=\n",
    "                [\n",
    "                    {\"role\": \"user\",\n",
    "                    \"content\": \n",
    "                    f\"Please answer the question: {prompt}\"\n",
    "                    }\n",
    "                ]\n",
    "                ).choices[0].message.content\n",
    "        return completion\n",
    "    \n",
    "llm_app = APP()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Ground Truth, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Ground Truth, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback\n",
    "from trulens_eval.feedback import GroundTruthAgreement\n",
    "\n",
    "golden_set = [\n",
    "    {\"query\": \"who invented the lightbulb?\", \"response\": \"Thomas Edison\"},\n",
    "    {\"query\": \"¬øquien invento la bombilla?\", \"response\": \"Thomas Edison\"}\n",
    "]\n",
    "\n",
    "f_groundtruth = Feedback(GroundTruthAgreement(golden_set).agreement_measure, name = \"Ground Truth\").on_input_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add trulens as a context manager for llm_app\n",
    "from trulens_eval import TruCustomApp\n",
    "tru_app = TruCustomApp(llm_app, app_id = 'LLM App v1', feedbacks = [f_groundtruth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrumented query engine can operate as a context manager:\n",
    "with tru_app as recording:\n",
    "    llm_app.completion(\"¬øquien invento la bombilla?\")\n",
    "    llm_app.completion(\"who invented the lightbulb?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>Human Feedack</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LLM App v1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.38994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ground Truth  positive_sentiment  Human Feedack  latency  \\\n",
       "app_id                                                                 \n",
       "LLM App v1           1.0             0.38994            1.0     1.75   \n",
       "\n",
       "            total_cost  \n",
       "app_id                  \n",
       "LLM App v1    0.000076  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[tru_app.app_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Methods\n",
    "\n",
    "## Automatic Logging\n",
    "\n",
    "The simplest method for logging with TruLens is by wrapping with TruChain and\n",
    "including the tru argument, as shown in the quickstart.\n",
    "\n",
    "This is done like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports main tools:\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval import Huggingface\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval import TruChain\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "Tru().migrate_database()\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "full_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\n",
    "        \"Provide a helpful response with relevant background information for the following: {prompt}\",\n",
    "        input_variables=[\"prompt\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
    "\n",
    "llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=chat_prompt_template, verbose=True)\n",
    "\n",
    "truchain = TruChain(\n",
    "    chain,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    tru=tru\n",
    ")\n",
    "with truchain:\n",
    "    chain(\"This will be automatically logged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback functions can also be logged automatically by providing them in a list\n",
    "to the feedbacks arg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = Huggingface()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on_input_output()\n",
    "# By default this will check language match on the main app input and main app\n",
    "# output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truchain = TruChain(\n",
    "    chain,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_lang_match], # feedback functions\n",
    "    tru=tru\n",
    ")\n",
    "with truchain:\n",
    "    chain(\"This will be automatically logged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Logging\n",
    "\n",
    "### Wrap with TruChain to instrument your chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TruChain(chain, app_id='Chain1_ChatApplication')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logging and instrumentation\n",
    "\n",
    "Making the first call to your wrapped LLM Application will now also produce a log or \"record\" of the chain execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input = 'que hora es?'\n",
    "gpt3_response, record = tc.with_record(chain.__call__, prompt_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can log the records but first we need to log the chain itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.add_app(app=truchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can log the record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.add_record(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log App Feedback\n",
    "Capturing app feedback such as user feedback of the responses can be added with\n",
    "one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumb_result = True\n",
    "tru.add_feedback(\n",
    "    name=\"üëç (1) or üëé (0)\", \n",
    "    record_id=record.record_id, \n",
    "    result=thumb_result\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Quality\n",
    "\n",
    "Following the request to your app, you can then evaluate LLM quality using\n",
    "feedback functions. This is completed in a sequential call to minimize latency\n",
    "for your application, and evaluations will also be logged to your local machine.\n",
    "\n",
    "To get feedback on the quality of your LLM, you can use any of the provided\n",
    "feedback functions or add your own.\n",
    "\n",
    "To assess your LLM quality, you can provide the feedback functions to\n",
    "`tru.run_feedback()` in a list provided to `feedback_functions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[f_lang_match]\n",
    ")\n",
    "for result in feedback_results:\n",
    "    display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After capturing feedback, you can then log it to your local database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-band Feedback evaluation\n",
    "\n",
    "In the above example, the feedback function evaluation is done in the same\n",
    "process as the chain evaluation. The alternative approach is the use the\n",
    "provided persistent evaluator started via\n",
    "`tru.start_deferred_feedback_evaluator`. Then specify the `feedback_mode` for\n",
    "`TruChain` as `deferred` to let the evaluator handle the feedback functions.\n",
    "\n",
    "For demonstration purposes, we start the evaluator here but it can be started in\n",
    "another process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truchain: TruChain = TruChain(\n",
    "    chain,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_lang_match],\n",
    "    tru=tru,\n",
    "    feedback_mode=\"deferred\"\n",
    ")\n",
    "\n",
    "with truchain:\n",
    "    chain(\"This will be logged by deferred evaluator.\")\n",
    "\n",
    "tru.start_evaluator()\n",
    "# tru.stop_evaluator()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì Custom Feedback Functions\n",
    "\n",
    "Feedback functions are an extensible framework for evaluating LLMs. You can add your own feedback functions to evaluate the qualities required by your application by updating `trulens_eval/feedback.py`, or simply creating a new provider class and feedback function in youre notebook. If your contributions would be useful for others, we encourage you to contribute to TruLens!\n",
    "\n",
    "Feedback functions are organized by model provider into Provider classes.\n",
    "\n",
    "The process for adding new feedback functions is:\n",
    "1. Create a new Provider class or locate an existing one that applies to your feedback function. If your feedback function does not rely on a model provider, you can create a standalone class. Add the new feedback function method to your selected class. Your new method can either take a single text (str) as a parameter or both prompt (str) and response (str). It should return a float between 0 (worst) and 1 (best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Provider, Feedback, Select, Tru\n",
    "\n",
    "class StandAlone(Provider):\n",
    "    def custom_feedback(self, my_text_field: str) -> float:\n",
    "        \"\"\"\n",
    "        A dummy function of text inputs to float outputs.\n",
    "\n",
    "        Parameters:\n",
    "            my_text_field (str): Text to evaluate.\n",
    "\n",
    "        Returns:\n",
    "            float: square length of the text\n",
    "        \"\"\"\n",
    "        return 1.0 / (1.0 + len(my_text_field) * len(my_text_field))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Instantiate your provider and feedback functions. The feedback function is wrapped by the trulens-eval Feedback class which helps specify what will get sent to your function parameters (For example: Select.RecordInput or Select.RecordOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standalone = StandAlone()\n",
    "f_custom_function = Feedback(standalone.custom_feedback).on(\n",
    "    my_text_field=Select.RecordOutput\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Your feedback function is now ready to use just like the out of the box feedback functions. Below is an example of it being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[f_custom_function]\n",
    ")\n",
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending existing providers.\n",
    "\n",
    "In addition to calling your own methods, you can also extend stock feedback providers (such as `OpenAI`, `AzureOpenAI`, `Bedrock`) to custom feedback implementations. This can be especially useful for tweaking stock feedback functions, or running custom feedback function prompts while letting TruLens handle the backend LLM provider.\n",
    "\n",
    "This is done by subclassing the provider you wish to extend, and using the `generate_score` method that runs the provided prompt with your specified provider, and extracts a float score from 0-1. Your prompt should request the LLM respond on the scale from 0 to 10, then the `generate_score` method will normalize to 0-1.\n",
    "\n",
    "See below for example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import AzureOpenAI\n",
    "from trulens_eval.utils.generated import re_0_10_rating\n",
    "\n",
    "class Custom_AzureOpenAI(AzureOpenAI):\n",
    "    def style_check_professional(self, response: str) -> float:\n",
    "        \"\"\"\n",
    "        Custom feedback function to grade the professional style of the resposne, extending AzureOpenAI provider.\n",
    "\n",
    "        Args:\n",
    "            response (str): text to be graded for professional style.\n",
    "\n",
    "        Returns:\n",
    "            float: A value between 0 and 1. 0 being \"not professional\" and 1 being \"professional\".\n",
    "        \"\"\"\n",
    "        professional_prompt = str.format(\"Please rate the professionalism of the following text on a scale from 0 to 10, where 0 is not at all professional and 10 is extremely professional: \\n\\n{}\", response)\n",
    "        return self.generate_score(system_prompt=professional_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running \"chain of thought evaluations\" is another use case for extending providers. Doing so follows a similar process as above, where the base provider (such as `AzureOpenAI`) is subclassed.\n",
    "\n",
    "For this case, the method `generate_score_and_reasons` can be used to extract both the score and chain of thought reasons from the LLM response.\n",
    "\n",
    "To use this method, the prompt used should include the `COT_REASONS_TEMPLATE` available from the TruLens prompts library (`trulens_eval.feedback.prompts`).\n",
    "\n",
    "See below for example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "from trulens_eval.feedback import prompts\n",
    "\n",
    "class Custom_AzureOpenAI(AzureOpenAI):\n",
    "    def context_relevance_with_cot_reasons_extreme(self, question: str, context: str) -> Tuple[float, Dict]:\n",
    "        \"\"\"\n",
    "        Tweaked version of context relevance, extending AzureOpenAI provider.\n",
    "        A function that completes a template to check the relevance of the statement to the question.\n",
    "        Scoring guidelines for scores 5-8 are removed to push the LLM to more extreme scores.\n",
    "        Also uses chain of thought methodology and emits the reasons.\n",
    "\n",
    "        Args:\n",
    "            question (str): A question being asked. \n",
    "            context (str): A statement to the question.\n",
    "\n",
    "        Returns:\n",
    "            float: A value between 0 and 1. 0 being \"not relevant\" and 1 being \"relevant\".\n",
    "        \"\"\"\n",
    "\n",
    "        # remove scoring guidelines around middle scores\n",
    "        system_prompt = prompts.CONTEXT_RELEVANCE_SYSTEM.replace(\n",
    "        \"- STATEMENT that is RELEVANT to most of the QUESTION should get a score of 5, 6, 7 or 8. Higher score indicates more RELEVANCE.\\n\\n\", \"\")\n",
    "        \n",
    "        user_prompt = str.format(prompts.CONTEXT_RELEVANCE_USER, question = question, context = context)\n",
    "        user_prompt = user_prompt.replace(\n",
    "            \"RELEVANCE:\", prompts.COT_REASONS_TEMPLATE\n",
    "        )\n",
    "\n",
    "        return self.generate_score_and_reasons(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Output Feedback functions\n",
    "Trulens also supports multi-output feedback functions. As a typical feedback function will output a float between 0 and 1, multi-output should output a dictionary of `output_key` to a float between 0 and 1. The feedbacks table will display the feedback with column `feedback_name:::outputkey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_output_feedback = Feedback(lambda input_param: {'output_key1': 0.1, 'output_key2': 0.9}, name=\"multi\").on(\n",
    "    input_param=Select.RecordOutput\n",
    ")\n",
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[multi_output_feedback]\n",
    ")\n",
    "tru.add_feedbacks(feedback_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators will run on the same dict keys.\n",
    "import numpy as np\n",
    "multi_output_feedback = Feedback(lambda input_param: {'output_key1': 0.1, 'output_key2': 0.9}, name=\"multi-agg\").on(\n",
    "    input_param=Select.RecordOutput\n",
    ").aggregate(np.mean)\n",
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[multi_output_feedback]\n",
    ")\n",
    "tru.add_feedbacks(feedback_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multi-context chunking, an aggregator can operate on a list of multi output dictionaries.\n",
    "def dict_aggregator(list_dict_input):\n",
    "    agg = 0\n",
    "    for dict_input in list_dict_input:\n",
    "        agg += dict_input['output_key1']\n",
    "    return agg\n",
    "multi_output_feedback = Feedback(lambda input_param: {'output_key1': 0.1, 'output_key2': 0.9}, name=\"multi-agg-dict\").on(\n",
    "    input_param=Select.RecordOutput\n",
    ").aggregate(dict_aggregator)\n",
    "feedback_results = tru.run_feedback_functions(\n",
    "    record=record,\n",
    "    feedback_functions=[multi_output_feedback]\n",
    ")\n",
    "tru.add_feedbacks(feedback_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5737f6101ac92451320b0e41890107145710b89f85909f3780d702e7818f973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
