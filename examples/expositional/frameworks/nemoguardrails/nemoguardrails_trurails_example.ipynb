{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring and Evaluating _NeMo Guardrails_ apps\n",
    "\n",
    "This notebook demonstrates how to instrument _NeMo Guardrails_ apps to monitor\n",
    "their invocations and run feedback functions on their final or intermediate\n",
    "results. The reverse integration, of using trulens within rails apps, is shown\n",
    "in the other notebook in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NeMo Guardrails if not already installed.\n",
    "! pip install nemoguardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup keys and trulens_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses openai and huggingface providers which need some keys set.\n",
    "# You can set them here:\n",
    "\n",
    "from trulens.core.utils.keys import check_or_set_keys\n",
    "\n",
    "check_or_set_keys(OPENAI_API_KEY=\"to fill in\", HUGGINGFACE_API_KEY=\"to fill in\")\n",
    "\n",
    "# Load trulens, reset the database:\n",
    "from trulens.core import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rails app setup\n",
    "\n",
    "The files created below define a configuration of a rails app adapted from\n",
    "various examples in the NeMo-Guardrails repository. There is nothing unusual\n",
    "about the app beyond the knowledge base here being the trulens_eval\n",
    "documentation. This means you should be able to ask the resulting bot questions\n",
    "regarding trulens instead of the fictional company handbook as was the case in\n",
    "the originating example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.yaml\n",
    "# Adapted from NeMo-Guardrails/nemoguardrails/examples/bots/abc/config.yml\n",
    "instructions:\n",
    "  - type: general\n",
    "    content: |\n",
    "      Below is a conversation between a user and a bot called the trulens Bot.\n",
    "      The bot is designed to answer questions about the trulens_eval python library.\n",
    "      The bot is knowledgeable about python.\n",
    "      If the bot does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "sample_conversation: |\n",
    "  user \"Hi there. Can you help me with some questions I have about trulens?\"\n",
    "    express greeting and ask for assistance\n",
    "  bot express greeting and confirm and offer assistance\n",
    "    \"Hi there! I'm here to help answer any questions you may have about the trulens. What would you like to know?\"\n",
    "\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.co\n",
    "# Adapted from NeMo-Guardrails/tests/test_configs/with_kb_openai_embeddings/config.co\n",
    "define user ask capabilities\n",
    "  \"What can you do?\"\n",
    "  \"What can you help me with?\"\n",
    "  \"tell me what you can do\"\n",
    "  \"tell me about you\"\n",
    "\n",
    "define bot inform capabilities\n",
    "  \"I am an AI bot that helps answer questions about trulens_eval.\"\n",
    "\n",
    "define flow\n",
    "  user ask capabilities\n",
    "  bot inform capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rails app instantiation\n",
    "\n",
    "The instantiation of the app does not differ from the steps presented in NeMo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import LLMRails\n",
    "from nemoguardrails import RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\".\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    rails.kb is not None\n",
    "), \"Knowledge base not loaded. You might be using the wrong nemo release or branch.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback functions setup\n",
    "\n",
    "Lets consider some feedback functions. We will define two types: a simple\n",
    "language match that checks whether output of the app is in the same language as\n",
    "the input. The second is a set of three for evaluating context retrieval. The\n",
    "setup for these is similar to that for other app types such as langchain except\n",
    "we provide a utility `RAG_triad` to create the three context retrieval functions\n",
    "for you instead of having to create them seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.instrument.nemo import TruRails\n",
    "from trulens.providers.huggingface import Huggingface\n",
    "from trulens.providers.openai import OpenAI\n",
    "from trulens.feedback.feedback import rag_triad\n",
    "\n",
    "# Initialize provider classes\n",
    "openai = OpenAI()\n",
    "hugs = Huggingface()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens.core.app import App\n",
    "\n",
    "context = App.select_context(rails)\n",
    "question = Select.RecordInput\n",
    "answer = Select.RecordOutput\n",
    "\n",
    "f_language_match = (\n",
    "    Feedback(hugs.language_match, if_exists=answer).on(question).on(answer)\n",
    ")\n",
    "\n",
    "fs_triad = rag_triad(\n",
    "    provider=openai, question=question, answer=answer, context=context\n",
    ")\n",
    "\n",
    "# Overview of the 4 feedback functions defined.\n",
    "pprint(f_language_match)\n",
    "pprint(fs_triad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TruRails` recorder instantiation\n",
    "\n",
    "Tru recorder construction is identical to other app types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_rails = TruRails(\n",
    "    rails,\n",
    "    app_id=\"my first trurails app\",  # optional\n",
    "    feedbacks=[f_language_match, *fs_triad.values()],  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logged app invocation\n",
    "\n",
    "Using `tru_rails` as a context manager means the invocations of the rail app\n",
    "will be logged and feedback will be evaluated on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rails as recorder:\n",
    "    res = rails.generate(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can I use AzureOpenAI to define a provider?\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(res[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard\n",
    "\n",
    "You should be able to view the above invocation in the dashboard. It can be\n",
    "started with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(tru, _dev=base, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback retrieval\n",
    "\n",
    "While feedback can be inspected on the dashboard, you can also retrieve its\n",
    "results in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the record from the above context manager.\n",
    "record = recorder.get()\n",
    "\n",
    "# Wait for the result futures to be completed and print them.\n",
    "for feedback, result in record.wait_for_feedback_results().items():\n",
    "    print(feedback.name, result.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App testing with Feedback\n",
    "\n",
    "Try out various other interactions to show off the capabilities of the feedback functions. For example, we can try to make the model answer in a different language than our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intended to produce low score on language match but seems random:\n",
    "with tru_rails as recorder:\n",
    "    res = rails.generate(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Please answer in Spanish: can I use AzureOpenAI to define a provider?\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(res[\"content\"])\n",
    "\n",
    "for feedback, result in recorder.get().wait_for_feedback_results().items():\n",
    "    print(feedback.name, result.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
