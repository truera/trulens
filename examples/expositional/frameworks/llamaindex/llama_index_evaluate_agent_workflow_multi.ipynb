{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing and Evaluating Multi-Agent Systems with TruLens and LlamaIndex AgentWorkflow\n",
    "\n",
    "In this notebook, we demonstrate how to use **TruLens** to trace, monitor, and evaluate multi-agent systems built with LlamaIndex's `AgentWorkflow`. \n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to instrument LlamaIndex `AgentWorkflow` with TruLens for comprehensive tracing\n",
    "- How to capture agent-level spans and tool calls in the TruLens dashboard\n",
    "- How to evaluate multi-agent system performance using TruLens feedback functions\n",
    "- How to monitor execution efficiency and logical consistency across agent handoffs\n",
    "\n",
    "## The Multi-Agent System\n",
    "\n",
    "We'll build a report generation system with three specialized agents:\n",
    "- **ResearchAgent**: Searches the web and records research notes\n",
    "- **WriteAgent**: Creates markdown reports based on research\n",
    "- **ReviewAgent**: Reviews and provides feedback on reports\n",
    "\n",
    "The key focus is on **observability and evaluation** - understanding how agents interact, where bottlenecks occur, and how to measure system performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This example requires several key components:\n",
    "\n",
    "- **TruLens**: For tracing, monitoring, and evaluating the multi-agent system\n",
    "- **LlamaIndex**: For the `AgentWorkflow` and agent implementations  \n",
    "- **OpenAI**: As the LLM provider for all agents\n",
    "- **Tavily**: For web search capabilities\n",
    "\n",
    "We'll use OpenAI's GPT-4 as our LLM across all agents for consistency. TruLens will capture every interaction, tool call, and agent handoff, providing complete visibility into the system's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index trulens-apps-llamaindex trulens-providers-openai tavily-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"tvly-dev-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Design & Tracing Architecture\n",
    "\n",
    "Our multi-agent system consists of three specialized agents that work together in a coordinated workflow:\n",
    "\n",
    "### Agent Roles\n",
    "1. **ResearchAgent**: Searches the web and records research notes\n",
    "2. **WriteAgent**: Creates markdown reports based on research findings  \n",
    "3. **ReviewAgent**: Reviews reports and provides feedback for improvements\n",
    "\n",
    "### Tools & Observability\n",
    "Each agent uses specific tools that TruLens will trace:\n",
    "- `web_search`: Web search queries and results\n",
    "- `record_notes`: Note-taking and knowledge storage\n",
    "- `write_report`: Report generation process\n",
    "- `review_report`: Review and feedback generation\n",
    "\n",
    "### What TruLens Captures\n",
    "With TruLens instrumentation, we'll observe:\n",
    "- **Agent-level spans**: Each agent's execution time and context\n",
    "- **Tool call traces**: Individual tool invocations and their results\n",
    "- **Agent handoffs**: When and why control passes between agents\n",
    "- **State transitions**: How the shared context evolves\n",
    "- **Performance metrics**: Execution efficiency and logical consistency\n",
    "\n",
    "The `Context` class enables state sharing between agents, and TruLens will track how this state evolves throughout the workflow execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import AsyncTavilyClient\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "\n",
    "async def search_web(query: str) -> str:\n",
    "    \"\"\"Useful for using the web to answer questions.\"\"\"\n",
    "    client = AsyncTavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    return str(await client.search(query))\n",
    "\n",
    "\n",
    "async def record_notes(ctx: Context, notes: str, notes_title: str) -> str:\n",
    "    \"\"\"Useful for recording notes on a given topic. Your input should be notes with a title to save the notes under.\"\"\"\n",
    "    async with ctx.store.edit_state() as ctx_state:\n",
    "        if \"research_notes\" not in ctx_state[\"state\"]:\n",
    "            ctx_state[\"state\"][\"research_notes\"] = {}\n",
    "        ctx_state[\"state\"][\"research_notes\"][notes_title] = notes\n",
    "    return \"Notes recorded.\"\n",
    "\n",
    "\n",
    "async def write_report(ctx: Context, report_content: str) -> str:\n",
    "    \"\"\"Useful for writing a report on a given topic. Your input should be a markdown formatted report.\"\"\"\n",
    "    async with ctx.store.edit_state() as ctx_state:\n",
    "        ctx_state[\"state\"][\"report_content\"] = report_content\n",
    "    return \"Report written.\"\n",
    "\n",
    "\n",
    "async def review_report(ctx: Context, review: str) -> str:\n",
    "    \"\"\"Useful for reviewing a report and providing feedback. Your input should be a review of the report.\"\"\"\n",
    "    async with ctx.store.edit_state() as ctx_state:\n",
    "        ctx_state[\"state\"][\"review\"] = review\n",
    "    return \"Report reviewed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Traceable Agents\n",
    "\n",
    "Now we'll create our three agents using LlamaIndex's `FunctionAgent` class. Each agent has:\n",
    "- **Unique names**: Essential for TruLens to distinguish agents in traces\n",
    "- **Clear descriptions**: Help with agent handoff decisions and trace clarity\n",
    "- **Specific tools**: Each tool call will appear as a distinct span in TruLens\n",
    "- **Handoff capabilities**: TruLens will track when and why agents transfer control\n",
    "\n",
    "The agent names (`ResearchAgent`, `WriteAgent`, `ReviewAgent`) will appear as span names in the TruLens dashboard, making it easy to follow the execution flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import FunctionAgent, ReActAgent\n",
    "\n",
    "research_agent = FunctionAgent(\n",
    "    name=\"ResearchAgent\",\n",
    "    description=\"Useful for searching the web for information on a given topic and recording notes on the topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ResearchAgent that can search the web for information on a given topic and record notes on the topic. \"\n",
    "        \"Once notes are recorded and you are satisfied, you should hand off control to the WriteAgent to write a report on the topic. \"\n",
    "        \"You should have at least some notes on a topic before handing off control to the WriteAgent.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[search_web, record_notes],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "write_agent = FunctionAgent(\n",
    "    name=\"WriteAgent\",\n",
    "    description=\"Useful for writing a report on a given topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the WriteAgent that can write a report on a given topic. \"\n",
    "        \"Your report should be in a markdown format. The content should be grounded in the research notes. \"\n",
    "        \"Once the report is written, you should get feedback at least once from the ReviewAgent.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[write_report],\n",
    "    can_handoff_to=[\"ReviewAgent\", \"ResearchAgent\"],\n",
    ")\n",
    "\n",
    "review_agent = FunctionAgent(\n",
    "    name=\"ReviewAgent\",\n",
    "    description=\"Useful for reviewing a report and providing feedback.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ReviewAgent that can review the write report and provide feedback. \"\n",
    "        \"Your review should either approve the current report or request changes for the WriteAgent to implement. \"\n",
    "        \"If you have feedback that requires changes, you should hand off control to the WriteAgent to implement the changes after submitting the review.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[review_report],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the AgentWorkflow\n",
    "\n",
    "With our agents defined, we create the `AgentWorkflow` that orchestrates their interactions. The workflow configuration includes:\n",
    "- **Agent list**: All participating agents\n",
    "- **Root agent**: The starting point (`ResearchAgent`)\n",
    "- **Initial state**: Shared context that TruLens will track as it evolves\n",
    "\n",
    "This workflow will be instrumented by TruLens to capture the complete execution trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "agent_workflow = AgentWorkflow(\n",
    "    agents=[research_agent, write_agent, review_agent],\n",
    "    root_agent=research_agent.name,\n",
    "    initial_state={\n",
    "        \"research_notes\": {},\n",
    "        \"report_content\": \"Not written yet.\",\n",
    "        \"review\": \"Review required.\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize TruLens for Tracing\n",
    "\n",
    "We start by initializing a TruLens session that will:\n",
    "- **Store all traces**: Every agent call, tool usage, and handoff\n",
    "- **Enable OTEL tracing**: Advanced OpenTelemetry-based instrumentation\n",
    "- **Prepare for evaluation**: Set up the infrastructure for feedback functions\n",
    "\n",
    "The database will capture detailed execution traces that we can analyze in the TruLens dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluation Metrics\n",
    "\n",
    "For multi-agent systems, we focus on evaluating:\n",
    "\n",
    "### Execution Efficiency\n",
    "- Measures how effectively the agents coordinate and complete tasks\n",
    "- Identifies bottlenecks and unnecessary steps in the workflow\n",
    "- Evaluates resource utilization across agent handoffs\n",
    "\n",
    "### Logical Consistency  \n",
    "- Ensures agents make coherent decisions throughout the workflow\n",
    "- Validates that handoffs occur at appropriate times\n",
    "- Checks that the final output aligns with the initial request\n",
    "\n",
    "These trace-level evaluations analyze the entire workflow execution, providing insights into system-wide performance rather than individual component behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Feedback\n",
    "from trulens.core.feedback.selector import Selector\n",
    "from trulens.providers.openai import OpenAI as OpenAIProvider\n",
    "\n",
    "llm_judge = OpenAIProvider(model_engine=\"gpt-4.1\")\n",
    "\n",
    "f_execution_efficiency = Feedback(\n",
    "    llm_judge.execution_efficiency_with_cot_reasons,\n",
    "    name=\"Execution Efficiency\",\n",
    ").on({\n",
    "    \"trace\": Selector(trace_level=True),\n",
    "})\n",
    "\n",
    "f_logical_consistency = Feedback(\n",
    "    llm_judge.logical_consistency_with_cot_reasons,\n",
    "    name=\"Logical Consistency\",\n",
    ").on({\n",
    "    \"trace\": Selector(trace_level=True),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument the Workflow with TruLens\n",
    "\n",
    "Now we wrap our `AgentWorkflow` with `TruLlamaWorkflow` to enable comprehensive tracing:\n",
    "\n",
    "- **Automatic instrumentation**: Captures all agent calls and tool usage\n",
    "- **Agent-level spans**: Each agent execution appears as a distinct trace segment  \n",
    "- **Tool call tracking**: Individual tool invocations are traced with inputs/outputs\n",
    "- **Evaluation integration**: Feedback functions run automatically on each trace\n",
    "\n",
    "The instrumentation happens transparently - no changes needed to your workflow code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.llamaindex import TruLlamaWorkflow\n",
    "\n",
    "tru_workflow_recorder = TruLlamaWorkflow(\n",
    "    agent_workflow,\n",
    "    app_name=\"AgentWorkflow\",\n",
    "    app_version=\"base\",\n",
    "    main_method=agent_workflow.run,\n",
    "    feedbacks=[f_execution_efficiency, f_logical_consistency],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute and Trace the Workflow\n",
    "\n",
    "Now we run the workflow within a TruLens recording context. This will capture:\n",
    "\n",
    "- **Complete execution trace**: Every agent call, tool usage, and state change\n",
    "- **Timing information**: How long each agent and tool takes to execute  \n",
    "- **Input/output data**: What each agent receives and produces\n",
    "- **Agent handoffs**: When and why control transfers between agents\n",
    "- **Evaluation scores**: Automatic assessment of execution efficiency and logical consistency\n",
    "\n",
    "The workflow will execute normally while TruLens captures everything in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_workflow_recorder as recording:\n",
    "    # For TruLens recording, we need to use the regular run method and await the result\n",
    "    result = await agent_workflow.run(\n",
    "        user_msg=(\n",
    "            \"Write me a report on the history of the internet. \"\n",
    "            \"Briefly describe the history of the internet, including the development of the internet, the development of the web, \"\n",
    "            \"and the development of the internet in the 21st century.\"\n",
    "        )\n",
    "    )\n",
    "    print(\"✅ Workflow completed successfully!\")\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(result.response.blocks[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results in TruLens Dashboard\n",
    "\n",
    "Launch the TruLens dashboard to explore your multi-agent system's behavior:\n",
    "\n",
    "### What You'll See\n",
    "- **Trace Timeline**: Visual representation of agent execution and handoffs\n",
    "- **Agent Spans**: Individual agent executions with timing and context\n",
    "- **Tool Call Details**: Each tool invocation with inputs, outputs, and duration\n",
    "- **Evaluation Scores**: Execution efficiency and logical consistency metrics\n",
    "- **Performance Insights**: Bottlenecks, optimization opportunities, and system health\n",
    "\n",
    "### Key Metrics to Monitor\n",
    "- **Agent utilization**: Which agents are most/least active\n",
    "- **Handoff patterns**: How control flows between agents\n",
    "- **Tool effectiveness**: Which tools provide the most value\n",
    "- **Execution bottlenecks**: Where the system spends the most time\n",
    "\n",
    "💡 **Tip**: Evaluations may take a few moments to compute. Refresh the dashboard to see updated results as they become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
