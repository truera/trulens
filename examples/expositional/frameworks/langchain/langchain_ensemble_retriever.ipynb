{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _LangChain_ Ensemble Retriever\n",
    "\n",
    "The _LangChain_ `EnsembleRetriever` takes a list of retrievers as input and ensemble the results of their `get_relevant_documents()` methods and rerank the results based on the [Reciprocal Rank Fusion (RRF) algorithm](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf). With TruLens, we have the ability to evaluate the context of each component retriever along with the ensemble retriever, compare performance, and track context relevance across all retrievers. This example walks through that process.\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/frameworks/langchain/langchain_ensemble_retriever.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens trulens-apps-langchain trulens-providers-openai openai langchain langchain_community langchain_openai rank_bm25 faiss_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports main tools:\n",
    "# Imports from LangChain to build app\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from trulens.apps.langchain import TruChain\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"JavaScript is mainly used for web development.\",\n",
    "    \"C++ is known for its performance in system programming.\",\n",
    "    \"The snake is a reptile found in many parts of the world.\",  # Lexical distractor\n",
    "    \"Web pages are often made interactive with JS.\",  # Paraphrase\n",
    "    \"Many developers love coding in Python due to its simplicity.\",  # Paraphrase\n",
    "    \"A 500 error code indicates an internal server error.\",\n",
    "    \"Internal server errors occur for a variety of reasons, including a bug in the code or a configuration error.\",\n",
    "]\n",
    "# initialize the bm25 retriever and faiss retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k = 1\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "faiss_vectorstore = FAISS.from_texts(doc_list, embedding)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Context Relevance checks for each component retriever + ensemble\n",
    "\n",
    "This requires knowing the feedback selector for each retriever. You can find this path by logging a run of your application and examining the application traces on the Evaluations page.\n",
    "\n",
    "Read more in our docs: [Selecting Components](https://www.trulens.org/component_guides/evaluation/feedback_selectors/selecting_components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core.feedback.selector import Selector\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "bm25_context = Selector(\n",
    "    function_name=\"langchain_community.retrievers.bm25.BM25Retriever._get_relevant_documents\",\n",
    "    span_attribute=SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS,\n",
    "    collect_list=False,\n",
    ")\n",
    "faiss_context = Selector(\n",
    "    function_name=\"langchain_core.vectorstores.base.VectorStoreRetriever._get_relevant_documents\",\n",
    "    span_attribute=SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS,\n",
    "    collect_list=False,\n",
    ")\n",
    "ensemble_context = Selector(\n",
    "    span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "    span_attribute=SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS,\n",
    "    collect_list=False,\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance_bm25 = (\n",
    "    Feedback(openai.context_relevance, name=\"BM25\")\n",
    "    .on_input()\n",
    "    .on({\"context\": bm25_context})\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_context_relevance_faiss = (\n",
    "    Feedback(openai.context_relevance, name=\"FAISS\")\n",
    "    .on_input()\n",
    "    .on({\"context\": faiss_context})\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_context_relevance_ensemble = (\n",
    "    Feedback(openai.context_relevance, name=\"Ensemble\")\n",
    "    .on_input()\n",
    "    .on({\"context\": ensemble_context})\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(\n",
    "    ensemble_retriever,\n",
    "    app_name=\"Ensemble Retriever\",\n",
    "    feedbacks=[\n",
    "        f_context_relevance_bm25,\n",
    "        f_context_relevance_faiss,\n",
    "        f_context_relevance_ensemble,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Internal server error code?\",\n",
    "    \"A limbless animal that slithers and is widespread.\",  # Should match snake (semantic only)\n",
    "    \"Which language is preferred for low-level, high-speed applications?\",  # Should match C++ (semantic only)\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\n",
    "        \"BM25:\",\n",
    "        [d.page_content for d in bm25_retriever.get_relevant_documents(query)],\n",
    "    )\n",
    "    print(\n",
    "        \"FAISS:\",\n",
    "        [d.page_content for d in faiss_retriever.get_relevant_documents(query)],\n",
    "    )\n",
    "    print(\n",
    "        \"Ensemble:\",\n",
    "        [\n",
    "            d.page_content\n",
    "            for d in ensemble_retriever.get_relevant_documents(query)\n",
    "        ],\n",
    "    )\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)  # open a local streamlit app to explore\n",
    "\n",
    "# stop_dashboard(session) # stop if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can run `trulens` from the CLI in the same folder to start the dashboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_rag_stack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
