{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _LangChain_ Async\n",
    "\n",
    "This notebook demonstrates how to monitor a _LangChain_ async apps. Note that this notebook does not demonstrate streaming. See `langchain_stream.ipynb` for that.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/frameworks/langchain/langchain_async.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from LangChain and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens trulens.apps.langchain trulens-providers-huggingface 'langchain>=0.2.16' 'langchain-openai>=0.0.1rc0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from trulens.core import Feedback, TruSession\n",
    "from trulens.providers.huggingface import Huggingface\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Add API keys\n",
    "For this example you will need Huggingface and OpenAI keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"hf_...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Async Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    ")\n",
    "llm = OpenAI(\n",
    "    temperature=0.0,\n",
    ")\n",
    "memory = ChatMessageHistory()\n",
    "\n",
    "# Setup a simple question/answer chain with streaming ChatOpenAI.\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"human_input\", \"chat_history\"],\n",
    "    template=\"\"\"\n",
    "    You are having a conversation with a person. Make small talk.\n",
    "    {chat_history}\n",
    "        Human: {human_input}\n",
    "        AI:\"\"\",\n",
    ")\n",
    "\n",
    "chain = RunnableWithMessageHistory(\n",
    "    prompt | chatllm,\n",
    "    lambda: memory, \n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a language match feedback function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = TruSession()\n",
    "session.reset_database()\n",
    "hugs = Huggingface()\n",
    "f_lang_match = Feedback(hugs.language_match).on_input_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up evaluation and tracking with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to also get filled-in prompt templates in timeline:\n",
    "from trulens.core.instruments import instrument\n",
    "from trulens.apps.langchain import TruChain\n",
    "\n",
    "instrument.method(PromptTemplate, \"format\")\n",
    "\n",
    "tc = TruChain(chain, feedbacks=[f_lang_match], app_name=\"chat_with_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.print_instrumented()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the TruLens dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "run_dashboard(session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Hi. How are you?\"\n",
    "\n",
    "async with tc as recording:\n",
    "    response = await chain.ainvoke(\n",
    "        input=dict(human_input=message, chat_history=[]),\n",
    "    )\n",
    "\n",
    "record = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the main output:\n",
    "\n",
    "record.main_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check costs:\n",
    "\n",
    "record.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feedback:\n",
    "\n",
    "record.feedback_results[0].result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d153714b979d5e6d08dd8ec90712dd93bff2c9b6c1f0c118169738af3430cd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
