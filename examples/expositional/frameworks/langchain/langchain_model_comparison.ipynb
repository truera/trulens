{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Comparison\n",
    "\n",
    "When building an LLM application we have hundreds of different models to choose from, all with different costs/latency and performance characteristics. Importantly, performance of LLMs can be heterogeneous across different use cases. Rather than relying on standard benchmarks or leaderboard performance, we want to evaluate an LLM for the use case we need.\n",
    "\n",
    "Doing this sort of comparison is a core use case of TruLens. In this example, we'll walk through how to build a simple langchain app and evaluate across 3 different models: small flan, large flan and text-turbo-3.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/frameworks/langchain/langchain_model_comparison.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens trulens-providers-huggingface trulens-providers-openai langchain==0.0.283 langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Imports from langchain to build app. You may need to install langchain first\n",
    "# with the following:\n",
    "# !pip install langchain>=0.0.170\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Imports main tools:\n",
    "# Imports main tools:\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import TruSession\n",
    "from trulens.apps.langchain import TruChain\n",
    "from trulens.providers.huggingface import Huggingface\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "session = TruSession()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set API Keys\n",
    "\n",
    "For this example, we need API keys for the Huggingface, HuggingFaceHub, and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoints for models used in feedback functions:\n",
    "hugs = Huggingface()\n",
    "openai = OpenAI()\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# By default this will evaluate feedback on main app input and main app output.\n",
    "\n",
    "all_feedbacks = [f_qa_relevance]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a couple sizes of Flan and ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain import LLMChain\n",
    "\n",
    "# initialize the models\n",
    "hub_llm_smallflan = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-small\", model_kwargs={\"temperature\": 1e-10}\n",
    ")\n",
    "\n",
    "hub_llm_largeflan = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 1e-10}\n",
    ")\n",
    "\n",
    "davinci = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "# create prompt template > LLM chain\n",
    "smallflan_chain = LLMChain(prompt=prompt, llm=hub_llm_smallflan)\n",
    "\n",
    "largeflan_chain = LLMChain(prompt=prompt, llm=hub_llm_largeflan)\n",
    "\n",
    "davinci_chain = LLMChain(prompt=prompt, llm=davinci)\n",
    "\n",
    "# Trulens instrumentation.\n",
    "smallflan_app_recorder = TruChain(\n",
    "    app_name=\"small_flan\", app_version=\"v1\", app=smallflan_chain, feedbacks=all_feedbacks\n",
    ")\n",
    "\n",
    "largeflan_app_recorder = TruChain(\n",
    "    app_name=\"large_flan\", app_version=\"v1\", app=largeflan_chain, feedbacks=all_feedbacks\n",
    ")\n",
    "\n",
    "davinci_app_recorder = TruChain(\n",
    "    app_name=\"davinci\", app_version=\"v1\", app=davinci_chain, feedbacks=all_feedbacks\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the application with all 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Who won the superbowl in 2010?\",\n",
    "    \"What is the capital of Thailand?\",\n",
    "    \"Who developed the theory of evolution by natural selection?\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    with smallflan_app_recorder as recording:\n",
    "        smallflan_chain(prompt)\n",
    "    with largeflan_app_recorder as recording:\n",
    "        largeflan_chain(prompt)\n",
    "    with davinci_app_recorder as recording:\n",
    "        davinci_chain(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the TruLens dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d153714b979d5e6d08dd8ec90712dd93bff2c9b6c1f0c118169738af3430cd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
