{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cortex Chat + TruLens\n",
    "\n",
    "This quickstart assumes you already have a [Cortex Search Service](https://docs.snowflake.com/user-guide/snowflake-cortex/cortex-search/cortex-search-overview) started, [JWT token created](https://community.snowflake.com/s/article/How-To-Use-SnowSQL-to-generate-JWT-Token-for-Key-Pair-Authentication-Mechanism) and Cortex Chat Private Preview enabled for your account. If you need assistance getting started with Cortex Chat, or having Cortex Chat Private Preview enabled please contact your Snowflake account contact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install trulens-core trulens-providers-cortex trulens-connectors-snowflake snowflake-sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set JWT Token, Chat URL, and Search Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SNOWFLAKE_JWT\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_CHAT_URL\"] = \".../api/v2/cortex/chat\"\n",
    "os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE\"] = \"<database>.<schema>.<cortex search service name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Cortex Chat App\n",
    "\n",
    "The `CortexChat` class below can be configured with your URL and model selection.\n",
    "\n",
    "It contains two methods: `handle_cortex_chat_response`, and `chat`.\n",
    "- `_handle_cortex_chat_response` serves to handle the streaming response, and expose the debugging information.\n",
    "- `chat` is a user-facing method that allows you to input a `query` and receive a `response` and `citation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from trulens.apps.custom import instrument\n",
    "\n",
    "class CortexChat:\n",
    "    def __init__(self, url: str, cortex_search_service: str, model: str = \"mistral-large\"):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the CortexChat class.\n",
    "        Parameters:\n",
    "            url (str): The URL of the chat service.\n",
    "            model (str): The model to be used for chat. Defaults to \"mistral-large\".\n",
    "            cortex_search_service (str): The search service to be used for chat.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "        self.cortex_search_service = cortex_search_service\n",
    "\n",
    "    @instrument\n",
    "    def _handle_cortex_chat_response(self, response: requests.Response) -> tuple[str, str, str]:\n",
    "        \"\"\"\n",
    "        Process the response from the Cortex Chat API.\n",
    "        Args:\n",
    "            response: The response object from the Cortex Chat API.\n",
    "        Returns:\n",
    "            A tuple containing the extracted text, citation, and debug information from the response.\n",
    "        \"\"\"\n",
    "\n",
    "        text = \"\"\n",
    "        citation = \"\"\n",
    "        debug_info = \"\"\n",
    "        previous_line = \"\"\n",
    "        \n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                decoded_line = line.decode('utf-8')\n",
    "                if decoded_line.startswith(\"event: done\"):\n",
    "                    if debug_info == \"\":\n",
    "                        raise Exception(\"No debug information, required for TruLens feedback, provided by Cortex Chat API.\")\n",
    "                    return text, citation, debug_info\n",
    "                if previous_line.startswith(\"event: error\"):\n",
    "                    error_data = json.loads(decoded_line[5:])\n",
    "                    error_code = error_data[\"code\"]\n",
    "                    error_message = error_data[\"message\"]\n",
    "                    raise Exception(f\"Error event received from Cortex Chat API. Error code: {error_code}, Error message: {error_message}\")\n",
    "                else:\n",
    "                    if decoded_line.startswith('data:'):\n",
    "                        try:\n",
    "                            data = json.loads(decoded_line[5:])\n",
    "                            if data['delta']['content'][0]['type'] == \"text\":\n",
    "                                print(data['delta']['content'][0]['text']['value'], end = '')\n",
    "                                text += data['delta']['content'][0]['text']['value']\n",
    "                            if data['delta']['content'][0]['type'] == \"citation\":\n",
    "                                citation = data['delta']['content'][0]['citation']\n",
    "                            if data['delta']['content'][0]['type'] == \"debug_info\":\n",
    "                                debug_info = data['delta']['content'][0]['debug_info']\n",
    "                        except json.JSONDecodeError:\n",
    "                            raise Exception(f\"Error decoding JSON: {decoded_line} from {previous_line}\")\n",
    "                    previous_line = decoded_line\n",
    "\n",
    "    @instrument           \n",
    "    def chat(self, query: str) -> tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Sends a chat query to the Cortex Chat API and returns the response.\n",
    "        Args:\n",
    "            query (str): The chat query to send.\n",
    "        Returns:\n",
    "            tuple: A tuple containing the text response and citation.\n",
    "        Raises:\n",
    "            None\n",
    "        Example:\n",
    "            cortex = CortexChat()\n",
    "            response = cortex.chat(\"Hello, how are you?\")\n",
    "            print(response)\n",
    "            (\"I'm good, thank you!\", \"Cortex Chat API v1.0\")\n",
    "        \"\"\"\n",
    "\n",
    "        url = self.url\n",
    "        headers = {\n",
    "            'X-Snowflake-Authorization-Token-Type': 'KEYPAIR_JWT',\n",
    "            'Content-Type': 'application/json',\n",
    "            'Accept': 'application/json',\n",
    "            'Authorization': f\"Bearer {os.environ.get('SNOWFLAKE_JWT')}\"\n",
    "        }\n",
    "        data = {\n",
    "            \"query\": query,\n",
    "            \"model\": self.model,\n",
    "            \"debug\": True,\n",
    "            \"search_services\": [{\n",
    "                \"name\": self.cortex_search_service,\n",
    "                \"max_results\": 10,\n",
    "            }],\n",
    "            \"prompt\": \"{{.Question}} {{.Context}}\",\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            text, citation, _ = self._handle_cortex_chat_response(response)\n",
    "            return text, citation\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "cortex = CortexChat(os.environ[\"SNOWFLAKE_CHAT_URL\"], os.environ[\"SNOWFLAKE_SEARCH_SERVICE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a TruLens session\n",
    "\n",
    "Start a TruLens session connected to Snowflake so we can log traces and evaluations in our Snowflake account.\n",
    "\n",
    "Learn more about how to [log in Snowflake](https://www.trulens.org/trulens/tracking/logging/where_to_log/log_in_snowflake/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruSession\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "connection_params = {\n",
    "    \"account\": \"...\",\n",
    "    \"user\": \"...\",\n",
    "    \"password\": \"...\",\n",
    "    \"database\": \"...\",\n",
    "    \"schema\": \"...\",\n",
    "    \"warehouse\": \"...\",\n",
    "    \"role\": \"...\",\n",
    "    \"init_server_side\": False,\n",
    "}\n",
    "\n",
    "connector = SnowflakeConnector(**connection_params)\n",
    "session = TruSession(connector=connector)\n",
    "\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feedback Functions\n",
    "\n",
    "Here we initialize the [RAG Triad](https://www.trulens.org/trulens/getting_started/core_concepts/rag_triad/) to provide feedback on the Chat API responses.\n",
    "\n",
    "If you'd like, you can also choose from a wide variety of [stock feedback functions](https://www.trulens.org/trulens/evaluation/feedback_implementations/stock/) or even create [custom feedback functions](https://www.trulens.org/trulens/evaluation/feedback_implementations/custom_feedback_functions/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.cortex import Cortex\n",
    "from snowflake.snowpark.session import Session\n",
    "\n",
    "snowpark_session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "provider = Cortex(snowpark_session, \"llama3.1-8b\")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(Select.RecordCalls._handle_cortex_chat_response.rets[2][\"retrieved_results\"].collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls._handle_cortex_chat_response.rets[2][\"retrieved_results\"][:])\n",
    "    .aggregate(np.mean)  # choose a different aggregation method if you wish\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the TruLens recorder and run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "tru_recorder = TruCustomApp(\n",
    "    cortex,\n",
    "    app_name=\"Cortex Chat\",\n",
    "    app_version=\"mistral-large\",\n",
    "    feedbacks=[f_answer_relevance, f_groundedness, f_context_relevance],\n",
    ")\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    # Example usage\n",
    "    user_query = \"Hello! What kind of service does Gregory have?\"\n",
    "    cortex.chat(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_trulens_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
