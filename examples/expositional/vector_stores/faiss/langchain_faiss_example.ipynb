{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain with FAISS Vector DB\n",
    "\n",
    "Example by Joselin James. Example was adapted to use README.md as the source of documents in the DB."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra packages may be necessary:\n",
    "# !pip install --pre trulens trulens-instrument-langchain faiss-cpu unstructured==0.10.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "import nltk\n",
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.core import Tru\n",
    "from trulens.instrument.langchain import TruChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local FAISS Vector DB based on README.md .\n",
    "loader = UnstructuredMarkdownLoader(\"README.md\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Save it.\n",
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreRetrieverWithScore(VectorStoreRetriever):\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        if self.search_type == \"similarity\":\n",
    "            docs_and_scores = (\n",
    "                self.vectorstore.similarity_search_with_relevance_scores(\n",
    "                    query, **self.search_kwargs\n",
    "                )\n",
    "            )\n",
    "\n",
    "            print(\"From relevant doc in vec store\")\n",
    "            docs = []\n",
    "            for doc, score in docs_and_scores:\n",
    "                if score > 0.6:\n",
    "                    doc.metadata[\"score\"] = score\n",
    "                    docs.append(doc)\n",
    "        elif self.search_type == \"mmr\":\n",
    "            docs = self.vectorstore.max_marginal_relevance_search(\n",
    "                query, **self.search_kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"search_type of {self.search_type} not allowed.\")\n",
    "        return docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the example app.\n",
    "class FAISSWithScore(FAISS):\n",
    "    def as_retriever(self) -> VectorStoreRetrieverWithScore:\n",
    "        return VectorStoreRetrieverWithScore(\n",
    "            vectorstore=self,\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 4},\n",
    "        )\n",
    "\n",
    "\n",
    "class FAISSStore:\n",
    "    @staticmethod\n",
    "    def load_vector_store():\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        faiss_store = FAISSWithScore.load_local(\n",
    "            \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
    "        )\n",
    "        print(\"Faiss vector DB loaded\")\n",
    "        return faiss_store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "# Create a feedback function.\n",
    "openai = OpenAI()\n",
    "\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.context_relevance, name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(\n",
    "        Select.Record.app.combine_docs_chain._call.args.inputs.input_documents[\n",
    "            :\n",
    "        ].page_content\n",
    "    )\n",
    "    .aggregate(np.min)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring it all together.\n",
    "def load_conversational_chain(vector_store):\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model_name=\"gpt-4\",\n",
    "    )\n",
    "    retriever = vector_store.as_retriever()\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm, retriever, return_source_documents=True\n",
    "    )\n",
    "\n",
    "    truchain = TruChain(chain, feedbacks=[f_context_relevance], with_hugs=False)\n",
    "\n",
    "    return chain, truchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run example:\n",
    "vector_store = FAISSStore.load_vector_store()\n",
    "chain, tru_chain_recorder = load_conversational_chain(vector_store)\n",
    "\n",
    "with tru_chain_recorder as recording:\n",
    "    ret = chain({\"question\": \"What is trulens?\", \"chat_history\": \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result.\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that components of the app have been instrumented despite various\n",
    "# subclasses used.\n",
    "tru_chain_recorder.print_instrumented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start dashboard to inspect records.\n",
    "Tru().run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
