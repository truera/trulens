{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB Atlas Quickstart\n",
    "\n",
    "[MongoDB Atlas Vector Search](https://www.mongodb.com/products/platform/atlas-vector-search) is part of the MongoDB platform that enables MongoDB customers to build intelligent applications powered by semantic search over any type of data. Atlas Vector Search allows you to integrate your operational database and vector search in a single, unified, fully managed platform with full vector database capabilities.\n",
    "\n",
    "You can integrate TruLens with your application built on Atlas Vector Search to leverage observability and measure improvements in your application's search capabilities.\n",
    "\n",
    "This tutorial will walk you through the process of setting up TruLens with MongoDB Atlas Vector Search and Llama-Index as the orchestrator.\n",
    "\n",
    "Even better, you'll learn how to use metadata filters to create specialized query engines and leverage a router to choose the most appropriate query engine based on the query.\n",
    "\n",
    "See [MongoDB Atlas/LlamaIndex Quickstart](https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/llamaindex/) for more details.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/vector_stores/mongodb_atlas/atlas_quickstart.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens trulens-apps-llamaindex trulens-providers-openai llama-index llama-index-vector-stores-mongodb llama-index-embeddings-openai pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TruLens and start the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruSession\n",
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()\n",
    "run_dashboard(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set imports, keys and llama-index settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.vector_stores import ExactMatchFilter\n",
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.vector_stores.mongodb import MongoDBAtlasVectorSearch\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "ATLAS_CONNECTION_STRING = (\n",
    "    \"mongodb+srv://<username>:<password>@<clusterName>.<hostname>.mongodb.net\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI()\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "Settings.chunk_size = 100\n",
    "Settings.chunk_overlap = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample data\n",
    "\n",
    "Here we'll load two PDFs: one for Atlas best practices and one textbook on database essentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample data\n",
    "!mkdir -p 'data/'\n",
    "!wget 'https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4HkJP' -O 'data/atlas_best_practices.pdf'\n",
    "atlas_best_practices = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/atlas_best_practices.pdf\"]\n",
    ").load_data()\n",
    "\n",
    "!wget 'http://fondamentidibasididati.it/wp-content/uploads/2020/11/DBEssential-2021-C30-11-21.pdf' -O 'data/DBEssential-2021.pdf'\n",
    "db_essentials = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/DBEssential-2021.pdf\"]\n",
    ").load_data()\n",
    "\n",
    "!wget 'https://courses.edx.org/asset-v1:Databricks+LLM101x+2T2023+type@asset+block@Module_2_slides.pdf' -O 'data/DataBrick_vector_search.pdf'\n",
    "databrick_vector_search = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/DataBrick_vector_search.pdf\"]\n",
    ").load_data()\n",
    "\n",
    "documents = atlas_best_practices + db_essentials + databrick_vector_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector store\n",
    "\n",
    "Next you need to create an Atlas Vector Search Index.\n",
    "\n",
    "When you do so, use the following in the json editor:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"numDimensions\": 1536,\n",
    "      \"path\": \"embedding\",\n",
    "      \"similarity\": \"cosine\",\n",
    "      \"type\": \"vector\"\n",
    "    },\n",
    "    {\n",
    "      \"path\": \"metadata.file_name\",\n",
    "      \"type\": \"filter\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your Atlas cluster\n",
    "mongodb_client = pymongo.MongoClient(ATLAS_CONNECTION_STRING)\n",
    "\n",
    "# Instantiate the vector store\n",
    "atlas_vector_search = MongoDBAtlasVectorSearch(\n",
    "    mongodb_client,\n",
    "    db_name=\"atlas-quickstart-demo\",\n",
    "    collection_name=\"test\",\n",
    "    index_name=\"vector_index\",\n",
    ")\n",
    "vector_store_context = StorageContext.from_defaults(\n",
    "    vector_store=atlas_vector_search\n",
    ")\n",
    "\n",
    "# load both documents into the vector store\n",
    "vector_store_index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=vector_store_context, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_store_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.providers.openai import OpenAI\n",
    "from trulens.apps.llamaindex import TruLlama\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "context = TruLlama.select_context(query_engine)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(context.collect())  # collect context chunks into a list\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    ").on_input_output()\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_query_engine_recorder = TruLlama(\n",
    "    query_engine,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"Basic RAG\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write test cases\n",
    "\n",
    "Let's write a few test queries to test the ability of our RAG to answer questions on both documents in the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = {\n",
    "    \"MongoDB Atlas\": [\n",
    "        \"How do you secure MongoDB Atlas?\",\n",
    "        \"How can Time to Live (TTL) be used to expire data in MongoDB Atlas?\",\n",
    "        \"What is vector search index in Mongo Atlas?\",\n",
    "        \"How does MongoDB Atlas different from relational DB in terms of data modeling\",\n",
    "    ],\n",
    "    \"Database Essentials\": [\n",
    "        \"What is the impact of interleaving transactions in database operations?\",\n",
    "        \"What is vector search index? how is it related to semantic search?\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatively, we can generate test set automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = GenerateTestSet(app_callable = query_engine.query)\n",
    "# Generate the test set of a specified breadth and depth without examples automatically\n",
    "from trulens.benchmark.generate.generate_test_set import GenerateTestSet\n",
    "test = GenerateTestSet(app_callable=query_engine.query)\n",
    "test_set_autogenerated = test.generate_test_set(test_breadth=3, test_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get testing!\n",
    "\n",
    "Our test set is made up of 2 topics (test breadth), each with 2-3 questions (test depth).\n",
    "\n",
    "We can store the topic as record level metadata and then test queries from each topic, using `tru_query_engine_recorder` as a context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_query_engine_recorder as recording:\n",
    "    for category in test_set:\n",
    "        recording.record_metadata = dict(prompt_category=category)\n",
    "        test_prompts = test_set[category]\n",
    "        for test_prompt in test_prompts:\n",
    "            response = query_engine.query(test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check evaluation results\n",
    "\n",
    "Evaluation results can be viewed in the TruLens dashboard (started at the top of the notebook) or directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps if we use metadata filters to create specialized query engines, we can improve the search results and thus, the overall evaluation results.\n",
    "\n",
    "But it may be clunky to have two separate query engines - then we have to decide which one to use!\n",
    "\n",
    "Instead, let's use a router query engine to choose the query engine based on the query.\n",
    "\n",
    "## Router Query Engine + Metadata Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify metadata filters\n",
    "metadata_filters_db_essentials = MetadataFilters(\n",
    "    filters=[\n",
    "        ExactMatchFilter(key=\"metadata.file_name\", value=\"DBEssential-2021.pdf\")\n",
    "    ]\n",
    ")\n",
    "metadata_filters_atlas = MetadataFilters(\n",
    "    filters=[\n",
    "        ExactMatchFilter(\n",
    "            key=\"metadata.file_name\", value=\"atlas_best_practices.pdf\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "metadata_filters_databrick = MetadataFilters(\n",
    "    filters=[\n",
    "        ExactMatchFilter(\n",
    "            key=\"metadata.file_name\", value=\"DataBrick_vector_search.pdf\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "# Instantiate Atlas Vector Search as a retriever for each set of filters\n",
    "vector_store_retriever_db_essentials = VectorIndexRetriever(\n",
    "    index=vector_store_index,\n",
    "    filters=metadata_filters_db_essentials,\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "vector_store_retriever_atlas = VectorIndexRetriever(\n",
    "    index=vector_store_index, filters=metadata_filters_atlas, similarity_top_k=5\n",
    ")\n",
    "vector_store_retriever_databrick = VectorIndexRetriever(\n",
    "    index=vector_store_index,\n",
    "    filters=metadata_filters_databrick,\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "# Pass the retrievers into the query engines\n",
    "query_engine_with_filters_db_essentials = RetrieverQueryEngine(\n",
    "    retriever=vector_store_retriever_db_essentials\n",
    ")\n",
    "query_engine_with_filters_atlas = RetrieverQueryEngine(\n",
    "    retriever=vector_store_retriever_atlas\n",
    ")\n",
    "query_engine_with_filters_databrick = RetrieverQueryEngine(\n",
    "    retriever=vector_store_retriever_databrick\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "# Set up the two distinct tools (query engines)\n",
    "\n",
    "essentials_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine_with_filters_db_essentials,\n",
    "    description=(\"Useful for retrieving context about database essentials\"),\n",
    ")\n",
    "\n",
    "atlas_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine_with_filters_atlas,\n",
    "    description=(\"Useful for retrieving context about MongoDB Atlas\"),\n",
    ")\n",
    "\n",
    "databrick_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine_with_filters_databrick,\n",
    "    description=(\n",
    "        \"Useful for retrieving context about Databrick's course on Vector Databases and Search\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the router query engine\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import PydanticSingleSelector\n",
    "\n",
    "router_query_engine = RouterQueryEngine(\n",
    "    selector=PydanticSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[essentials_tool, atlas_tool, databrick_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.llamaindex import TruLlama\n",
    "\n",
    "tru_query_engine_recorder_with_router = TruLlama(\n",
    "    router_query_engine,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"Router Query Engine + Filters v2\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_query_engine_recorder_with_router as recording:\n",
    "    for category in test_set:\n",
    "        recording.record_metadata = dict(prompt_category=category)\n",
    "        test_prompts = test_set[category]\n",
    "        for test_prompt in test_prompts:\n",
    "            response = router_query_engine.query(test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens_dev_empty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
