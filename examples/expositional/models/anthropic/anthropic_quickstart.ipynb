{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Quickstart\n",
    "\n",
    "Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems. Through our LiteLLM integration, you are able to easily run feedback functions with Anthropic's Claude and Claude Instant.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/models/anthropic_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --pre trulens anthropic trulens-providers-litellm langchain==0.0.347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AI_PROMPT\n",
    "from anthropic import HUMAN_PROMPT\n",
    "from anthropic import Anthropic\n",
    "\n",
    "anthropic = Anthropic()\n",
    "\n",
    "\n",
    "def claude_2_app(prompt):\n",
    "    completion = anthropic.completions.create(\n",
    "        model=\"claude-2\",\n",
    "        max_tokens_to_sample=300,\n",
    "        prompt=f\"{HUMAN_PROMPT} {prompt} {AI_PROMPT}\",\n",
    "    ).completion\n",
    "    return completion\n",
    "\n",
    "\n",
    "claude_2_app(\"How does a case reach the supreme court?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Feedback\n",
    "from trulens.providers.litellm import LiteLLM\n",
    "\n",
    "# Initialize Huggingface-based feedback function collection class:\n",
    "claude_2 = LiteLLM(model_engine=\"claude-2\")\n",
    "\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_relevance = Feedback(claude_2.relevance).on_input_output()\n",
    "# By default this will check language match on the main app input and main app\n",
    "# output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruBasicApp\n",
    "\n",
    "tru_recorder = TruBasicApp(\n",
    "    claude_2_app, app_id=\"Anthropic Claude 2\", feedbacks=[f_relevance]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = tru_recorder.app(\n",
    "        \"How does a case make it to the supreme court?\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(tru)  # open a local streamlit app to explore\n",
    "\n",
    "# stop_dashboard(tru) # stop if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or view results directly in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_records_and_feedback(app_ids=[])[\n",
    "    0\n",
    "]  # pass an empty list of app_ids to get all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('bedrock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbd8bda268d97161c416082acfe7f3544f1ce04ec31d1cf6cbb43b1d95b363a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
