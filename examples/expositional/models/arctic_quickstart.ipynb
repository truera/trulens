{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â„ï¸ Snowflake Arctic Quickstart with Cortex LLM Functions\n",
    "\n",
    "In this quickstart you will learn build and evaluate a RAG application with Snowflake Arctic.\n",
    "\n",
    "Building and evaluating RAG applications with Snowflake Arctic offers developers a unique opportunity to leverage a top-tier, enterprise-focused LLM that is both cost-effective and open-source. Arctic excels in enterprise tasks like SQL generation and coding, providing a robust foundation for developing intelligent applications with significant cost savings. [Learn more about Snowflake Arctic](https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/)\n",
    "\n",
    "In this example, we will use Arctic Embed (`snowflake-arctic-embed-m`) as our embedding model via HuggingFace, and Arctic, a 480B hybrid MoE LLM for both generation and as the LLM to power TruLens feedback functions. The Arctic LLM is fully-mananaged by [Cortex LLM functions](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions)\n",
    "\n",
    "Note, you'll need to have an [active Snowflake account](https://signup.snowflake.com/\n",
    ") to run Cortex LLM functions from Snowflake's data warehouse.\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/models/arctic_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval chromadb sentence-transformers snowflake-snowpark-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SNOWFLAKE_ACCOUNT\"] = \"xxx-xxx\" # xxx-xxx.snowflakecomputing.com\n",
    "os.environ[\"SNOWFLAKE_USER\"] = \"...\" \n",
    "os.environ[\"SNOWFLAKE_USER_PASSWORD\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package json not present in requirements.\n",
      "No .env found in /Users/dhuang/Documents/git/trulens/trulens_eval/examples/expositional/models or its parents. You may need to specify secret keys in another manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Key SNOWFLAKE_ACCOUNT set from environment.\n",
      "âœ… Key SNOWFLAKE_USER set from environment.\n",
      "âœ… Key SNOWFLAKE_USER_PASSWORD set from environment.\n"
     ]
    }
   ],
   "source": [
    "from trulens.utils.keys import check_keys\n",
    "check_keys(\"SNOWFLAKE_ACCOUNT\", \"SNOWFLAKE_USER\", \"SNOWFLAKE_USER_PASSWORD\")\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "connection_params = {\n",
    "    \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "    \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Create a Snowflake session\n",
    "snowflake_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "In this case, we'll just initialize some simple text in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_info = \"\"\"\n",
    "The University of Washington, founded in 1861 in Seattle, is a public research university\n",
    "with over 45,000 students across three campuses in Seattle, Tacoma, and Bothell.\n",
    "As the flagship institution of the six public universities in Washington state,\n",
    "UW encompasses over 500 buildings and 20 million square feet of space,\n",
    "including one of the largest library systems in the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Store\n",
    "\n",
    "Create a chromadb vector store in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = model.encode([university_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(name=\"Universities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add the university_info to the embedding database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_store.add(\"uni_info\",\n",
    "                 documents=university_info,\n",
    "                 embeddings=document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG from scratch\n",
    "\n",
    "Build a custom RAG from scratch, and add TruLens custom instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens.core import Tru\n",
    "from trulens.core.tru_custom_app import instrument\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class RAG_from_scratch:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(\n",
    "            query_embeddings=model.encode(\n",
    "            [query], prompt_name=\"query\"),\n",
    "            n_results=2\n",
    "        )\n",
    "        return results['documents']\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        \n",
    "        def escape_string_for_sql(input_string):\n",
    "            escaped_string = input_string.replace('\\\\', '\\\\\\\\')\n",
    "            escaped_string = escaped_string.replace(\"'\", \"''\")\n",
    "            return escaped_string\n",
    "        \n",
    "        prompt=escape_string_for_sql(f\"\"\"\n",
    "         We have provided context information below. \n",
    "            {context_str}\n",
    "            Given this information, please answer the question: {query}\n",
    "        \"\"\")\n",
    " \n",
    "        res = snowflake_session.sql(f\"\"\"SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "            'snowflake-arctic',\n",
    "            [\n",
    "            {{'role': 'user', 'content': '{prompt}'}}\n",
    "            ], {{\n",
    "                'temperature': 0\n",
    "            }}\n",
    "            )\"\"\").collect()\n",
    "       \n",
    "        completion = json.loads(res[0][0])[\"choices\"][0][\"messages\"]\n",
    "        print(\"full response from cortex function:\")\n",
    "        print(res)\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        completion = self.generate_completion(query, context_str)\n",
    "        return completion\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Note as of June 2024: \n",
    "Alternatively, we can use Cortex's Python API ([documentation](https://docs.snowflake.com/user-guide/snowflake-cortex/llm-functions#using-snowflake-cortex-llm-functions-with-python)) directly to have cleaner interface and avoid constructing SQL commands ourselves. \n",
    "The reason we are invoking the SQL function directly via `snowflake_session.sql()` is that the response from Cortex's Python API is still experimental and not as feature-rich as the one from SQL function as of the time of writing. i.e. inconsistency issues with structured json outputs and missing usage information have been observed, lack of support for advanced chat-style (multi-message), etc.\n",
    "Below is a minimal example of using Python API instead. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from snowflake.cortex import Complete\n",
    "# def complete(user_query) -> str:\n",
    "#     completion = Complete(\n",
    "#         model=\"snowflake-arctic\",\n",
    "#         prompt=f\"[FILL IN SYSTEM PROMPTS IF NEEDED ]{user_query}\",\n",
    "#         session=snowflake_session,\n",
    "#     )\n",
    "#     return completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up feedback functions.\n",
    "\n",
    "Here we'll use groundedness, answer relevance and context relevance to detect hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.app.retrieve.args.query .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.app.retrieve.args.query .\n",
      "âœ… In Context Relevance, input context will be set to __record__.app.retrieve.rets.collect() .\n",
      "âœ… In coherence, input text will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens.core import Feedback, Select\n",
    "from trulens.external.provider import Cortex\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize LiteLLM-based feedback function collection class:\n",
    "provider = Cortex(model_engine=\"snowflake-arctic\")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_coherence = (\n",
    "    Feedback(provider.coherence_with_cot_reasons, name = \"coherence\")\n",
    "    .on_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the app\n",
    "Wrap the custom RAG with TruCustomApp, add list of feedbacks for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruCustomApp\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'RAG v1',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance, f_coherence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app\n",
    "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full response from cortex function:\n",
      "[Row(SNOWFLAKE.CORTEX.COMPLETE(\n",
      "            'SNOWFLAKE-ARCTIC',\n",
      "            [\n",
      "            {'ROLE': 'USER', 'CONTENT': '\n",
      "         WE HAVE PROVIDED CONTEXT INFORMATION BELOW. \n",
      "            [[''\\\\NTHE UNIVERSITY OF WASHINGTON, FOUNDED IN 1861 IN SEATTLE, IS A PUBL='{\\n  \"choices\": [\\n    {\\n      \"messages\": \" The University of Washington was founded in 1861.\"\\n    }\\n  ],\\n  \"created\": 1718315813,\\n  \"model\": \"snowflake-arctic\",\\n  \"usage\": {\\n    \"completion_tokens\": 14,\\n    \"prompt_tokens\": 148,\\n    \"total_tokens\": 162\\n  }\\n}')]\n"
     ]
    }
   ],
   "source": [
    "with tru_rag as recording:\n",
    "    resp = rag.query(\"When is University of Washington founded?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The University of Washington was founded in 1861.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>coherence</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Groundedness  Context Relevance  coherence  Answer Relevance  latency  \\\n",
       "app_id                                                                          \n",
       "RAG v1           1.0                1.0        1.0               1.0      2.0   \n",
       "\n",
       "        total_cost  \n",
       "app_id              \n",
       "RAG v1         0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[\"RAG v1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n\nrun_dashboard(tru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens18_release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
