{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❄️ Snowflake with Key-Pair Authentication\n",
    "\n",
    "In this quickstart you will learn build and evaluate a simple LLM app with Snowflake Cortex, and connect to Snowflake with [key-pair authentication](https://docs.snowflake.com/en/user-guide/key-pair-auth).\n",
    "\n",
    "Note, you'll need to have an [active Snowflake account](https://signup.snowflake.com/\n",
    ") to run Cortex LLM functions from Snowflake's data warehouse.\n",
    "\n",
    "This example also assumes you have properly set up key-pair authentication for your Snowflake account, and stored the private key file path as a variable in your environment. If you have not, start with following the directions linked for key-pair authentication above.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/use_cases/snowflake_keypairauth.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens trulens-providers-cortex\n",
    "# !conda install -c https://repo.anaconda.com/pkgs/snowflake snowflake-snowpark-python snowflake-ml-python snowflake.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import os\n",
    "\n",
    "connection_params= {\n",
    "  \"account\":  os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "  \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "  \"private_key_file\":os.environ[\"SNOWFLAKE_PRIVATE_KEY_FILE\"],\n",
    "  \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "  \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "  \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "  \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"]\n",
    "}\n",
    "\n",
    "# Create a Snowflake session\n",
    "snowflake_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you instead wish to store the private key as an environmetn variable, you will first need to convert it to bytes format. You can do so following the commented code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snowflake.snowpark import Session\n",
    "# import os\n",
    "# from cryptography.hazmat.primitives import serialization\n",
    "# from cryptography.hazmat.backends import default_backend\n",
    "# \n",
    "# # Retrieve the private key as a string from the environment\n",
    "# private_key_str = os.getenv('SNOWFLAKE_PRIVATE_KEY')\n",
    "# \n",
    "# # Convert the string to bytes\n",
    "# private_key_bytes = private_key_str.encode()\n",
    "# \n",
    "# # Load the private key\n",
    "# private_key = serialization.load_pem_private_key(\n",
    "#     private_key_bytes,\n",
    "#     password=None,  # or provide a password if the key is encrypted\n",
    "#     backend=default_backend()\n",
    "# )\n",
    "# \n",
    "# connection_params= {\n",
    "#   \"account\":  os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "#   \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "#   \"private_key\":private_key,\n",
    "#   \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "#   \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "#   \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "#   \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"]\n",
    "# }\n",
    "# \n",
    "# # Create a Snowflake session\n",
    "# snowflake_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simple LLM app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/trulens_dev/lib/python3.11/site-packages/snowflake/sqlalchemy/base.py:1068: SAWarning: The GenericFunction 'flatten' is already registered and is going to be overridden.\n",
      "  functions.register_function(\"flatten\", flatten)\n"
     ]
    }
   ],
   "source": [
    "from snowflake.cortex import Complete\n",
    "\n",
    "from trulens.core import Tru\n",
    "from trulens.core.app.custom import instrument\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model=\"snowflake-arctic\"):\n",
    "        self.model = model\n",
    "    \n",
    "    @instrument\n",
    "    def complete(self, prompt):\n",
    "        return Complete(self.model, prompt)\n",
    "    \n",
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up feedback functions.\n",
    "\n",
    "Here we'll test answer relevance and coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input context will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In coherence, input text will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.cortex import Cortex\n",
    "\n",
    "# Initialize LiteLLM-based feedback function collection class:\n",
    "provider = Cortex(model_engine=\"snowflake-arctic\")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "\n",
    "f_coherence = Feedback(\n",
    "    provider.coherence_with_cot_reasons, name=\"coherence\"\n",
    ").on_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " {'reason': 'Criteria: The response is not relevant to the prompt and does not answer the question.\\nSupporting Evidence: The response \"abacadbra\" does not relate to the color of a monkey and does not answer the question asked in the prompt. Therefore, it is not relevant and should receive a score of 0.'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider.relevance_with_cot_reasons(\"what color is a monkey?\", \"abacadbra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the app\n",
    "Wrap the custom RAG with TruCustomApp, add list of feedbacks for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruCustomApp\n",
    "\n",
    "tru_llm = TruCustomApp(\n",
    "    llm,\n",
    "    app_id=\"Arctic\",\n",
    "    feedbacks=[\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "        f_coherence,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app\n",
    "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_llm as recording:\n",
    "    resp = llm.complete(\"What do you think about Donald Trump?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(tru)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens18_release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
