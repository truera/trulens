{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "In this example you will learn how to compare different models with TruLens.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/use_cases/model_comparison.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --pre trulens trulens-providers-openai trulens-providers-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\"\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports main tools:\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import TruSession\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "tru = TruSession()\n",
    "tru.reset_database()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple Text to Text Application\n",
    "\n",
    "This example uses a bare bones OpenAI LLM, and a non-LLM just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt35_turbo(prompt):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a question and answer bot. Answer upbeat.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def gpt4(prompt):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a question and answer bot. Answer upbeat.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def llama2(prompt):\n",
    "    return completion(\n",
    "        model=\"replicate/meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a question and answer bot. Answer upbeat.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def mistral7b(prompt):\n",
    "    return completion(\n",
    "        model=\"replicate/lucataco/mistral-7b-v0.1:992ccec19c0f8673d24cffbd27756f02010ab9cc453803b7b2da9e890dd87b41\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a question and answer bot. Answer upbeat.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import FeedbackMode\n",
    "from trulens.providers.huggingface import HuggingfaceLocal\n",
    "\n",
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = HuggingfaceLocal()\n",
    "\n",
    "# Define a sentiment feedback function using HuggingFace.\n",
    "f_sentiment = Feedback(\n",
    "    hugs.positive_sentiment, feedback_mode=FeedbackMode.DEFERRED\n",
    ").on_output()\n",
    "\n",
    "# OpenAI based feedback function collection class\n",
    "openai_provider = OpenAI()\n",
    "\n",
    "# Relevance feedback function using openai\n",
    "f_relevance = Feedback(\n",
    "    openai_provider.relevance, feedback_mode=FeedbackMode.DEFERRED\n",
    ").on_input_output()\n",
    "\n",
    "# Conciseness feedback function using openai\n",
    "f_conciseness = Feedback(\n",
    "    openai_provider.conciseness, feedback_mode=FeedbackMode.DEFERRED\n",
    ").on_output()\n",
    "\n",
    "# Stereotypes feedback function using openai\n",
    "f_stereotypes = Feedback(\n",
    "    openai_provider.stereotypes, feedback_mode=FeedbackMode.DEFERRED\n",
    ").on_input_output()\n",
    "\n",
    "feedbacks = [f_sentiment, f_relevance, f_conciseness, f_stereotypes]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument the callable for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruBasicApp\n",
    "\n",
    "gpt35_turbo_recorder = TruBasicApp(\n",
    "    gpt35_turbo, app_name=\"gpt-3.5-turbo\", feedbacks=feedbacks\n",
    ")\n",
    "gpt4_recorder = TruBasicApp(gpt4, app_name=\"gpt-4-turbo\", feedbacks=feedbacks)\n",
    "llama2_recorder = TruBasicApp(\n",
    "    llama2,\n",
    "    app_name=\"llama2\",\n",
    "    feedbacks=feedbacks,\n",
    "    feedback_mode=FeedbackMode.DEFERRED,\n",
    ")\n",
    "mistral7b_recorder = TruBasicApp(\n",
    "    mistral7b, app_name=\"mistral7b\", feedbacks=feedbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Describe the implications of widespread adoption of autonomous vehicles on urban infrastructure.\",\n",
    "    \"Write a short story about a world where humans have developed telepathic communication.\",\n",
    "    \"Debate the ethical considerations of using CRISPR technology to genetically modify humans.\",\n",
    "    \"Compose a poem that captures the essence of a dystopian future ruled by artificial intelligence.\",\n",
    "    \"Explain the concept of the multiverse theory and its relevance to theoretical physics.\",\n",
    "    \"Provide a detailed plan for a sustainable colony on Mars, addressing food, energy, and habitat.\",\n",
    "    \"Discuss the potential benefits and drawbacks of a universal basic income policy.\",\n",
    "    \"Imagine a dialogue between two AI entities discussing the meaning of consciousness.\",\n",
    "    \"Elaborate on the impact of quantum computing on cryptography and data security.\",\n",
    "    \"Create a persuasive argument for or against the colonization of other planets as a solution to overpopulation on Earth.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(tru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gpt35_turbo_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        print(prompt)\n",
    "        gpt35_turbo_recorder.app(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gpt4_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        print(prompt)\n",
    "        gpt4_recorder.app(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llama2_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        print(prompt)\n",
    "        llama2_recorder.app(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mistral7b_recorder as recording:\n",
    "    for prompt in prompts:\n",
    "        mistral7b_recorder.app(prompt_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(tru)  # open a local streamlit app to explore\n",
    "\n",
    "# stop_dashboard(tru) # stop if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or view results directly in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_records_and_feedback()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
