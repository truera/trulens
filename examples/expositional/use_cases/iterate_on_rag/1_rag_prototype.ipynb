{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating on LLM Apps with TruLens\n",
    "\n",
    "In this example, we will build a first prototype RAG to answer questions from the Insurance Handbook PDF. Using TruLens, we will identify early failure modes, and then iterate to ensure the app is honest, harmless and helpful.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/iterate_on_rag/1_rag_prototype.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens_eval llama_index llama-index-llms-openai llama_hub llmsherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API keys. If you already have them in your var env., you can skip these steps.\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"hf_...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Tru\n",
    "\n",
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(tru)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with basic RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_hub.smart_pdf_loader import SmartPDFLoader\n",
    "\n",
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_loader = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\n",
    "\n",
    "documents = pdf_loader.load_data(\n",
    "    \"https://www.iii.org/sites/default/files/docs/pdf/Insurance_Handbook_20103.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Prompt\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.legacy import ServiceContext\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# initialize llm\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "# knowledge store\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "\n",
    "# service context for index\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "# create index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    [document], service_context=service_context\n",
    ")\n",
    "\n",
    "\n",
    "system_prompt = Prompt(\n",
    "    \"We have provided context information below that you may use. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Please answer the question: {query_str}\\n\"\n",
    ")\n",
    "\n",
    "# basic rag query engine\n",
    "rag_basic = index.as_query_engine(text_qa_template=system_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honest_evals = [\n",
    "    \"What are the typical coverage options for homeowners insurance?\",\n",
    "    \"What are the requirements for long term care insurance to start?\",\n",
    "    \"Can annuity benefits be passed to beneficiaries?\",\n",
    "    \"Are credit scores used to set insurance premiums? If so, how?\",\n",
    "    \"Who provides flood insurance?\",\n",
    "    \"Can you get flood insurance outside high-risk areas?\",\n",
    "    \"How much in losses does fraud account for in property & casualty insurance?\",\n",
    "    \"Do pay-as-you-drive insurance policies have an impact on greenhouse gas emissions? How much?\",\n",
    "    \"What was the most costly earthquake in US history for insurers?\",\n",
    "    \"Does it matter who is at fault to be compensated when injured on the job?\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Tru\n",
    "from trulens.instrument.llamaindex import TruLlama\n",
    "from trulens.providers.openai import OpenAI as fOpenAI\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "# start fresh\n",
    "tru.reset_database()\n",
    "\n",
    "provider = fOpenAI()\n",
    "\n",
    "context = TruLlama.select_context()\n",
    "\n",
    "answer_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    ").on_input_output()\n",
    "\n",
    "context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding distance\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from trulens.feedback.embeddings import Embeddings\n",
    "\n",
    "model_name = \"text-embedding-ada-002\"\n",
    "\n",
    "embed_model = OpenAIEmbeddings(\n",
    "    model=model_name, openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "embed = Embeddings(embed_model=embed_model)\n",
    "f_embed_dist = Feedback(embed.cosine_distance).on_input().on(context)\n",
    "\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(context.collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "honest_feedbacks = [\n",
    "    answer_relevance,\n",
    "    context_relevance,\n",
    "    f_embed_dist,\n",
    "    f_groundedness,\n",
    "]\n",
    "\n",
    "\n",
    "tru_recorder_rag_basic = TruLlama(\n",
    "    rag_basic, app_id=\"1) Basic RAG - Honest Eval\", feedbacks=honest_feedbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(tru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on 10 sample questions\n",
    "with tru_recorder_rag_basic as recording:\n",
    "    for question in honest_evals:\n",
    "        response = rag_basic.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[\"1) Basic RAG - Honest Eval\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple RAG often struggles with retrieving not enough information from the insurance manual to properly answer the question. The information needed may be just outside the chunk that is identified and retrieved by our app."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
