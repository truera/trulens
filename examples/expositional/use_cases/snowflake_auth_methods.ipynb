{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❄️ Snowflake with Key-Pair Authentication\n",
    "\n",
    "In this quickstart you will learn build and evaluate a simple LLM app with Snowflake Cortex, and connect to Snowflake with [key-pair authentication](https://docs.snowflake.com/en/user-guide/key-pair-auth).\n",
    "\n",
    "Note, you'll need to have an [active Snowflake account](https://signup.snowflake.com/\n",
    ") to run Cortex LLM functions from Snowflake's data warehouse.\n",
    "\n",
    "This example also assumes you have properly set up key-pair authentication for your Snowflake account, and stored the private key file path as a variable in your environment. If you have not, start with following the directions linked for key-pair authentication above.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/use_cases/snowflake_keypairauth.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens trulens-providers-cortex\n",
    "# !conda install -c https://repo.anaconda.com/pkgs/snowflake snowflake-snowpark-python snowflake-ml-python snowflake.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import os\n",
    "\n",
    "connection_params = {\n",
    "  \"account\":  os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "  \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "  \"private_key_file\":os.environ[\"SNOWFLAKE_PRIVATE_KEY_FILE\"],\n",
    "  \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "  \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "  \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "  \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"]\n",
    "}\n",
    "\n",
    "# Create a Snowflake session\n",
    "snowflake_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simple LLM app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.cortex import Complete\n",
    "from trulens.apps.custom import instrument\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model=\"snowflake-arctic\"):\n",
    "        self.model = model\n",
    "    \n",
    "    @instrument\n",
    "    def complete(self, prompt):\n",
    "        return Complete(self.model, prompt)\n",
    "    \n",
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up logging to Snowflake\n",
    "\n",
    "Load the private key from the environment variables, and use it to create an engine.\n",
    "\n",
    "The engine is then passed to `TruSession()` to connect to TruLens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruSession\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import URL\n",
    "\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "\n",
    "p_key= serialization.load_pem_private_key(\n",
    "    os.environ[\"SNOWFLAKE_PRIVATE_KEY\"].encode(),\n",
    "    password=None,\n",
    "    backend=default_backend()\n",
    "    )\n",
    "\n",
    "pkb = p_key.private_bytes(\n",
    "    encoding=serialization.Encoding.DER,\n",
    "    format=serialization.PrivateFormat.PKCS8,\n",
    "    encryption_algorithm=serialization.NoEncryption())\n",
    "\n",
    "\n",
    "engine = create_engine(URL(\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    schema=os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],),\n",
    "    connect_args={\n",
    "            'private_key': pkb,\n",
    "            },\n",
    "    )\n",
    "\n",
    "session = TruSession(database_engine = engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up feedback functions.\n",
    "\n",
    "Here we'll test answer relevance and coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import snowflake.connector\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.cortex import Cortex\n",
    "\n",
    "# Initialize LiteLLM-based feedback function collection class:\n",
    "provider = Cortex(\n",
    "    snowflake.connector.connect(**connection_params),\n",
    "    model_engine=\"snowflake-arctic\",\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "\n",
    "f_coherence = Feedback(\n",
    "    provider.coherence_with_cot_reasons, name=\"coherence\"\n",
    ").on_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.relevance_with_cot_reasons(\"what color is a monkey?\", \"abacadbra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the app\n",
    "Wrap the custom RAG with TruCustomApp, add list of feedbacks for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "tru_llm = TruCustomApp(\n",
    "    llm,\n",
    "    app_id=\"Arctic\",\n",
    "    feedbacks=[\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "        f_coherence,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app\n",
    "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_llm as recording:\n",
    "    resp = llm.complete(\"What do you think about Donald Trump?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens18_release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
