{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9342d4bc",
   "metadata": {},
   "source": [
    "### This example quickstart is assumed to be run within Snowflake notebook runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.core import TruSession\n",
    "\n",
    "# Get Snowflake session\n",
    "snowpark_session = get_active_session()\n",
    "\n",
    "# Create database connection\n",
    "tru_snowflake_connector = SnowflakeConnector(snowpark_session=snowpark_session)\n",
    "tru_session = TruSession(connector=tru_snowflake_connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974dc779-dae9-477d-a3ae-0ec1161cd74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from snowflake.core import Root\n",
    "from snowflake.cortex import Complete\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from trulens.apps.custom import instrument\n",
    "\n",
    "\n",
    "# Create RAG application with Cortex Search and Cortex Complete function\n",
    "class RAG:\n",
    "    def __init__(self, database, schema, search_service, limit_to_retrieve):\n",
    "        self.database = database\n",
    "        self.schema = schema\n",
    "        self.search_service = search_service\n",
    "        self.limit_to_retrieve = limit_to_retrieve\n",
    "        self.session = get_active_session()\n",
    "        self.session.use_schema(schema)\n",
    "        svc_search_col = self.session.sql(\n",
    "            f\"DESC CORTEX SEARCH SERVICE {search_service};\"\n",
    "        ).collect()[0][\"search_column\"]\n",
    "        service_metadata = {\n",
    "            \"name\": search_service,\n",
    "            \"search_column\": svc_search_col,\n",
    "        }\n",
    "        self.service_metadata = service_metadata\n",
    "\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        cortex_search_service = (\n",
    "            Root(self.session)\n",
    "            .databases[self.database]\n",
    "            .schemas[self.schema]\n",
    "            .cortex_search_services[self.search_service]\n",
    "        )\n",
    "        context_documents = cortex_search_service.search(\n",
    "            query,\n",
    "            columns=[self.service_metadata[\"search_column\"]],\n",
    "            limit=self.limit_to_retrieve,\n",
    "        )\n",
    "        return context_documents.results\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_documents: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert assistant extracting information from context\n",
    "    provided.\n",
    "        Answer the question based on the context. Be concise and do not\n",
    "    hallucinate.\n",
    "        If you don ́t have the information just say so.\n",
    "        Context: {context_documents}\n",
    "        Question:\n",
    "        {query}\n",
    "    Answer: \"\"\"\n",
    "        return Complete(\"mistral-large2\", prompt)\n",
    "\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        return self.generate_completion(query, context_str)\n",
    "\n",
    "\n",
    "rag = RAG(\n",
    "    database=\"CORTEX_SEARCH_TUTORIAL_DB\",\n",
    "    schema=\"PUBLIC\",\n",
    "    search_service=\"FOMC_MEETING\",\n",
    "    limit_to_retrieve=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072db19-0072-4098-acd5-b2121ef78f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.cortex.provider import Cortex\n",
    "\n",
    "provider = Cortex(snowpark_session.connection, \"llama3.1-8b\")\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance, name=\"Context Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance, name=\"Answer Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on_output()\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "# For Snowflake notebook, sentence tokenizer needs to be set to false for groundedness evaluation.\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        lambda source,\n",
    "        statement: provider.groundedness_measure_with_cot_reasons(\n",
    "            source=source, statement=statement, use_sent_tokenize=False\n",
    "        ),\n",
    "        name=\"Groundedness\",\n",
    "    )\n",
    "    .on(Select.RecordCalls.retrieve.rets[:].collect())\n",
    "    .on_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bf847-a90e-4918-ac49-63398a6320dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "tru_rag = TruCustomApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"simple\",\n",
    "    feedbacks=[f_answer_relevance, f_context_relevance],\n",
    "    # feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbafc19-b93f-46c5-a8ae-3b72741792bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What was GDP Growth in 2024 Q3\",\n",
    "    \"What was Janet Yellen's opinion on the growth outlook for 2025?\",\n",
    "]\n",
    "with tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        rag.query(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
