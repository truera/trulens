{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ““ TruLens Quickstart\n",
    "\n",
    "In this quickstart you will create a RAG from scratch, trace the execution and get feedback on an LLM response.\n",
    "\n",
    "For evaluation, we will leverage the \\\"hallucination triad\\\" of groundedness, context relevance and answer relevance.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/quickstart/quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens trulens-providers-openai chromadb openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "In this case, we'll just initialize some simple text in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_info = \"\"\"\n",
    "Seattle, a city on Puget Sound in the Pacific Northwest, is surrounded by water, mountains and evergreen forests, and contains thousands of acres of parkland.\n",
    "It's home to a large tech industry, with Microsoft and Amazon headquartered in its metropolitan area.\n",
    "The futuristic Space Needle, a legacy of the 1962 World's Fair, is its most iconic landmark.\n",
    "\"\"\"\n",
    "\n",
    "starbucks_info = \"\"\"\n",
    "Starbucks Corporation is an American multinational chain of coffeehouses and roastery reserves headquartered in Seattle, Washington.\n",
    "As the world's largest coffeehouse chain, Starbucks is seen to be the main representation of the United States' second wave of coffee culture.\n",
    "\"\"\"\n",
    "\n",
    "coffee_culture_info = \"\"\"\n",
    "Coffee culture has evolved through three distinct waves. The first wave focused on convenience and mass production,\n",
    "exemplified by brands like Folgers and Maxwell House. The second wave, led by Starbucks, introduced espresso-based drinks,\n",
    "customization, and the cafe as a 'third place' between work and home. The third wave treats coffee as artisanal food,\n",
    "emphasizing origin, processing methods, and brewing techniques.\n",
    "\"\"\"\n",
    "\n",
    "seattle_coffee_info = \"\"\"\n",
    "Seattle became the epicenter of American coffee culture, birthplace of Starbucks in 1971, and home to numerous independent roasters.\n",
    "The city's coffee scene has evolved from the second wave dominance of Starbucks to embrace third wave coffee shops\n",
    "that focus on single-origin beans and precise brewing methods.\n",
    "\"\"\"\n",
    "\n",
    "ocean_waves_info = \"\"\"\n",
    "Ocean waves along the United States coastline provide significant renewable energy opportunities through wave power generation.\n",
    "The Pacific Northwest, particularly off the coasts of Washington and Oregon, has some of the best wave energy resources in the nation.\n",
    "Wave energy converters can harness this power to generate electricity.\n",
    "\"\"\"\n",
    "\n",
    "radio_waves_info = \"\"\"\n",
    "Radio waves were first successfully transmitted across the Atlantic Ocean in 1901 by Guglielmo Marconi.\n",
    "In the United States, radio wave technology revolutionized communication and entertainment throughout the 20th century.\n",
    "The Federal Communications Commission regulates radio wave frequencies to prevent interference.\n",
    "\"\"\"\n",
    "\n",
    "starbucks_stock_info = \"\"\"\n",
    "Starbucks Corporation (NASDAQ: SBUX) has shown volatile stock performance in recent years, influenced by market trends,\n",
    "expansion strategies, and consumer spending patterns. The company's stock price reflects broader economic conditions\n",
    "and competition in the quick-service restaurant sector.\n",
    "\"\"\"\n",
    "\n",
    "heat_waves_info = \"\"\"\n",
    "Heat waves in the United States have become more frequent and intense due to climate change.\n",
    "The Pacific Northwest, including Washington State, experienced record-breaking temperatures in recent heat waves,\n",
    "challenging infrastructure designed for milder climates.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Store\n",
    "\n",
    "Create a chromadb vector store in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"text-embedding-3-small\",\n",
    ")\n",
    "\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(\n",
    "    name=\"Washington\", embedding_function=embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\"seattle_info\", documents=seattle_info)\n",
    "vector_store.add(\"starbucks_info\", documents=starbucks_info)\n",
    "vector_store.add(\"coffee_culture_info\", documents=coffee_culture_info)\n",
    "vector_store.add(\"seattle_coffee_info\", documents=seattle_coffee_info)\n",
    "vector_store.add(\"ocean_waves_info\", documents=ocean_waves_info)\n",
    "vector_store.add(\"radio_waves_info\", documents=radio_waves_info)\n",
    "vector_store.add(\"starbucks_stock_info\", documents=starbucks_stock_info)\n",
    "vector_store.add(\"heat_waves_info\", documents=heat_waves_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG from scratch\n",
    "\n",
    "Build a custom RAG from scratch, and add TruLens custom instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from trulens.core.otel.instrument import instrument\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "\n",
    "oai_client = OpenAI()\n",
    "\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, model_name: str = \"gpt-5\"):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes={\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        results = vector_store.query(\n",
    "            query_texts=query, n_results=4\n",
    "        )  # Get more results\n",
    "        return [doc for sublist in results[\"documents\"] for doc in sublist]\n",
    "\n",
    "    @instrument(span_type=SpanAttributes.SpanType.GENERATION)\n",
    "    def generate_completion(self, query: str, context_list: list) -> str:\n",
    "        \"\"\"Generate answer from context with improved prompting.\"\"\"\n",
    "        if len(context_list) == 0:\n",
    "            return \"I don't have enough relevant information to answer this question.\"\n",
    "\n",
    "        # Join context if it's a list\n",
    "        context = (\n",
    "            \"\\n---\\n\".join(context_list)\n",
    "            if isinstance(context_list, list)\n",
    "            else context_list\n",
    "        )\n",
    "\n",
    "        completion = (\n",
    "            oai_client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a helpful assistant. \",\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer using the context above:\",\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "            .choices[0]\n",
    "            .message.content\n",
    "        )\n",
    "        return (\n",
    "            completion\n",
    "            if completion\n",
    "            else \"I don't have enough information to answer this question.\"\n",
    "        )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def query(self, query: str) -> str:\n",
    "        context_list = self.retrieve(query=query)\n",
    "        completion = self.generate_completion(\n",
    "            query=query, context_list=context_list\n",
    "        )\n",
    "        return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Metric\n",
    "from trulens.core import Selector\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "provider = OpenAI(model_engine=\"gpt-5-nano\")\n",
    "\n",
    "# Define a groundedness metric\n",
    "f_groundedness = Metric(\n",
    "    implementation=provider.groundedness_measure_with_cot_reasons_consider_answerability,\n",
    "    name=\"Groundedness\",\n",
    "    selectors={\n",
    "        \"source\": Selector.select_context(collect_list=True),\n",
    "        \"statement\": Selector.select_record_output(),\n",
    "        \"question\": Selector.select_record_input(),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = Metric(\n",
    "    implementation=provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\",\n",
    "    selectors={\n",
    "        \"prompt\": Selector.select_record_input(),\n",
    "        \"response\": Selector.select_record_output(),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = Metric(\n",
    "    implementation=provider.context_relevance_with_cot_reasons,\n",
    "    name=\"Context Relevance\",\n",
    "    selectors={\n",
    "        \"question\": Selector.select_record_input(),\n",
    "        \"context\": Selector.select_context(collect_list=False),\n",
    "    },\n",
    "    agg=np.mean,  # choose a different aggregation method if you wish\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the app\n",
    "Wrap the custom RAG with TruApp, add list of feedbacks for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.app import TruApp\n",
    "\n",
    "rag = RAG(model_name=\"gpt-5-mini\")\n",
    "\n",
    "tru_rag = TruApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"base\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app\n",
    "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What wave of coffee culture does Starbucks represent?\",\n",
    "    \"Describe climate challenges for Starbucks.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    for query in test_queries:\n",
    "        rag.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results\n",
    "\n",
    "We can view results in the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens_plotly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
