{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì Logging Human Feedback\n",
    "\n",
    "In many situations, it can be useful to log human feedback from your users about your LLM app's performance. Combining human feedback along with automated feedback can help you drill down on subsets of your app that underperform, and uncover new failure modes. This example will walk you through a simple example of recording human feedback with TruLens.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/quickstart/human_feedback.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --pre trulens openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from trulens.core import TruCustomApp\n",
    "from trulens.core import TruSession\n",
    "\n",
    "tru = TruSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Keys\n",
    "\n",
    "For this example, you need an OpenAI key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your app\n",
    "\n",
    "Here we set up a custom application using just an OpenAI chat completion. The process for logging human feedback is the same however you choose to set up your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from trulens.core.app.custom import instrument\n",
    "\n",
    "oai_client = OpenAI()\n",
    "\n",
    "\n",
    "class APP:\n",
    "    @instrument\n",
    "    def completion(self, prompt):\n",
    "        completion = (\n",
    "            oai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Please answer the question: {prompt}\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            .choices[0]\n",
    "            .message.content\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "\n",
    "llm_app = APP()\n",
    "\n",
    "# add trulens as a context manager for llm_app\n",
    "tru_app = TruCustomApp(llm_app, app_name=\"LLM App\", app_version=\"v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_app as recording:\n",
    "    llm_app.completion(\"Give me 10 names for a colorful sock company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the record to add the feedback to.\n",
    "record = recording.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mechanism for recording human feedback.\n",
    "\n",
    "Be sure to click an emoji in the record to record `human_feedback` to log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Button\n",
    "from ipywidgets import HBox\n",
    "\n",
    "thumbs_up_button = Button(description=\"üëç\")\n",
    "thumbs_down_button = Button(description=\"üëé\")\n",
    "\n",
    "human_feedback = None\n",
    "\n",
    "\n",
    "def on_thumbs_up_button_clicked(b):\n",
    "    global human_feedback\n",
    "    human_feedback = 1\n",
    "\n",
    "\n",
    "def on_thumbs_down_button_clicked(b):\n",
    "    global human_feedback\n",
    "    human_feedback = 0\n",
    "\n",
    "\n",
    "thumbs_up_button.on_click(on_thumbs_up_button_clicked)\n",
    "thumbs_down_button.on_click(on_thumbs_down_button_clicked)\n",
    "\n",
    "HBox([thumbs_up_button, thumbs_down_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the human feedback to a particular app and record\n",
    "tru.add_feedback(\n",
    "    name=\"Human Feedack\",\n",
    "    record_id=record.record_id,\n",
    "    app_id=tru_app.app_id,\n",
    "    result=human_feedback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the result logged with your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[tru_app.app_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens18_release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
