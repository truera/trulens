{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ce3c0b",
   "metadata": {},
   "source": [
    "# Evaluate and Trace LangGraph MCP Tool Selection\n",
    "\n",
    "This notebook demonstrates how to use TruLens to trace and evaluate LangGraph applications that use Model Context Protocol (MCP) tools.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll build a health research agent that uses MCP tools to query:\n",
    "- PubMed for medical literature\n",
    "- Clinical trials databases for trial information\n",
    "\n",
    "TruLens will automatically trace all tool calls, showing:\n",
    "- Which MCP tools are being called\n",
    "- Input arguments and outputs\n",
    "- Execution time and errors\n",
    "- Full conversation flow in the dashboard\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's configure our API keys and MCP server connection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configure API keys and MCP server connection\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_PAT\"] = \"ey...\"\n",
    "os.environ[\"SNOWFLAKE_MCP_SERVER_URL\"] = (\n",
    "    \"https://<account-id>.snowflakecomputing.com/api/v2/databases/health_db/schemas/mcp/mcp-servers/health_mcp_server\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0933e60",
   "metadata": {},
   "source": [
    "## Create MCP Client and Get Tools\n",
    "\n",
    "We'll use the `MultiServerMCPClient` from `langchain_mcp_adapters` to connect to the health research MCP server and retrieve available tools.\n",
    "\n",
    "This step assumes you have already created an MCP Server in snowflake to use. If you need help doing that, you can use this [quickstart](https://quickstarts.snowflake.com/guide/getting-started-with-snowflake-mcp-server/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import START\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "client = MultiServerMCPClient({\n",
    "    \"health_research\": {\n",
    "        \"transport\": \"streamable_http\",\n",
    "        \"url\": os.environ[\"SNOWFLAKE_MCP_SERVER_URL\"],\n",
    "        \"headers\": {\"Authorization\": f\"Bearer {os.environ['SNOWFLAKE_PAT']}\"},\n",
    "    }\n",
    "})\n",
    "tools = await client.get_tools()\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abcaa0",
   "metadata": {},
   "source": [
    "## Build the LangGraph Agent\n",
    "\n",
    "Now we'll create a LangGraph application with:\n",
    "1. **call_model** node - The LLM that decides which tools to use\n",
    "2. **tools** node - Executes the selected MCP tools\n",
    "3. **tools_condition** - Routes between the model and tools\n",
    "\n",
    "The graph will loop between the model and tools until the agent has enough information to answer the question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa92cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the call_model function\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.bind_tools(tools).invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Create the StateGraph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_node(ToolNode(tools))\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"call_model\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8dd2b",
   "metadata": {},
   "source": [
    "## Initialize TruLens Session\n",
    "\n",
    "Set up TruLens to track and store traces. We'll reset the database to start fresh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c7315",
   "metadata": {},
   "source": [
    "## Create Tool Selection Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2676fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Feedback\n",
    "from trulens.core.feedback.selector import Selector\n",
    "from trulens.providers.openai import OpenAI as OpenAIProvider\n",
    "\n",
    "provider = OpenAIProvider(model_engine=\"gpt-4.1\")\n",
    "\n",
    "f_tool_selection = Feedback(provider.tool_selection_with_cot_reasons).on({\n",
    "    \"trace\": Selector(trace_level=True),\n",
    "})\n",
    "\n",
    "f_tool_calling = Feedback(provider.tool_calling_with_cot_reasons).on({\n",
    "    \"trace\": Selector(trace_level=True),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c060a5",
   "metadata": {},
   "source": [
    "## Record Agent Execution with TruLens\n",
    "\n",
    "Wrap the LangGraph application with `TruGraph` to automatically instrument and trace all executions.\n",
    "\n",
    "TruLens will capture:\n",
    "- Each node execution in the graph\n",
    "- MCP tool calls with their names (e.g., `pubmed_search`, `clinical_trials_search`)\n",
    "- Input/output states at each step\n",
    "- LLM generation calls\n",
    "- Tool routing decisions\n",
    "\n",
    "The trace will show the complete flow of the agent's reasoning and tool usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17deb326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.langgraph import TruGraph\n",
    "\n",
    "tru_recorder = TruGraph(\n",
    "    app=graph,\n",
    "    app_name=\"health_research\",\n",
    "    app_version=\"base\",\n",
    "    feedbacks=[f_tool_selection, f_tool_calling],\n",
    ")\n",
    "\n",
    "with tru_recorder:\n",
    "    response = await graph.ainvoke({\n",
    "        \"messages\": \"How do semaglutide and tirzepatide compare in published studies, and what head-to-head clinical trials are recruiting patients?\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2f3a3",
   "metadata": {},
   "source": [
    "## View the Agent Response\n",
    "\n",
    "Let's see what the agent found:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Agent Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fdbc42",
   "metadata": {},
   "source": [
    "## Launch TruLens Dashboard\n",
    "\n",
    "Open the TruLens dashboard to explore the traces interactively.\n",
    "\n",
    "In the dashboard you'll see:\n",
    "- **Tree View**: Visual representation of the agent's execution flow showing:\n",
    "  - Graph nodes (call_model, tools_condition)\n",
    "  - MCP tool calls with their actual names (pubmed_search, clinical_trials_search)\n",
    "  - LLM generation calls\n",
    "- **Timeline View**: Chronological execution timeline\n",
    "- **MCP Tool Details**: For each tool call, you can see:\n",
    "  - `mcp.tool_name`: The specific tool that was called\n",
    "  - `mcp.input_arguments`: Arguments passed to the tool\n",
    "  - `mcp.output_content`: Results returned by the tool\n",
    "  - Execution time and any errors\n",
    "\n",
    "This provides complete observability into how your agent uses MCP tools to answer questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
