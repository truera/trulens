{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit App UI Experimental\n",
    "\n",
    "**This notebook demonstrates experimental features. The more stable streamlit app ui is demonstrated in `quickstart/dashboard_appui.ipynb`.**\n",
    "\n",
    "This notebook demonstrates an app interface that runs alongside the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Tru\n",
    "from trulens.core.utils.keys import check_keys\n",
    "\n",
    "check_keys(\"OPENAI_API_KEY\")\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "tru.start_dashboard(force=True, _dev=Path().cwd().parent.parent.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_langchain_app():\n",
    "    # All relevant imports must be inside this function.\n",
    "\n",
    "    from langchain.chains import ConversationChain\n",
    "    from langchain.memory import ConversationSummaryBufferMemory\n",
    "    from langchain_community.llms import OpenAI\n",
    "\n",
    "    llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "    # Conversation memory.\n",
    "    memory = ConversationSummaryBufferMemory(\n",
    "        max_token_limit=64,\n",
    "        llm=llm,\n",
    "    )\n",
    "\n",
    "    # Conversational app puts it all together.\n",
    "    app = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "    return app\n",
    "\n",
    "\n",
    "app1 = load_langchain_app()\n",
    "\n",
    "tru_app1 = tru.Chain(\n",
    "    app1, app_id=\"langchain_app\", initial_app_loader=load_langchain_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llama_index example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "# Be careful what you include as globals to be used by the loader function as it\n",
    "# will have to be serialized. We enforce a size limit which prohibits large\n",
    "# objects to be included in the loader's closure.\n",
    "\n",
    "# This object will be serialized alongside `load_llamaindex_app` below.\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"http://paulgraham.com/worked.html\"]\n",
    ")\n",
    "\n",
    "\n",
    "def load_llamaindex_app():\n",
    "    from llama_index.core import VectorStoreIndex\n",
    "\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    query_engine = index.as_query_engine()\n",
    "\n",
    "    return query_engine\n",
    "\n",
    "\n",
    "app2 = load_llamaindex_app()\n",
    "tru_app2 = tru.Llama(\n",
    "    app2, app_id=\"llamaindex_app\", initial_app_loader=load_llamaindex_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic app example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.app import TruWrapperApp\n",
    "\n",
    "\n",
    "def load_basic_app():\n",
    "    def custom_application(prompt: str) -> str:\n",
    "        return f\"a useful response to {prompt}\"\n",
    "\n",
    "    return TruWrapperApp(custom_application)\n",
    "\n",
    "\n",
    "app3 = load_basic_app()\n",
    "\n",
    "tru_app3 = tru.Basic(\n",
    "    app3, app_id=\"basic_app\", initial_app_loader=load_basic_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom app example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.expositional.end2end_apps.custom_app.custom_app import (\n",
    "    CustomApp,  # our custom app\n",
    ")\n",
    "\n",
    "\n",
    "# Create custom app:\n",
    "def load_custom_app():\n",
    "    app = CustomApp()\n",
    "    return app\n",
    "\n",
    "\n",
    "app4 = load_custom_app()\n",
    "\n",
    "# Create trulens wrapper:\n",
    "tru_app4 = tru.Custom(\n",
    "    app=app4,\n",
    "    app_id=\"custom_app\",\n",
    "    # Make sure to specify using the bound method, bound to self=app.\n",
    "    main_method=app4.respond_to_query,\n",
    "    initial_app_loader=load_custom_app,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "You can get a list of apps that include the `initial_app_loader` with the following utility method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.schema import AppDefinition\n",
    "\n",
    "for app_json in AppDefinition.get_loadable_apps():\n",
    "    print(app_json[\"app_id\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
