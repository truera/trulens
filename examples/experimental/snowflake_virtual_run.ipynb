{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate gen AI apps with Snowflake Cortex AI and TruLens\n",
    "This notebook demonstrates how AI Observability in Snowflake Cortex AI helps quantitatively measure the performance of a RAG applications using  different LLMs, providing insights into application behavior and helping the user select the best model for their use case.\n",
    "\n",
    "### Required Packages\n",
    "* trulens-core (1.4.5 or above)\n",
    "* trulens-connectors-snowflake (1.4.5 or above)\n",
    "* trulens-providers-cortex (1.4.5 or above)\n",
    "* snowflake.core (1.0.5 or above)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Information\n",
    "Fetches the current session information and the connection details for the Snowflake account. This connection details will be used to ingest application traces and trigger metric computation jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"SNOWFLAKE_ACCOUNT\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_USER\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_USER_PASSWORD\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_DATABASE\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_SCHEMA\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_WAREHOUSE\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_ROLE\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "snowflake_connection_parameters = {\n",
    "    \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "    \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "    \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "    \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "    \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "}\n",
    "snowpark_session = Session.builder.configs(\n",
    "    snowflake_connection_parameters\n",
    ").create()\n",
    "\n",
    "# TruSession is no longer required as long as snowflake connector exists\n",
    "sf_connector = SnowflakeConnector(snowpark_session=snowpark_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest Virtual Run approach!\n",
    "import uuid\n",
    "\n",
    "from trulens.apps.app import TruApp\n",
    "from trulens.core.run import RunConfig\n",
    "\n",
    "APP_NAME = \"RAG evaluation run on existing data\"\n",
    "APP_VERSION = \"V1\"\n",
    "\n",
    "# Create TruApp with None - no app object or main_method needed!\n",
    "tru_app = TruApp(\n",
    "    app=None,  # No app object needed for virtual runs\n",
    "    app_name=APP_NAME,\n",
    "    app_version=APP_VERSION,\n",
    "    connector=sf_connector,\n",
    ")\n",
    "\n",
    "# Create run config with dataset specification\n",
    "run_name = f\"virtual_run_{uuid.uuid4()}\"\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=run_name,\n",
    "    dataset_name=\"virtual_run_test\",  # Your Snowflake table name\n",
    "    source_type=\"TABLE\",\n",
    "    dataset_spec={\n",
    "        # The dataset_spec maps span attribute paths to column names\n",
    "        # This creates spans dynamically based on what you define here!\n",
    "        \"record_root.input\": \"QUERY_STRING\",  # Root span input\n",
    "        \"record_root.output\": \"OUTPUT_STRING\",  # Root span output\n",
    "        \"retrieved_contexts\": \"CONTEXTS\",  # Retrieval span contexts\n",
    "    },\n",
    ")\n",
    "\n",
    "# Use the existing add_run() flow\n",
    "virtual_run = tru_app.add_run(run_config=run_config)\n",
    "\n",
    "print(f\"Created virtual run: {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the virtual run - this will create OTEL spans from existing data\n",
    "virtual_run.start(virtual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Run - New Feature!\n",
    "With the new virtual run feature, you can now ingest existing data directly into the Event Table without creating a dummy app. This approach is much cleaner and avoids the awkward pattern of creating fake app methods.\n",
    "\n",
    "The example schema used is shown below:\n",
    "```sql\n",
    "create table YOUR_TABLE_NAME (\n",
    "    query_string VARCHAR,\n",
    "    output_string VARCHAR, \n",
    "    contexts VARCHAR\n",
    ");\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check virtual run status\n",
    "import time\n",
    "\n",
    "while virtual_run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    print(\"Waiting for ingestion to complete...\")\n",
    "    time.sleep(2)\n",
    "\n",
    "print(f\"Virtual run status: {virtual_run.get_status()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics\n",
    "\n",
    "Computes the RAG triad metrics for both runs to measure the quality of response in the RAG application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for the virtual run\n",
    "virtual_run.compute_metrics([\n",
    "    \"answer_relevance\",\n",
    "    \"context_relevance\",\n",
    "    \"groundedness\",\n",
    "])\n",
    "\n",
    "print(\"Metrics computation started for virtual run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results\n",
    "\n",
    "To view evaluation results:\n",
    "* Login to [Snowsight](https://app.snowflake.com/).\n",
    "* Navigate to **AI & ML** -> **Evaluations** from the left navigation menu.\n",
    "* Select “RAG evaluation run on existing data” to view the runs, see detailed traces and compare runs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
