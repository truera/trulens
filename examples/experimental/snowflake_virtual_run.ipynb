{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate gen AI apps with Snowflake Cortex AI and TruLens\n",
    "This notebook demonstrates how AI Observability in Snowflake Cortex AI helps quantitatively measure the performance of a RAG applications using  different LLMs, providing insights into application behavior and helping the user select the best model for their use case.\n",
    "\n",
    "### Required Packages\n",
    "* trulens-core (1.4.5 or above)\n",
    "* trulens-connectors-snowflake (1.4.5 or above)\n",
    "* trulens-providers-cortex (1.4.5 or above)\n",
    "* snowflake.core (1.0.5 or above)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Information\n",
    "Fetches the current session information and the connection details for the Snowflake account. This connection details will be used to ingest application traces and trigger metric computation jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "snowpark_session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables\n",
    "\n",
    "Sets the environment variables to use OpenTelemetry for generated traces. This step is mandatory to trace and evaluate the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "sf_connector = SnowflakeConnector(snowpark_session=snowpark_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Application\n",
    "Defines the RAG application with retrieval and generation steps. Here, instead of invoking application with LLM generation, we directly query and fetch existing data in Snowflake table, ingest them into event table and run evaluation metrics on the existing data. \n",
    "\n",
    "The example schema used is shown below\n",
    "```\n",
    "create table YOUR_TABLE_NAME (\n",
    "    query_string VARCHAR,\n",
    "    output_string VARCHAR, \n",
    "    contexts VARCHAR\n",
    "    );\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.otel.instrument import instrument\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "\n",
    "\n",
    "class TestApp:\n",
    "    def __init__(self, snowflake_table_name: str):\n",
    "        self.snowflake_table_name = snowflake_table_name\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def query(self, query: str) -> str:\n",
    "        retrieved_contexts = self.get_contexts(query)\n",
    "        return self.generate_answer(query, retrieved_contexts)\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes={\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def get_contexts(self, query: str) -> list[str]:\n",
    "        # query the snowflake table with query and find the relevant retrieved contexts. the contexts column is a string in comma separated format. parse them into a list of strings.\n",
    "        query_result = snowpark_session.sql(\n",
    "            f\"SELECT CONTEXTS FROM {self.snowflake_table_name} WHERE QUERY_STRING = '{query}'\"\n",
    "        ).collect()\n",
    "\n",
    "        if not query_result:\n",
    "            return []\n",
    "\n",
    "        # Get contexts string from first row\n",
    "        contexts_str = query_result[0][\"CONTEXTS\"]\n",
    "\n",
    "        # Parse comma-separated string into list\n",
    "        if contexts_str:\n",
    "            contexts = [context.strip() for context in contexts_str.split(\",\")]\n",
    "            return contexts\n",
    "\n",
    "        return []\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.GENERATION,\n",
    "    )\n",
    "    def generate_answer(self, query: str, contexts: list[str]) -> str:\n",
    "        # Query snowflake table to get output string for the given query\n",
    "\n",
    "        if len(contexts) == 0:\n",
    "            return \"Sorry, I couldn't find an answer to your question.\"\n",
    "        query_result = snowpark_session.sql(\n",
    "            f\"SELECT OUTPUT_STRING FROM {self.snowflake_table_name} WHERE QUERY_STRING = '{query}'\"\n",
    "        ).collect()\n",
    "        answer = query_result[0][\"OUTPUT_STRING\"] if query_result else None\n",
    "        if answer:\n",
    "            return answer\n",
    "        else:\n",
    "            return \"Did not find an answer.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App Registration\n",
    "Registers the two app instances in Snowflake, creating EXTERNAL AGENT objects to represent the app instances in the Snowflake account and registers both the app instances as different versions of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TruLens instrumented app from custom app.\n",
    "\n",
    "import uuid\n",
    "\n",
    "from trulens.apps.app import TruApp\n",
    "\n",
    "APP_NAME = \"RAG evaluation run on existing data\"\n",
    "APP_VERSION = \"V1\"\n",
    "\n",
    "test_app = TestApp(snowflake_table_name=\"YOUR_TABLE_NAME\")\n",
    "\n",
    "tru_app = TruApp(\n",
    "    test_app,\n",
    "    app_name=APP_NAME,\n",
    "    app_version=APP_VERSION,\n",
    "    connector=sf_connector,\n",
    "    main_method=test_app.query,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add runs to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.run import Run\n",
    "from trulens.core.run import RunConfig\n",
    "\n",
    "run_name = f\"test_virtual_run_{uuid.uuid4()}\"\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=run_name,\n",
    "    dataset_name=\"VIRTUAL_RUN_TEST\",\n",
    "    source_type=\"TABLE\",\n",
    "    dataset_spec={\n",
    "        \"RECORD_ROOT.INPUT\": \"QUERY_STRING\",  # column name \"QUERY_STRING\" is case sensitive\n",
    "    },\n",
    ")\n",
    "\n",
    "run: Run = tru_app.add_run(run_config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Status Check\n",
    "Checks the status of the runs for \"INVOCATION_IN_PROGRESS\". \n",
    "\n",
    "Note: Metric computation cannot be started until the invocation is in progress. Once the runs' status is changed to \"INVOCATION_COMPLETED\", metric computation can be triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.compute_metrics([\n",
    "    \"answer_relevance\",\n",
    "    \"context_relevance\",\n",
    "    \"groundedness\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics\n",
    "\n",
    "Computes the RAG triad metrics for both runs to measure the quality of response in the RAG application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results\n",
    "\n",
    "To view evaluation results:\n",
    "* Login to [Snowsight](https://app.snowflake.com/).\n",
    "* Navigate to **AI & ML** -> **Evaluations** from the left navigation menu.\n",
    "* Select “RAG evaluation run on existing data” to view the runs, see detailed traces and compare runs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
