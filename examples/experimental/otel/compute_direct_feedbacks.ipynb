{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Experimental, OTel] Compute Direct Feedbacks and Output as Spans\n",
    "\n",
    "Prerequisites:\n",
    "- That you use Snowflake (and Snowpark)\n",
    "- that you have events (OTel spans)\n",
    "- that you have a table whose schema is compatible with the TruLens-defined Event ORM ([see orm.py](../../../src/core/trulens/core/database/orm.py#L409))\n",
    "- that your database is SQLAlchemy-compatible (we use the function `get_events()`, which is [defined in sqlalchemy.py](../../../src/core/trulens/core/database/sqlalchemy.py#L1640))\n",
    "\n",
    "\n",
    "Alternatively, you may BYO table, as long as we can fetch from it and write to it!\n",
    "- You are welcome and encouraged to contribute new connectors and their corresponding access methods as well via PR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from snowflake.snowpark import Session\n",
    "from trulens.apps.app import TruApp\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.core.feedback import Feedback\n",
    "from trulens.core.feedback.selector import Selector\n",
    "from trulens.core.feedback.selector import Trace\n",
    "from trulens.core.session import TruSession\n",
    "from trulens.feedback.computer import compute_feedback_by_span_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables.\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"\n",
    "\n",
    "# For ease of access.\n",
    "app_name = \"REPLACE_APP_NAME\"\n",
    "app_version = \"REPLACE_APP_VERSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Snowflake via Snowpark.\n",
    "connection_params: Dict[str, str] = {\n",
    "    \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "    # \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "    \"authenticator\": \"externalbrowser\",\n",
    "    \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "    \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "    \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "}\n",
    "snowpark_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TruSession for Snowflake.\n",
    "connector = SnowflakeConnector(\n",
    "    snowpark_session=snowpark_session,\n",
    "    use_account_event_table=False,\n",
    ")\n",
    "tru_session = TruSession(connector=connector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and run evals/feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom feedback.\n",
    "def uses_anthropic(trace: Trace) -> float:\n",
    "    if trace.events is None:\n",
    "        return 0.0\n",
    "    if any(\n",
    "        trace.events[\"processed_content\"].apply(\n",
    "            lambda curr: \"anthropic\" in str(curr)\n",
    "        )\n",
    "    ):\n",
    "        return 1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom feedback function.\n",
    "f_uses_anthropic = Feedback(\n",
    "    uses_anthropic,\n",
    "    name=\"Uses Anthropic\",\n",
    "    description=\"Whether the model uses Anthropic.\",\n",
    ").on({\n",
    "    \"trace\": Selector(\n",
    "        trace_level=True,\n",
    "        span_attribute=\"ai.observability.agent.tool.cortex_analyst.model_name\",\n",
    "    )\n",
    "})\n",
    "\n",
    "all_feedbacks = [f_uses_anthropic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake app to use with TruSession (to satisfy TruApp requirement).\n",
    "class FakeApp:\n",
    "    pass\n",
    "\n",
    "\n",
    "fake_app = FakeApp()\n",
    "tru_app = TruApp(\n",
    "    fake_app,\n",
    "    app_name=app_name,\n",
    "    app_version=app_version,\n",
    "    feedbacks=all_feedbacks,\n",
    ")\n",
    "\n",
    "# Make sure no evaluation threads are running, and reset threads for future compute runs.\n",
    "tru_app.stop_evaluator()\n",
    "\n",
    "tru_app.compute_feedbacks(raise_error_on_no_feedbacks_computed=False)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental\n",
    "\n",
    "Below, we are trying to exploring methods to reduce the amount of setup required in order to get a user to a specific evaluation/feedback computation by circumventing certain abstractions (in this case, `TruApp`).\n",
    "\n",
    "TODOs:\n",
    "- verify that this also exports feedback spans to the table\n",
    "- verify if this shows up in TruLens Streamlit UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Experimental) Directly compute feedbacks without TruApp (to simplify path to feedback computation as much as possible)\n",
    "# Note: the logic here is identical to the TruApp.compute_feedbacks method\n",
    "def directly_compute_feedbacks_for_events(\n",
    "    events: pd.DataFrame,\n",
    "    feedbacks: List[Feedback],\n",
    "    app_name: Optional[str] = None,\n",
    "    app_version: Optional[str] = None,\n",
    ") -> None:\n",
    "    if events is None:\n",
    "        if app_name is None and app_version is None:\n",
    "            raise ValueError(\n",
    "                \"Either events must be provided or both app_name and app_version must be provided\"\n",
    "            )\n",
    "        # Get all events associated with a provided app name and version.\n",
    "        events = connector.get_events(\n",
    "            app_name=app_name, app_version=app_version\n",
    "        )\n",
    "    for feedback in all_feedbacks:\n",
    "        compute_feedback_by_span_group(\n",
    "            events,\n",
    "            feedback.name,\n",
    "            feedback.imp,\n",
    "            feedback.higher_is_better,\n",
    "            feedback.selectors,\n",
    "            feedback.aggregator,\n",
    "            raise_error_on_no_feedbacks_computed=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feedback computation.\n",
    "directly_compute_feedbacks_for_events(\n",
    "    # events=None,\n",
    "    feedbacks=all_feedbacks,\n",
    "    app_name=app_name,\n",
    "    app_version=app_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: verify that this works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Visualize Event table results from a CSV file.\n",
    "# NOTE: You can also download this CSV from the Snowsight UI.\n",
    "df = pd.read_csv(\"REPLACE_PATH_TO_EVENT_TABLE_CSV\")\n",
    "record_attributes = df[\"RECORD_ATTRIBUTES\"]\n",
    "record_ids = set()\n",
    "for curr in record_attributes:\n",
    "    curr = json.loads(curr)\n",
    "    if \"ai.observability.record_id\" in curr:\n",
    "        record_ids.add(curr[\"ai.observability.record_id\"])\n",
    "for record_id in record_ids:\n",
    "    attribute_count = defaultdict(list)\n",
    "    for attributes in record_attributes:\n",
    "        attributes = json.loads(attributes)\n",
    "        if attributes.get(\"ai.observability.record_id\") != record_id:\n",
    "            continue\n",
    "        for k, v in attributes.items():\n",
    "            attribute_count[k].append(v)\n",
    "    print(\"RECORD_ID:\", record_id)\n",
    "    for k, v in attribute_count.items():\n",
    "        if len(v) == 1:\n",
    "            print(f\"{k}: {v}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens-gcbF4QQE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
