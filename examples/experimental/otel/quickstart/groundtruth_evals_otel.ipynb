{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ““ Ground Truth Evaluations with OTel\n",
    "\n",
    "In this quickstart you will create a evaluate a _LangChain_ app using ground truth. Ground truth evaluation can be especially useful during early LLM experiments when you have a small set of example queries that are critical to get right.\n",
    "\n",
    "Ground truth evaluation works by comparing the similarity of an LLM response compared to its matching verified response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add API keys\n",
    "For this quickstart, you will need Open AI keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens trulens-providers-openai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple LLM Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from trulens.core.otel.instrument import instrument\n",
    "\n",
    "oai_client = OpenAI()\n",
    "\n",
    "\n",
    "class APP:\n",
    "    @instrument()\n",
    "    def completion(self, prompt):\n",
    "        completion = (\n",
    "            oai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Please answer the question: {prompt}\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            .choices[0]\n",
    "            .message.content\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "\n",
    "llm_app = APP()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Feedback\n",
    "from trulens.feedback import GroundTruthAgreement\n",
    "from trulens.providers.openai import OpenAI as fOpenAI\n",
    "\n",
    "golden_set = [\n",
    "    {\n",
    "        \"query\": \"who invented the lightbulb?\",\n",
    "        \"expected_response\": \"Thomas Edison\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Â¿quien invento la bombilla?\",\n",
    "        \"expected_response\": \"Thomas Edison\",\n",
    "    },\n",
    "]\n",
    "\n",
    "f_groundtruth = Feedback(\n",
    "    GroundTruthAgreement(golden_set, provider=fOpenAI()).agreement_measure,\n",
    "    name=\"Ground Truth Semantic Agreement\",\n",
    ").on_input_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add trulens as a context manager for llm_app\n",
    "from trulens.apps.app import TruApp\n",
    "\n",
    "tru_app = TruApp(\n",
    "    llm_app, app_name=\"LLM App\", app_version=\"v1\", feedbacks=[f_groundtruth]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrumented query engine can operate as a context manager:\n",
    "with tru_app as recording:\n",
    "    llm_app.completion(\"Â¿quien invento la bombilla?\")\n",
    "    llm_app.completion(\"who invented the lightbulb?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard(app_ids=[tru_app.app_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session=session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_rag_stack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
