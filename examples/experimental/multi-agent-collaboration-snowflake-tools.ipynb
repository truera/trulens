{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
   "metadata": {},
   "source": [
    "# Multi-agent network with Snowflake tools for querying unstructured and structured data\n",
    "\n",
    "Adapted from the original [Langgraph multi-agent notebook example](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/multi-agent-collaboration.ipynb)\n",
    "\n",
    "A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like `gpt-4`, it can be less effective at using many tools. \n",
    "\n",
    "One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create a specialized agent for each task or domain and route tasks to the correct \"expert\". This is an example of a [multi-agent network](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#network) architecture.\n",
    "\n",
    "This notebook (inspired by the paper [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155), by Wu, et. al.) shows one way to do this using LangGraph.\n",
    "\n",
    "This notebook is an extension of the multi-agent-collaboration notebook, showing how access to more tools - particularly with private data can enhance the ability of a data agent.\n",
    "\n",
    "We will slowly build up the agent with more tools, starting with web search, then adding document search via Cortex Search, and lastly replacing document search with a Cortex Agent that can both document search and query snowflake tables in sql via Cortex Analyst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# pip install -U langchain_community langchain_openai langchain_experimental matplotlib langgraph pygraphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e48d5f",
   "metadata": {},
   "source": [
    "## Set keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdc791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# need both API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = (\n",
    "    \"tvly-dev-...\"  # get a free one at https://app.tavily.com/home\n",
    ")\n",
    "\n",
    "# enable OTEL tracing\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = (\n",
    "    \"1\"  # to enable OTEL tracing -> note the Snowsight UI experience for now is limited to PuPr customers, not yet supported for OSS.\n",
    ")\n",
    "\n",
    "# connect to Snowflake for tools, tracing and eval\n",
    "os.environ[\"SNOWFLAKE_ACCOUNT\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_USER\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_USER_PASSWORD\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_DATABASE\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_SCHEMA\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_ROLE\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_WAREHOUSE\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_JWT\"] = \"...\"  # for cortex agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f2f08",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e874860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from langchain.load.dump import dumps\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import START\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command\n",
    "from snowflake.snowpark import Session\n",
    "from trulens.apps.app import TruApp\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.core.otel.instrument import instrument\n",
    "from trulens.core.run import Run\n",
    "from trulens.core.run import RunConfig\n",
    "from trulens.otel.semconv.trace import BASE_SCOPE\n",
    "from trulens.otel.semconv.trace import SpanAttributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb1f53",
   "metadata": {},
   "source": [
    "## Create TruLens/Snowflake Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflake account for trulens\n",
    "snowflake_connection_parameters = {\n",
    "    \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "    \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "    \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "    \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "    \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "}\n",
    "snowpark_session_trulens = Session.builder.configs(\n",
    "    snowflake_connection_parameters\n",
    ").create()\n",
    "\n",
    "\n",
    "trulens_sf_connector = SnowflakeConnector(\n",
    "    snowpark_session=snowpark_session_trulens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"Finance Data Agent Demo\"  # set this app name for your use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a283e-ea04-40c1-b792-f9e5f7d81203",
   "metadata": {},
   "source": [
    "### Define the agent with web search and charting tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(search_max_results: int = 5):\n",
    "    def make_system_prompt(suffix: str) -> str:\n",
    "        return (\n",
    "            \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "            \" Use the provided tools to progress towards answering the question.\"\n",
    "            \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "            \" will help where you left off. Execute what you can to make progress.\"\n",
    "            \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "            \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "            f\"\\n{suffix}\"\n",
    "        )\n",
    "\n",
    "    tavily_tool = TavilySearchResults(max_results=search_max_results)\n",
    "\n",
    "    # Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "    repl = PythonREPL()\n",
    "\n",
    "    @tool\n",
    "    @instrument(\n",
    "        span_type=\"PYTHON_REPL_TOOL\",\n",
    "        attributes={\n",
    "            f\"{BASE_SCOPE}.python_tool_input_code\": \"code\",\n",
    "        },\n",
    "    )\n",
    "    def python_repl_tool(\n",
    "        code: Annotated[\n",
    "            str, \"The python code to execute to generate your chart.\"\n",
    "        ],\n",
    "    ):\n",
    "        \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "        you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "\n",
    "        try:\n",
    "            result = repl.run(code)\n",
    "        except BaseException as e:\n",
    "            return f\"Failed to execute. Error: {repr(e)}\"\n",
    "        result_str = (\n",
    "            f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "        )\n",
    "        return (\n",
    "            result_str\n",
    "            + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "        )\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    def get_next_node(last_message: BaseMessage, goto: str):\n",
    "        if \"FINAL ANSWER\" in last_message.content:\n",
    "            # Any agent decided the work is done\n",
    "            return END\n",
    "        return goto\n",
    "\n",
    "    # Research agent and node\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[tavily_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only do research. You are working with both a chart generator and a chart summarizer colleagues.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"WEB_RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def web_research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_generator\"]]:\n",
    "        result = research_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"web_researcher\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of research agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Chart generator agent and node\n",
    "    # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        [python_repl_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate charts. The generated chart should be save at a local directory at current directory PATH './langgraph_saved_images_snowflaketools/v1' , and this PATH should be sent to your colleague. You are working with a chart summarizer colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_GENERATOR_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.chart_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "        },\n",
    "    )\n",
    "    def chart_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "        result = chart_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_summarizer\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of chart agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Build the image captioning agent.\n",
    "    # If you have any specific image processing tools (e.g., for extracting chart images),\n",
    "    # you can add them in the tools list. For now, we leave it empty.\n",
    "    chart_summary_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[],  # Add image processing tools if available/needed.\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate image captions. You are working with a researcher colleague and a chart generator colleague. \"\n",
    "            + \"Your task is to generate a concise summary for the provided chart image saved at a local PATH, where the PATH should be and only be provided by your chart generator colleague. The summary should be no more than 3 sentences.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.summary_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.summary_node_output\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"NO SUMMARY GENERATED\",\n",
    "        },\n",
    "    )\n",
    "    def chart_summary_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"web_researcher\", END]]:\n",
    "        result = chart_summary_agent.invoke(state)\n",
    "        # After captioning the image, we send control back (e.g., to the researcher)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"web_researcher\")\n",
    "        # Wrap the output message in a HumanMessage to maintain consistency in the conversation flow.\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_summarizer\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\"messages\": result[\"messages\"]},\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    workflow.add_node(\"web_researcher\", web_research_node)\n",
    "    workflow.add_node(\"chart_generator\", chart_node)\n",
    "    workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "\n",
    "    workflow.add_edge(START, \"web_researcher\")\n",
    "    graph = workflow.compile()\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89763c",
   "metadata": {},
   "source": [
    "## Register the agent and create a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe95b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruAgent:\n",
    "    def __init__(self):\n",
    "        self.graph = build_graph()\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def invoke_agent_graph(self, query: str) -> str:\n",
    "        events = self.graph.stream(\n",
    "            {\n",
    "                \"messages\": [(\"user\", query)],\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": 150},\n",
    "        )\n",
    "\n",
    "        # resp_messages = []\n",
    "\n",
    "        for event in events:\n",
    "            messages = list(event.values())[0][\"messages\"]\n",
    "        return (\n",
    "            messages[-1].content\n",
    "            if messages and hasattr(messages[-1], \"content\")\n",
    "            else \"\"\n",
    "        )\n",
    "\n",
    "\n",
    "tru_agent = TruAgent()\n",
    "\n",
    "tru_agent_app = TruApp(\n",
    "    tru_agent,\n",
    "    app_name=APP_NAME,\n",
    "    app_version=\"web search\",\n",
    "    connector=trulens_sf_connector,\n",
    "    main_method=tru_agent.invoke_agent_graph,\n",
    ")\n",
    "\n",
    "st_1 = datetime.datetime.fromtimestamp(time.time()).strftime(\n",
    "    \"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=\"Multi-agent demo run - web search and charting\",\n",
    "    description=\"this is a run with access to web search and charting capabilities\",\n",
    "    dataset_name=\"Research test dataset\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    label=\"langgraph demo\",\n",
    "    dataset_spec={\n",
    "        \"RECORD_ROOT.INPUT\": \"query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "run: Run = tru_agent_app.add_run(run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed35594",
   "metadata": {},
   "source": [
    "## Display the agent's graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c325b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(tru_agent.graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18dba0",
   "metadata": {},
   "source": [
    "## Start the run\n",
    "\n",
    "This runs the agent in batch using the queries in the `input_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_queries = [\n",
    "    \"In 2023, how did the fed funds rate fluctuate? What were the key drivers? Create a line chart that best illustrates this data, including a caption with the key drivers. Once the chart is generated, summarize the chart, and finish.\",\n",
    "    \"What is the total market value of securities by asset class according to SEC filings? Create a bar chart that best illustrates this data. Once the chart is generated, summarize the chart, and finish.\",\n",
    "    \"Who are the top 10 filing managers by number of holdings in the most recent reporting quarter according to SEC filings? Create a bar chart that best illustrates this data. Once the chart is generated, summarize the chart, and finish.\",\n",
    "]\n",
    "\n",
    "user_queries_df = pd.DataFrame(user_queries, columns=[\"query\"])\n",
    "\n",
    "run.start(input_df=user_queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a8c8f",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    time.sleep(3)\n",
    "\n",
    "run.compute_metrics([\"groundedness\", \"context_relevance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580b028",
   "metadata": {},
   "source": [
    "Web is not as precise as it could be if it had access to the acutal minutes. Let's supplement web search with a document search.\n",
    "\n",
    "## Add Cortex Search to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_with_search():\n",
    "    def make_system_prompt(suffix: str) -> str:\n",
    "        return (\n",
    "            \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "            \" Use the provided tools to progress towards answering the question.\"\n",
    "            \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "            \" will help where you left off. Execute what you can to make progress.\"\n",
    "            \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "            \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "            f\"\\n{suffix}\"\n",
    "        )\n",
    "\n",
    "    tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "    # Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "    repl = PythonREPL()\n",
    "\n",
    "    @tool\n",
    "    @instrument(\n",
    "        span_type=\"PYTHON_REPL_TOOL\",\n",
    "        attributes={\n",
    "            f\"{BASE_SCOPE}.python_tool_input_code\": \"code\",\n",
    "        },\n",
    "    )\n",
    "    def python_repl_tool(\n",
    "        code: Annotated[\n",
    "            str, \"The python code to execute to generate your chart.\"\n",
    "        ],\n",
    "    ):\n",
    "        \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "        you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "\n",
    "        try:\n",
    "            result = repl.run(code)\n",
    "        except BaseException as e:\n",
    "            return f\"Failed to execute. Error: {repr(e)}\"\n",
    "        result_str = (\n",
    "            f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "        )\n",
    "        return (\n",
    "            result_str\n",
    "            + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "        )\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "    )\n",
    "\n",
    "    def get_next_node(last_message: BaseMessage, goto: str):\n",
    "        if \"FINAL ANSWER\" in last_message.content:\n",
    "            # Any agent decided the work is done\n",
    "            return END\n",
    "        return goto\n",
    "\n",
    "        # Research agent and node\n",
    "\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[tavily_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only do research. You are working with both a chart generator and a chart summarizer colleagues.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"WEB_RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def web_research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_generator\"]]:\n",
    "        result = research_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"researcher\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of research agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"DOCUMENT_RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def document_research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_generator\"]]:\n",
    "        # Extract the user query from the state.\n",
    "        user_query = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "\n",
    "        # Use Snowflake environment variables already set in the notebook.\n",
    "        CONNECTION_PARAMETERS = {\n",
    "            \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "            \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "            \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "            \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "            \"database\": \"CORTEX_SEARCH_TUTORIAL_DB\",\n",
    "            \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "            \"schema\": \"PUBLIC\",\n",
    "        }\n",
    "        from snowflake.snowpark import Session\n",
    "\n",
    "        session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "        from snowflake.core import Root\n",
    "\n",
    "        root = Root(session)\n",
    "\n",
    "        search_service = (\n",
    "            root.databases[\"CORTEX_SEARCH_TUTORIAL_DB\"]\n",
    "            .schemas[\"PUBLIC\"]\n",
    "            .cortex_search_services[\"FOMC_SEARCH_SERVICE\"]\n",
    "        )\n",
    "\n",
    "        # Execute the Cortex search call.\n",
    "        resp = search_service.search(\n",
    "            query=user_query,\n",
    "            columns=[\"chunk\"],\n",
    "            limit=10,\n",
    "        )\n",
    "        result_json = resp.to_json()\n",
    "\n",
    "        # Create a human message with the Cortex search result.\n",
    "        from langchain_core.messages import HumanMessage\n",
    "\n",
    "        response_message = HumanMessage(\n",
    "            content=f\"Document Research result: {result_json}\",\n",
    "            name=\"document_researcher\",\n",
    "        )\n",
    "\n",
    "        # Return a command to pass control to the chart generator node.\n",
    "        return Command(\n",
    "            update={\"messages\": state[\"messages\"] + [response_message]},\n",
    "            goto=\"chart_generator\",\n",
    "        )\n",
    "\n",
    "    # Chart generator agent and node\n",
    "    # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        [python_repl_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate charts. The generated chart should be saved at a local directory at current directory PATH './langgraph_saved_images_snowflaketools/v2' , and this PATH should be sent to your colleague. You are working with a chart summarizer colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_GENERATOR_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.chart_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "        },\n",
    "    )\n",
    "    def chart_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "        result = chart_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_summarizer\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of chart agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Build the image captioning agent.\n",
    "    # If you have any specific image processing tools (e.g., for extracting chart images),\n",
    "    # you can add them in the tools list. For now, we leave it empty.\n",
    "    chart_summary_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[],  # Add image processing tools if available/needed.\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate image captions. You are working with a researcher colleague and a chart generator colleague. \"\n",
    "            + \"Your task is to generate a concise summary for the provided chart image saved at a local PATH, where the PATH should be and only be provided by your chart generator colleague. The summary should be no more than 3 sentences.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.summary_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.summary_node_output\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"NO SUMMARY GENERATED\",\n",
    "        },\n",
    "    )\n",
    "    def chart_summary_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"document_researcher\", END]]:\n",
    "        result = chart_summary_agent.invoke(state)\n",
    "        # Determine the next node based on the content of the last message\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"document_researcher\")\n",
    "        # Wrap the output message in a HumanMessage to maintain consistency in the conversation flow.\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_summarizer\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\"messages\": result[\"messages\"]},\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Build the workflow graph.\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    workflow.add_node(\"document_researcher\", document_research_node)\n",
    "    workflow.add_node(\"web_researcher\", web_research_node)\n",
    "    workflow.add_node(\"chart_generator\", chart_node)\n",
    "    workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "\n",
    "    # Define transitions between nodes\n",
    "    workflow.set_entry_point(\"document_researcher\")\n",
    "    workflow.add_edge(\"document_researcher\", \"web_researcher\")\n",
    "    workflow.add_edge(\"web_researcher\", \"chart_generator\")\n",
    "    workflow.add_edge(\"document_researcher\", \"chart_generator\")\n",
    "    workflow.add_edge(\"chart_generator\", \"chart_summarizer\")\n",
    "    workflow.add_edge(\"chart_summarizer\", END)\n",
    "    graph = workflow.compile()\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruAgent:\n",
    "    def __init__(self):\n",
    "        self.graph = build_graph_with_search()\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def invoke_agent_graph(self, query: str) -> str:\n",
    "        events = self.graph.stream(\n",
    "            {\n",
    "                \"messages\": [(\"user\", query)],\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": 150},\n",
    "        )\n",
    "\n",
    "        # resp_messages = []\n",
    "\n",
    "        for event in events:\n",
    "            messages = list(event.values())[0][\"messages\"]\n",
    "        return (\n",
    "            messages[-1].content\n",
    "            if messages and hasattr(messages[-1], \"content\")\n",
    "            else \"\"\n",
    "        )\n",
    "\n",
    "\n",
    "tru_agent = TruAgent()\n",
    "\n",
    "tru_agent_app = TruApp(\n",
    "    tru_agent,\n",
    "    app_name=APP_NAME,\n",
    "    app_version=\"doc and web search\",\n",
    "    connector=trulens_sf_connector,\n",
    "    main_method=tru_agent.invoke_agent_graph,\n",
    ")\n",
    "\n",
    "st_1 = datetime.datetime.fromtimestamp(time.time()).strftime(\n",
    "    \"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=\"Multi-agent demo run - document and web search\",\n",
    "    description=\"this is a run with access to cortex search and tavily + qualitative caption\",\n",
    "    dataset_name=\"Research test dataset\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    label=\"langgraph demo\",\n",
    "    dataset_spec={\n",
    "        \"RECORD_ROOT.INPUT\": \"query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "run: Run = tru_agent_app.add_run(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(tru_agent.graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23788cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.start(\n",
    "    input_df=user_queries_df\n",
    ")  # note: if you use MFA, you will need to authenticate with the Duo prompt many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    time.sleep(3)\n",
    "\n",
    "run.compute_metrics([\"groundedness\", \"context_relevance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25d0ad",
   "metadata": {},
   "source": [
    "### Use Cortex Agent to gain access to querying structured SEC data without complicating the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_with_agent():\n",
    "    def make_system_prompt(suffix: str) -> str:\n",
    "        return (\n",
    "            \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "            \" Use the provided tools to progress towards answering the question.\"\n",
    "            \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "            \" will help where you left off. Execute what you can to make progress.\"\n",
    "            \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "            \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "            f\"\\n{suffix}\"\n",
    "        )\n",
    "\n",
    "    tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "    # Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "    repl = PythonREPL()\n",
    "\n",
    "    @tool\n",
    "    @instrument(\n",
    "        span_type=\"PYTHON_REPL_TOOL\",\n",
    "        attributes={\n",
    "            f\"{BASE_SCOPE}.python_tool_input_code\": \"code\",\n",
    "        },\n",
    "    )\n",
    "    def python_repl_tool(\n",
    "        code: Annotated[\n",
    "            str, \"The python code to execute to generate your chart.\"\n",
    "        ],\n",
    "    ):\n",
    "        \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "        you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "\n",
    "        try:\n",
    "            result = repl.run(code)\n",
    "        except BaseException as e:\n",
    "            return f\"Failed to execute. Error: {repr(e)}\"\n",
    "        result_str = (\n",
    "            f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "        )\n",
    "        return (\n",
    "            result_str\n",
    "            + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "        )\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "    )\n",
    "\n",
    "    # Research agent and node\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[tavily_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only do research. You are working with both a chart generator and a chart summarizer colleagues.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"WEB_RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def web_research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_generator\"]]:\n",
    "        result = research_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"researcher\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of research agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    def get_next_node(last_message: BaseMessage, goto: str):\n",
    "        if \"FINAL ANSWER\" in last_message.content:\n",
    "            # Any agent decided the work is done\n",
    "            return END\n",
    "        return goto\n",
    "\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        [python_repl_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate charts. The generated chart should be save at a local directory at current directory PATH './langgraph_saved_images_snowflaketools/v3' , and this PATH should be sent to your colleague. You are working with a chart summarizer colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_GENERATOR_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.chart_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "        },\n",
    "    )\n",
    "    def chart_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "        result = chart_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_summarizer\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of chart agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Build the image captioning agent.\n",
    "    # If you have any specific image processing tools (e.g., for extracting chart images),\n",
    "    # you can add them in the tools list. For now, we leave it empty.\n",
    "    chart_summary_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[],  # Add image processing tools if available/needed.\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate image captions. You are working with a researcher colleague and a chart generator colleague. \"\n",
    "            + \"Your task is to generate a concise summary for the provided chart image saved at a local PATH, where the PATH should be and only be provided by your chart generator colleague. The summary should be no more than 3 sentences.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.summary_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.summary_node_output\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"NO SUMMARY GENERATED\",\n",
    "        },\n",
    "    )\n",
    "    def chart_summary_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"researcher\", END]]:\n",
    "        result = chart_summary_agent.invoke(state)\n",
    "        # Determine the next node based on the content of the last message\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"researcher\")\n",
    "        # Wrap the output message in a HumanMessage to maintain consistency in the conversation flow.\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_summarizer\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\"messages\": result[\"messages\"]},\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    import requests\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"researcher\", END]]:\n",
    "        # Extract the user query from the state.\n",
    "        user_query = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "        # Prepare the payload for the Cortex Agents API.\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4.1-mini\",\n",
    "            \"response_instruction\": \"You are a helpful AI assistant, collaborate with colleagues if needed.\",\n",
    "            \"experimental\": {},\n",
    "            \"tools\": [\n",
    "                {\n",
    "                    \"tool_spec\": {\n",
    "                        \"type\": \"cortex_analyst_text_to_sql\",\n",
    "                        \"name\": \"Analyst1\",\n",
    "                    }\n",
    "                },\n",
    "                {\"tool_spec\": {\"type\": \"cortex_search\", \"name\": \"Search1\"}},\n",
    "            ],\n",
    "            \"tool_resources\": {\n",
    "                \"Analyst1\": {\n",
    "                    \"semantic_model_file\": \"@agents_db.notebooks.semantic_models.sec_filings.yaml\"\n",
    "                },\n",
    "                \"Search1\": {\n",
    "                    \"name\": \"CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.FOMC_SEARCH_SERVICE\"\n",
    "                },\n",
    "            },\n",
    "            \"tool_choice\": {\"type\": \"auto\"},\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": user_query}],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "        # Define the API endpoint and headers.\n",
    "        api_url = \"http://SFDEVREL-SFDEVREL_ENTERPRISE.snowflakecomputing.com/api/v2/cortex/agent:run\"\n",
    "        headers = {\n",
    "            \"Authorization\": os.environ.get(\"SNOWFLAKE_JWT\"),\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(api_url, json=payload, headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                result_text = f\"Failed Cortex Agents API call with status code {response.status_code}: {response.text}\"\n",
    "            else:\n",
    "                data = response.json()\n",
    "                # Aggregate the text content from the response's delta message.\n",
    "                contents = data.get(\"delta\", {}).get(\"content\", [])\n",
    "                result_parts = [\n",
    "                    chunk.get(\"text\", \"\")\n",
    "                    for chunk in contents\n",
    "                    if chunk.get(\"type\") == \"text\"\n",
    "                ]\n",
    "                result_text = \" \".join(result_parts).strip() or str(data)\n",
    "        except Exception as e:\n",
    "            result_text = f\"Exception during API call: {str(e)}\"\n",
    "        from langchain_core.messages import HumanMessage\n",
    "\n",
    "        result_message = HumanMessage(content=result_text, name=\"researcher\")\n",
    "        goto = (\n",
    "            \"researcher\"\n",
    "            if \"FINAL ANSWER\" not in result_message.content\n",
    "            else END\n",
    "        )\n",
    "        return Command(\n",
    "            update={\"messages\": state[\"messages\"] + [result_message]},\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Build the workflow graph\n",
    "    workflow = StateGraph(MessagesState)\n",
    "\n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"researcher\", research_node)\n",
    "    workflow.add_node(\"web_researcher\", web_research_node)\n",
    "    workflow.add_node(\"chart_generator\", chart_node)\n",
    "    workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "\n",
    "    # Entry point\n",
    "    workflow.set_entry_point(\"researcher\")\n",
    "\n",
    "    # Parallel or conditional edge from researcher\n",
    "    workflow.add_edge(\n",
    "        \"researcher\", \"web_researcher\"\n",
    "    )  # optional: could be conditional\n",
    "    workflow.add_edge(\"researcher\", \"chart_generator\")\n",
    "\n",
    "    # Web researcher supplements data before chart\n",
    "    workflow.add_edge(\"web_researcher\", \"chart_generator\")\n",
    "\n",
    "    # After chart is generated, summarize it\n",
    "    workflow.add_edge(\"chart_generator\", \"chart_summarizer\")\n",
    "\n",
    "    # End of flow\n",
    "    workflow.add_edge(\"chart_summarizer\", END)\n",
    "\n",
    "    graph = workflow.compile()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruAgent:\n",
    "    def __init__(self):\n",
    "        self.graph = build_graph_with_agent()\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def invoke_agent_graph(self, query: str) -> str:\n",
    "        events = self.graph.stream(\n",
    "            {\n",
    "                \"messages\": [(\"user\", query)],\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": 150},\n",
    "        )\n",
    "\n",
    "        # resp_messages = []\n",
    "\n",
    "        for event in events:\n",
    "            messages = list(event.values())[0][\"messages\"]\n",
    "        return (\n",
    "            messages[-1].content\n",
    "            if messages and hasattr(messages[-1], \"content\")\n",
    "            else \"\"\n",
    "        )\n",
    "\n",
    "\n",
    "tru_agent = TruAgent()\n",
    "\n",
    "tru_agent_app = TruApp(\n",
    "    tru_agent,\n",
    "    app_name=APP_NAME,\n",
    "    app_version=\"cortex agent + web search + charting\",\n",
    "    connector=trulens_sf_connector,\n",
    "    main_method=tru_agent.invoke_agent_graph,\n",
    ")\n",
    "\n",
    "st_1 = datetime.datetime.fromtimestamp(time.time()).strftime(\n",
    "    \"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=\"Multi-agent demo run - cortex agent + web search + charting\",\n",
    "    description=\"this is a run with access to cortex agent, with internally uses cortex search and analyst as tools\",\n",
    "    dataset_name=\"Research test dataset\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    label=\"langgraph demo\",\n",
    "    dataset_spec={\n",
    "        \"RECORD_ROOT.INPUT\": \"query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "run: Run = tru_agent_app.add_run(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde20b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_queries = [\n",
    "    \"In 2023, how did the fed funds rate fluctuate? What were the key drivers? Create a line chart that best illustrates this data, including a caption with the key drivers. Once the chart is generated, summarize the chart, and finish.\",\n",
    "    \"What is the total market value of securities by asset class according to SEC filings? Create a bar chart that best illustrates this data. Once the chart is generated, summarize the chart, and finish.\",\n",
    "    \"Who are the top 10 filing managers by number of holdings in the most recent reporting quarter according to SEC filings? Create a bar chart that best illustrates this data. Once the chart is generated, summarize the chart, and finish.\",\n",
    "]\n",
    "\n",
    "user_queries_df = pd.DataFrame(user_queries, columns=[\"query\"])\n",
    "\n",
    "run.start(\n",
    "    input_df=user_queries_df\n",
    ")  # note: if you use MFA, you will need to authenticate with the Duo prompt many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    time.sleep(3)\n",
    "\n",
    "run.compute_metrics([\"groundedness\", \"context_relevance\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_rag_stack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
