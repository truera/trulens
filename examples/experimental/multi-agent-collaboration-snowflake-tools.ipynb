{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
   "metadata": {},
   "source": [
    "# Multi-agent network\n",
    "Adapted from the original [Langgraph multi-agent notebook example](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/multi-agent-collaboration.ipynb)\n",
    "\n",
    "A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like `gpt-4`, it can be less effective at using many tools. \n",
    "\n",
    "One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create a specialized agent for each task or domain and route tasks to the correct \"expert\". This is an example of a [multi-agent network](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#network) architecture.\n",
    "\n",
    "This notebook (inspired by the paper [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155), by Wu, et. al.) shows one way to do this using LangGraph.\n",
    "\n",
    "This notebook in particular replaces the standard search tool with two different researchers, one for qualitative research using Cortex Search over federal reserve minutes, and a second for quantitative research using Cortex Analyst over structured sec filings data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# pip install -U langchain_community langchain_openai langchain_experimental matplotlib langgraph pygraphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8581683",
   "metadata": {},
   "source": [
    "####  We use Tavily to perform web search with LLMs for illustration. But any search tool should do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdc791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# need both API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = (\n",
    "    \"1\"  # to enable OTEL tracing -> note the Snowsight UI experience for now is limited to PuPr customers, not yet supported for OSS.\n",
    ")\n",
    "\n",
    "os.environ[\"SNOWFLAKE_ACCOUNT\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_USER\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_USER_PASSWORD\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_DATABASE\"] = \"AGENTS_DB\"\n",
    "os.environ[\"SNOWFLAKE_SCHEMA\"] = \"NOTEBOOKS\"\n",
    "os.environ[\"SNOWFLAKE_ROLE\"] = \"CORTEX_USER_ROLE\"\n",
    "os.environ[\"SNOWFLAKE_WAREHOUSE\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b40de2-5dd4-4d5b-882e-577210723ff4",
   "metadata": {},
   "source": [
    "## Define tools\n",
    "\n",
    "We will also define some tools that our agents will use in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b54c0c-0b09-408b-abc5-86308929afb6",
   "metadata": {},
   "source": [
    "## Create graph\n",
    "\n",
    "Now that we've defined our tools and made some helper functions, will create the individual agents below and tell them how to talk to each other using LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a283e-ea04-40c1-b792-f9e5f7d81203",
   "metadata": {},
   "source": [
    "### Define Agent Nodes\n",
    "\n",
    "We now need to define the nodes.\n",
    "\n",
    "First, we'll create a utility to create a system prompt for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b790ca-9cef-4b22-b469-4b1d5d8424d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from langchain.load.dump import dumps\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command\n",
    "from trulens.core.otel.instrument import instrument\n",
    "from trulens.otel.semconv.trace import BASE_SCOPE\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "\n",
    "\n",
    "def build_graph():\n",
    "    def make_system_prompt(suffix: str) -> str:\n",
    "        return (\n",
    "            \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "            \" Use the provided tools to progress towards answering the question.\"\n",
    "            \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "            \" will help where you left off. Execute what you can to make progress.\"\n",
    "            \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "            \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "            f\"\\n{suffix}\"\n",
    "        )\n",
    "\n",
    "    # Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "    repl = PythonREPL()\n",
    "\n",
    "    @tool\n",
    "    @instrument(\n",
    "        span_type=\"PYTHON_REPL_TOOL\",\n",
    "        attributes={\n",
    "            f\"{BASE_SCOPE}.python_tool_input_code\": \"code\",\n",
    "        },\n",
    "    )\n",
    "    def python_repl_tool(\n",
    "        code: Annotated[\n",
    "            str, \"The python code to execute to generate your chart.\"\n",
    "        ],\n",
    "    ):\n",
    "        \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "        you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "\n",
    "        try:\n",
    "            result = repl.run(code)\n",
    "        except BaseException as e:\n",
    "            return f\"Failed to execute. Error: {repr(e)}\"\n",
    "        result_str = (\n",
    "            f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "        )\n",
    "        return (\n",
    "            result_str\n",
    "            + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "        )\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    def get_next_node(last_message: BaseMessage, goto: str):\n",
    "        if \"FINAL ANSWER\" in last_message.content:\n",
    "            # Any agent decided the work is done\n",
    "            return END\n",
    "        return goto\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"QUALITATIVE_RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.qualitative_research_node_input\": args[0][\n",
    "                \"messages\"\n",
    "            ][-1].content,\n",
    "            f\"{BASE_SCOPE}.qualitative_research_node_response\": ret.update[\n",
    "                \"messages\"\n",
    "            ][-1].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def qualitative_research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_generator\"]]:\n",
    "        # Extract the user query from the state.\n",
    "        user_query = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "\n",
    "        # Use Snowflake environment variables already set in the notebook.\n",
    "        CONNECTION_PARAMETERS = {\n",
    "            \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "            \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "            \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "            \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "            \"database\": \"CORTEX_SEARCH_TUTORIAL_DB\",\n",
    "            \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "            \"schema\": \"PUBLIC\",\n",
    "        }\n",
    "        from snowflake.snowpark import Session\n",
    "\n",
    "        session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "        from snowflake.core import Root\n",
    "\n",
    "        root = Root(session)\n",
    "\n",
    "        # Replace the placeholders with your actual Cortex search service details.\n",
    "        my_service = (\n",
    "            root.databases[\"CORTEX_SEARCH_TUTORIAL_DB\"]\n",
    "            .schemas[\"PUBLIC\"]\n",
    "            .cortex_search_services[\"FOMC_SEARCH_SERVICE\"]\n",
    "        )\n",
    "\n",
    "        # Execute the Cortex search call.\n",
    "        resp = my_service.search(\n",
    "            query=user_query,\n",
    "            columns=[\"chunk\"],\n",
    "            limit=20,\n",
    "        )\n",
    "        result_json = resp.to_json()\n",
    "\n",
    "        # Create a human message with the Cortex search result.\n",
    "        from langchain_core.messages import HumanMessage\n",
    "\n",
    "        response_message = HumanMessage(\n",
    "            content=f\"Cortex Search result: {result_json}\",\n",
    "            name=\"qualitative_researcher\",\n",
    "        )\n",
    "\n",
    "        # Return a command to pass control to the chart generator node.\n",
    "        return Command(\n",
    "            update={\"messages\": state[\"messages\"] + [response_message]},\n",
    "            goto=\"chart_generator\",\n",
    "        )\n",
    "\n",
    "    # Chart generator agent and node\n",
    "    # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        [python_repl_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate charts. The generated chart should be save at a local directory at current directory PATH './langgraph_saved_images' , and this PATH should be sent to your colleague. You are working with a chart summarizer colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_GENERATOR_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.chart_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "        },\n",
    "    )\n",
    "    def chart_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "        result = chart_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_summarizer\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of chart agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Build the image captioning agent.\n",
    "    # If you have any specific image processing tools (e.g., for extracting chart images),\n",
    "    # you can add them in the tools list. For now, we leave it empty.\n",
    "    chart_summary_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[],  # Add image processing tools if available/needed.\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate image captions. You are working with a researcher colleague and a chart generator colleague. \"\n",
    "            + \"Your task is to generate a concise summary for the provided chart image saved at a local PATH, where the PATH should be and only be provided by your chart generator colleague. The summary should be no more than 3 sentences.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.summary_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.summary_node_output\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"NO SUMMARY GENERATED\",\n",
    "        },\n",
    "    )\n",
    "    def chart_summary_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"qualitative_researcher\", END]]:\n",
    "        result = chart_summary_agent.invoke(state)\n",
    "        # Determine the next node based on the content of the last message\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"qualitative_researcher\")\n",
    "        # Wrap the output message in a HumanMessage to maintain consistency in the conversation flow.\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_summarizer\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\"messages\": result[\"messages\"]},\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    import requests\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"QUANTITATIVE_RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.quantitative_research_node_input\": args[0][\n",
    "                \"messages\"\n",
    "            ][-1].content,\n",
    "            f\"{BASE_SCOPE}.quantitative_research_node_response\": ret.update[\n",
    "                \"messages\"\n",
    "            ][-1].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def quantitative_research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"qualitative_researcher\", END]]:\n",
    "        # Extract the user query from the state.\n",
    "        user_query = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "        # Prepare the payload for Cortex Analyst API.\n",
    "        payload = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": user_query}],\n",
    "                }\n",
    "            ],\n",
    "            \"semantic_model_file\": \"@agents_db.notebooks.semantic_models.sec_filings.yaml\",\n",
    "        }\n",
    "        # Define the API endpoint and headers (update these values as needed).\n",
    "        api_url = os.environ.get(\n",
    "            \"CORES_ANALYST_URL\",\n",
    "            \"http://localhost:8000/api/v2/cortex/analyst/message\",\n",
    "        )\n",
    "        headers = {\n",
    "            \"Authorization\": os.environ.get(\n",
    "                \"CORES_ANALYST_AUTH_TOKEN\", \"Bearer YOUR_TOKEN_HERE\"\n",
    "            ),\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(api_url, json=payload, headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                result_text = f\"Failed Cortex Analyst API call with status code {response.status_code}: {response.text}\"\n",
    "            else:\n",
    "                data = response.json()\n",
    "                contents = data.get(\"message\", {}).get(\"content\", [])\n",
    "                result_text = \" \".join([\n",
    "                    c.get(\"text\", c.get(\"statement\", \"\")) for c in contents\n",
    "                ])\n",
    "        except Exception as e:\n",
    "            result_text = f\"Exception during API call: {str(e)}\"\n",
    "        from langchain_core.messages import HumanMessage\n",
    "\n",
    "        result_message = HumanMessage(\n",
    "            content=result_text, name=\"quantitative_researcher\"\n",
    "        )\n",
    "        goto = (\n",
    "            \"qualitative_researcher\"\n",
    "            if \"FINAL ANSWER\" not in result_message.content\n",
    "            else END\n",
    "        )\n",
    "        return Command(\n",
    "            update={\"messages\": state[\"messages\"] + [result_message]}, goto=goto\n",
    "        )\n",
    "\n",
    "    # Build the workflow graph.\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    workflow.add_node(\"qualitative_researcher\", qualitative_research_node)\n",
    "    workflow.add_node(\"quantitative_researcher\", quantitative_research_node)\n",
    "    workflow.add_node(\"chart_generator\", chart_node)\n",
    "    workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "\n",
    "    # Define transitions between nodes\n",
    "    workflow.set_entry_point(\"qualitative_researcher\")\n",
    "    workflow.add_edge(\"qualitative_researcher\", \"quantitative_researcher\")\n",
    "    workflow.add_edge(\"quantitative_researcher\", \"chart_generator\")\n",
    "    workflow.add_edge(\"chart_generator\", \"chart_summarizer\")\n",
    "    workflow.add_edge(\"chart_summarizer\", END)\n",
    "    graph = workflow.compile()\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a707f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "from snowflake.snowpark import Session\n",
    "from trulens.apps.app import TruApp\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.core.run import Run\n",
    "from trulens.core.run import RunConfig\n",
    "\n",
    "# Snowflake account for trulens\n",
    "\n",
    "\n",
    "snowflake_connection_parameters = {\n",
    "    \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "    \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "    \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "    \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "    \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "}\n",
    "snowpark_session_trulens = Session.builder.configs(\n",
    "    snowflake_connection_parameters\n",
    ").create()\n",
    "\n",
    "\n",
    "trulens_sf_connector = SnowflakeConnector(\n",
    "    snowpark_session=snowpark_session_trulens\n",
    ")\n",
    "\n",
    "\n",
    "class TruAgent:\n",
    "    def __init__(self, max_results=3):\n",
    "        self.graph = build_graph()\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def invoke_agent_graph(self, query: str) -> str:\n",
    "        events = self.graph.stream(\n",
    "            {\n",
    "                \"messages\": [(\"user\", query)],\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": 10},\n",
    "        )\n",
    "\n",
    "        # resp_messages = []\n",
    "\n",
    "        for event in events:\n",
    "            messages = list(event.values())[0][\"messages\"]\n",
    "        return (\n",
    "            messages[-1].content\n",
    "            if messages and hasattr(messages[-1], \"content\")\n",
    "            else \"\"\n",
    "        )\n",
    "\n",
    "\n",
    "tru_agent = TruAgent(max_results=1)\n",
    "\n",
    "APP_NAME = \"Financial Research Agent\"\n",
    "\n",
    "tru_agent_app = TruApp(\n",
    "    tru_agent,\n",
    "    app_name=APP_NAME,\n",
    "    app_version=\"updated graph - search and analyst - lower recursion limit\",\n",
    "    connector=trulens_sf_connector,\n",
    "    main_method=tru_agent.invoke_agent_graph,\n",
    ")\n",
    "\n",
    "st_1 = datetime.datetime.fromtimestamp(time.time()).strftime(\n",
    "    \"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=\"Multi-agent demo run - search and analyst graph - lower recursion limit\",\n",
    "    description=\"this is a run with access to cortex search and cortex analyst, along with chart and summarization capabilities\",\n",
    "    dataset_name=\"Research test dataset\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    label=\"langgraph demo\",\n",
    "    dataset_spec={\n",
    "        \"RECORD_ROOT.INPUT\": \"query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "run: Run = tru_agent_app.add_run(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df451ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(tru_agent.graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_queries = [\n",
    "    \"In 2023, how did the fed funds rate fluctuate? What were the key drivers?\",\n",
    "    \"What were the core drivers of inflation in 2023? How did the federal reserve respond?\",\n",
    "    \"What is the total market value of securities by asset class according to SEC filings? Create a bar chart that best illustrates this data. Once the chart is generated, summarize the chart, and finish.\",\n",
    "    \"Who are the top 10 filing managers by number of holdings in the most recent reporting quarter according to SEC filings? Create a bar chart that best illustrates this data. Once the chart is generated, summarize the chart, and finish.\",\n",
    "]\n",
    "\n",
    "user_queries_df = pd.DataFrame(user_queries, columns=[\"query\"])\n",
    "\n",
    "run.start(\n",
    "    input_df=user_queries_df\n",
    ")  # note: if you use MFA, you will need to authenticate with the Duo prompt that appears many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3568917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a8efb",
   "metadata": {},
   "source": [
    "### Compute metrics:\n",
    "Here, we compute context relevance for the retrieval quality of the Tavily web search tool, and groundedness for the summaries generated from the charts to evaluate whether the text summaries are supported by the content in the graphical charts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5258c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.compute_metrics([\"groundedness\", \"context_relevance\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_rag_stack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
