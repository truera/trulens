{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
   "metadata": {},
   "source": [
    "# Multi-agent network with Snowflake tools for querying unstructured and structured data\n",
    "\n",
    "Adapted from the original [Langgraph multi-agent notebook example](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/multi-agent-collaboration.ipynb)\n",
    "\n",
    "A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like `gpt-4`, it can be less effective at using many tools. \n",
    "\n",
    "One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create a specialized agent for each task or domain and route tasks to the correct \"expert\". This is an example of a [multi-agent network](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#network) architecture.\n",
    "\n",
    "This notebook (inspired by the paper [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155), by Wu, et. al.) shows one way to do this using LangGraph.\n",
    "\n",
    "This notebook is an extension of the multi-agent-collaboration notebook, showing how access to more tools - particularly with private data can enhance the ability of a data agent.\n",
    "\n",
    "We will slowly build up the agent with more tools, starting with web search, then adding document search via Cortex Search, and lastly replacing document search with a Cortex Agent that can both document search and query snowflake tables in sql via Cortex Analyst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# pip install -U langchain_community langchain_openai langchain_experimental matplotlib langgraph pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c0e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"Finance Research Agent with Data 101\"  # set this app name for your use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e48d5f",
   "metadata": {},
   "source": [
    "## Set keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61bdc791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# need both API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"tvly-dev-...\"  # get a free one at https://app.tavily.com/home\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = (\n",
    "    \"1\"  # to enable OTEL tracing -> note the Snowsight UI experience for now is limited to PuPr customers, not yet supported for OSS.\n",
    ")\n",
    "\n",
    "os.environ[\"SNOWFLAKE_ACCOUNT\"] = \"SFDEVREL_ENTERPRISE\"\n",
    "os.environ[\"SNOWFLAKE_USER\"] = \"JREINI\"\n",
    "os.environ[\"SNOWFLAKE_USER_PASSWORD\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_DATABASE\"] = \"AGENTS_DB\"\n",
    "os.environ[\"SNOWFLAKE_SCHEMA\"] = \"NOTEBOOKS\"\n",
    "os.environ[\"SNOWFLAKE_ROLE\"] = \"CORTEX_USER_ROLE\"\n",
    "os.environ[\"SNOWFLAKE_WAREHOUSE\"] = \"CONTAINER_RUNTIME_WH\"\n",
    "os.environ[\"SNOWFLAKE_JWT\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f2f08",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e874860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from typing import Annotated, Literal\n",
    "import os, textwrap\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "import uuid\n",
    "import re\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.load.dump import dumps\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import START\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command\n",
    "from snowflake.snowpark import Session\n",
    "from trulens.apps.app import TruApp\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.core.otel.instrument import instrument\n",
    "from trulens.core.run import Run\n",
    "from trulens.core.run import RunConfig\n",
    "from trulens.otel.semconv.trace import BASE_SCOPE\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "from trulens.providers.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb1f53",
   "metadata": {},
   "source": [
    "## Create TruLens/Snowflake Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflake account for trulens\n",
    "snowflake_connection_parameters = {\n",
    "    \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "    \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "    \"database\": os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    \"schema\": os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "    \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "    \"warehouse\": os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "}\n",
    "snowpark_session_trulens = Session.builder.configs(\n",
    "    snowflake_connection_parameters\n",
    ").create()\n",
    "\n",
    "\n",
    "trulens_sf_connector = SnowflakeConnector(\n",
    "    snowpark_session=snowpark_session_trulens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a283e-ea04-40c1-b792-f9e5f7d81203",
   "metadata": {},
   "source": [
    "### Define the agent with web search and charting tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(search_max_results: int = 5):\n",
    "    def make_system_prompt(suffix: str) -> str:\n",
    "        return (\n",
    "            \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "            \" Use the provided tools to progress towards answering the question.\"\n",
    "            \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "            \" will help where you left off. Execute what you can to make progress.\"\n",
    "            \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "            \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "            f\"\\n{suffix}\"\n",
    "        )\n",
    "\n",
    "    tavily_tool = TavilySearchResults(max_results=search_max_results)\n",
    "\n",
    "    tool_registry = {str(uuid.uuid4()): tavily_tool}\n",
    "\n",
    "    # Index tool descriptions in a vector store for semantic tool retrieval\n",
    "    tool_documents = [\n",
    "        Document(\n",
    "            page_content=tavily_tool.description,\n",
    "            id=tid,\n",
    "            metadata={\"tool_name\": tavily_tool.name},\n",
    "        )\n",
    "        for tid, tavily_tool in tool_registry.items()\n",
    "    ]\n",
    "    vector_store = InMemoryVectorStore(embedding=OpenAIEmbeddings())\n",
    "    vector_store.add_documents(tool_documents)\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"SELECT_TOOLS\",\n",
    "        attributes=lambda ret, exc, *args, **kw: {\n",
    "            # ---- state as JSON-text (OTLP needs a scalar) -----------------\n",
    "            f\"{BASE_SCOPE}.select_tools_input_state\":\n",
    "                json.dumps(                                      # ← turns dict → str\n",
    "                    {\n",
    "                        **{k: v for k, v in args[0].items() if k != \"messages\"},\n",
    "                        \"messages\": [\n",
    "                            {\"type\": m.__class__.__name__, \"content\": m.content}\n",
    "                            if hasattr(m, \"content\")             # BaseMessage subclasses\n",
    "                            else m                               # already JSON-friendly\n",
    "                            for m in args[0].get(\"messages\", [])\n",
    "                        ],\n",
    "                    }\n",
    "                ),\n",
    "\n",
    "            # ---- selected tool IDs as a simple comma-separated string -----\n",
    "            f\"{BASE_SCOPE}.selected_tool_ids\":\n",
    "                \", \".join(ret.get(\"selected_tools\", [])) if isinstance(ret, dict) else \"\",\n",
    "        },\n",
    "    )\n",
    "    def select_tools(state: MessagesState):\n",
    "        \"\"\"\n",
    "        This tool is used to select tools based on the user query.\n",
    "        The tool uses the vector store to find the most semantically similar tool to the user query.\n",
    "        The tool then returns the selected tool's ID.\"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "        last_user_query = messages[-1][\"content\"] if isinstance(messages[-1], dict) \\\n",
    "                        else messages[-1].content\n",
    "        \n",
    "        print(last_user_query)\n",
    "\n",
    "        docs = vector_store.similarity_search(last_user_query)\n",
    "        return {\"selected_tools\": [doc.id for doc in docs]}\n",
    "\n",
    "\n",
    "    # Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "    repl = PythonREPL()\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "    def ensure_chart_dir():\n",
    "        target_dir = \"./langgraph_saved_images_snowflaketools/v1\"\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        return target_dir\n",
    "\n",
    "    \n",
    "    @tool\n",
    "    @instrument(\n",
    "        span_type=\"PYTHON_REPL_TOOL\",\n",
    "        attributes={\n",
    "            f\"{BASE_SCOPE}.python_tool_input_code\": \"code\",\n",
    "        },\n",
    "    )\n",
    "    def python_repl_tool(code: str):\n",
    "        \"\"\"\n",
    "        Run arbitrary Python, grab the CURRENT matplotlib figure (if any),\n",
    "        save it to ./langgraph_saved_images_snowflaketools/v1/chart_<uuid>.png,\n",
    "        and return a first-line `CHART_PATH=…`.\n",
    "        \"\"\"\n",
    "        import matplotlib\n",
    "        matplotlib.use(\"Agg\")                 # headless safety\n",
    "        import matplotlib.pyplot as plt\n",
    "        import uuid, os, textwrap, io, contextlib, sys\n",
    "\n",
    "        # ------------------ run user code & capture stdout ------------------\n",
    "        repl.run(code)\n",
    "\n",
    "        # ------------------ locate a figure (if generated) ------------------\n",
    "        fig = plt.gcf()\n",
    "        has_axes = bool(fig.axes)            # True if something was plotted\n",
    "\n",
    "        # ------------------ always save if we have a figure -----------------\n",
    "        chart_path = \"\"\n",
    "        if has_axes:\n",
    "            target_dir = \"./langgraph_saved_images_snowflaketools/v1\"\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "            chart_path = os.path.join(\n",
    "                target_dir, f\"chart_{uuid.uuid4().hex}.png\"\n",
    "            )\n",
    "            fig.savefig(chart_path, format=\"png\")\n",
    "            plt.close(fig)\n",
    "\n",
    "        # ------------------ tool result (1st line = CHART_PATH) -------------\n",
    "        return (\n",
    "            f\"CHART_PATH={chart_path if chart_path else 'NONE'}\\n\"\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    def get_next_node(last_message: BaseMessage, goto: str):\n",
    "        if \"FINAL ANSWER\" in last_message.content:\n",
    "            # Any agent decided the work is done\n",
    "            return END\n",
    "        return goto\n",
    "\n",
    "    # Research agent and node\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[tavily_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only do research. You are working with both a chart generator and a chart summarizer colleagues.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def research_agent_node(state: MessagesState) -> Command[Literal[\"chart_generator\"]]:\n",
    "        \"\"\"\n",
    "        This function represents the research agent node in the workflow.\n",
    "        It selects tools based on the user's query and invokes the research agent\n",
    "        to perform the research task. If tools are selected, they are bound to the\n",
    "        LLM, and a new research agent is created with the selected tools. Otherwise,\n",
    "        the default research agent is used.\n",
    "\n",
    "        The function determines the next node in the workflow based on the content\n",
    "        of the last message. If the message contains \"FINAL ANSWER,\" the workflow\n",
    "        ends. Otherwise, it transitions to the chart generator node.\n",
    "        \"\"\"\n",
    "        selected_ids = state.get(\"selected_tools\", [])\n",
    "        if selected_ids:\n",
    "            selected_tools = [tool_registry[tid] for tid in selected_ids]\n",
    "            # Bind the selected tools to the LLM\n",
    "            bound_llm = llm.bind_tools(selected_tools)\n",
    "            # Create a research agent using the bound LLM and same prompt\n",
    "            bound_research_agent = create_react_agent(\n",
    "                bound_llm,\n",
    "                tools=[],  # tools are already bound\n",
    "                prompt=research_agent.prompt,\n",
    "            )\n",
    "            result = bound_research_agent.invoke(state)\n",
    "        else:\n",
    "            result = research_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
    "        result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "        return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
    "\n",
    "    # Chart generator agent and node\n",
    "    # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        [python_repl_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate charts. The generated chart should be save at a local directory at current directory PATH './langgraph_saved_images_snowflaketools/v1' , and this PATH should be sent to your colleague. You are working with a chart summarizer colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    def extract_chart_path(text: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Returns the first CHART_PATH=… found in `text`, else None.\n",
    "        \"\"\"\n",
    "        m = re.search(r\"^CHART_PATH=(.+)$\", text, flags=re.MULTILINE)\n",
    "        return m.group(1).strip() if m else None\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_GENERATOR_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.chart_node_response\": (\n",
    "                ret.update[\"messages\"][-1].content if ret and hasattr(ret, \"update\") and ret.update else \"No update response\"\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    def chart_node(state: MessagesState) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "        \"\"\"\n",
    "        This function represents the chart generation node in the workflow.\n",
    "        It invokes the chart generation agent to create a chart based on the provided state.\n",
    "        The generated chart is saved to a specified directory, and its path is extracted from the tool messages.\n",
    "        A summary prompt is then prepared to send to the chart summarizer agent.\n",
    "        If the chart path is not found, the workflow ends; otherwise, it transitions to the chart summarizer node.\n",
    "        \"\"\"\n",
    "        # 1. let the agent run\n",
    "        result = chart_agent.invoke(state)\n",
    "\n",
    "        # 2. try to grab a path from any ToolMessage\n",
    "        chart_path = None\n",
    "        for msg in result[\"messages\"]:\n",
    "            if isinstance(msg, ToolMessage):\n",
    "                chart_path = extract_chart_path(msg.content)\n",
    "                if chart_path and chart_path.upper() != \"NONE\":\n",
    "                    break\n",
    "\n",
    "        print(f\"Chart Path: {chart_path!r}\")\n",
    "\n",
    "        # 3. If no valid chart path, return to researcher with error message\n",
    "        if not chart_path or chart_path.upper() == \"NONE\":\n",
    "            result[\"messages\"].append(\n",
    "                HumanMessage(\n",
    "                    content=\"Failed to generate chart. Please try again with different parameters.\",\n",
    "                    name=\"chart_generator\"\n",
    "                )\n",
    "            )\n",
    "            return Command(update={\"messages\": result[\"messages\"]}, goto=\"researcher\")\n",
    "            \n",
    "        # 4. Add chart path to messages for downstream nodes\n",
    "        result[\"messages\"].append(\n",
    "            HumanMessage(\n",
    "                content=f\"CHART_PATH={chart_path}\",\n",
    "                name=\"chart_generator\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 5. Add summary prompt\n",
    "        summary_prompt = (\n",
    "            \"Please summarise the chart in ≤ 3 sentences.\"\n",
    "        )\n",
    "        result[\"messages\"].append(\n",
    "            HumanMessage(name=\"chart_generator\", content=summary_prompt)\n",
    "        )\n",
    "\n",
    "        return Command(update={\"messages\": result[\"messages\"]}, goto=\"chart_summarizer\")\n",
    "\n",
    "\n",
    "    # Build the image captioning agent.\n",
    "    # If you have any specific image processing tools (e.g., for extracting chart images),\n",
    "    # you can add them in the tools list. For now, we leave it empty.\n",
    "    chart_summary_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[],  # Add image processing tools if available/needed.\n",
    "        prompt=make_system_prompt(\n",
    "                    \"\"\"You can only generate charts with Python.\n",
    "        ALWAYS:\n",
    "        1. Save the figure as PNG to './langgraph_saved_images_snowflaketools/v1'.\n",
    "        2. Do NOT display the image inline.\n",
    "        3. End your reply with `CHART_PATH=<absolute-or-relative-path>`.\n",
    "        You are working with a summariser colleague.\"\"\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    reflection_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"user_query\", \"chart_summary\"],\n",
    "        template=\"\"\"\\\n",
    "        You are an AI assistant tasked with reflecting on the quality of a chart summary. The user has asked the following question:\n",
    "        \"{user_query}\"\n",
    "\n",
    "        You are given the following chart summary:\n",
    "        \"{chart_summary}\"\n",
    "\n",
    "        Your task is to evaluate how well the chart summary answers the user's question. Consider the following:\n",
    "        - Does the summary capture the **key insights** and trends from the chart, even if in a more general form?\n",
    "        - Does it provide **adequate context** to address the user's query, even if it's not exhaustive?\n",
    "        - If the summary provides some context but could benefit from more details, consider it sufficient for now unless significant details are missing.\n",
    "\n",
    "        If the summary **generally** addresses the question, respond with 'Task complete'. If the summary **lacks significant** details or clarity, then respond with 'Refine summary'. Avoid being overly critical unless the summary completely misses key elements necessary to answer the query.\n",
    "\n",
    "        Please provide your answer in a **concise and encouraging** manner.\n",
    "        \"\"\"\n",
    "            )\n",
    "\n",
    "    # Create the chain using the prompt template and the LLM (ChatOpenAI)\n",
    "    reflection_chain = (\n",
    "        reflection_prompt_template | llm\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_REFLECTION\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_summary_reflection_input_user_query\": args[0],\n",
    "            f\"{BASE_SCOPE}.chart_summary_reflection_input_chart_summary\": args[1],\n",
    "            f\"{BASE_SCOPE}.chart_summary_reflection_response\": ret,\n",
    "        },\n",
    ")\n",
    "    def perform_reflection(user_query: str, chart_summary: str) -> str:\n",
    "        \"\"\"\n",
    "        This function uses an LLM to reflect on the quality of a chart summary\n",
    "        and determine if the task is complete or requires further refinement.\n",
    "        \"\"\"\n",
    "        # Call the chain with the user query and chart summary\n",
    "        reflection_result = reflection_chain.invoke({\"user_query\": user_query, \"chart_summary\": chart_summary})\n",
    "        return reflection_result.content\n",
    "\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.summary_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.summary_node_output\": (\n",
    "                ret.update[\"messages\"][-1].content\n",
    "                if hasattr(ret, \"update\") else \"NO SUMMARY GENERATED\"\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    def chart_summary_node(state: MessagesState) -> Command[Literal[END]]:\n",
    "        \"\"\"\n",
    "        This function represents the chart summarizer node in the workflow graph.\n",
    "        It uses the chart summary agent to generate a concise summary for the chart image\n",
    "        provided by the chart generator node. The summary is limited to three sentences\n",
    "        and is based on the chart image saved at the specified local path.\n",
    "        \"\"\"\n",
    "        # 1. Extract chart path from messages\n",
    "        chart_path = None\n",
    "        for msg in state[\"messages\"]:\n",
    "            if isinstance(msg, ToolMessage) and \"CHART_PATH=\" in msg.content:\n",
    "                chart_path = extract_chart_path(msg.content)\n",
    "                if chart_path and chart_path.upper() != \"NONE\":\n",
    "                    break\n",
    "\n",
    "        print(f\"Chart Path in Chart Summary Node: {chart_path!r}\")\n",
    "\n",
    "        # 2. If no valid chart path, return to researcher with error message\n",
    "        if not chart_path or chart_path.upper() == \"NONE\":\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(\n",
    "                            content=\"No valid chart was generated. Please try again.\",\n",
    "                            name=\"chart_summarizer\"\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                goto=\"researcher\"\n",
    "            )\n",
    "\n",
    "        # 3. Run the summarizer\n",
    "        result = chart_summary_agent.invoke(state)\n",
    "        if not result or \"messages\" not in result:\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(\n",
    "                            content=\"Failed to generate chart summary. Please try again.\",\n",
    "                            name=\"chart_summarizer\"\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                goto=\"researcher\"\n",
    "            )\n",
    "\n",
    "        # 4. Add reflection\n",
    "        user_query = state[\"messages\"][-2].content\n",
    "        chart_summary = result[\"messages\"][-1].content\n",
    "        reflection = perform_reflection(user_query, chart_summary)\n",
    "\n",
    "        # 5. Determine next node\n",
    "        goto = END if \"Task complete\" in reflection or \"FINAL ANSWER\" in reflection else \"researcher\"\n",
    "        result[\"messages\"][-1] = HumanMessage(name=\"chart_summarizer\", content=chart_summary)\n",
    "\n",
    "        return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
    "\n",
    "\n",
    "\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    workflow.add_node(\"select_tools\", select_tools)\n",
    "    workflow.add_node(\"research_agent\", research_agent_node)\n",
    "    workflow.add_node(\"chart_generator\", chart_node)\n",
    "    workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "\n",
    "    # Update transitions: begin with tool selection then go to research agent.\n",
    "    workflow.add_edge(START, \"select_tools\")\n",
    "    workflow.add_edge(\"select_tools\", \"research_agent\")\n",
    "    workflow.add_edge(\"research_agent\", \"chart_generator\")\n",
    "    workflow.add_edge(\"chart_generator\", \"chart_summarizer\")\n",
    "    # workflow.add_edge(\"chart_summarizer\", \"select_tools\")\n",
    "    workflow.add_edge(\"chart_summarizer\", END)\n",
    "    graph = workflow.compile()\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89763c",
   "metadata": {},
   "source": [
    "## Register the agent and create a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe95b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruAgent:\n",
    "    def __init__(self):\n",
    "        self.graph = build_graph()\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def invoke_agent_graph(self, query: str) -> str:\n",
    "        state = {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n",
    "        events = self.graph.stream(\n",
    "            state,\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": 150},\n",
    "        )\n",
    "\n",
    "        # resp_messages = []\n",
    "\n",
    "        for event in events:\n",
    "            node_name, payload = next(iter(event.items()))\n",
    "            if not payload:                     # <- skip empty payloads\n",
    "                continue\n",
    "\n",
    "            messages = payload.get(\"messages\")\n",
    "            if not messages:\n",
    "                continue\n",
    "        return (\n",
    "            messages[-1].content\n",
    "            if messages and hasattr(messages[-1], \"content\")\n",
    "            else \"\"\n",
    "        )\n",
    "\n",
    "\n",
    "tru_agent = TruAgent()\n",
    "\n",
    "tru_agent_app = TruApp(\n",
    "    tru_agent,\n",
    "    app_name=APP_NAME,\n",
    "    app_version=\"web search\",\n",
    "    connector=trulens_sf_connector,\n",
    "    main_method=tru_agent.invoke_agent_graph,\n",
    ")\n",
    "\n",
    "st_1 = datetime.datetime.fromtimestamp(time.time()).strftime(\n",
    "    \"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=\"Multi-agent demo run - web search and charting\",\n",
    "    description=\"this is a run with access to web search and charting capabilities\",\n",
    "    dataset_name=\"Research test dataset\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    label=\"langgraph demo\",\n",
    "    dataset_spec={\n",
    "        \"RECORD_ROOT.INPUT\": \"query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "run: Run = tru_agent_app.add_run(run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed35594",
   "metadata": {},
   "source": [
    "## Display the agent's graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c325b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(tru_agent.graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18dba0",
   "metadata": {},
   "source": [
    "## Start the run\n",
    "\n",
    "This runs the agent in batch using the queries in the `input_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_queries = [\n",
    "    \"In 2023, how did the fed funds rate fluctuate? What were the key drivers? Create a line chart that best illustrates this data, including a caption with the key drivers.\",\n",
    "    \"What is the total market value of securities by asset class according to SEC filings? Create a bar chart that best illustrates this data.\",\n",
    "    \"Who are the top 10 filing managers by number of holdings in the most recent reporting quarter according to SEC filings?\",\n",
    "]\n",
    "\n",
    "user_queries_df = pd.DataFrame(user_queries, columns=[\"query\"])\n",
    "\n",
    "run.start(input_df=user_queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a8c8f",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    time.sleep(3)\n",
    "\n",
    "run.compute_metrics([\"groundedness\", \"context_relevance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580b028",
   "metadata": {},
   "source": [
    "Web is not as precise as it could be if it had access to private minutes data. Let's supplement web search with a document search.\n",
    "\n",
    "## Add Cortex Search to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765e30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.core import Root\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CortexSearchArgs(BaseModel):\n",
    "    query: str\n",
    "\n",
    "\n",
    "# --- Define a new Cortex Search Tool to perform document search via Cortex ---\n",
    "class CortexSearchTool(StructuredTool):\n",
    "    name: str = \"CortexSearch\"\n",
    "    description: str = \"Searches documents using Cortex Search via Snowflake.\"\n",
    "    args_schema: type[BaseModel] = CortexSearchArgs\n",
    "    session: Session\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Executes a search query using the Cortex Search service in Snowflake.\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query string.\n",
    "\n",
    "        Returns:\n",
    "            str: A JSON string containing the search results, limited to 10 entries.\n",
    "        \"\"\"\n",
    "        root = Root(self.session)\n",
    "        search_service = (\n",
    "            root.databases[\"CORTEX_SEARCH_TUTORIAL_DB\"]\n",
    "            .schemas[\"PUBLIC\"]\n",
    "            .cortex_search_services[\"FOMC_SEARCH_SERVICE\"]\n",
    "        )\n",
    "        resp = search_service.search(query=query, columns=[\"chunk\"], limit=10)\n",
    "        return resp.to_json()\n",
    "\n",
    "def build_graph_with_search(search_max_results: int = 5):\n",
    "    def make_system_prompt(suffix: str) -> str:\n",
    "        return (\n",
    "            \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "            \" Use the provided tools to progress towards answering the question.\"\n",
    "            \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "            \" will help where you left off. Execute what you can to make progress.\"\n",
    "            \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "            \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "            f\"\\n{suffix}\"\n",
    "        )\n",
    "\n",
    "    tavily_tool = TavilySearchResults(max_results=search_max_results)\n",
    "\n",
    "    # Create document search tool using Cortex Search (uses your Snowflake session)\n",
    "    cortex_search_tool = CortexSearchTool(session=snowpark_session_trulens)\n",
    "\n",
    "    # The tool registry now includes both the web and document search tools.\n",
    "    tool_registry = {\n",
    "        str(uuid.uuid4()): tavily_tool,\n",
    "        str(uuid.uuid4()): cortex_search_tool,\n",
    "    }\n",
    "\n",
    "    # Index tool descriptions in a vector store for semantic tool retrieval\n",
    "    tool_documents = [\n",
    "        Document(\n",
    "            page_content=tavily_tool.description,\n",
    "            id=tid,\n",
    "            metadata={\"tool_name\": tavily_tool.name},\n",
    "        )\n",
    "        for tid, tavily_tool in tool_registry.items()\n",
    "    ]\n",
    "    vector_store = InMemoryVectorStore(embedding=OpenAIEmbeddings())\n",
    "    vector_store.add_documents(tool_documents)\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"SELECT_TOOLS\",\n",
    "        attributes=lambda ret, exc, *args, **kw: {\n",
    "            # ---- state as JSON-text (OTLP needs a scalar) -----------------\n",
    "            f\"{BASE_SCOPE}.select_tools_input_state\":\n",
    "                json.dumps(                                      # ← turns dict → str\n",
    "                    {\n",
    "                        **{k: v for k, v in args[0].items() if k != \"messages\"},\n",
    "                        \"messages\": [\n",
    "                            {\"type\": m.__class__.__name__, \"content\": m.content}\n",
    "                            if hasattr(m, \"content\")             # BaseMessage subclasses\n",
    "                            else m                               # already JSON-friendly\n",
    "                            for m in args[0].get(\"messages\", [])\n",
    "                        ],\n",
    "                    }\n",
    "                ),\n",
    "\n",
    "            # ---- selected tool IDs as a simple comma-separated string -----\n",
    "            f\"{BASE_SCOPE}.selected_tool_ids\":\n",
    "                \", \".join(ret.get(\"selected_tools\", [])) if isinstance(ret, dict) else \"\",\n",
    "        },\n",
    "    )\n",
    "    def select_tools(state: MessagesState):\n",
    "        \"\"\"\n",
    "        This tool is used to select tools based on the user query.\n",
    "        The tool uses the vector store to find the most semantically similar tool to the user query.\n",
    "        The tool then returns the selected tool's ID.\"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "        last_user_query = messages[-1][\"content\"] if isinstance(messages[-1], dict) \\\n",
    "                        else messages[-1].content\n",
    "        \n",
    "        print(last_user_query)\n",
    "\n",
    "        docs = vector_store.similarity_search(last_user_query)\n",
    "        return {\"selected_tools\": [doc.id for doc in docs]}\n",
    "\n",
    "\n",
    "    # Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "    repl = PythonREPL()\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "    def ensure_chart_dir():\n",
    "        target_dir = \"./langgraph_saved_images_snowflaketools/v2\"\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        return target_dir\n",
    "\n",
    "    \n",
    "    @tool\n",
    "    @instrument(\n",
    "        span_type=\"PYTHON_REPL_TOOL\",\n",
    "        attributes={\n",
    "            f\"{BASE_SCOPE}.python_tool_input_code\": \"code\",\n",
    "        },\n",
    "    )\n",
    "    def python_repl_tool(code: str):\n",
    "        \"\"\"\n",
    "        Run arbitrary Python, grab the CURRENT matplotlib figure (if any),\n",
    "        save it to ./langgraph_saved_images_snowflaketools/v2/chart_<uuid>.png,\n",
    "        and return a first-line `CHART_PATH=…`.\n",
    "        \"\"\"\n",
    "        import matplotlib\n",
    "        matplotlib.use(\"Agg\")                 # headless safety\n",
    "        import matplotlib.pyplot as plt\n",
    "        import uuid, os, textwrap, io, contextlib, sys\n",
    "\n",
    "        # ------------------ run user code & capture stdout ------------------\n",
    "        repl.run(code)\n",
    "\n",
    "        # ------------------ locate a figure (if generated) ------------------\n",
    "        fig = plt.gcf()\n",
    "        has_axes = bool(fig.axes)            # True if something was plotted\n",
    "\n",
    "        # ------------------ always save if we have a figure -----------------\n",
    "        chart_path = \"\"\n",
    "        if has_axes:\n",
    "            target_dir = \"./langgraph_saved_images_snowflaketools/v2\"\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "            chart_path = os.path.join(\n",
    "                target_dir, f\"chart_{uuid.uuid4().hex}.png\"\n",
    "            )\n",
    "            fig.savefig(chart_path, format=\"png\")\n",
    "            plt.close(fig)\n",
    "\n",
    "        # ------------------ tool result (1st line = CHART_PATH) -------------\n",
    "        return (\n",
    "            f\"CHART_PATH={chart_path if chart_path else 'NONE'}\\n\")\n",
    "\n",
    "        \n",
    "\n",
    "    def get_next_node(last_message: BaseMessage, goto: str):\n",
    "        if \"FINAL ANSWER\" in last_message.content:\n",
    "            # Any agent decided the work is done\n",
    "            return END\n",
    "        return goto\n",
    "\n",
    "    # Research agent and node\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[tavily_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only do research. You are working with both a chart generator and a chart summarizer colleagues.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def research_agent_node(state: MessagesState) -> Command[Literal[\"chart_generator\"]]:\n",
    "        \"\"\"\n",
    "        This function represents the research agent node in the workflow.\n",
    "        It selects tools based on the user's query and invokes the research agent\n",
    "        to perform the research task. If tools are selected, they are bound to the\n",
    "        LLM, and a new research agent is created with the selected tools. Otherwise,\n",
    "        the default research agent is used.\n",
    "\n",
    "        The function determines the next node in the workflow based on the content\n",
    "        of the last message. If the message contains \"FINAL ANSWER,\" the workflow\n",
    "        ends. Otherwise, it transitions to the chart generator node.\n",
    "        \"\"\"\n",
    "        selected_ids = state.get(\"selected_tools\", [])\n",
    "        if selected_ids:\n",
    "            selected_tools = [tool_registry[tid] for tid in selected_ids]\n",
    "            # Bind the selected tools to the LLM\n",
    "            bound_llm = llm.bind_tools(selected_tools)\n",
    "            # Create a research agent using the bound LLM and same prompt\n",
    "            bound_research_agent = create_react_agent(\n",
    "                bound_llm,\n",
    "                tools=[],  # tools are already bound\n",
    "                prompt=research_agent.prompt,\n",
    "            )\n",
    "            result = bound_research_agent.invoke(state)\n",
    "        else:\n",
    "            result = research_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
    "        result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "        return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
    "\n",
    "    # Chart generator agent and node\n",
    "    # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        [python_repl_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate charts. The generated chart should be save at a local directory at current directory PATH './langgraph_saved_images_snowflaketools/v1' , and this PATH should be sent to your colleague. You are working with a chart summarizer colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    def extract_chart_path(text: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Returns the first CHART_PATH=… found in `text`, else None.\n",
    "        \"\"\"\n",
    "        m = re.search(r\"^CHART_PATH=(.+)$\", text, flags=re.MULTILINE)\n",
    "        return m.group(1).strip() if m else None\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_GENERATOR_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.chart_node_response\": (\n",
    "                ret.update[\"messages\"][-1].content if ret and hasattr(ret, \"update\") and ret.update else \"No update response\"\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    def chart_node(state: MessagesState) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "        \"\"\"\n",
    "        This function represents the chart generation node in the workflow.\n",
    "        It invokes the chart generation agent to create a chart based on the provided state.\n",
    "        The generated chart is saved to a specified directory, and its path is extracted from the tool messages.\n",
    "        A summary prompt is then prepared to send to the chart summarizer agent.\n",
    "        If the chart path is not found, the workflow ends; otherwise, it transitions to the chart summarizer node.\n",
    "        \"\"\"\n",
    "        # 1. let the agent run\n",
    "        result = chart_agent.invoke(state)\n",
    "\n",
    "        # 2. try to grab a path from any ToolMessage\n",
    "        chart_path = None\n",
    "        for msg in result[\"messages\"]:\n",
    "            if isinstance(msg, ToolMessage):\n",
    "                chart_path = extract_chart_path(msg.content)\n",
    "                if chart_path and chart_path.upper() != \"NONE\":\n",
    "                    break\n",
    "\n",
    "        print(f\"Chart Path: {chart_path!r}\")\n",
    "\n",
    "        # 3. If no valid chart path, return to researcher with error message\n",
    "        if not chart_path or chart_path.upper() == \"NONE\":\n",
    "            result[\"messages\"].append(\n",
    "                HumanMessage(\n",
    "                    content=\"Failed to generate chart. Please try again with different parameters.\",\n",
    "                    name=\"chart_generator\"\n",
    "                )\n",
    "            )\n",
    "            return Command(update={\"messages\": result[\"messages\"]}, goto=\"researcher\")\n",
    "            \n",
    "        # 4. Add chart path to messages for downstream nodes\n",
    "        result[\"messages\"].append(\n",
    "            HumanMessage(\n",
    "                content=f\"CHART_PATH={chart_path}\",\n",
    "                name=\"chart_generator\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 5. Add summary prompt\n",
    "        summary_prompt = (\n",
    "            \"Please summarise the chart in ≤ 3 sentences.\"\n",
    "        )\n",
    "        result[\"messages\"].append(\n",
    "            HumanMessage(name=\"chart_generator\", content=summary_prompt)\n",
    "        )\n",
    "\n",
    "        return Command(update={\"messages\": result[\"messages\"]}, goto=\"chart_summarizer\")\n",
    "\n",
    "\n",
    "    # Build the image captioning agent.\n",
    "    # If you have any specific image processing tools (e.g., for extracting chart images),\n",
    "    # you can add them in the tools list. For now, we leave it empty.\n",
    "    chart_summary_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[],  # Add image processing tools if available/needed.\n",
    "        prompt=make_system_prompt(\n",
    "                    \"\"\"You can only generate charts with Python.\n",
    "        ALWAYS:\n",
    "        1. Save the figure as PNG to './langgraph_saved_images_snowflaketools/v2'.\n",
    "        2. Do NOT display the image inline.\n",
    "        3. End your reply with `CHART_PATH=<absolute-or-relative-path>`.\n",
    "        You are working with a summariser colleague.\"\"\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    reflection_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"user_query\", \"chart_summary\"],\n",
    "        template=\"\"\"\\\n",
    "        You are an AI assistant tasked with reflecting on the quality of a chart summary. The user has asked the following question:\n",
    "        \"{user_query}\"\n",
    "\n",
    "        You are given the following chart summary:\n",
    "        \"{chart_summary}\"\n",
    "\n",
    "        Your task is to evaluate how well the chart summary answers the user's question. Consider the following:\n",
    "        - Does the summary capture the **key insights** and trends from the chart, even if in a more general form?\n",
    "        - Does it provide **adequate context** to address the user's query, even if it's not exhaustive?\n",
    "        - If the summary provides some context but could benefit from more details, consider it sufficient for now unless significant details are missing.\n",
    "\n",
    "        If the summary **generally** addresses the question, respond with 'Task complete'. If the summary **lacks significant** details or clarity, then respond with 'Refine summary'. Avoid being overly critical unless the summary completely misses key elements necessary to answer the query.\n",
    "\n",
    "        Please provide your answer in a **concise and encouraging** manner.\n",
    "        \"\"\"\n",
    "            )\n",
    "\n",
    "    # Create the chain using the prompt template and the LLM (ChatOpenAI)\n",
    "    reflection_chain = (\n",
    "        reflection_prompt_template | llm\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_REFLECTION\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_summary_reflection_input_user_query\": args[0],\n",
    "            f\"{BASE_SCOPE}.chart_summary_reflection_input_chart_summary\": args[1],\n",
    "            f\"{BASE_SCOPE}.chart_summary_reflection_response\": ret,\n",
    "        },\n",
    ")\n",
    "    def perform_reflection(user_query: str, chart_summary: str) -> str:\n",
    "        \"\"\"\n",
    "        This function uses an LLM to reflect on the quality of a chart summary\n",
    "        and determine if the task is complete or requires further refinement.\n",
    "        \"\"\"\n",
    "        # Call the chain with the user query and chart summary\n",
    "        reflection_result = reflection_chain.invoke({\"user_query\": user_query, \"chart_summary\": chart_summary})\n",
    "        return reflection_result.content\n",
    "\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.summary_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.summary_node_output\": (\n",
    "                ret.update[\"messages\"][-1].content\n",
    "                if hasattr(ret, \"update\") else \"NO SUMMARY GENERATED\"\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    def chart_summary_node(state: MessagesState) -> Command[Literal[END]]:\n",
    "        \"\"\"\n",
    "        This function represents the chart summarizer node in the workflow graph.\n",
    "        It uses the chart summary agent to generate a concise summary for the chart image\n",
    "        provided by the chart generator node. The summary is limited to three sentences\n",
    "        and is based on the chart image saved at the specified local path.\n",
    "        \"\"\"\n",
    "        # 1. Extract chart path from messages\n",
    "        chart_path = None\n",
    "        for msg in state[\"messages\"]:\n",
    "            if isinstance(msg, ToolMessage) and \"CHART_PATH=\" in msg.content:\n",
    "                chart_path = extract_chart_path(msg.content)\n",
    "                if chart_path and chart_path.upper() != \"NONE\":\n",
    "                    break\n",
    "\n",
    "        print(f\"Chart Path in Chart Summary Node: {chart_path!r}\")\n",
    "\n",
    "        # 2. If no valid chart path, return to researcher with error message\n",
    "        if not chart_path or chart_path.upper() == \"NONE\":\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(\n",
    "                            content=\"No valid chart was generated. Please try again.\",\n",
    "                            name=\"chart_summarizer\"\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                goto=\"researcher\"\n",
    "            )\n",
    "\n",
    "        # 3. Run the summarizer\n",
    "        result = chart_summary_agent.invoke(state)\n",
    "        if not result or \"messages\" not in result:\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(\n",
    "                            content=\"Failed to generate chart summary. Please try again.\",\n",
    "                            name=\"chart_summarizer\"\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                goto=\"researcher\"\n",
    "            )\n",
    "\n",
    "        # 4. Add reflection\n",
    "        user_query = state[\"messages\"][-2].content\n",
    "        chart_summary = result[\"messages\"][-1].content\n",
    "        reflection = perform_reflection(user_query, chart_summary)\n",
    "\n",
    "        # 5. Determine next node\n",
    "        goto = END if \"Task complete\" in reflection or \"FINAL ANSWER\" in reflection else \"researcher\"\n",
    "        result[\"messages\"][-1] = HumanMessage(name=\"chart_summarizer\", content=chart_summary)\n",
    "\n",
    "        return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
    "\n",
    "\n",
    "\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    workflow.add_node(\"select_tools\", select_tools)\n",
    "    workflow.add_node(\"research_agent\", research_agent_node)\n",
    "    workflow.add_node(\"chart_generator\", chart_node)\n",
    "    workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "\n",
    "    # Update transitions: begin with tool selection then go to research agent.\n",
    "    workflow.add_edge(START, \"select_tools\")\n",
    "    workflow.add_edge(\"select_tools\", \"research_agent\")\n",
    "    workflow.add_edge(\"research_agent\", \"chart_generator\")\n",
    "    workflow.add_edge(\"chart_generator\", \"chart_summarizer\")\n",
    "    # workflow.add_edge(\"chart_summarizer\", \"select_tools\")\n",
    "    workflow.add_edge(\"chart_summarizer\", END)\n",
    "    graph = workflow.compile()\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class TruAgent:\n",
    "    def __init__(self):\n",
    "        self.graph = build_graph_with_search()\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def invoke_agent_graph(self, query: str) -> str:\n",
    "        events = self.graph.stream(\n",
    "            {\n",
    "                \"messages\": [(\"user\", query)],\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": 150},\n",
    "        )\n",
    "\n",
    "        # resp_messages = []\n",
    "\n",
    "        for event in events:\n",
    "            # Grab the payload if it exists\n",
    "            payload = next(iter(event.values()), None)\n",
    "            if payload is None:\n",
    "                continue  # skip this event if no payload\n",
    "            \n",
    "            messages = payload.get(\"messages\")\n",
    "        return (\n",
    "            messages[-1].content\n",
    "            if messages and hasattr(messages[-1], \"content\")\n",
    "            else \"\"\n",
    "        )\n",
    "\n",
    "tru_agent = TruAgent()\n",
    "\n",
    "tru_agent_app = TruApp(\n",
    "    tru_agent,\n",
    "    app_name=APP_NAME,\n",
    "    app_version=\"doc and web search\",\n",
    "    connector=trulens_sf_connector,\n",
    "    main_method=tru_agent.invoke_agent_graph,\n",
    ")\n",
    "\n",
    "st_1 = datetime.datetime.fromtimestamp(time.time()).strftime(\n",
    "    \"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=\"Multi-agent demo run - document and web search\",\n",
    "    description=\"this is a run with access to cortex search and tavily + qualitative caption\",\n",
    "    dataset_name=\"Research test dataset\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    label=\"langgraph demo\",\n",
    "    dataset_spec={\n",
    "        \"RECORD_ROOT.INPUT\": \"query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "run: Run = tru_agent_app.add_run(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(tru_agent.graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23788cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.start(\n",
    "    input_df=user_queries_df\n",
    ")  # note: if you use MFA, you will need to authenticate with the Duo prompt many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    time.sleep(3)\n",
    "\n",
    "run.compute_metrics([\"groundedness\", \"context_relevance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25d0ad",
   "metadata": {},
   "source": [
    "### Use Cortex Agent to gain access to querying structured SEC data without complicating the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb49a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_with_agent():\n",
    "    def make_system_prompt(suffix: str) -> str:\n",
    "        return (\n",
    "            \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "            \" Use the provided tools to progress towards answering the question.\"\n",
    "            \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "            \" will help where you left off. Execute what you can to make progress.\"\n",
    "            \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "            \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "            f\"\\n{suffix}\"\n",
    "        )\n",
    "\n",
    "    tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "    # Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "    repl = PythonREPL()\n",
    "\n",
    "    @tool(name=\"python_repl_tool\")\n",
    "    @instrument(\n",
    "        span_type=\"PYTHON_REPL_TOOL\",\n",
    "        attributes={\n",
    "            f\"{BASE_SCOPE}.python_tool_input_code\": \"code\",\n",
    "        },\n",
    "    )\n",
    "    def python_repl_tool(code: str):\n",
    "        \"\"\"\n",
    "        Executes code and saves the chart image even if stdout does not return a figure.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            chart_uuid = str(uuid.uuid4())\n",
    "            target_dir = \"./langgraph_saved_images_snowflaketools/v1\"\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "            chart_path = f\"{target_dir}/chart_{chart_uuid}.png\"\n",
    "\n",
    "            # Execute user code\n",
    "            exec_globals = {}\n",
    "            exec_locals = {}\n",
    "            exec(code, exec_globals, exec_locals)\n",
    "\n",
    "            # After user code, forcibly save current matplotlib figure if exists\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig = plt.gcf()  # get current figure\n",
    "            if fig:\n",
    "                fig.savefig(chart_path)\n",
    "                print(f\"Chart saved at {chart_path}\")\n",
    "            else:\n",
    "                print(\"⚠️ No figure generated.\")\n",
    "\n",
    "            return f\"✅ Code executed.\\n🔗 CHART_PATH={chart_path}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error executing code: {e!r}\"\n",
    "\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"WEB_RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def web_research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_generator\"]]:\n",
    "        result = research_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"researcher\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of research agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    def get_next_node(last_message: BaseMessage, goto: str):\n",
    "        if \"FINAL ANSWER\" in last_message.content:\n",
    "            # Any agent decided the work is done\n",
    "            return END\n",
    "        return goto\n",
    "\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        [python_repl_tool],\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate charts. The generated chart should be save at a local directory at current directory PATH './langgraph_saved_images_snowflaketools/v3' , and this PATH should be sent to your colleague. You are working with a chart summarizer colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_GENERATOR_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.chart_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.chart_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "        },\n",
    "    )\n",
    "    def chart_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "        result = chart_agent.invoke(state)\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"chart_summarizer\")\n",
    "        # wrap in a human message, as not all providers allow\n",
    "        # AI message at the last position of the input messages list\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\n",
    "                # share internal message history of chart agent with other agents\n",
    "                \"messages\": result[\"messages\"],\n",
    "            },\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Build the image captioning agent.\n",
    "    # If you have any specific image processing tools (e.g., for extracting chart images),\n",
    "    # you can add them in the tools list. For now, we leave it empty.\n",
    "    chart_summary_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[],  # Add image processing tools if available/needed.\n",
    "        prompt=make_system_prompt(\n",
    "            \"You can only generate image captions. You are working with a researcher colleague and a chart generator colleague. \"\n",
    "            + \"Your task is to generate a concise summary for the provided chart image saved at a local PATH, where the PATH should be and only be provided by your chart generator colleague. The summary should be no more than 3 sentences.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"CHART_SUMMARY_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.summary_node_input\": args[0][\"messages\"][-1].content,\n",
    "            f\"{BASE_SCOPE}.summary_node_output\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"NO SUMMARY GENERATED\",\n",
    "        },\n",
    "    )\n",
    "    def chart_summary_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"researcher\", END]]:\n",
    "        result = chart_summary_agent.invoke(state)\n",
    "        # Determine the next node based on the content of the last message\n",
    "        goto = get_next_node(result[\"messages\"][-1], \"researcher\")\n",
    "        # Wrap the output message in a HumanMessage to maintain consistency in the conversation flow.\n",
    "        result[\"messages\"][-1] = HumanMessage(\n",
    "            content=result[\"messages\"][-1].content, name=\"chart_summarizer\"\n",
    "        )\n",
    "        return Command(\n",
    "            update={\"messages\": result[\"messages\"]},\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    import requests\n",
    "\n",
    "    @instrument(\n",
    "        span_type=\"RESEARCH_NODE\",\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            f\"{BASE_SCOPE}.research_node_input\": args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            f\"{BASE_SCOPE}.research_node_response\": ret.update[\"messages\"][\n",
    "                -1\n",
    "            ].content\n",
    "            if hasattr(ret, \"update\")\n",
    "            else json.dumps(ret, indent=4, sort_keys=True),\n",
    "            f\"{BASE_SCOPE}.tool_messages\": [\n",
    "                dumps(message)\n",
    "                for message in ret.update[\"messages\"]\n",
    "                if isinstance(message, ToolMessage)\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else \"No tool call\",\n",
    "        },\n",
    "    )\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes=lambda ret, exception, *args, **kwargs: {\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0][\"messages\"][\n",
    "                -1\n",
    "            ].content,\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "                ret.update[\"messages\"][-1].content\n",
    "            ]\n",
    "            if hasattr(ret, \"update\")\n",
    "            else [json.dumps(ret, indent=4, sort_keys=True)],\n",
    "        },\n",
    "    )\n",
    "    def research_node(\n",
    "        state: MessagesState,\n",
    "    ) -> Command[Literal[\"researcher\", END]]:\n",
    "        # Extract the user query from the state.\n",
    "        user_query = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "        # Prepare the payload for the Cortex Agents API.\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4.1-mini\",\n",
    "            \"response_instruction\": \"You are a helpful AI assistant, collaborate with colleagues if needed.\",\n",
    "            \"experimental\": {},\n",
    "            \"tools\": [\n",
    "                {\n",
    "                    \"tool_spec\": {\n",
    "                        \"type\": \"cortex_analyst_text_to_sql\",\n",
    "                        \"name\": \"Analyst1\",\n",
    "                    }\n",
    "                },\n",
    "                {\"tool_spec\": {\"type\": \"cortex_search\", \"name\": \"Search1\"}},\n",
    "            ],\n",
    "            \"tool_resources\": {\n",
    "                \"Analyst1\": {\n",
    "                    \"semantic_model_file\": \"@agents_db.notebooks.semantic_models.sec_filings.yaml\"\n",
    "                },\n",
    "                \"Search1\": {\n",
    "                    \"name\": \"CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.FOMC_SEARCH_SERVICE\"\n",
    "                },\n",
    "            },\n",
    "            \"tool_choice\": {\"type\": \"auto\"},\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": user_query}],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "        # Define the API endpoint and headers.\n",
    "        api_url = \"http://SFDEVREL-SFDEVREL_ENTERPRISE.snowflakecomputing.com/api/v2/cortex/agent:run\"\n",
    "        headers = {\n",
    "            \"Authorization\": os.environ.get(\"SNOWFLAKE_JWT\"),\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(api_url, json=payload, headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                result_text = f\"Failed Cortex Agents API call with status code {response.status_code}: {response.text}\"\n",
    "            else:\n",
    "                data = response.json()\n",
    "                # Aggregate the text content from the response's delta message.\n",
    "                contents = data.get(\"delta\", {}).get(\"content\", [])\n",
    "                result_parts = [\n",
    "                    chunk.get(\"text\", \"\")\n",
    "                    for chunk in contents\n",
    "                    if chunk.get(\"type\") == \"text\"\n",
    "                ]\n",
    "                result_text = \" \".join(result_parts).strip() or str(data)\n",
    "        except Exception as e:\n",
    "            result_text = f\"Exception during API call: {str(e)}\"\n",
    "        from langchain_core.messages import HumanMessage\n",
    "\n",
    "        result_message = HumanMessage(content=result_text, name=\"researcher\")\n",
    "        goto = (\n",
    "            \"researcher\"\n",
    "            if \"FINAL ANSWER\" not in result_message.content\n",
    "            else END\n",
    "        )\n",
    "        return Command(\n",
    "            update={\"messages\": state[\"messages\"] + [result_message]},\n",
    "            goto=goto,\n",
    "        )\n",
    "\n",
    "    # Build the workflow graph\n",
    "    workflow = StateGraph(MessagesState)\n",
    "\n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"researcher\", research_node)\n",
    "    workflow.add_node(\"web_researcher\", web_research_node)\n",
    "    workflow.add_node(\"chart_generator\", chart_node)\n",
    "    workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "\n",
    "    # Entry point\n",
    "    workflow.set_entry_point(\"researcher\")\n",
    "\n",
    "    # Parallel or conditional edge from researcher\n",
    "    workflow.add_edge(\n",
    "        \"researcher\", \"web_researcher\"\n",
    "    )  # optional: could be conditional\n",
    "    workflow.add_edge(\"researcher\", \"chart_generator\")\n",
    "\n",
    "    # Web researcher supplements data before chart\n",
    "    workflow.add_edge(\"web_researcher\", \"chart_generator\")\n",
    "\n",
    "    # After chart is generated, summarize it\n",
    "    workflow.add_edge(\"chart_generator\", \"chart_summarizer\")\n",
    "\n",
    "    # End of flow\n",
    "    workflow.add_edge(\"chart_summarizer\", END)\n",
    "\n",
    "    graph = workflow.compile()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruAgent:\n",
    "    def __init__(self):\n",
    "        self.graph = build_graph_with_agent()\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT,\n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        },\n",
    "    )\n",
    "    def invoke_agent_graph(self, query: str) -> str:\n",
    "        events = self.graph.stream(\n",
    "            {\n",
    "                \"messages\": [(\"user\", query)],\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": 150},\n",
    "        )\n",
    "\n",
    "        # resp_messages = []\n",
    "\n",
    "        for event in events:\n",
    "            messages = list(event.values())[0][\"messages\"]\n",
    "        return (\n",
    "            messages[-1].content\n",
    "            if messages and hasattr(messages[-1], \"content\")\n",
    "            else \"\"\n",
    "        )\n",
    "\n",
    "\n",
    "tru_agent = TruAgent()\n",
    "\n",
    "tru_agent_app = TruApp(\n",
    "    tru_agent,\n",
    "    app_name=APP_NAME,\n",
    "    app_version=\"cortex agent + web search\",\n",
    "    connector=trulens_sf_connector,\n",
    "    main_method=tru_agent.invoke_agent_graph,\n",
    ")\n",
    "\n",
    "st_1 = datetime.datetime.fromtimestamp(time.time()).strftime(\n",
    "    \"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=\"Multi-agent demo run - cortex agent + web search + charting\",\n",
    "    description=\"this is a run with access to cortex agent, with internally uses cortex search and analyst as tools\",\n",
    "    dataset_name=\"Research test dataset\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    label=\"langgraph demo\",\n",
    "    dataset_spec={\n",
    "        \"RECORD_ROOT.INPUT\": \"query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "run: Run = tru_agent_app.add_run(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde20b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_queries = [\n",
    "    \"In 2023, how did the fed funds rate fluctuate? What were the key drivers? Create a line chart that best illustrates this data, including a caption with the key drivers. Once the chart is generated, summarize the chart, and finish.\",\n",
    "    \"What is the total market value of securities by asset class according to SEC filings? Create a bar chart that best illustrates this data. Once the chart is generated, summarize the chart, and finish.\",\n",
    "    \"Who are the top 10 filing managers by number of holdings in the most recent reporting quarter according to SEC filings? Create a bar chart that best illustrates this data. Once the chart is generated, summarize the chart, and finish.\",\n",
    "]\n",
    "\n",
    "user_queries_df = pd.DataFrame(user_queries, columns=[\"query\"])\n",
    "\n",
    "run.start(\n",
    "    input_df=user_queries_df\n",
    ")  # note: if you use MFA, you will need to authenticate with the Duo prompt many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() == \"INVOCATION_IN_PROGRESS\":\n",
    "    time.sleep(3)\n",
    "\n",
    "run.compute_metrics([\"groundedness\", \"context_relevance\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_rag_stack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
