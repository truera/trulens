{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
   "metadata": {},
   "source": [
    "# Build and Evaluate a Web Search Agent\n",
    "\n",
    "Build a web-enabled data agent that can operate across perform web research, answer questions, and generate charts. Then evaluate it to identify failure modes.\n",
    "\n",
    "For this example you will need access to LLMs (OpenAI) and web search (Tavily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cda4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens 'langgraph==0.5.4' trulens-apps-langgraph trulens-providers-openai openai matplotlib 'langchain_openai==0.3.30' 'langchain_tavily==0.2.11' 'langchain_experimental==0.3.4' -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2172e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"tvly-dev-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf984dd",
   "metadata": {},
   "source": [
    "## 1. Initialize the agent's state\n",
    "\n",
    "State provides the agent a shared, evolving memory across nodes so that the agents have the context and instructions needed to act coherently and achieve the goal.\n",
    "\n",
    "In addition to the additional state variables we're adding, our State will also inherit messages from MessageState to track the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65289f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Literal, Optional\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "# Custom State class with specific keys\n",
    "class State(MessagesState):\n",
    "    user_query: Optional[str]  # The user's original query\n",
    "    enabled_agents: Optional[\n",
    "        List[str]\n",
    "    ]  # Makes our multi-agent system modular on which agents to include\n",
    "    plan: Optional[\n",
    "        List[Dict[int, Dict[str, Any]]]\n",
    "    ]  # Listing the steps in the plan needed to achieve the goal.\n",
    "    current_step: int  # Marking the current step in the plan.\n",
    "    agent_query: Optional[\n",
    "        str\n",
    "    ]  # Inbox note: `agent_query` tells the next agent exactly what to do at the current step.\n",
    "    last_reason: Optional[\n",
    "        str\n",
    "    ]  # Explains the executor’s decision to help maintain continuity and provide traceability.\n",
    "    replan_flag: Optional[\n",
    "        bool\n",
    "    ]  # Set by the executor    to indicate that the planner should revise the plan.\n",
    "    replan_attempts: Optional[\n",
    "        Dict[int, Dict[int, int]]\n",
    "    ]  # Replan attempts tracked per step number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6402c01",
   "metadata": {},
   "source": [
    "## 2. Create planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b02faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "MAX_REPLANS = 2\n",
    "\n",
    "\n",
    "def get_agent_descriptions() -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Return structured agent descriptions with capabilities and guidelines.\n",
    "    Edit this function to change how the planner/executor reason about agents.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"web_researcher\": {\n",
    "            \"name\": \"Web Researcher\",\n",
    "            \"capability\": \"Fetch public data via Tavily web search\",\n",
    "            \"use_when\": \"Public information, news, current events, or external facts are needed\",\n",
    "            \"limitations\": \"Cannot access private/internal company data\",\n",
    "            \"output_format\": \"Raw research data and findings from public sources\",\n",
    "        },\n",
    "        \"chart_generator\": {\n",
    "            \"name\": \"Chart Generator\",\n",
    "            \"capability\": \"Build visualizations from structured data\",\n",
    "            \"use_when\": \"User explicitly requests charts, graphs, plots, visualizations (keywords: chart, graph, plot, visualise, bar-chart, line-chart, histogram, etc.)\",\n",
    "            \"limitations\": \"Requires structured data input from previous steps\",\n",
    "            \"output_format\": \"Visual charts and graphs\",\n",
    "            \"position_requirement\": \"Must be used as final step after data gathering is complete\",\n",
    "        },\n",
    "        \"chart_summarizer\": {\n",
    "            \"name\": \"Chart Summarizer\",\n",
    "            \"capability\": \"Summarize and explain chart visualizations\",\n",
    "            \"use_when\": \"After chart_generator has created a visualization\",\n",
    "            \"limitations\": \"Requires a chart as input\",\n",
    "            \"output_format\": \"Written summary and analysis of chart content\",\n",
    "        },\n",
    "        \"synthesizer\": {\n",
    "            \"name\": \"Synthesizer\",\n",
    "            \"capability\": \"Write comprehensive prose summaries of findings\",\n",
    "            \"use_when\": \"Final step when no visualization is requested - combines all previous research\",\n",
    "            \"limitations\": \"Requires research data from previous steps\",\n",
    "            \"output_format\": \"Coherent written summary incorporating all findings\",\n",
    "            \"position_requirement\": \"Should be used as final step when no chart is needed\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def _get_enabled_agents(state: State | None = None) -> List[str]:\n",
    "    \"\"\"Return enabled agents; if absent, use baseline/default.\n",
    "\n",
    "    Supports both dict-style and attribute-style state objects.\n",
    "    \"\"\"\n",
    "    baseline = [\n",
    "        \"web_researcher\",\n",
    "        \"chart_generator\",\n",
    "        \"chart_summarizer\",\n",
    "        \"synthesizer\",\n",
    "    ]\n",
    "    if not state:\n",
    "        return baseline\n",
    "    val = (\n",
    "        state.get(\"enabled_agents\")\n",
    "        if hasattr(state, \"get\")\n",
    "        else getattr(state, \"enabled_agents\", None)\n",
    "    )\n",
    "\n",
    "    if isinstance(val, list) and val:\n",
    "        allowed = {\n",
    "            \"web_researcher\",\n",
    "            \"chart_generator\",\n",
    "            \"chart_summarizer\",\n",
    "            \"synthesizer\",\n",
    "        }\n",
    "        filtered = [a for a in val if a in allowed]\n",
    "        return filtered\n",
    "    return baseline\n",
    "\n",
    "\n",
    "def format_agent_list_for_planning(state: State | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Format agent descriptions for the planning prompt.\n",
    "    \"\"\"\n",
    "    descriptions = get_agent_descriptions()\n",
    "    enabled_list = _get_enabled_agents(state)\n",
    "    agent_list = []\n",
    "\n",
    "    for agent_key, details in descriptions.items():\n",
    "        if agent_key not in enabled_list:\n",
    "            continue\n",
    "        agent_list.append(f\"  • `{agent_key}` – {details['capability']}\")\n",
    "\n",
    "    return \"\\n\".join(agent_list)\n",
    "\n",
    "\n",
    "def format_agent_guidelines_for_planning(state: State | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Format agent usage guidelines for the planning prompt.\n",
    "    \"\"\"\n",
    "    descriptions = get_agent_descriptions()\n",
    "    enabled = set(_get_enabled_agents(state))\n",
    "    guidelines = []\n",
    "\n",
    "    if \"web_researcher\" in enabled:\n",
    "        guidelines.append(\n",
    "            f\"- Use `web_researcher` for {descriptions['web_researcher']['use_when'].lower()}.\"\n",
    "        )\n",
    "\n",
    "    # Chart generator specific rules\n",
    "    if \"chart_generator\" in enabled:\n",
    "        chart_desc = descriptions[\"chart_generator\"]\n",
    "        cs_hint = (\n",
    "            \" A `chart_summarizer` should be used to summarize the chart.\"\n",
    "            if \"chart_summarizer\" in enabled\n",
    "            else \"\"\n",
    "        )\n",
    "        guidelines.append(\n",
    "            f\"- **Include `chart_generator` _only_ if {chart_desc['use_when'].lower()}**. If included, `chart_generator` must be {chart_desc['position_requirement'].lower()}. Visualizations should include all of the data from the previous steps that is reasonable for the chart type.{cs_hint}\"\n",
    "        )\n",
    "\n",
    "    # Synthesizer default\n",
    "    if \"synthesizer\" in enabled:\n",
    "        synth_desc = descriptions[\"synthesizer\"]\n",
    "        guidelines.append(\n",
    "            f\"  – Otherwise use `synthesizer` as {synth_desc['position_requirement'].lower()}, and be sure to include all of the data from the previous steps.\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(guidelines)\n",
    "\n",
    "\n",
    "def plan_prompt(state: State) -> HumanMessage:\n",
    "    \"\"\"\n",
    "    Build the prompt that instructs the LLM to return a high‑level plan.\n",
    "    \"\"\"\n",
    "    replan_flag = state.get(\"replan_flag\", False)\n",
    "    user_query = state.get(\"user_query\", state[\"messages\"][0].content)\n",
    "    prior_plan = state.get(\"plan\") or {}\n",
    "    replan_reason = state.get(\"last_reason\", \"\")\n",
    "\n",
    "    # Get agent descriptions dynamically\n",
    "\n",
    "    agent_list = format_agent_list_for_planning(state)\n",
    "    agent_guidelines = format_agent_guidelines_for_planning(state)\n",
    "\n",
    "    enabled_list = _get_enabled_agents(state)\n",
    "\n",
    "    # Build planner agent enum based on enabled agents\n",
    "    enabled_for_planner = [\n",
    "        a\n",
    "        for a in enabled_list\n",
    "        if a\n",
    "        in (\n",
    "            \"web_researcher\",\n",
    "            \"cortex_researcher\",\n",
    "            \"chart_generator\",\n",
    "            \"synthesizer\",\n",
    "        )\n",
    "    ]\n",
    "    planner_agent_enum = (\n",
    "        \" | \".join(enabled_for_planner)\n",
    "        or \"web_researcher | chart_generator | synthesizer\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are the **Planner** in a multi‑agent system.  Break the user's request\n",
    "        into a sequence of numbered steps (1, 2, 3, …).  **There is no hard limit on\n",
    "        step count** as long as the plan is concise and each step has a clear goal.\n",
    "\n",
    "        You may decompose the user's query into sub-queries, each of which is a\n",
    "        separate step.  Break the query into the smallest possible sub-queries\n",
    "        so that each sub-query is answerable with a single data source.\n",
    "        For example, if the user's query is \"What were the key\n",
    "        action items in the last quarter, and what was a recent news story for \n",
    "        each of them?\", you may break it into steps:\n",
    "        \n",
    "        1. Fetch the key action items in the last quarter.\n",
    "        2. Fetch a recent news story for the first action item.\n",
    "        3. Fetch a recent news story for the second action item.\n",
    "        4. Fetch a recent news story for the last action item\n",
    "\n",
    "        Here is a list of available agents you can call upon to execute the tasks in your plan. You may call only one agent per step.\n",
    "\n",
    "        {agent_list}\n",
    "\n",
    "        Return **ONLY** valid JSON (no markdown, no explanations) in this form:\n",
    "\n",
    "        {{\n",
    "        \"1\": {{\n",
    "            \"agent\": \"{planner_agent_enum}\",\n",
    "            \"action\": \"string\",\n",
    "            \"goal\": \"string\",\n",
    "            \"pre_conditions\": [\"string\", ...],\n",
    "            \"post_conditions\": [\"string\", ...]\n",
    "        }},\n",
    "        \"2\": {{ ... }},\n",
    "        \"3\": {{ ... }}\n",
    "        }}\n",
    "\n",
    "        Guidelines:\n",
    "        {agent_guidelines}\n",
    "        \"\"\"\n",
    "\n",
    "    if replan_flag:\n",
    "        prompt += f\"\"\"\n",
    "        The current plan needs revision because: {replan_reason}\n",
    "\n",
    "        Current plan:\n",
    "        {json.dumps(prior_plan, indent=2)}\n",
    "\n",
    "        When replanning:\n",
    "        - Focus on UNBLOCKING the workflow rather than perfecting it.\n",
    "        - Only modify steps that are truly preventing progress.\n",
    "        - Prefer simpler, more achievable alternatives over complex rewrites.\n",
    "        \"\"\"\n",
    "\n",
    "    else:\n",
    "        prompt += \"\\nGenerate a new plan from scratch.\"\n",
    "\n",
    "    prompt += f'\\nUser query: \"{user_query}\"'\n",
    "\n",
    "    return HumanMessage(content=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.types import Command\n",
    "\n",
    "# ── LLMs ────────────────────────────────────────────────────────────────\n",
    "reasoning_llm = ChatOpenAI(\n",
    "    model=\"o3\",\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    ")\n",
    "\n",
    "\n",
    "def planner_node(state: State) -> Command[Literal[\"executor\"]]:\n",
    "    \"\"\"\n",
    "    Runs the planning LLM and stores the resulting plan in state.\n",
    "    \"\"\"\n",
    "    # 1. Invoke LLM with the planner prompt\n",
    "    llm_reply = reasoning_llm.invoke([plan_prompt(state)])\n",
    "\n",
    "    # 2. Validate JSON\n",
    "    try:\n",
    "        content_str = (\n",
    "            llm_reply.content\n",
    "            if isinstance(llm_reply.content, str)\n",
    "            else str(llm_reply.content)\n",
    "        )\n",
    "        parsed_plan = json.loads(content_str)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Planner returned invalid JSON:\\n{llm_reply.content}\")\n",
    "\n",
    "    # 3. Store as current plan only\n",
    "    replan = state.get(\"replan_flag\", False)\n",
    "    updated_plan: Dict[str, Any] = parsed_plan\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"plan\": updated_plan,\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=llm_reply.content,\n",
    "                    name=\"replan\" if replan else \"initial_plan\",\n",
    "                )\n",
    "            ],\n",
    "            \"user_query\": state.get(\"user_query\", state[\"messages\"][0].content),\n",
    "            \"current_step\": 1 if not replan else state[\"current_step\"],\n",
    "            # Preserve replan flag so executor runs planned agent once before reconsidering\n",
    "            \"replan_flag\": state.get(\"replan_flag\", False),\n",
    "            \"last_reason\": \"\",\n",
    "            \"enabled_agents\": state.get(\"enabled_agents\"),\n",
    "        },\n",
    "        goto=\"executor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140771f4",
   "metadata": {},
   "source": [
    "## 3. Create executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ab989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_agent_guidelines_for_executor(state: State | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Format agent usage guidelines for the executor prompt.\n",
    "    \"\"\"\n",
    "    descriptions = get_agent_descriptions()\n",
    "    enabled = _get_enabled_agents(state)\n",
    "    guidelines = []\n",
    "\n",
    "    if \"web_researcher\" in enabled:\n",
    "        web_desc = descriptions[\"web_researcher\"]\n",
    "        guidelines.append(\n",
    "            f\"- Use `\\\"web_researcher\\\"` when {web_desc['use_when'].lower()}.\"\n",
    "        )\n",
    "    if \"cortex_researcher\" in enabled:\n",
    "        cortex_desc = descriptions[\"cortex_researcher\"]\n",
    "        guidelines.append(\n",
    "            f\"- Use `\\\"cortex_researcher\\\"` for {cortex_desc['use_when'].lower()}.\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(guidelines)\n",
    "\n",
    "\n",
    "def executor_prompt(state: State) -> HumanMessage:\n",
    "    \"\"\"\n",
    "    Build the single‑turn JSON prompt that drives the executor LLM.\n",
    "    \"\"\"\n",
    "    step = int(state.get(\"current_step\", 0))\n",
    "    latest_plan: Dict[str, Any] = state.get(\"plan\") or {}\n",
    "    plan_block: Dict[str, Any] = latest_plan.get(str(step), {})\n",
    "    max_replans = MAX_REPLANS\n",
    "\n",
    "    # Get agent guidelines dynamically\n",
    "    executor_guidelines = format_agent_guidelines_for_executor(state)\n",
    "    plan_agent = plan_block.get(\"agent\", \"web_researcher\")\n",
    "\n",
    "    messages_tail = (state.get(\"messages\") or [])[-4:]\n",
    "\n",
    "    executor_prompt = f\"\"\"\n",
    "        You are the **executor** in a multi‑agent system with these agents:\n",
    "        `{\"`, `\".join(sorted(set([a for a in _get_enabled_agents(state) if a in [\"web_researcher\", \"cortex_researcher\", \"chart_generator\", \"chart_summarizer\", \"synthesizer\"]] + [\"planner\"])))}`.\n",
    "\n",
    "        **Tasks**\n",
    "        1. Decide if the current plan needs revision.  → `\"replan_flag\": true|false`\n",
    "        2. Decide which agent to run next.             → `\"goto\": \"<agent_name>\"`\n",
    "        3. Give one‑sentence justification.            → `\"reason\": \"<text>\"`\n",
    "        4. Write the exact question that the chosen agent should answer\n",
    "                                                    → \"query\": \"<text>\"\n",
    "\n",
    "        **Guidelines**\n",
    "        {executor_guidelines}\n",
    "        - After **{MAX_REPLANS}** failed replans for the same step, move on.\n",
    "        - If you *just replanned* (replan_flag is true) let the assigned agent try before\n",
    "        requesting another replan.\n",
    "\n",
    "        Respond **only** with valid JSON (no additional text):\n",
    "\n",
    "        {{\n",
    "        \"replan\": <true|false>,\n",
    "        \"goto\": \"<{\"|\".join([a for a in _get_enabled_agents(state) if a in [\"web_researcher\", \"cortex_researcher\", \"chart_generator\", \"chart_summarizer\", \"synthesizer\"]] + [\"planner\"])}>\",\n",
    "        \"reason\": \"<1 sentence>\",\n",
    "        \"query\": \"<text>\"\n",
    "        }}\n",
    "\n",
    "        **PRIORITIZE FORWARD PROGRESS:** Only replan if the current step is completely blocked.\n",
    "        1. If any reasonable data was obtained that addresses the step's core goal, set `\"replan\": false` and proceed.\n",
    "        2. Set `\"replan\": true` **only if** ALL of these conditions are met:\n",
    "        • The step has produced zero useful information\n",
    "        • The missing information cannot be approximated or obtained by remaining steps\n",
    "        • `attempts < {max_replans}`\n",
    "        3. When `attempts == {max_replans}`, always move forward (`\"replan\": false`).\n",
    "\n",
    "        ### Decide `\"goto\"`\n",
    "        - If `\"replan\": true` → `\"goto\": \"planner\"`.\n",
    "        - If current step has made reasonable progress → move to next step's agent.\n",
    "        - Otherwise execute the current step's assigned agent (`{plan_agent}`).\n",
    "\n",
    "        ### Build `\"query\"`\n",
    "        Write a clear, standalone instruction for the chosen agent. If the chosen agent \n",
    "        is `web_researcher` or `cortex_researcher`, the query should be a standalone question, \n",
    "        written in plain english, and answerable by the agent.\n",
    "\n",
    "        Ensure that the query uses consistent language as the user's query.\n",
    "\n",
    "        Context you can rely on\n",
    "        - User query ..............: {state.get(\"user_query\")}\n",
    "        - Current step index ......: {step}\n",
    "        - Current plan step .......: {plan_block}\n",
    "        - Just‑replanned flag .....: {state.get(\"replan_flag\")}\n",
    "        - Previous messages .......: {messages_tail}\n",
    "\n",
    "        Respond **only** with JSON, no extra text.\n",
    "        \"\"\"\n",
    "\n",
    "    return HumanMessage(content=executor_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "MAX_REPLANS = 3\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────\n",
    "# Executor node\n",
    "# ────────────────────────────────────────────────────────────────────────\n",
    "def executor_node(\n",
    "    state: State,\n",
    ") -> Command[\n",
    "    Literal[\"web_researcher\", \"chart_generator\", \"synthesizer\", \"planner\"]\n",
    "]:\n",
    "    plan: Dict[str, Any] = state.get(\"plan\", {})\n",
    "    step: int = state.get(\"current_step\", 1)\n",
    "\n",
    "    # 0) If we *just* replanned, run the planned agent once before reconsidering.\n",
    "    if state.get(\"replan_flag\"):\n",
    "        planned_agent = plan.get(str(step), {}).get(\"agent\")\n",
    "        return Command(\n",
    "            update={\n",
    "                \"replan_flag\": False,\n",
    "                \"current_step\": step\n",
    "                + 1,  # advance because we executed the planned agent\n",
    "            },\n",
    "            goto=planned_agent,\n",
    "        )\n",
    "\n",
    "    # 1) Build prompt & call LLM\n",
    "    llm_reply = reasoning_llm.invoke([executor_prompt(state)])\n",
    "    try:\n",
    "        content_str = (\n",
    "            llm_reply.content\n",
    "            if isinstance(llm_reply.content, str)\n",
    "            else str(llm_reply.content)\n",
    "        )\n",
    "        parsed = json.loads(content_str)\n",
    "        replan: bool = parsed[\"replan\"]\n",
    "        goto: str = parsed[\"goto\"]\n",
    "        reason: str = parsed[\"reason\"]\n",
    "        query: str = parsed[\"query\"]\n",
    "    except Exception as exc:\n",
    "        raise ValueError(\n",
    "            f\"Invalid executor JSON:\\n{llm_reply.content}\"\n",
    "        ) from exc\n",
    "\n",
    "    # Upodate the state\n",
    "    updates: Dict[str, Any] = {\n",
    "        \"messages\": [HumanMessage(content=llm_reply.content, name=\"executor\")],\n",
    "        \"last_reason\": reason,\n",
    "        \"agent_query\": query,\n",
    "    }\n",
    "\n",
    "    # Replan accounting\n",
    "    replans: Dict[int, int] = state.get(\"replan_attempts\", {}) or {}\n",
    "    step_replans = replans.get(step, 0)\n",
    "\n",
    "    # 2) Replan decision\n",
    "    if replan:\n",
    "        if step_replans < MAX_REPLANS:\n",
    "            replans[step] = step_replans + 1\n",
    "            updates.update({\n",
    "                \"replan_attempts\": replans,\n",
    "                \"replan_flag\": True,  # ensure next turn executes the planned agent once\n",
    "                \"current_step\": step,  # stay on same step for the new plan\n",
    "            })\n",
    "            return Command(update=updates, goto=\"planner\")\n",
    "        else:\n",
    "            # Cap hit: skip this step; let next step (or synthesizer) handle termination\n",
    "            next_agent = plan.get(str(step + 1), {}).get(\"agent\", \"synthesizer\")\n",
    "            updates[\"current_step\"] = step + 1\n",
    "            return Command(update=updates, goto=next_agent)\n",
    "\n",
    "    # 3) Happy path: run chosen agent; advance only if following the plan\n",
    "    planned_agent = plan.get(str(step), {}).get(\"agent\")\n",
    "    updates[\"current_step\"] = step + 1 if goto == planned_agent else step\n",
    "    updates[\"replan_flag\"] = False\n",
    "    return Command(update=updates, goto=goto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b75e40",
   "metadata": {},
   "source": [
    "## 4. Create Web Search Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "tavily_tool = TavilySearch(max_results=5)\n",
    "\n",
    "tavily_tool.invoke(\"What is JP Morgan's stock price?\")[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_system_prompt(suffix: str) -> str:\n",
    "    return (\n",
    "        \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "        \" Use the provided tools to progress towards answering the question.\"\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "        \" will help where you left off. Execute what you can to make progress.\"\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "        f\"\\n{suffix}\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Research agent and node\n",
    "web_search_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[tavily_tool],\n",
    "    prompt=agent_system_prompt(\"\"\"\n",
    "        You are the Researcher. You can ONLY perform research by using the provided search tool (tavily_tool). \n",
    "        When you have found the necessary information, end your output.  \n",
    "        Do NOT attempt to take further actions.\n",
    "    \"\"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9694060",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_response = web_search_agent.invoke({\n",
    "    \"messages\": \"what is jp morgan's current market cap?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.otel.instrument import instrument\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "\n",
    "\n",
    "@instrument(\n",
    "    span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "    attributes=lambda ret, exception, *args, **kwargs: {\n",
    "        SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0].get(\"agent_query\")\n",
    "        if args[0].get(\"agent_query\")\n",
    "        else None,\n",
    "        SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "            ret.update[\"messages\"][-1].content\n",
    "        ]\n",
    "        if hasattr(ret, \"update\")\n",
    "        else \"No tool call\",\n",
    "    },\n",
    ")\n",
    "def web_research_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"executor\"]]:\n",
    "    agent_query = state.get(\"agent_query\")\n",
    "    result = web_search_agent.invoke({\"messages\": agent_query})\n",
    "    goto = \"executor\"\n",
    "    # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"web_researcher\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of research agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2627ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a283e-ea04-40c1-b792-f9e5f7d81203",
   "metadata": {},
   "source": [
    "## 5. Create Charting Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d34f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = (\n",
    "        f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    )\n",
    "    return (\n",
    "        result_str\n",
    "        + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Chart generator agent and node\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "chart_agent = create_react_agent(\n",
    "    llm,\n",
    "    [python_repl_tool],\n",
    "    prompt=agent_system_prompt(\n",
    "        \"\"\"\n",
    "        You can only generate charts. You are working with a researcher colleague.\n",
    "        1) Print the chart first.\n",
    "        2) Save the chart to a file in the current working directory.\n",
    "        3) At the very end of your message, output EXACTLY two lines so the summarizer can find them:\n",
    "           CHART_PATH: <relative_path_to_chart_file>\n",
    "           CHART_NOTES: <one concise sentence summarizing the main insight in the chart>\n",
    "        Do not include any other trailing text after these two lines.\n",
    "        \"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def chart_node(state: State) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "    result = chart_agent.invoke(state)\n",
    "    # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "    )\n",
    "    goto = \"chart_summarizer\"\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of chart agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41edd3c5",
   "metadata": {},
   "source": [
    "## 6. Create Chart Summary Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_summary_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[],  # Add image processing tools if available/needed.\n",
    "    prompt=agent_system_prompt(\n",
    "        \"You can only generate image captions. You are working with a researcher colleague and a chart generator colleague. \"\n",
    "        + \"Your task is to generate a standalone, concise summary for the provided chart image saved at a local PATH, where the PATH should be and only be provided by your chart generator colleague. The summary should be no more than 3 sentences and should not mention the chart itself.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def chart_summary_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[END]]:\n",
    "    result = chart_summary_agent.invoke(state)\n",
    "    print(f\"Chart summarizer answer: {result['messages'][-1].content}\")\n",
    "    # Send to the end node\n",
    "    goto = END\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of chart agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "            \"final_answer\": result[\"messages\"][-1].content,\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dee1d3",
   "metadata": {},
   "source": [
    "## 7. Create a Synthesizer (Text Summarizer) Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd6e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "def synthesizer_node(state: State) -> Command[Literal[END]]:\n",
    "    \"\"\"\n",
    "    Creates a concise, human‑readable summary of the entire interaction,\n",
    "    **purely in prose**.\n",
    "\n",
    "    It ignores structured tables or chart IDs and instead rewrites the\n",
    "    relevant agent messages (research results, chart commentary, etc.)\n",
    "    into a short final answer.\n",
    "    \"\"\"\n",
    "    # Gather informative messages for final synthesis\n",
    "    relevant_msgs = [\n",
    "        m.content\n",
    "        for m in state.get(\"messages\", [])\n",
    "        if getattr(m, \"name\", None)\n",
    "        in (\"web_researcher\", \"chart_generator\", \"chart_summarizer\")\n",
    "    ]\n",
    "\n",
    "    user_question = state.get(\n",
    "        \"user_query\",\n",
    "        state.get(\"messages\", [{}])[0].content if state.get(\"messages\") else \"\",\n",
    "    )\n",
    "\n",
    "    synthesis_instructions = (\n",
    "        \"You are the Synthesizer. Use the context below to directly answer the user's question. \"\n",
    "        \"Perform any lightweight calculations, comparisons, or inferences required. \"\n",
    "        \"Do not invent facts not supported by the context. If data is missing, say what's missing and, if helpful, \"\n",
    "        \"offer a clearly labeled best-effort estimate with assumptions.\\n\\n\"\n",
    "        \"Produce a concise response that fully answers the question, with the following guidance:\\n\"\n",
    "        \"- Start with the direct answer (one short paragraph or a tight bullet list).\\n\"\n",
    "        \"- Include key figures from any 'Results:' tables (e.g., totals, top items).\\n\"\n",
    "        \"- If any message contains citations, include them as a brief 'Citations: [...]' line.\\n\"\n",
    "        \"- Keep the output crisp; avoid meta commentary or tool instructions.\"\n",
    "    )\n",
    "\n",
    "    summary_prompt = [\n",
    "        HumanMessage(\n",
    "            content=(\n",
    "                f\"User question: {user_question}\\n\\n\"\n",
    "                f\"{synthesis_instructions}\\n\\n\"\n",
    "                f\"Context:\\n\\n\" + \"\\n\\n---\\n\\n\".join(relevant_msgs)\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    llm_reply = llm.invoke(summary_prompt)\n",
    "\n",
    "    answer = llm_reply.content.strip()\n",
    "    print(f\"Sythesizer answer: {answer}\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"final_answer\": answer,\n",
    "            \"messages\": [HumanMessage(content=answer, name=\"synthesizer\")],\n",
    "        },\n",
    "        goto=END,  # hand off to the END node\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810f00e",
   "metadata": {},
   "source": [
    "## 8. Build the Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb15bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"executor\", executor_node)\n",
    "workflow.add_node(\"web_researcher\", web_research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "workflow.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b816c0",
   "metadata": {},
   "source": [
    "## 9. Trace the agent and log in TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.database.connector.default import DefaultDBConnector\n",
    "from trulens.core.session import TruSession\n",
    "\n",
    "# Initialize connector with SQLite database with custom name\n",
    "connector = DefaultDBConnector(database_url=\"sqlite:///data_agent.sqlite\")\n",
    "\n",
    "# Create TruSession with the custom connector\n",
    "session = TruSession(connector=connector)\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb66c06",
   "metadata": {},
   "source": [
    "### Register the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.langgraph import TruGraph\n",
    "\n",
    "tru_recorder = TruGraph(\n",
    "    graph,\n",
    "    app_name=\"Web Search Data Agent\",\n",
    "    app_version=\"Base - for Human Annotations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0673ff",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fedb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "query = \"Chart the current market capitalization of the top 5 banks in the US?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "    \"user_query\": query,\n",
    "    \"enabled_agents\": [\n",
    "        \"web_researcher\",\n",
    "        \"chart_generator\",\n",
    "        \"chart_summarizer\",\n",
    "        \"synthesizer\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "record1 = recording.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32efa0fe",
   "metadata": {},
   "source": [
    "### Start the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41747325",
   "metadata": {},
   "source": [
    "### Human Annotation\n",
    "\n",
    "Using `add_feedback_result`, you can add your human annotations to TruLens associated with each trace.\n",
    "\n",
    "To identify a failure mode, update the `feedback_name` to the failure mode you identify, while leaving the `feedback_result` value as 0 - the lowest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d314085",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_feedback_result(\n",
    "    record=record1,\n",
    "    feedback_name=\"Annotated Logical Consistency\",  # ADD YOUR OWN IDENTIFIED FAILURE MODE, ALIGNED TO GPA EVAL METRICS\n",
    "    feedback_result=0,\n",
    "    higher_is_better=True,\n",
    ")\n",
    "\n",
    "session.force_flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef18f8",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Identify current regulatory changes for the financial services industry in the US.\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "    \"user_query\": query,\n",
    "    \"enabled_agents\": [\n",
    "        \"web_researcher\",\n",
    "        \"chart_generator\",\n",
    "        \"chart_summarizer\",\n",
    "        \"synthesizer\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "record2 = recording.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38588ba",
   "metadata": {},
   "source": [
    "### Human Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_feedback_result(\n",
    "    record=record2,\n",
    "    feedback_name=\"Annotated Logical Consistency\",  # ADD YOUR OWN IDENTIFIED FAILURE MODE, ALIGNED TO GPA EVAL METRICS\n",
    "    feedback_result=0,\n",
    "    higher_is_better=True,\n",
    ")\n",
    "\n",
    "session.force_flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1b5d8",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f64262",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the harmonic mean of the price-to-earnings ratio of the top 5 banks in the US?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "    \"user_query\": query,\n",
    "    \"enabled_agents\": [\n",
    "        \"web_researcher\",\n",
    "        \"chart_generator\",\n",
    "        \"chart_summarizer\",\n",
    "        \"synthesizer\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "record3 = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_feedback_result(\n",
    "    record=record3,\n",
    "    feedback_name=\"Annotated Logical Consistency\",  # ADD YOUR OWN IDENTIFIED FAILURE MODE, ALIGNED TO GPA EVAL METRICS\n",
    "    feedback_result=0,\n",
    "    higher_is_better=True,\n",
    ")\n",
    "\n",
    "session.force_flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab05829",
   "metadata": {},
   "source": [
    "### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Provide a list of all revolvers that include JP Morgan as lender?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "    \"user_query\": query,\n",
    "    \"enabled_agents\": [\n",
    "        \"web_researcher\",\n",
    "        \"chart_generator\",\n",
    "        \"chart_summarizer\",\n",
    "        \"synthesizer\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "record4 = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a890f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_feedback_result(\n",
    "    record=record4,\n",
    "    feedback_name=\"Annotated Logical Consistency\",  # ADD YOUR OWN IDENTIFIED FAILURE MODE, ALIGNED TO GPA EVAL METRICS\n",
    "    feedback_result=0,\n",
    "    higher_is_better=True,\n",
    ")\n",
    "\n",
    "session.force_flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef36c4e",
   "metadata": {},
   "source": [
    "## 10. Add LLM Judge evaluations\n",
    "\n",
    "Here we add RAG triad evaluations to assess goal completion for data tasks (such as web search). We also add trace-level metrics that aim to surface specific issues at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "# Use GPT-4o for RAG Triad Evaluations\n",
    "provider = OpenAI(model_engine=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aeda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core.feedback.selector import Selector\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on({\n",
    "        \"source\": Selector(\n",
    "            span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "            span_attribute=SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS,\n",
    "            collect_list=True,\n",
    "        )\n",
    "    })\n",
    "    .on_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e025d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0be935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on({\n",
    "        \"question\": Selector(\n",
    "            span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "            span_attribute=SpanAttributes.RETRIEVAL.QUERY_TEXT,\n",
    "        )\n",
    "    })\n",
    "    .on({\n",
    "        \"context\": Selector(\n",
    "            span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "            span_attribute=SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS,\n",
    "            collect_list=False,\n",
    "        )\n",
    "    })\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75397247",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_eval_provider = OpenAI(model_engine=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2953c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_plan_quality = Feedback(\n",
    "    trace_eval_provider.plan_quality_with_cot_reasons,\n",
    "    name=\"Plan Quality\",\n",
    ").on({\n",
    "    \"trace\": Selector(trace_level=True),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_plan_adherence = Feedback(\n",
    "    trace_eval_provider.plan_adherence_with_cot_reasons,\n",
    "    name=\"Plan Adherence\",\n",
    ").on({\n",
    "    \"trace\": Selector(trace_level=True),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ece0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_execution_efficiency = Feedback(\n",
    "    trace_eval_provider.execution_efficiency_with_cot_reasons,\n",
    "    name=\"Execution Efficiency\",\n",
    ").on({\n",
    "    \"trace\": Selector(trace_level=True),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb75f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_logical_consistency = Feedback(\n",
    "    trace_eval_provider.logical_consistency_with_cot_reasons,\n",
    "    name=\"Logical Consistency\",\n",
    ").on({\n",
    "    \"trace\": Selector(trace_level=True),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c64c2",
   "metadata": {},
   "source": [
    "## 11. Register the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.langgraph import TruGraph\n",
    "\n",
    "tru_recorder = TruGraph(\n",
    "    graph,\n",
    "    app_name=\"Web Search Data Agent\",\n",
    "    app_version=\"Base - with LLM Judge Annotations\",\n",
    "    feedbacks=[\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "        f_groundedness,\n",
    "        f_plan_quality,\n",
    "        f_plan_adherence,\n",
    "        f_execution_efficiency,\n",
    "        f_logical_consistency,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3b1fe",
   "metadata": {},
   "source": [
    "## 12. Use the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "queries = [\n",
    "    \"Chart the current market capitalization of the top 5 banks in the US?\",\n",
    "    \"Identify current regulatory changes for the financial services industry in the US\",\n",
    "    \"What is the harmonic mean of the price to earnings ratio of the top 5 banks in the US\",\n",
    "    \"Provide a list of all revolvers that include JP Morgan as a lender\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Query: {query}\")\n",
    "\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"user_query\": query,\n",
    "        \"enabled_agents\": [\n",
    "            \"web_researcher\",\n",
    "            \"chart_generator\",\n",
    "            \"chart_summarizer\",\n",
    "            \"synthesizer\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with tru_recorder as recording:\n",
    "        graph.invoke(state)\n",
    "\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf20180",
   "metadata": {},
   "source": [
    "## 13. See evaluation results\n",
    "\n",
    "You may need to run this step multiple times to see full results, as the LLM judge evaluations take time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13adb70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda81a5e",
   "metadata": {},
   "source": [
    "## 14. Make improvements to your agent\n",
    "\n",
    "In the below cell, select a node or nodes that you wish to modify and copy the code. Then, make the change to the node(s) that you hypothesize will best address the failure mode(s) you identified earlier in the notebook either through your human annotations or via the LLM judges.\n",
    "\n",
    "Once you've adjusted and recreated the node, you will then:\n",
    "1. Recreate the agent graph\n",
    "2. Register a new version of your agent with TruLens\n",
    "3. Re-run and evaluate the improved agent to validate your change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COPY AND IMPROVE SELECTED NODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ce601",
   "metadata": {},
   "source": [
    "### Recreate the agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcefa024",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"executor\", executor_node)\n",
    "workflow.add_node(\"web_researcher\", web_research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "workflow.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b508d",
   "metadata": {},
   "source": [
    "### Register a new version of your agent with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fcbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruGraph(\n",
    "    graph,\n",
    "    app_name=\"Web Search Data Agent\",\n",
    "    app_version=\"Improved Agent - <insert short improvement description here>\",\n",
    "    feedbacks=[\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "        f_groundedness,\n",
    "        f_plan_quality,\n",
    "        f_plan_adherence,\n",
    "        f_execution_efficiency,\n",
    "        f_logical_consistency,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7530e3",
   "metadata": {},
   "source": [
    "### Re-run and evaluate the improved agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e87d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    print(f\"Query: {query}\")\n",
    "\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"user_query\": query,\n",
    "        \"enabled_agents\": [\n",
    "            \"web_researcher\",\n",
    "            \"chart_generator\",\n",
    "            \"chart_summarizer\",\n",
    "            \"synthesizer\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with tru_recorder as recording:\n",
    "        graph.invoke(state)\n",
    "\n",
    "    print(\"--------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
