{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverside Evaluation and Batch Trace Ingestion with Snowflake\n",
    "\n",
    "This notebook walks through the complete TruLens + Snowflake experience.\n",
    "\n",
    "This setup offers two advantages compared to other ways of use:\n",
    "- Batch ingestion of records (traces) to Snowflake offers a faster ingestion experience\n",
    "- Compuation of Evaluations on the Snowflake warehouse (serverside) removes the computation from the client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Connect to Snowflake for Logging Traces and Evaluations\n",
    "\n",
    "Notice we're setting the `init_server_side` parameter to `True`. This will trigger uploading the tasks, streams and stored procedures to your Snowflake account needed to compute evaluations in the warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.core.schema.app import RecordIngestMode\n",
    "from trulens.core.session import TruSession\n",
    "\n",
    "connection_params = {\n",
    "    \"account\": \"...\",\n",
    "    \"user\": \"...\",\n",
    "    \"password\": \"...\",\n",
    "    \"database\": \"...\",\n",
    "    \"schema\": \"...\",\n",
    "    \"warehouse\": \"...\",\n",
    "    \"role\": \"...\",\n",
    "    \"init_server_side\": True,  # Set to True to enable server side feedback functions\n",
    "}\n",
    "\n",
    "connector = SnowflakeConnector(**connection_params)\n",
    "session = TruSession(connector=connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Cortex Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from snowflake.core import Root\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "snowpark_session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "\n",
    "class CortexSearchRetriever:\n",
    "    def __init__(self, session: Session, limit_to_retrieve: int = 4):\n",
    "        self._session = session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        root = Root(self._session)\n",
    "        cortex_search_service = (\n",
    "            root.databases[\"JREINI_DB\"]\n",
    "            .schemas[\"TRULENS_DEMO_SCHEMA\"]\n",
    "            .cortex_search_services[\"TRULENS_DEMO_CORTEX_SEARCH_SERVICE\"]\n",
    "        )\n",
    "        resp = cortex_search_service.search(\n",
    "            query=query,\n",
    "            columns=[\"doc_text\"],\n",
    "            limit=self._limit_to_retrieve,\n",
    "        )\n",
    "\n",
    "        if resp.results:\n",
    "            return [curr[\"doc_text\"] for curr in resp.results]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Instrument an existing app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.cortex import Complete\n",
    "from trulens.apps.custom import instrument\n",
    "\n",
    "\n",
    "class RAG_from_scratch:\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(\n",
    "            session=snowpark_session, limit_to_retrieve=4\n",
    "        )\n",
    "\n",
    "    @instrument\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        return self.retriever.retrieve(query)\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "          You are an expert assistant extracting information from context provided.\n",
    "          Answer the question based on the context. Be concise and do not hallucinate.\n",
    "          If you donÂ´t have the information just say so.\n",
    "          Context: {context_str}\n",
    "          Question:\n",
    "          {query}\n",
    "          Answer:\n",
    "        \"\"\"\n",
    "        return Complete(\"mistral-large\", prompt)\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query)\n",
    "        return self.generate_completion(query, context_str)\n",
    "\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define evaluations to run on Snowflake\n",
    "\n",
    "By simply using the `SnowflakeFeedback` class isntead of `Feedback`, we specify that these feedback functions will run in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Select\n",
    "from trulens.core.feedback.feedback import SnowflakeFeedback\n",
    "from trulens.providers.cortex import Cortex\n",
    "\n",
    "provider = Cortex(\n",
    "    connection_params,\n",
    "    model_engine=\"mistral-large2\",\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    SnowflakeFeedback(\n",
    "        provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    SnowflakeFeedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve_context.rets)\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_groundedness = (\n",
    "    SnowflakeFeedback(\n",
    "        provider.groundedness_measure_with_cot_reasons,\n",
    "        name=\"Groundedness\",\n",
    "        use_sent_tokenize=False,\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve_context.rets.collect())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Register the app with TruLens\n",
    "\n",
    "Here we add the new record ingest mode parameter set to buffered. This means that the records (traces) will be sent to Snowflake in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "tru_rag = TruCustomApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"base\",\n",
    "    feedbacks=[\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "        f_groundedness,\n",
    "    ],\n",
    "    record_ingest_mode=RecordIngestMode.BUFFERED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"How do I deploy streamlit in the cloud?\",\n",
    "    \"What is the best way to deploy a streamlit app?\",\n",
    "    \"How do I use streamlit buttons?\",\n",
    "    \"How do I change the color of the background of a streamlit app?\",\n",
    "    \"How do I add a logo to a streamlit app?\",\n",
    "    \"How do I deploy streamlit in the cloud?\",\n",
    "    \"What is the best way to deploy a streamlit app?\",\n",
    "    \"How do I use streamlit buttons?\",\n",
    "    \"How do I change the color of the background of a streamlit app?\",\n",
    "    \"How do I add a logo to a streamlit app?\",\n",
    "    \"How do I deploy streamlit in the cloud?\",\n",
    "    \"What is the best way to deploy a streamlit app?\",\n",
    "    \"How do I use streamlit buttons?\",\n",
    "    \"How do I change the color of the background of a streamlit app?\",\n",
    "    \"How do I add a logo to a streamlit app?\",\n",
    "    \"How do I deploy streamlit in the cloud?\",\n",
    "    \"What is the best way to deploy a streamlit app?\",\n",
    "    \"How do I use streamlit buttons?\",\n",
    "    \"How do I change the color of the background of a streamlit app?\",\n",
    "    \"How do I add a logo to a streamlit app?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Record application traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    with tru_rag as recording:\n",
    "        resp = rag.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Improve the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.feedback.feedback import Feedback\n",
    "from trulens.core.guardrails.base import context_filter\n",
    "\n",
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = Feedback(\n",
    "    provider.context_relevance, name=\"Context Relevance\"\n",
    ")\n",
    "\n",
    "\n",
    "class filtered_RAG_from_scratch(RAG_from_scratch):\n",
    "    @instrument\n",
    "    @context_filter(f_context_relevance_score, 0.75, keyword_for_prompt=\"query\")\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        return self.retriever.retrieve(query)\n",
    "\n",
    "\n",
    "filtered_rag = filtered_RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "tru_filtered_rag = TruCustomApp(\n",
    "    filtered_rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"filtered context\",\n",
    "    feedbacks=[\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "    ],\n",
    "    record_ingest_mode=RecordIngestMode.BUFFERED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    with tru_filtered_rag as recording:\n",
    "        resp = filtered_rag.query(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
